<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Semantic Role Labeling for Learner Chinese: the Importance of Syntactic Parsing and L2-L1 Parallel Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zi</forename><surname>Lin</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuguang</forename><surname>Duan</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Chinese Language and Literature</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanyuan</forename><surname>Zhao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">The MOE Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Center for Chinese Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="laboratory">Academy for Advanced Interdisciplinary Studies</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Semantic Role Labeling for Learner Chinese: the Importance of Syntactic Parsing and L2-L1 Parallel Data</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="3793" to="3802"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>3793</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper studies semantic parsing for in-terlanguage (L2 1), taking semantic role labeling (SRL) as a case task and learner Chi-nese as a case language. We first manually annotate the semantic roles for a set of learner texts to derive a gold standard for automatic SRL. Based on the new data, we then evaluate three off-the-shelf SRL systems, i.e., the PCFGLA-parser-based, neural-parser-based and neural-syntax-agnostic systems, to gauge how successful SRL for learner Chi-nese can be. We find two non-obvious facts: 1) the L1-sentence-trained systems performs rather badly on the L2 data; 2) the performance drop from the L1 data to the L2 data of the two parser-based systems is much smaller, indicating the importance of syntactic parsing in SRL for interlanguages. Finally, the paper introduces a new agreement-based model to explore the semantic coherency information in the large-scale L2-L1 parallel data. We then show such information is very effective to enhance SRL for learner texts. Our model achieves an F-score of 72.06, which is a 2.02 point improvement over the best baseline.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A learner language (interlanguage) is an idiolect developed by a learner of a second or foreign language which may preserve some features of his/her first language. Previously, encouraging re- sults of automatically building the syntactic anal- ysis of learner languages were reported <ref type="bibr" target="#b10">(Nagata and Sakaguchi, 2016</ref>), but it is still unknown how semantic processing performs, while parsing a learner language (L2) into semantic representa- tions is the foundation of a variety of deeper anal- ysis of learner languages, e.g., automatic essay scoring. In this paper, we study semantic pars- ing for interlanguage, taking semantic role label- ing (SRL) as a case task and learner Chinese as a case language.</p><p>Before discussing a computation system, we first consider the linguistic competence and per- formance. Can human robustly understand learner texts? Or to be more precise, to what extent, a na- tive speaker can understand the meaning of a sen- tence written by a language learner? Intuitively, the answer is towards the positive side. To validate this, we ask two senior students majoring in Ap- plied Linguistics to carefully annotate some L2-L1 parallel sentences with predicate-argument struc- tures according to the specification of Chinese PropBank (CPB; <ref type="bibr" target="#b20">Xue and Palmer, 2009)</ref>, which is developed for L1. A high inter-annotator agree- ment is achieved, suggesting the robustness of lan- guage comprehension for L2. During the course of semantic annotation, we find a non-obvious fact that we can re-use the semantic annotation spec- ification, Chinese PropBank in our case, which is developed for L1. Only modest rules are needed to handle some tricky phenomena. This is quite dif- ferent from syntactic treebanking for learner sen- tences, where defining a rich set of new annotation heuristics seems necessary <ref type="bibr" target="#b13">(Ragheb and Dickinson, 2012;</ref><ref type="bibr" target="#b10">Nagata and Sakaguchi, 2016;</ref><ref type="bibr" target="#b0">Berzak et al., 2016)</ref>.</p><p>Our second concern is to mimic the human's ro- bust semantic processing ability by computer pro- grams. The feasibility of reusing the annotation specification for L1 implies that we can reuse stan- dard CPB data to train an SRL system to pro- cess learner texts. To test the robustness of the state-of-the-art SRL algorithms, we evaluate two types of SRL frameworks. The first one is a tradi- tional SRL system that leverages a syntactic parser and heavy feature engineering to obtain explicit information of semantic roles <ref type="bibr" target="#b2">(Feng et al., 2012</ref>). Furthermore, we employ two different parsers for comparison: 1) the PCFGLA-based parser, viz. Berkeley parser ( <ref type="bibr" target="#b11">Petrov et al., 2006</ref>), and 2) a min- imal span-based neural parser ( <ref type="bibr" target="#b15">Stern et al., 2017)</ref>. The other SRL system uses a stacked BiLSTM to implicitly capture local and non-local information <ref type="bibr" target="#b4">(He et al., 2017)</ref>. and we call it the neural syntax- agnostic system. All systems can achieve state-of- the-art performance on L1 texts but show a signif- icant degradation on L2 texts. This highlights the weakness of applying an L1-sentence-trained sys- tem to process learner texts.</p><p>While the neural syntax-agnostic system ob- tains superior performance on the L1 data, the two syntax-based systems both produce better analy- ses on the L2 data. Furthermore, as illustrated in the comparison between different parsers, the bet- ter the parsing results we get, the better the perfor- mance on L2 we achieve. This shows that syntac- tic parsing is important in semantic construction for learner Chinese. The main reason, according to our analysis, is that the syntax-based system may generate correct syntactic analyses for par- tial grammatical fragments in L2 texts, which pro- vides crucial information for SRL. Therefore, syn- tactic parsing helps build more generalizable SRL models that transfer better to new languages, and enhancing syntactic parsing can improve SRL to some extent.</p><p>Our last concern is to explore the potential of a large-scale set of L2-L1 parallel sentences to en- hance SRL systems. We find that semantic struc- tures of the L2-L1 parallel sentences are highly consistent. This inspires us to design a novel agreement-based model to explore such seman- tic coherency information. In particular, we de- fine a metric for comparing predicate-argument structures and searching for relatively good auto- matic syntactic and semantic annotations to ex- tend the training data for SRL systems. Experi- ments demonstrate the value of the L2-L1 paral- lel sentences as well as the effectiveness of our method. We achieve an F-score of 72.06, which is a 2.02 percentage point improvement over the best neural-parser-based baseline.</p><p>To the best of our knowledge, this is the first time that the L2-L1 parallel data is utilized to en- hance NLP systems for learner texts.</p><p>For research purpose, we have released our SRL annotations on 600 sentence pairs and the L2-L1 parallel dataset 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Semantic Analysis of An L2-L1</head><p>Parallel Corpus</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">An L2-L1 Parallel Corpus</head><p>An L2-L1 parallel corpus can greatly facilitate the analysis of a learner language (   <ref type="formula">(3)</ref> dropping overly simple sentences which may not be informative, and (4) utilizing a rule-based clas- sifier to determine whether to include the sentence into the corpus.</p><p>The final corpus consists of 717,241 learner sentences from writers of 61 different native lan- guages, in which English and Japanese constitute the majority. As for completeness, 82.78% of the Chinese Second Language sentences on Lang-8 are corrected by native human annotators. One sentence gets corrected approximately 1.53 times on average.</p><p>In this paper, we manually annotate the predicate-argument structures for the 600 L2-L1 pairs as the basis for the semantic analysis of learner Chinese. It is from the above corpus that we carefully select 600 pairs of L2-L1 parallel sentences. We would choose the most appropri- ate one among multiple versions of corrections and recorrect the L1s if necessary. Because word structure is very fundamental for various NLP tasks, our annotation also contains gold word seg- mentation for both L2 and L1 sentences. Note that there are no natural word boundaries in Chinese <ref type="bibr">2</ref> The data is collected from <ref type="bibr">Lang-8 (www.lang-8. com)</ref> and used as the training data in NLPCC 2018 Shared Task: Grammatical Error Correction ( <ref type="bibr" target="#b22">Zhao et al., 2018)</ref>, which can be downloaded at https://github.com/ pkucoli/srl4il text. We first employ a state-of-the-art word seg- mentation system to produce initial segmentation results and then manually fix segmentation errors. The dataset includes four typologically differ- ent mother tongues, i.e., English (ENG), Japanese (JPN), Russian (RUS) and Arabic (ARA). Sub- corpus of each language consists of 150 sentence pairs. We take the mother languages of the learn- ers into consideration, which have a great im- pact on grammatical errors and hence automatic semantic analysis. We hope that four selected mother tongues guarantee a good coverage of ty- pologies. The annotated corpus can be used both for linguistic investigation and as test data for NLP systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The Annotation Process</head><p>Semantic role labeling (SRL) is the process of as- signing semantic roles to constituents or their head words in a sentence according to their relation- ship to the predicates expressed in the sentence. Typical semantic roles can be divided into core arguments and adjuncts. The core arguments in- clude Agent, Patient, Source, Goal, etc, while the adjuncts include Location, Time, Manner, Cause, etc.</p><p>To create a standard semantic-role-labeled cor- pus for learner Chinese, we first annotate a 50- sentence trial set for each native language. Two senior students majoring in Applied Linguistics conducted the annotation. Based on a total of 400 sentences, we adjudicate an initial gold standard, adapting and refining CPB specification as our an- notation heuristics. Then the two annotators pro- ceed to annotate a 100-sentence set for each lan- guage independently. It is on these larger sets that we report the inter-annotator agreement.</p><p>In the final stage, we also produce an adju- dicated gold standard for all 600 annotated sen- tences. This was achieved by comparing the anno- tations selected by each annotator, discussing the differences, and either selecting one as fully cor- rect or creating a hybrid representing the consen- sus decision for each choice point. When we felt that the decisions were not already fully guided by the existing annotation guidelines, we worked to articulate an extension to the guidelines that would support the decision.</p><p>During the annotation, the annotators apply both position labels and semantic role labels. Po- sition labels include S, B, I and E, which are used to mark whether the word is an argument by itself, or at the beginning or in the middle or at the end of a argument. As for role labels, we mainly apply representations defined by CPB ( <ref type="bibr" target="#b20">Xue and Palmer, 2009)</ref>. The predicate in a sentence was labeled as rel, the core semantic roles were labeled as AN and the adjuncts were labeled as AM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Inter-annotator Agreement</head><p>For inter-annotator agreement, we evaluate the precision (P), recall (R), and F1-score (F) of the semantic labels given by the two annotators. Ta- ble 1 shows that our inter-annotator agreement is promising. All L1 texts have F-score above 95, and we take this as a reflection that our annota- tors are qualified. F-scores on L2 sentences are all above 90, just a little bit lower than those of L1, indicating that L2 sentences can be greatly under- stood by native speakers. Only modest rules are needed to handle some tricky phenomena:</p><p>1. The labeled argument should be strictly lim- ited to the core roles defined in the frameset of CPB, though the number of arguments in L2 sentences may be more or less than the number defined.</p><p>2. For the roles in L2 that cannot be labeled as arguments under the specification of CPB, if they provide semantic information such as time, location and reason, we would labeled them as adjuncts though they may not be well-formed adjuncts due to the absence of function words.</p><p>3. For unnecessary roles in L2 caused by mis- takes of verb subcategorization (see examples in <ref type="figure" target="#fig_3">Figure 3b</ref>), we would leave those roles un- labeled. <ref type="table" target="#tab_3">Table 2</ref> further reports agreements on each argu- ment (AN) and adjunct (AM) in detail, according to which the high scores are attributed to the high agreement on arguments (AN). The labels of A3 and A4 have no disagreement since they are sparse in CPB and are usually used to label specific se- mantic roles that have little ambiguity.</p><p>We also conducted in-depth analysis on inter- annotator disagreement. For further details, please refer to <ref type="bibr" target="#b1">Duan et al. (2018</ref>  3 Evaluating Robustness of SRL</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Three SRL Systems</head><p>The work on SRL has included a broad spec- trum of machine learning and deep learning ap- proaches to the task. Early work showed that syntactic information is crucial for learning long- range dependencies, syntactic constituency struc- ture and global constraints <ref type="bibr" target="#b12">(Punyakanok et al., 2008;</ref><ref type="bibr" target="#b16">Täckström et al., 2015)</ref>, while initial stud- ies on neural methods achieved state-of-the-art re- sults with little to no syntactic input ( <ref type="bibr" target="#b23">Zhou and Xu, 2015;</ref><ref type="bibr" target="#b18">Wang et al., 2015;</ref><ref type="bibr" target="#b7">Marcheggiani et al., 2017;</ref><ref type="bibr" target="#b4">He et al., 2017)</ref>. However, the question whether fully labeled syntactic structures provide an improvement for neural SRL is still unsettled pending further investigation.</p><p>To evaluate the robustness of state-of-the-art SRL algorithms, we evaluate two representative SRL frameworks. One is a traditional syntax- based SRL system that leverages a syntactic parser and manually crafted features to obtain explicit in- formation to find semantic roles (Gildea and Ju- rafsky, <ref type="bibr">2000</ref>; Xue, 2008) In particular, we employ the system introduced in <ref type="bibr" target="#b2">Feng et al. (2012)</ref>. This system first collects all c-commanders of a pred- icate in question from the output of a parser and puts them in order. It then employs a first or- der linear-chain global linear model to perform semantic tagging. For constituent parsing, we use two parsers for comparison, one is Berkeley parser <ref type="bibr">3 (Petrov et al., 2006</ref>), a well-known im- plementation of the unlexicalized latent variable PCFG model, the other is a minimal span-based neural parser based on independent scoring of la- bels and spans <ref type="bibr" target="#b15">(Stern et al., 2017)</ref>. As proposed in <ref type="bibr" target="#b15">Stern et al. (2017)</ref></p><note type="other">, the second parser is capa- ble of achieving state-of-the-art single-model per- formance on the Penn Treebank. On the Chinese TreeBank (CTB; Xue et al., 2005), it also out- performs the Berkeley parser for the in-domain test. We call the corresponding SRL systems as the PCFGLA-parser-based and neural-parser- based systems.</note><p>The second SRL framework leverages an end- to-end neural model to implicitly capture local and non-local information ( <ref type="bibr" target="#b23">Zhou and Xu, 2015;</ref><ref type="bibr" target="#b4">He et al., 2017</ref>). In particular, this framework treats SRL as a BIO tagging problem and uses a stacked BiLSTM to find informative embeddings. We ap- ply the system introduced in <ref type="bibr" target="#b4">He et al. (2017)</ref> for experiments. Because all syntactic information (including POS tags) is excluded, we call this sys- tem the neural syntax-agnostic system.</p><p>To train the three SRL systems as well as the supporting parsers, we use the CTB and CPB data 4 . In particular, the sentences selected for the CoNLL 2009 shared task are used here for pa- rameter estimation. Note that, since the Berke- ley parser is based on PCFGLA grammar, it may fail to get the syntactic outputs for some sentences, while the other parser does not have that problem. In this case, we have made sure that both parsers can parse all 1,200 sentences successfully.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Main Results</head><p>The overall performances of the three SRL sys- tems on both L1 and L2 data (150 parallel sen- tences for each mother tongue) are shown in Ta- ble 3. For all systems, significant decreases on different mother languages can be consistently ob- served, highlighting the weakness of applying L1- sentence-trained systems to process learner texts. Comparing the two syntax-based systems with the neural syntax-agnostic system, we find that the overall ∆F, which denotes the F-score drop from L1 to L2, is smaller in the syntax-based framework  <ref type="table">Table 3</ref>: Performances of the syntax-based and neural syntax-agnostic SRL systems on the L1 and L2 data. "ALL" denotes the overall performance.</p><note type="other">PCFGLA-parser-based SRL Neural-parser-based SRL Neural syntax-agnostic SRL Arg</note><formula xml:id="formula_0">.-F Adj.-F F ∆F Arg.-F Adj.-F F ∆F Arg.-F Adj.-F F ∆F ENG L1</formula><p>than in the syntax-agnostic system. On English, Japanese and Russian L2 sentences, the syntax- based system has better performances though it sometimes works worse on the corresponding L1 sentences, indicating the syntax-based systems are more robust when handling learner texts. Furthermore, the neural-parser-based system achieves the best overall performance on the L2 data. Though performing slightly worse than the neural syntax-agnostic one on the L1 data, it has much smaller ∆F, showing that as the syntactic analysis improves, the performances on both the L1 and L2 data grow, while the gap can be main- tained. This demonstrates again the importance of syntax in semantic constructions, especially for learner texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Analysis</head><p>To better understand the overall results, we further look deep into the output by addressing the ques- tions:</p><p>1. What types of error negatively impact both systems over learner texts?</p><p>2. What types of error are more problematic for the neural syntax-agnostic one over the L2 data but can be solved by the syntax-based one to some extent?</p><p>We first carry out a suite of empirical investiga- tions by breaking down error types for more de- tailed evaluation. To compare two systems, we analyze results on ENG-L2 and JPN-L2 given that they reflect significant advantages of the syntax- based systems over the neural syntax-agnostic sys- tem. Note that the syntax-based system here refers to the neural-parser-based one. Finally, a concrete study on the instances in the output is conducted, as to validate conclusions in the previous step. Add a gold argument that does not overlap with any predicated span. <ref type="table">Table 4</ref>: Oracle transformations paired with the rel- ative error reduction after each operation. The op- erations are permitted only if they do not cause any overlapping arguments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Breaking down Error Types</head><p>We employ 6 oracle transformations designed by <ref type="bibr" target="#b4">He et al. (2017)</ref> to fix various prediction errors sequentially (see details in <ref type="table">Table 4</ref>), and observe the relative improvements after each operation, as to obtain fine-grained error types. <ref type="figure">Figure 1</ref> com- pares two systems in terms of different mistakes on ENG-L2 and JPN-L2 respectively. After fix- ing the boundaries of spans, the neural syntax- agnostic system catches up with the other, illus- trating that though both systems handle boundary detection poorly on the L2 sentences, the neural syntax-agnostic one suffers more from this type of errors.</p><p>Excluding boundary errors (after moving, merg- Figure 1: Relative improvements of performance after doing each type of oracle transformation in se- quence over ENG-L2 and JPN-L2</p><p>ing, splitting spans and fixing boundaries), we also compare two systems on L2 in terms of detailed la- bel identification, so as to observe which semantic role is more likely to be incorrectly labeled. <ref type="figure" target="#fig_0">Fig- ure 2</ref> shows the confusion matrices. Comparing (a) with (c) and (b) with (d), we can see that the syntax-based and the neural system often overly label A1 when processing learner texts. Besides, the neural syntax-agnostic system predicts the ad- junct AM more than necessary on L2 sentences by 54.24% compared with the syntax-based one.</p><p>(a) Syntax-based system, L1</p><p>(b) Neural system, L1</p><p>(c) Syntax-based system, L2</p><p>(d) Neural system, L2 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Examples for Validation</head><p>On the basis of typical error types found in the pre- vious stage, specifically, boundary detection and incorrect labels, we further conduct an on-the-spot investigation on the output sentences.</p><p>Boundary Detection Previous work has pro- posed that the drop in performance of SRL systems mainly occurs in identifying argument boundaries <ref type="bibr">(M` arquez et al., 2008)</ref>. According to our results, this problem will be exacerbated when it comes to L2 sentences, while syntactic structure sometimes helps to address this problem. <ref type="figure" target="#fig_3">Figure 3a</ref> is an example of an output sentence. The Chinese word "也" (also) usually serves as an adjunct but is now used for linking the paral- lel structure "用 汉语 也 说话 快" (using Chinese also speaking quickly) in this sentence, which is ill-formed to native speakers and negatively affects the boundary detection of A0 for both systems.</p><p>On the other hand, the neural system incorrectly takes the whole part before "很 难" (very hard) as A0, regardless of the adjunct "对 我 来说" (for me), while this can be figured out by exploiting syntactic analysis, as illustrated in <ref type="figure" target="#fig_3">Figure 3c</ref>. The constituent "对 我 来说" (for me) has been recog- nized as a prepositional phrase (PP) attached to the VP, thus labeled as AM. This shows that by pro- viding information of some well-formed sub-trees associated with correct semantic roles, the syntac- tic system can perform better than the neural one on SRL for learner texts.</p><p>Mistaken Labels A second common source of errors is wrong labels, especially for A1. Based on our quantitative analysis, as reported in <ref type="table">Table 5</ref>,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>用 汉语 也 说话 快 对我来说 很 难 啊。</head><p>Using Chinese also speaking quickly to me very hard.</p><p>Gold A0 rel A0 Syntax-based system</p><p>Neural end-to-end system AM AM</p><formula xml:id="formula_1">A0 AM AM AM rel AM rel</formula><p>(a) SRL output of both systems for a L2 sentence, "用 汉语也说话快对我来说很难" (using Chinese and also speaking quickly is very hard for me).   these phenomena are mainly caused by mistakes of verb subcategorization, where the systems label more arguments than allowed by the predicates. Besides, the deep end-to-end system is also likely to incorrectly attach adjuncts AM to the predicates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>我 常常 练习 做饭 中国 菜。</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Syntax</head><p>Cause of error YES NO Verb subcategorization 62.50% 62.50% Labeling A1 to punctuation 12.50% 6.25% Word order error 6.25% 0.00% Other types of error 18.75% 31.25% <ref type="table">Table 5</ref>: Causes of labeling unnecessary A1 <ref type="figure" target="#fig_3">Figure 3b</ref> is another example. The Chinese verb "做饭" (cook-meal) is intransitive while this sen- tence takes it as a transitive verb, which is very common in L2. Lacking in proper verb subcatego- rization, both two systems fail to recognize those verbs allowing only one argument and label the A1 incorrectly.</p><p>As for AM, the neural system mistakenly adds the adjunct to the predicate, which can be avoided by syntactic information of the sentence shown in <ref type="figure" target="#fig_3">Figure 3d</ref>. The constituent "常常" (often) are ad- juncts attached to VP structure governed by the verb "练习"(practice), which will not be labeled as AM in terms of the verb "做饭"(cook-meal). In other words, the hierarchical structure can help in argument identification and assignment by ex- ploiting local information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Enhancing SRL with L2-L1 Parallel Data</head><p>We explore the valuable information about the se- mantic coherency encoded in the L2-L1 parallel data to improve SRL for learner Chinese. In par- ticular, we introduce an agreement-based model to search for high-quality automatic syntactic and se- mantic role annotations, and then use these anno- tations to retrain the two parser-based SRL sys- tems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The Method</head><p>For the purpose of harvesting the good auto- matic syntactic and semantic analysis, we con- sider the consistency between the automatically produced analysis of a learner sentence and its corresponding well-formed sentence. Determining the measurement metric for comparing predicate- argument structures, however, presents another challenge, because the words of the L2 sentence and its L1 counterpart do not necessarily match.</p><p>To solve the problem, we use an automatic word aligner. BerkeleyAligner <ref type="bibr">5 (Liang et al., 2006</ref>), a state-of-the-art tool for obtaining a word align- ment, is utilized. The metric for comparing SRL results of two sentences is based on recall of w p , w a , r tuples, where w p is a predicate, w a is a word that is in the argument or adjunct of w p and r is the cor- responding role. Based on a word alignment, we define the shared tuple as a mutual tuple between two SRL results of an L2-L1 sentence pair, mean- ing that both the predicate and argument words are aligned respectively, and their role relations are the same. We then have two recall values:</p><p>• L2-recall is (# of shared tuples) / (# of tuples of the result in L2)</p><p>• L1-recall is (# of shared tuples) / (# of tuples of the result in L1)</p><p>In accordance with the above evaluation method, we select the automatic analysis of high- est scoring sentences and use them to expand the training data. Sentences whose L1 and L2 recall are both greater than a threshold p are taken as good ones. A parser-based SRL system consists of two essential modules: a syntactic parser and a se- mantic classifier. To enhance the syntactic parser, the automatically generated syntactic trees of the sentence pairs that exhibit high semantic consis- tency are directly used to extend training data. To improve a semantic classifier, besides the consis- tent semantic analysis, we also use the outputs of the L1 but not L2 data which are generated by the neural syntax-agnostic SRL system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Setup</head><p>Our SRL corpus contains 1200 sentences in total that can be used as an evaluation for SRL systems. We separate them into three data sets. The first data set is used as development data, which con- tains 50 L2-L1 sentence pairs for each language and 200 pairs in total. Hyperparameters are tuned using the development set. The second data set contains all other 400 L2 sentences, which is used as test data for L2. Similarly, all other 400 L1 sen- tences are used as test data for L1.</p><p>The sentence pool for extracting retraining annotations includes all English-and Japanese- 5 code.google.com/archive/p/ berkeleyaligner/ ENG JPN #All sentence pairs 310,075 484,140 #Selected (p = 0.9) 36,979 41,281 native speakers' data along with its corrections. <ref type="table" target="#tab_7">Table 6</ref> presents the basic statistics. Around 8.5 - 11.9% of the sentence can be taken as high L1/L2 recall sentences, which serves as a reflection that argument structure is vital for language acquisition and difficult for learners to master, as proposed in <ref type="bibr">Vázquez (2004)</ref> and <ref type="bibr" target="#b14">Shin (2010)</ref>. The threshold (p = 0.9) for selecting sentences is set upon the development data. For example, we use additional 156,520 sentences to enhance the Berkeley parser. <ref type="table" target="#tab_9">Table 7</ref> summarizes the SRL results of the baseline PCFGLA-parser-based model as well as its corre- sponding retrained models. Since both the syntac- tic parser and the SRL classifier can be retrained and thus enhanced, we report the individual im- pact as well as the combined one. We can clearly see that when the PCFGLA parser is retrained with the SRL-consistent sentence pairs, it is able to pro- vide better SRL-oriented syntactic analysis for the L2 sentences as well as their corrections, which are essentially L1 sentences. The outputs of the L1 sentences that are generated by the deep SRL sys- tem are also useful for improving the linear SRL classifier. A non-obvious fact is that such a re- trained model yields better analysis for not only L1 but also L2 sentences. Fortunately, combining both results in further improvement.   <ref type="table">Table 8</ref> shows the results of the parallel ex- periments based on the neural parser. Differ- ent from the PCFGLA model, the SRL-consistent trees only yield a slight improvement on the L2 data. On the contrary, retraining the SRL classi- fier is much more effective. This experiment high- lights the different strengths of different frame- works for parsing. Though for standard in-domain test, the neural parser performs better and thus is more and more popular, for some other scenarios, the PCFGLA model is stronger.  <ref type="table">Table 8</ref>: Accuracies of different neural-parser- based models on the two test data sets. <ref type="table">Table 9</ref> further shows F-scores for the baseline and the both-retrained model relative to each role type in detail. Given that the F-scores for both models are equal to 0 on A3 and A4, we just omit this part. From the figure we can observe that, all the semantic roles achieve significant improve- ments in performances.  <ref type="table">Table 9</ref>: F-scores of the baseline and the both- retrained models relative to role types on the two data sets. We only list results of the PCFGLA- parser-based system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Main Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Statistical models of annotating learner texts are making rapid progress. Although there have been some initial studies on defining annotation speci- fication as well as corpora for syntactic analysis, there is almost no work on semantic parsing for interlanguages. This paper discusses this topic, taking Semantic Role Labeling as a case task and learner Chinese as a case language. We reveal three unknown facts that are important towards a deeper analysis of learner languages: (1) the ro- bustness of language comprehension for interlan- guage, (2) the weakness of applying L1-sentence- trained systems to process learner texts, and (3) the significance of syntactic parsing and L2-L1 paral- lel data in building more generalizable SRL mod- els that transfer better to L2. We have successfully provided a better SRL-oriented syntactic parser as well as a semantic classifier for processing the L2 data by exploring L2-L1 parallel data, supported by a significant numeric improvement over a num- ber of state-of-the-art systems. To the best of our knowledge, this is the first work that demonstrates the effectiveness of large-scale L2-L1 parallel data to enhance the NLP system for learner texts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Confusion matrix for each semantic role (here we add up matrices of ENG-L2 and JPNL2). The predicted labels are only counted in three cases: (1) The predicated boundaries match the gold span boundaries. (2) The predicated argument does not overlap with any the gold span (Gold labeled as "O"). (3) The gold argument does not overlap with any predicted span (Prediction labeled as "O").</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Syntactic analysis for the sentence in Figure 3a</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Syntactic analysis for the sentence in Figure 3b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Two examples for SRL outputs of both systems and the corresponding syntactic analysis for the L2 sentences</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>) .</head><label>.</label><figDesc></figDesc><table>ENG 
JPN 
RUS 
ARA 

L1 

A0 
97.23 
99.10 
97.66 
98.22 
A1 
96.70 
96.99 
98.05 
98.34 
A2 
88.89 100.00 100.00 92.59 
A3 100.00 100.00 100.00 100.00 
A4 100.00 
-
-
100.00 
AM 94.94 
98.35 
93.07 
96.02 

L2 

A0 
94.09 
95.77 
97.92 
97.88 
A1 
90.68 
97.93 
97.40 
98.68 
A2 
88.46 100.00 95.24 
93.33 
A3 100.00 100.00 100.00 
-
A4 100.00 
-
-
-
AM 96.97 
96.51 
91.78 
96.02 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Inter-annotator agreement (F-scores) rela-
tive to languages and role types. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 : Statistics of unlabeled data.</head><label>6</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Accuracies different PCFGLA-parser-
based models on the two test data sets. 

</table></figure>

			<note place="foot" n="1"> In this paper, we call sentences written by non-native speakers (henceforth, &quot;L2 sentences&quot;), aligned to their corrections by native speakers (henceforth, &quot;L1 sentences&quot;) L2L1 parallel sentences.</note>

			<note place="foot" n="3"> code.google.com/p/berkeleyparser/ 4 Here we only use the trees that has semantic role annotations for parser training. This setup keeps us from overestimating the contribution of a parser.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This work was supported by the National Nat-ural Science Foundation of China (61772036, 61331011) and the Key Laboratory of Science, Technology and Standard in Press Industry (Key Laboratory of Intelligent Press Media Technol-ogy). We thank the anonymous reviewers and for their helpful comments. We also thank Nian-wen Xue for useful comments on the final version. Weiwei Sun is the corresponding author.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Universal dependencies for learner english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yevgeni</forename><surname>Berzak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Kenney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolyn</forename><surname>Spadine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing Xian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keiko</forename><forename type="middle">Sophie</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Garza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="737" to="746" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Is argument structure of learner chinese understandable: A corpus-based analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuguang</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 International Conference on Bilingual Learning and Teaching</title>
		<meeting>the 2018 International Conference on Bilingual Learning and Teaching</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>ICBLT-2018</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic cohesion model for phrase-based SMT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The COLING 2012 Organizing Committee</title>
		<meeting><address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="867" to="878" />
		</imprint>
	</monogr>
	<note>Proceedings of COLING 2012</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Automatic labeling of semantic roles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL &apos;00: Proceedings of the 38th Annual Meeting on Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep semantic role labeling: What works and what&apos;s next</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="473" to="483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">L1l2 parallel dependency treebank as learner corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keying</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herman</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on Parsing Technologies</title>
		<meeting>the 15th International Conference on Parsing Technologies<address><addrLine>Pisa, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="44" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Alignment by agreement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT-NAACL</title>
		<meeting>HLT-NAACL<address><addrLine>New York City, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="104" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">A simple and accurate syntax-agnostic neural model for dependency-based semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcheggiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Frolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.02593</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Semantic role labeling: an introduction to the special issue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kenneth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanne</forename><surname>Litkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stevenson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Mining revision log of language learning sns for automated japanese error correction of second language learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoya</forename><surname>Mizumoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mamoru</forename><surname>Komachi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaaki</forename><surname>Nagata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Joint Conference on Natural Language Processing</title>
		<meeting>5th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="147" to="155" />
		</imprint>
	</monogr>
	<note>Chiang Mai, Thailand. Asian Federation of Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Phrase structure annotation and parsing for learner english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryo</forename><surname>Nagata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1837" to="1847" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning accurate, compact, and interpretable tree annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Thibaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="433" to="440" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The importance of syntactic parsing and inference in semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasin</forename><surname>Punyakanok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="257" to="287" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Defining syntax for learner language annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marwa</forename><surname>Ragheb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Dickinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2012: Posters</title>
		<meeting>COLING 2012: Posters<address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="965" to="974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On the contribution of argument structure constructions to sentence meaning for korean learners of english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyu-Ho</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ENGLISH TEACHING</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="209" to="227" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">A minimal span-based neural constituency parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.03919</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient inference and structured learning for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="29" to="41" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Learning argument structure generalizations in a foreign language. VIAL, Vigo international journal of applied linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Montserrat Martínez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vázquez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="151" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Chinese semantic role labeling with bidirectional recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingsong</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1626" to="1631" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Labeling Chinese predicates with semantic roles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="225" to="255" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Adding semantic roles to the Chinese treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Lang. Eng</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="143" to="172" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The penn Chinese treebank: Phrase structure annotation of a large corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fu-Dong</forename><surname>Chiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="207" to="238" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Overview of the nlpcc 2018 shared task: Grammatical error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanyuan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural Language Processing and Chinese Computing</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="439" to="445" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">End-to-end learning of semantic role labeling using recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1127" to="1137" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
