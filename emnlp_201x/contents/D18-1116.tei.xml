<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:19+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Toward Fast and Accurate Neural Discourse Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhong</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EECS</orgName>
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EECS</orgName>
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfeng</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EECS</orgName>
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Toward Fast and Accurate Neural Discourse Segmentation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="962" to="967"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>962</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Discourse segmentation, which segments texts into Elementary Discourse Units, is a fundamental step in discourse analysis. Previous discourse segmenters rely on complicated hand-crafted features and are not practical in actual use. In this paper, we propose an end-to-end neural segmenter based on BiLSTM-CRF framework. To improve its accuracy, we address the problem of data insufficiency by transferring a word representation model that is trained on a large corpus. We also propose a restricted self-attention mechanism in order to capture useful information within a neighborhood. Experiments on the RST-DT corpus show that our model is significantly faster than previous methods, while achieving new state-of-the-art performance. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Discourse segmentation, which divides text into proper discourse units, is one of the fundamen- tal tasks in natural language processing. Accord- ing to Rhetorical Structure Theory (RST) <ref type="bibr" target="#b15">(Mann and Thompson, 1988)</ref>, a complex text is com- posed of non-overlapping Elementary Discourse Units (EDUs), as shown in <ref type="table">Table 1</ref>. Segment- ing text into such discourse units is a key step in discourse analysis <ref type="bibr" target="#b16">(Marcu, 2000</ref>) and can benefit many downstream tasks, such as sentence com- pression <ref type="bibr" target="#b21">(Sporleder and Lapata, 2005</ref>) or docu- ment summarization ( .</p><p>Since EDUs are initially designed to be deter- mined with lexical and syntactic clues <ref type="bibr" target="#b1">(Carlson et al., 2001</ref>), existing methods for discourse seg- mentation usually design hand-crafted features to capture these clues <ref type="bibr" target="#b4">(Feng and Hirst, 2014</ref>). Es- pecially, nearly all previous methods rely on syn- tactic parse trees to achieve good performance.</p><p>[Mr. <ref type="bibr">Rambo says]</ref>   <ref type="table">Table 1</ref>: A sentence that is segmented into five EDUs But extracting such features usually takes a long time, which contradicts the fundamental role of discourse segmentation and hinders its actual use. Considering the great success of deep learning on many NLP tasks ( <ref type="bibr" target="#b14">Lu and Li, 2016)</ref>, it's a natural idea for us to design an end-to-end neural model that can segment texts fast and accurately.</p><p>The first challenge of applying neural methods to discourse segmentation is data insufficiency. Due to the limited size of labeled data in exist- ing corpus <ref type="bibr" target="#b1">(Carlson et al., 2001</ref>), it's quite hard to train a data-hungry neural model without any prior knowledge. In fact, some traditional features, such as the POS tags or parse trees, naturally provide strong signals for identifying EDUs. Removing them definitely increases the difficulty of learning an accurate model. Secondly, many EDU bound- aries are actually not determined locally. For ex- ample, to recognize the boundary between e 3 and e 4 in <ref type="table">Table 1</ref>, our model has to be aware that e 3 is an embedded clauses starting from "overlooking", otherwise it could regard "San Fernando Valley" as the subject of e 4 . Such kind of long-distance dependency can be precisely extracted from parse trees but is difficult for neural models to capture.</p><p>To address these challenges, in this paper, we propose a neural discourse segmenter based on the BiLSTM-CRF ( <ref type="bibr" target="#b7">Huang et al., 2015</ref>) framework and further improve it from two aspects. Firstly, since the discourse segmentation corpus is too small to learn precise word representations, we transfer a word representation model trained on a large corpus into our task, and show that this trans-ferred model can provide very useful information for our task. Secondly, in order to model long- distance dependency, we employ the self-attention mechanism ( <ref type="bibr" target="#b24">Vaswani et al., 2017</ref>) when encoding the text. Different from previous self-attention, we restrict the attention area to a neighborhood of fixed size. The motivation is that effective infor- mation for determining the boundaries is usually collected from adjacent EDUs, while the whole text may contain many disturbing words, which could mislead the model into incorrect decisions. In summary, the contributions of this work are as follows:</p><p>• Our neural discourse segmentation model doesn't rely on any syntactic features, while it can outperform other state-of-the-art systems and achieve significant speedup.</p><p>• To our knowledge, we are the first to trans- fer word representations learned from large corpus into discourse segmentation task and show that they can significantly alleviate the data insufficiency problem.</p><p>• Based on the nature of discourse segmenta- tion, we propose a restricted attention mech- anism , which enables the model to capture useful information within a neighborhood but ignore unnecessary faraway noises.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Neural Discourse Segmentation Model</head><p>We model discourse segmentation as a sequence labeling task, where the start word of each EDU (except the first EDU) is supposed to be labeled as 1 and other words are labeled as 0. <ref type="figure">Figure 1</ref> gives an overview of our segmentation model. We will introduce the BiLSTM-CRF framework in Section 2.1, and describe the two key components of our model in Section 2.2, 2.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">BiLSTM-CRF for Sequence Labeling</head><p>Conditional Random Fields (CRF) ( <ref type="bibr" target="#b11">Lafferty et al., 2001</ref>) is an effective method to sequence labeling problem and has been widely used in many NLP tasks <ref type="bibr" target="#b23">(Sutton and McCallum, 2012)</ref>. To approach our discourse segmentation task in a neural way, we adopt the BiLSTM-CRF model ( <ref type="bibr" target="#b7">Huang et al., 2015)</ref> as the framework of our system. Formally, given an input sentence x = {x t } n t=1 , we first em- bed each word into a vector e t . Then these word embeddings are fed into a bi-directional LSTM </p><formula xml:id="formula_0">!# ÿ $ # %&amp; " ' ÿ #ÿ #( ÿ )# ÿ # ÿ !" * * * + * , 3-2 , 3-3 , 3-4</formula><p>Figure 1: Overview of our model for discourse segmen- tation layer to model the sequential information:</p><formula xml:id="formula_1">h t = BiLSTM(h t−1 , e t )<label>(1)</label></formula><p>where h t is the concatenation of the hidden states from both forward and backward LSTMs. After encoding this sentence, we make labeling deci- sions for each word. Instead of modeling the deci- sions independently, the CRF layer computes the conditional probability p(y|h; W, b) over all pos- sible label sequences y given h as follows:</p><formula xml:id="formula_2">p(y|h; W, b) = n i=1 ψ i (y i−1 , y i , h) y ∈Y n i=1 ψ i (y i−1 , y i , h)<label>(2)</label></formula><p>where</p><formula xml:id="formula_3">ψ i (y i−1 , y i , h) = exp(w T h i + b)</formula><p>is the po- tential function and Y is the set of possible label sequences. The training objective is to maximize the conditional likelihood of the golden label se- quence. During testing, we search for the label sequence with the highest conditional probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Transferring Representations Learned from Large Corpus</head><p>Due to the large parameter space, neural models usually require much more training data in order to achieve good performance. However, to the best of our knowledge, nearly all existing discourse segmentation corpora are limited in size. After we remove all the syntactic features, which has been proven useful in many previous work ( <ref type="bibr" target="#b0">Bach et al., 2012;</ref><ref type="bibr" target="#b4">Feng and Hirst, 2014;</ref><ref type="bibr" target="#b8">Joty et al., 2015</ref>), it's expected that our neural model will not achieve very satisfying results.</p><p>To tackle this issue, we propose to leverage model learned from other large datasets, aiming that this transferred model has been well trained to encode text and capture useful signals. Instead of training the transferred model by ourselves, in this paper, we adopt the ELMo word representa- tions ( , which are derived from a bidirectional language model (BiLM) trained on one billion word benchmark corpus ( <ref type="bibr" target="#b3">Chelba et al., 2014</ref></p><note type="other">). Specifically, this BiLM has one charac- ter convolution layer and two biLSTM layers, and correspondingly there are three internal represen- tations for each word x t , which are denoted as {h LM t,l } 3 l=1 . Following (Peters et al., 2018), we compute the ELMo representation r t for word x t as follows:</note><formula xml:id="formula_4">r t = γ LM 3 l=0 s LM l h LM t,l<label>(3)</label></formula><p>where s LM are normalized weights and γ LM con- trols the scaling of the entire ELMo vector. Then we concatenate r t with the word embedding e t , and take them as the input of Equation (1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Restricted Self-Attention</head><p>As we have introduced in Section 1, some EDU boundaries rely on relatively long-distance sig- nals to recognize, while normal LSTM model is still weak at this. Recently, self-attention mecha- nism, which relates different positions of a single sequence, has been successfully applied to many NLP tasks ( <ref type="bibr" target="#b24">Vaswani et al., 2017;</ref><ref type="bibr" target="#b25">Wang et al., 2017)</ref> and shows its superiority in capturing long dependency. However, we found that most bound- aries are actually only influenced by nearby EDUs, thereby forcing the model to attend to the whole sequence will bring in unnecessary noises. There- fore, we propose a restricted self-attention mech- anism, which only collects information from a fixed neighborhood. To do this, we first compute the similarity between current word x i and each nearby word x j within a window:</p><formula xml:id="formula_5">s i,j = w T attn [h i , h j , h i h j ]<label>(4)</label></formula><p>Then the attention vector a i is computed as a weighted sum of nearby words:</p><formula xml:id="formula_6">α i,j = e s i,j K k=−K e s i,i+k<label>(5)</label></formula><formula xml:id="formula_7">a i = K j=−K α i,i+k h i+k<label>(6)</label></formula><p>where hyper-parameter K is the window size. This attention vector a i is then put into another BiLSTM layer together with h i in order to fuse the information:</p><formula xml:id="formula_8">˜ h t = BiLSTM( ˜ h t−1 , [h t , a t ])<label>(7)</label></formula><p>We use˜huse˜ use˜h t as the new input to the CRF layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset and Metrics</head><p>We conduct experiments on the RST Discourse Treebank (RST-DT) ( <ref type="bibr" target="#b1">Carlson et al., 2001</ref>). The original corpus contains 385 Wall Street Journal articles from the Penn Treebank, which are di- vided in to training set (347 articles, 6132 sen- tences) and test set (38 articles, 991 sentences). We randomly sample 34 (10%) articles from the train set as validation set in order to tune the hyper- parameters and only train our model on the re- mained train set. We follow mainstream studies <ref type="bibr" target="#b20">(Soricut and Marcu, 2003;</ref><ref type="bibr" target="#b8">Joty et al., 2015</ref>) to measure segmentation accuracy only with respect to the intra-sentential segment boundaries, and we report Precision (P), Recall (R) and F1-score (F1) for segmentation performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Implementation Details</head><p>We tune all the hyper-parameters according to the model performance on the separated validation set. The 300-D Glove embeddings ( <ref type="bibr" target="#b17">Pennington et al., 2014</ref>) are employed and kept fixed during training. We use the AllenNLP toolkit ( ) to compute the ELMo word represen- tations. The hidden size of our model is set to be 200 and the batch size is 32. L2 regularization is applied to trainable variables with its weight as 0.0001 and we use dropout between every two lay- ers, where the dropout rate is 0.1. For model train- ing, we employ the Adam algorithm <ref type="bibr" target="#b9">(Kingma and Ba, 2014</ref>) with its initial learning rate as 0.0001 and we clip the gradients to a maximal norm 5.0. Exponential moving average is applied to all train- able variables with a decay rate 0.9999. The win- dow size K for restricted attention is set to be 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Performance</head><p>The results of our model and other competing sys- tems on the test set of RST-DT are shown in <ref type="table" target="#tab_3">Table  2</ref>. We compare our results against the following systems: (1) SPADE (Soricut and <ref type="bibr" target="#b20">Marcu, 2003</ref>) is an early system using simple lexical and syn- tactic features; <ref type="formula" target="#formula_2">(2)</ref>    <ref type="bibr" target="#b4">Feng and Hirst, 2014</ref>) conducts a sec- ond segmentation after extracting global features from the first segmentation result. All these meth- ods rely on tree features and we list their perfor- mance given different parse trees, where Gold are the trees extracted from the Penn Treebank ( <ref type="bibr" target="#b19">Prasad et al., 2005</ref>), Stanford represents trees from the Stanford parser ( <ref type="bibr" target="#b10">Klein and Manning, 2003)</ref> and BLLIP represents those from the BLLIP parser <ref type="bibr" target="#b2">(Charniak and Johnson, 2005</ref>). It should be noted that the results of SPADE and CRFSeg are taken from <ref type="bibr" target="#b0">Bach et al. (2012)</ref> since the original papers adopt different evaluation metrics. All the other results are taken from the corresponding original papers.</p><note type="other">88.0 92.3 90.1 Reranking Stanford 91.5 90.4 91.0 Two-Pass BLLIP 92.8 92.3 92.6 Our Model No 92.9 95.7 94.3 -Attention No 92.4 94.8 93.6 -ELMo No 87.9 84.5 86.2 -Both No 87.0 82.8 84.8 Human No 98.5 98.2 98.3</note><p>From <ref type="table" target="#tab_3">Table 2</ref>, we can see that our model achieves state-of-the-art performance without ex- tra parse trees. Especially, if no gold parse trees are provided, our system outperforms other meth- ods by more than 1.7 points in F1 score. Since the gold parse trees are not available when processing new sentences, this improvement becomes more valuable when the system is put into use. <ref type="bibr">3</ref> In parallel with our work, <ref type="bibr" target="#b12">Li et al. (2018)</ref> proposes an- other neural model with its performance as: P-91.6, R-92.8, F1-92.2. We didn't see their paper at the time of submission, but it's worth mentioning here for the readers' reference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head><p>Speed (Sents/s) Speedup Two-Pass  To further explore the influence of different components in our model, we also report the re- sults of ablation experiments in <ref type="table" target="#tab_3">Table 2</ref>. We can see that the transferred ELMo representations pro- vide the most significant improvement. This ac- cords with our assumption that the RST-DT cor- pus itself is not large enough to train an expres- sive neural model sufficiently. With the help of the transferred representations, we are capable of cap- turing more semantic and syntactic signals. Also, comparing the models with and without the re- stricted self-attention, we find that this attention mechanism can further boost the performance. Es- pecially, if there are no ELMo vectors, the im- provement provided by the attention mechanism is more noticeable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Speed Comparison</head><p>We also measure the speedup of our model against traditional systems in <ref type="table" target="#tab_5">Table 3</ref>. The Two-Pass sys- tem has the best performance among all existing methods, while SPADE is much simpler with less features. We test these systems on the same ma- chine (CPU: Intel Xeon E5-2690, GPU: NVIDIA Tesla P100). The results show that our system is 2.4-6.5 times faster than the compared systems if the batch size is 1. Moreover, if we process the test sentences in parallel, we can achieve 20.2- 54.8 times speedup with the batch size as 32. This makes our system more practical in actually use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Effect of Restricted Self-Attention</head><p>We propose to restrict the self-attention within a neighborhood instead of the whole sequence. Ta- ble 4 demonstrates the performance of our model over different window size K. We can see that all these results is better than the performance our model without attention mechanism. However, a proper restriction window is helpful for the atten- tion mechanism to take better effect. Window Size 1 5 10 ∞ F1-score 94.0 94.3 94.2 93.8 <ref type="table">Table 4</ref>: Performance of our model over different at- tention window size</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we propose a neural discourse seg- menter that can segment text fast and accurately. Different from previous methods, our segmenter doesn't rely on any hand-crafted features, espe- cially the syntactic parse tree. To achieve our goal, we propose to leverage the word representations learned from large corpus and we also propose a restricted self-attention mechanism. Experimen- tal results on RST-DT show that our system can achieve state-of-the-art performance together with significant speedup.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Performance of our model and other systems 
on the RST-DT test set 3 

segmentation after extracting features; (3) CRF-
Seg (Hernault et al., 2010) is the first discourse 
segmenter using CRF model; (4) CODRA (Joty 
et al., 2015) uses fewer features and a simple lo-
gistic regression model to achieve impressive re-
sults; (5) Reranking (Bach et al., 2012) reranks 
the N-best outputs of a base CRF segmenter; (6) 
Two-Pass (</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Speed comparison with two open-sourced dis-
course segmenter 

</table></figure>

			<note place="foot" n="1"> Our code is available at https://github.com/ PKU-TANGENT/NeuralEDUSeg</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their in-sightful comments on this paper. This work was partially supported by National Natural Science Foundation of China (61572049 and 6187022165). The corresponding author of this paper is Sujian Li.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A reranking model for discourse segmentation using subtree features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh</forename><forename type="middle">Le</forename><surname>Ngo Xuan Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akira</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shimazu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGDIAL 2012 Conference, The 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the SIGDIAL 2012 Conference, The 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue<address><addrLine>Seoul, South Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="160" to="168" />
		</imprint>
		<respStmt>
			<orgName>Seoul National University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Building a discourse-tagged corpus in the framework of rhetorical structure theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynn</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ellen</forename><surname>Okurovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2nd Annual Meeting of the Special Interest Group on Discourse and Dialogue, Saturday</title>
		<meeting><address><addrLine>Aalborg, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-09-01" />
		</imprint>
	</monogr>
	<note>Proceedings of the SIGDIAL 2001 Workshop</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Coarseto-fine n-best parsing and maxent discriminative reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL 2005, 43rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>University of Michigan, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06-30" />
			<biblScope unit="page" from="173" to="180" />
		</imprint>
	</monogr>
	<note>Proceedings of the Conference</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">One billion word benchmark for measuring progress in statistical language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ciprian</forename><surname>Chelba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Brants</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH 2014, 15th Annual Conference of the International Speech Communication Association</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-09-14" />
			<biblScope unit="page" from="2635" to="2639" />
		</imprint>
	</monogr>
	<note>Phillipp Koehn, and Tony Robinson</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Two-pass discourse segmentation with pairing and global features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Vanessa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hirst</surname></persName>
		</author>
		<idno>abs/1407.8215</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Grus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nelson</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.07640</idno>
		<title level="m">Allennlp: A deep semantic natural language processing platform</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Hilda: a discourse parser using support vector machine classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Hernault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Prendinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitsuru</forename><surname>David A Duverle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Ishizuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dialogue and Discourse</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="33" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Bidirectional LSTM-CRF models for sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno>abs/1508.01991</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">CODRA: A novel discriminative framework for rhetorical analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shafiq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">T</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="385" to="435" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Accurate unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>Sapporo Convention Center</publisher>
			<date type="published" when="2003-07" />
			<biblScope unit="page" from="423" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning</title>
		<meeting>the Eighteenth International Conference on Machine Learning<address><addrLine>Williams College, Williamstown, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-06-28" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Segbot: A generic neural text segmentation model with pointer network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aixin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018</title>
		<meeting>the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018<address><addrLine>Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07-13" />
			<biblScope unit="page" from="4166" to="4172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The role of discourse units in near-extractive summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyi Jessy</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kapil</forename><surname>Thadani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Stent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting><address><addrLine>Los Angeles, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-09" />
			<biblScope unit="page" from="137" to="147" />
		</imprint>
	</monogr>
	<note>Proceedings of the SIGDIAL 2016 Conference</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Recent progress in deep learning for NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting><address><addrLine>San Diego California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06-12" />
			<biblScope unit="page" from="11" to="13" />
		</imprint>
	</monogr>
	<note>Tutorial Abstracts, NAACL HLT 2016</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Rhetorical structure theory: Toward a functional theory of text organization. Text-Interdisciplinary Journal for the Study of Discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><forename type="middle">A</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thompson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="243" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">The theory and practice of discourse parsing and summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno>abs/1802.05365</idno>
		<title level="m">Deep contextualized word representations. CoRR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The penn discourse treebank as a resource for natural language generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rashmi</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Dinesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Miltsakaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Corpus Linguistics Workshop on Using Corpora for Natural Language Generation</title>
		<meeting>the Corpus Linguistics Workshop on Using Corpora for Natural Language Generation</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sentence level discourse parsing using syntactic and lexical information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter</title>
		<meeting>the 2003 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="149" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Discourse chunking and its application to sentence compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><surname>Sporleder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing</title>
		<meeting>the conference on Human Language Technology and Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="257" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Automatic discourse segmentation using neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajen</forename><surname>Subba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><forename type="middle">Di</forename><surname>Eugenio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Workshop on the Semantics and Pragmatics of Dialogue</title>
		<meeting>the 11th Workshop on the Semantics and Pragmatics of Dialogue</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="189" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">A</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<title level="m">An introduction to conditional random fields. Foundations and Trends in Machine Learning</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="267" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Gated self-matching networks for reading comprehension and question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017-07-30" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
