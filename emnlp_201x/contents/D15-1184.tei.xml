<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reading Documents for Bayesian Online Change Point Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taehoon</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Ulsan National Institute of Science and Technology Ulsan</orgName>
								<address>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaesik</forename><surname>Choi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Ulsan National Institute of Science and Technology Ulsan</orgName>
								<address>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Reading Documents for Bayesian Online Change Point Detection</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Modeling non-stationary time-series data for making predictions is a challenging but important task. One of the key issues is to identify long-term changes accurately in time-varying data. Bayesian On-line Change Point Detection (BO-CPD) algorithms efficiently detect long-term changes without assuming the Markov property which is vulnerable to local signal noise. We propose a Document based BO-CPD (DBO-CPD) model which automatically detects long-term temporal changes of continuous variables based on a novel dynamic Bayesian analysis which combines a non-parametric regression, the Gaussian Process (GP), with generative models of texts such as news articles and posts on social networks. Since texts often include important clues of signal changes, DBO-CPD enables the accurate prediction of long-term changes accurately. We show that our algorithm outperforms existing BO-CPDs in two real-world datasets: stock prices and movie revenues.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Time series data depends on the latent dependence structure which changes over time. Thus, sta- tionary parametric models are not appropriate to represent such dynamic non-stationary processes. Change point analysis <ref type="bibr" target="#b28">(Smith, 1975;</ref><ref type="bibr" target="#b31">Stephens, 1994;</ref><ref type="bibr" target="#b5">Chib, 1998;</ref><ref type="bibr" target="#b2">Barry and Hartigan, 1993</ref>) fo- cuses on formal frameworks to determine whether a change has taken place without assuming the Markov property which is vulnerable to local sig- nal noise. When change points are identified, each part of the time series is approximated by specified parametric models under the stationary assump- tions. Such change point detection models have successfully been applied to a variety of data, such as stock markets <ref type="bibr" target="#b4">(Chen and Gupta, 1997;</ref><ref type="bibr" target="#b14">Hsu, 1977;</ref><ref type="bibr" target="#b17">Koop and Potter, 2007)</ref>, analyzing bees' be- havior <ref type="bibr" target="#b36">(Xuan and Murphy, 2007)</ref>, forecasting cli- mates ( <ref type="bibr" target="#b6">Chu and Zhao, 2004;</ref><ref type="bibr" target="#b37">Zhao and Chu, 2010)</ref>, and physics experiments <ref type="bibr" target="#b34">(von Toussaint, 2011</ref>). However, offline-based change point analysis suf- fers from slow retrospective inference which pre- vents real-time analysis.</p><p>Bayesian Online Change Point Detection (BO- CPD) <ref type="bibr" target="#b0">(Adams and MacKay, 2007;</ref><ref type="bibr" target="#b32">Steyvers and Brown, 2005;</ref><ref type="bibr" target="#b21">Osborne, 2010;</ref><ref type="bibr" target="#b13">Gu et al., 2013)</ref> overcomes this restriction by exploiting efficient online inference algorithms. BO-CPD algorithms efficiently detect long-term changes by analyzing continuous target values with the Gaussian Pro- cess (GP), a non-parametric regression method. The GP-based CPD model is simple and flexible. However, it is not straightforward to utilize rich external data such as texts in news articles and posts in social networks.</p><p>In this paper, we propose a novel BO-CPD model that improves the detection of change points in continuous signals by incorporating the rich external information implicitly written in texts on top of the long-term change analysis of the GP. In particular, our model finds causes of sig- nal changes in news articles which are influential sources of markets of interests.</p><p>Given a set of news articles extracted from the Google News service and a sequence of target, continuous values, our new model, Document- based Bayesian Online Change Point Detection (DBO-CPD), learns a generative model which rep- resents the probability of a news article given the run length (a length of consecutive observations without a change). By using the new prior, DBO- CPD models a dynamic hazard rate (h) which de- termines the rate at which change points occur.</p><p>In the literature, important information is ex- tracted from news articles <ref type="bibr" target="#b20">(Nothman et al., 2012;</ref><ref type="bibr"></ref> (a) BO-CPD (b) DBO-CPD (this work) <ref type="figure" target="#fig_2">Figure 1</ref>: This figures illustrates a graphical repre- sentation of BO-CPD and our DBO-CPD model. x t , r t , and D t represent a continuous variable of interest, the run length (hidden) variable, and doc- uments, respectively. Our modeling contribution is to add texts D 1:t for the accurate prediction of the run length r t+1 . <ref type="bibr" target="#b26">Schumaker and Chen, 2009;</ref><ref type="bibr" target="#b10">Gidófalvi and Elkan, 2001;</ref><ref type="bibr" target="#b9">Fung et al., 2003;</ref><ref type="bibr" target="#b8">Fung et al., 2002</ref>; <ref type="bibr" target="#b25">Schumaker and Chen, 2006</ref>), tweets on Twitter ( <ref type="bibr" target="#b27">Si et al., 2013;</ref><ref type="bibr">Wang et al., 2012;</ref><ref type="bibr" target="#b3">Bollen et al., 2011;</ref><ref type="bibr" target="#b30">St Louis et al., 2012</ref>), online chats ( <ref type="bibr" target="#b15">Kim et al., 2010;</ref><ref type="bibr" target="#b12">Gruhl et al., 2005</ref>), and blog posts ( <ref type="bibr" target="#b23">Peng et al., 2015;</ref><ref type="bibr" target="#b19">Mishne and Glance, 2006)</ref>.</p><p>In experiments, we show that DBO-CPD can ef- fectively distinguish whether an abrupt change is a change point or not in real-world datasets (see Sec- tion 3.1). Compared to previous BO-CPD models which explain the changes by human manual map- pings, our DBO-CPD automatically explains the reasons why a change point has occurred by con- necting the numerical sequence of data and textual features of news articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Bayesian Online Change Point Detection</head><p>This section will review our research problem, the change point detection (CPD) <ref type="bibr" target="#b2">(Barry and Hartigan, 1993)</ref>, and the Bayesian Online Change Point Detection (BO-CPD) <ref type="bibr" target="#b0">(Adams and MacKay, 2007)</ref> and our model, Document Based Online Change Point Detection (DBO-CPD).</p><p>Let x t ∈R be a data observation at time t. We assume that a sequence of data (x 1 , x 2 , ..., x t ) is composed of several non-overlapping produc- tive partitions <ref type="bibr" target="#b1">(Barry and Hartigan, 1992)</ref>. The boundaries that separate the partitions is called the change points. Let r be the random variable that denotes the run length, which is the number of time steps since the last change point was detected. r t is the current run at time t. x (rt) t denotes the most recent data corresponding to the run r t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Online Recursive Detection</head><p>To make an optimal prediction of the next data x t+1 , one may need to consider all possible run lengths r t ∈N and a probability distribution over run length r t . Given a sequence of data up to time t, x 1:t = (x 1 , x 2 , ..., x t ), the run length prediction problem is formalized as computing the joint prob- ability of random variables P (x t+1 , x 1:t ). This distribution can be calculated in terms of the poste- rior distribution of run length at time t, P (r t |x 1:t ), as follows:</p><formula xml:id="formula_0">P (x t+1 , x 1:t ) = rt P (x t+1 |r t , x (rt) t )P (r t |x 1:t ) = rt P (x t+1 |x (rt) t )P (r t |x 1:t ).(1)</formula><p>The predictive distribution P (x t+1 |r t , x (rt) t ) de- pends only on the most recent r t observations x (rt) t . The posterior distribution of run length P (r t |x 1:t ) can be computed recursively:</p><formula xml:id="formula_1">P (r t |x 1:t ) = P (r t , x 1:t ) P (x 1:t )<label>(2)</label></formula><p>where:</p><formula xml:id="formula_2">P (x 1:t ) = rt P (r t , x 1:t ).<label>(3)</label></formula><p>The joint distribution over run length r t and data x 1:t can be derived by summing P (r t , r t−1 , x 1:t ) over r t−1 : P (r t , x 1:t ) = r t−1 P (r t , r t−1 , x 1:t ) = r t−1 P (r t , x t |r t−1 , x 1:t−1 )P (r t−1 , x 1:t−1 )</p><formula xml:id="formula_3">= r t−1 P (r t |r t−1 )P (x t |r t−1 , x (rt) t )P (r t−1 , x 1:t−1 ).</formula><p>This formulation updates the posterior distribution of the run length given the prior over r t from r t−1 and the predictive distribution of new data.</p><p>However, the existing BO-CPD model <ref type="bibr" target="#b0">(Adams and MacKay, 2007</ref>) specifies the conditional prior on the change point P (r t |r t−1 ) in advance. This approach may lead to model biased predictions be- cause the update formula highly relies on the pre- defined, fixed hazard rate (h). Furthermore, BO- CPD is incapable of incorporating external infor- mation that implicitly influences the observation and explains the reasons for the current change of the long-term trend. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Document-based Bayesian Online Change Point Detection</head><p>This section explains our DBO-CPD model. To represent the text documents, we add a variable D which denotes a series of text documents related to the observed data as shown in <ref type="figure" target="#fig_2">Figure 1</ref>. Let</p><formula xml:id="formula_4">D t be a set of N t text documents D 1 t , D 2 t , ..., D Nt t</formula><p>that are indexed at time of publication t, where N t is the number of documents observed at time t. Then, we can rewrite the joint probability over the run length as:</p><formula xml:id="formula_5">P (r t , x 1:t ) = r t−1 D (r t−1 ) t P r t |r t−1 , D (r t−1 ) t · P x t |r t−1 , x (r t−1 ) t P (r t−1 , x 1:t−1 ) (4)</formula><p>where</p><formula xml:id="formula_6">D (rt) t (= D t−rt+1:t )</formula><p>is the set of the r t most recent documents. <ref type="figure" target="#fig_0">Figure 2</ref> illustrates the recur- sive updates of posterior probability where solid lines indicate that the probability mass is passed upwards and dotted lines indicate the probability that the current run length r t is set to zero.</p><p>Given documents D (rt) t , the conditional proba- bility is represented as follows:</p><formula xml:id="formula_7">P r t = γ+1|r t−1 = γ, D (γ) t = P r t−1 = γ, D (γ) t |r t = γ+1 P (r t = γ+1) γ+1 ¯ γ=1 P r t−1 = γ, D (γ) t |r t = ¯ γ P (r t = ¯ γ) = P r t−1 = γ, D (γ) t |r t = γ + 1 P gap (γ+1) γ+1 ¯ γ=1 P r t−1 = γ, D (γ) t |r t = ¯ γ P gap (¯ γ)</formula><p>where P gap is the distribution of intervals be- tween consecutive change-points. As the BO-CPD model <ref type="bibr" target="#b0">(Adams and MacKay, 2007)</ref>, we assume the simplest case where the probability of a change- point at every step is constant if the length of a segment is modeled by a discrete exponential (ge- ometric) distribution as:</p><formula xml:id="formula_8">P gap (r t |λ) = λexp −λrt (5)</formula><p>where λ &gt; 0, a rate parameter, is the parameter of the distribution. The update rule for the prior distribution on r t makes the computation of the joint distribution tractable, γ+1</p><formula xml:id="formula_9">¯ γ=1 P (r t−1 =γ, D (γ)</formula><p>t |r t =¯ γ)·P gap (¯ γ). Because r t can only be increased to γ + 1 or set to 0, the conditional probability is as follows:</p><formula xml:id="formula_10">P (r t = γ + 1|r t−1 = γ, D (γ) t ) = T D (t, γ|γ+1) T D (t, γ|γ+1) + T D (t, γ|0) (6)</formula><p>where the function T D (t, α|¯ α) is an abbrevia- tion of</p><formula xml:id="formula_11">P r t−1 =α, D (α) t |r t =¯ α . In Equation (6), T D (t, γ|γ+1)=P (r t−1 =γ, D (γ) t |r t =γ+1)</formula><p>is the joint probability of the run length r t−1 and a set of documents D (γ) t when no change has occurred at time t and the run length becomes γ + 1. There- fore, we can simplify the equation by removing r t−1 =γ from the condition as follows: length parameter r t . In this setting, the conditional probability of the words takes the following form:</p><formula xml:id="formula_12">P D (γ) t |r t = γ+1 = 1 Z i,j P d i,j t |r t = γ+1 .</formula><p>(8) The conditional probability P (d i,j t |r t =γ+1) is represented by two generative models, φ wf and φ wi which illustrates word frequency and word im- pact, respectively. The key intuition of word fre- quency is that a word tends to close to a change point if a word has been frequently seen in arti- cles, published when there was a rapid change.</p><p>The key intuition of word impact is that how much does a word lose information in time which will be discussed in next section. In our paper, we use the unnormalized beta distribution of the weights of words to represent the exponential de- cays. The probability P D (γ) t |r t =γ + 1 can be represented recursively as:</p><formula xml:id="formula_13">P D (γ) t |rt=γ+1 =P D (γ) t |γ+1 ∝ φ wi (D (γ) t |γ+1) · φ wf (D (γ) t |γ+1) = φ wi (Dt|γ+1) · φ wf (Dt|γ+1) ·φ wi (D (γ−1) t−1 |rt−1=γ) · φ wf (D (γ−1) t−1 |rt−1=γ) = i,j φ wi (d i,j t |γ+1) · φ wf (d i,j t |γ+1)<label>(9)</label></formula><formula xml:id="formula_14">·φ wi (D (γ−1) t−1 |rt−1=γ) · φ wf (D (γ−1) t−1 |rt−1=γ)</formula><p>where:</p><formula xml:id="formula_15">φ wf (d x,y t |γ) = count(d x,y t , r t = γ) i,j count(d i,j t , r t = γ) .</formula><p>Here, φ wi (d x,y t |γ) and φ wf (d x,y t |γ) are empirical potentials which contribute to represent P (d i,j t |γ). φ wi (·) is explained in Section 2.3. Here, count(E) is the number of times event E appears in the dataset. In Equation (9), τ t is the time gap (dif- ference) between t and the time when a document is generated, and d i,j represents a document with- out considering the time domain.</p><p>T D (t, γ|0) is represented as follows:</p><formula xml:id="formula_16">P (r t−1 =γ, D (γ) t |r t =0) = P (r t−1 =γ|r t = 0)P (D (γ) t |r t =0) = H(γ+1)P (D (γ) t |r t =0)</formula><p>where H(τ ) is the hazard function <ref type="bibr" target="#b7">(Forbes et al., 2011</ref>),</p><formula xml:id="formula_17">H(τ ) = P gap (τ ) ∞ t=τ P gap (t) .<label>(10)</label></formula><p>Figure 3: This figure illustrates how our Equa- tion (9) is calculated and how it determines whether a change occurs or not. If the same data is given, BO-CPD gives us the same answer to a question whether an abrupt change at time t is a change point or not. However, DBO-CPD uses documents D γ t for its prediction to incorporate the external information which cannot be inferred only from the data.</p><p>When P gap is the discrete exponential distribution, the hazard function is constant at H(τ ) = 1/λ ( <ref type="bibr" target="#b0">Adams and MacKay, 2007)</ref>.</p><p>As an illustrative example, suppose that we found a rapid change in Google stock three days ago. Today at t = 3, we want to know how the articles are written and whether it will affect the change tomorrow (t = 4). As shown in <ref type="figure">Figure 3</ref>, we can calculate what degree a word, for example rises or stays, is likely to appear in articles pub- lished since today, which is P (D (γ) t |r t = γ+1), and this probability leads us to predict run lengths from the texts. Documents for each τ t = 0, 1 and 2 are generated from the generative models with a given predicted run length through recursive cal- culation of the Bayesian models which enables on- line prediction as shown in Equation (9). This is the main contribution of this paper that enables DBO-CPD to infer change points accurately with information included in text documents.</p><p>Let D ∈ R T ×N ×M be N documents of news arti- cles which consist of M vocabulary over time do- main T . D i t ∈ R M is the ith document of a set of documents generated at time t, and define r ∈ R N as the corresponding set of the run length, which is a time gap between the time when the document is generated and the next change point occurs. Then, given a text document D i t , we seek to predict the value of run length r by learning a parameterized function f :</p><formula xml:id="formula_18">ˆ r = f (D i t ; w)<label>(11)</label></formula><p>where w ∈ R d are the weights of text features for</p><formula xml:id="formula_19">d i,1 t , d i,2 t , ..., d i,M t</formula><note type="other">which compose documents D i t . From a collection of N documents, we use linear regression which is trained by solving the follow- ing optimization problem:</note><formula xml:id="formula_20">min w,D i t f (D i t ; w) ≡ C N i=1 ξ(w, D i t , r t ) + r(w)<label>(12)</label></formula><p>where r(w) is the regularization term and ξ(w, D i t , r t ) is the loss function. Parameter C &gt; 0 is a user-specified constant for balancing r(w) and the sum of losses.</p><p>Let h be a function from a document into a vector-space representation ∈ R d . In linear regres- sion, the function f takes the form:</p><formula xml:id="formula_21">f (D i t ; w) = h(D i t ) w +<label>(13)</label></formula><p>where is Gaussian noise. <ref type="figure">Figure 4</ref> illustrates how we trained a linear re- gression model on a sample article. One issue is that the run length can not be trained directly. Suppose that we train r 5 = 0 into regression, the weight w of the model will become 0 even though the set of words contained in D j 5 , ∀j ∈ {1, ..., T } is composed of salient words which can incur a possible future change point. To solve this inter- pretability problem, we trained the weight in the inverse exponential domain for the predicted vari- able, predicting e −rt instead of r t . In this setting, the predicted run-length takes the form:</p><formula xml:id="formula_22">e − ˆ rt = h(D t ) w + .<label>(14)</label></formula><p>By this method, the regression model can give a high weight to a word which often appears close to change points. We can interpret that highly <ref type="figure">Figure 4</ref>: This figure illustrates a graphical rep- resentation of how we train a generative model from a regression problem. We use a regression model to predict time gap r t between the release date of article and the nearest future change point.</p><p>The weights of regression model are changed into the negative exponential scale to be considered as word impact.</p><p>weighted words d are more closely related to an outbreak of changes than lower weighted words. With w, we can rewrite the probability of d, τ t given w as:</p><formula xml:id="formula_23">φ wi (d, τ t ) ∝ w d · (exp(−1/w d )) τt = w d · exp(−τ t /w d ).<label>(15)</label></formula><p>The potential, φ wi , can also be represented recur- sively as follows:</p><formula xml:id="formula_24">φ wi (d, τ t+1 ) = φ wi (d, τ t ) · exp(−1/w d ),<label>(16)</label></formula><p>since given a word d, τ t+1 = τ t +1 holds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>Now we explain experiments of DBO-CPD in two real-world datasets, stock prices and movie rev- enues. The first case is the historical end-of-day stock prices of five information technology corpo- rations. In the second dataset, we examine daily film revenues averaged by the number of theaters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>In the stock price dataset, we gather data for five different companies: Apple (AAPL), Google (GOOG), IBM (IBM), Microsoft (MSFT), and Facebook (FB). These companies were selected because they were the top 5 ranked in market value in 2015. We chose these technology companies because the announcement of new IT products and features and the interests of public media tend to be higher    News articles are collected from Google News and we use Google search queries to extract spe- cific articles related to each dataset in a specific time period. During the online article crawling, we store not only the titles of articles, HTML doc- uments, and publication dates, but also the num- ber of related articles. The number of articles is used to differentiate the weight of news articles during the training of regression. In the case of stock price data, we use two different queries to decrease noise. First, we search with the company name such as 'Google'. Then, we use queries spe- cific to stock 'NASDAQ:' to make the content of articles to be highly relevant to the stock market. In case of movie data, we search with the movie title with the additional word 'movie' to only col- lect articles related to the target movie.</p><p>With these collected articles, we used two ar-ticle extractors, newspaper (Ou-Yang, 2013) and python-goose <ref type="bibr" target="#b11">(Grangier, 2013)</ref>, to automate the text extraction of 291,057 HTML documents. Af- ter preprocessing, we could successfully extract texts from 287,389 (98.74%) HTMLs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Textual Feature Representation</head><p>After extracting texts from HTMLs, we tokenize the texts into words. We use three different tok- enization methods which are downcasing the char- acters, punctuation removal, and removing En- glish stop words. <ref type="table">Table 1</ref> shows the statistics on the corpora of collected news articles.</p><p>With these article corpora, we use a bag-of- words (BoW) representation to change each word into a vector representation where words from ar- ticles are indexed and then weighted. Using these vectors, we adopt three document representations, TF, TFIDF, and LOG1P, which extend BoW rep- resentation. TF and TFIDF <ref type="bibr" target="#b29">(Sparck Jones, 1972)</ref> calculate the importance of a word to a set of doc- uments based on term frequency. LOG1P ( <ref type="bibr" target="#b16">Kogan et al., 2009</ref>) calculates the logarithm of the word frequencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training BO-CPD</head><p>As we noted earlier, we use BO-CPD to train the regression model to learn high weight for words which are more related to changes. When we choose the parameters for the Gaussian Process of BO-CPD, we try to find the value which makes the distance of intervals between predicted change points around 1-2 weeks. This is because we as- sume that the information included in the articles will have an immediate effect on the data right af- ter it is published to the public, so the external information in texts will indicate the short-term causes for a future change.</p><p>For the reasonable comparison of BO-CPD and DBO-CPD, we use the same parameter for the Gaussian Process in both models. After several experiments we found that a = 1 and b = 1 for the Gaussian Process and λ gap = 250 is appropri- ate to train BO-CPD in the stock and film datasets. We separate the training and testing examples for cross-validation at a ratio of 2 : 1 for each year. Then we train each model differently by year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Learning the strength parameter w from Regression</head><p>The weight w of the regression model gives us an intuition of how a word is important which affect <ref type="bibr">2010 2011 2012 2013</ref>   to the length of the current run. With the predicted run length calculated in Section 3.3, we change the run length domain r ∈ R into 0 ≤ r ≤ 1 by pre- dicting e rt rather than r t to solve the interpretabil- ity problem. Therefore, we can think of a high weight w i as a powerful word which changes the current run length r to 0. To maintain the scala- bility of w, we normalize the weight by rescaling the range into w ∈ [−1, 1]. With the word rep- resentation calculated in Section 3.2, we train the regression model by using the number of relevant articles as the importance weight of training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Results</head><p>We evaluate the performance of BO-CPD and DBO-CPD by comparing the negative log likeli- hood (NLL) ( <ref type="bibr" target="#b33">Turner et al., 2009</ref>) of two models at time t as:</p><formula xml:id="formula_25">log p(x 1:T |w) = T t=1</formula><p>log p(x t |x 1:t−1 , w).</p><p>We calculate the marginal NLL by year and the re- sults are described in <ref type="table" target="#tab_3">Table 2 and Table 3</ref>. (Face- book data is not available before the year 2012.) The difference between DBO-CPD I and DBO- CPD II is whether the search queries include 'NASDAQ'. In stock data sets of 5 years, our model outperforms BO-CPD in Apple, Google, IBM, Microsoft dataset. The improvements of  <ref type="bibr">(19.1964</ref>) is smaller than BO-CPD (19.3438). The two zoomed intervals are the two longest intervals where the negative log likelihood of DBO-CPD is smaller than BO-CPD. The right table shows the sentences whose run length predicted by the regression model (described in Section 2.3) are the highest at the two zoomed points, which means the sentences are likely to appear near feature change points. The boldface words are the top 5 most strongly-weighted terms in the regression model. DBO-CPD compared to the BO-CPD is statisti- cally significant with 90% confidence in the four stocks except for stock of Facebook. We also found that most of the DBO-CPD II shows bet- ter results than DBO-CPD I and BO-CPD in most datasets due to noise reduction of texts through the additional search query 'NASDAQ:'. Out of 23 datasets, APPL in 2010 and FB in 2012 are the only datasets where NLLs of BO-CPD is smaller (better) than NLLs of DBO-CPD.</p><p>One of the advantages of using a linear model is that we can investigate what the model discov- ers about different terms. As shown in <ref type="figure" target="#fig_1">Figure 5</ref>, we can find negative semantic words such as vi- cious, whip, and desperately, and words represent- ing the status of a company like propel, innova- tions, and grateful are the most strongly-weighted terms in the regression model. We analyze and vi- sualize some change points where NLL of DBO- CPD is lower than NLL of BO-CPD. The results are shown in <ref type="figure" target="#fig_3">Figure 6</ref> and three sentences are the top 3 most weighted sentences in the regression model for two changes with the boldface words of top 5 strongly weighted terms like the terms big, money, and steadily. A particularly interest- ing case is the term earth which is found between Jan. 25 and Feb. 13 in 2013. After we investigated articles where the sentence is included, we found that Google announced a new tour guide feature in Google Earth on Jan. 31 and after this announce-  <ref type="table">Table 3</ref>: Negative log likelihood (NLL) of five movies (The Dark Knight, Inception, Avengers, Frozen, and Interstellar) without and with our model for 1 year from the release date of each movie.</p><p>ment the stock price increased. We can also find that the word million is also a positive term which can predict a new change in the near feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>In this paper, we propose a novel generative model for online inference to find change points from non-stationary time-series data. Unlike previ- ous approaches, our model can incorporate exter- nal information in texts which may includes the causes of signal changes. The main contribution of this paper is to combine the generative model for online change points detection and a regres- sion model learned from the weights of words in documents. Thus, our model accurately infers the conditional prior of the change points and auto- matically explains the reasons of a change by con- necting the numerical sequence of data and textual features of news articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Future work</head><p>Our DBO-CPD can be improved further by incor- porating more external information beyond docu- ments. In principle, our DBO-CPD can incorpo- rate other features if they are vectorized into a ma- trix form. Our implementation currently only uses the simple bag of words models (TF, TFIDF and LOG1P) to improve the baseline GP-based CPD models by bringing documents into change point detection. One possible direction of future work would explore ways to fully represent the rich in- formation in texts by extending the text features and language representations like continuous bag- of-words (CBOW) models <ref type="bibr" target="#b18">(Mikolov et al., 2013)</ref> or Global vectors for word representation (GloVe) ( <ref type="bibr" target="#b24">Pennington et al., 2014</ref>).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: This figure illustrates the recursive updates of the posterior probability in the DBO-CPD model. Even the BO-CPD model only uses current and previous run length to calculate the posterior, DBO-CPD can utilize the series of text documents to compute the conditional probability accurately.</figDesc><graphic url="image-3.png" coords="3,72.29,212.82,217.69,102.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: (a) Two plots show the results of BO-CPD (top) and DBO-CPD (middle) on Apple stock prices in January 2014. The stock price is plotted in light gray, with the predictive change points drawn as small circles. The red line represents the most likely predicted run-lengths for each day. The bottom figures are a set of visualizations of the top 15 strongly weighted words which are found at selected change points which BO-CPD is unable to predict. The size of each word represents the weight of its textual features learned during the training of the regression model.</figDesc><graphic url="image-6.png" coords="6,101.48,62.81,394.58,241.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 :</head><label>1</label><figDesc>Dimensions of the datasets used in this paper, after tokenizing and filtering the news ar- ticles. ':N' means the articles are collected with additional 'NASDAQ:' search query. The second dataset is a set of movie revenues averaged by the number of theaters for five months from the release date of film. We target 5 different movies: The Dark Knight (KNGHT), Inception (INCPT), The Avengers (AVGR), Frozen (FRZ) and Interstellar (INTRS), because these movies are on highest-grossing movie list and also are screened recently. The cumulative daily revenue per theater is collected from 'Box Office Mojo' (www.boxofficemojo.com).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: (b) The left plot illustrates daily stock prices of Google in 2013 from early January to late May. The black line represents the stock price, black circles indicate the predicted change points, and the red line shows the predicted run length calculated by DBO-CPD. The middle plot shows the negative log likelihood (NLL) of BO-CPD and DBO-CPD on the same data. The overall marginal NLL of DBO-CPD (19.1964) is smaller than BO-CPD (19.3438). The two zoomed intervals are the two longest intervals where the negative log likelihood of DBO-CPD is smaller than BO-CPD. The right table shows the sentences whose run length predicted by the regression model (described in Section 2.3) are the highest at the two zoomed points, which means the sentences are likely to appear near feature change points. The boldface words are the top 5 most strongly-weighted terms in the regression model.</figDesc><graphic url="image-7.png" coords="8,72.00,62.80,453.56,337.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>and lead to many news articles. We use the his- torical stock price data from the Google Finance service. 1 .</figDesc><table>category 
words documents words/doc 
AAPL 
15.0M 
29,459 
509 
AAPL:N 
11.0M 
18,896 
581 
GOOG 
15.0M 
29,422 
511 
GOOG:N 
8.2M 
13,658 
603 
IBM 
26.7M 
45,741 
583 
IBM:N 
3.4M 
4,741 
726 
MSFT 
20.5M 
35,905 
570 
MSFT:N 
3.5M 
5,070 
681 
FB 
18.9M 
38,168 
495 
FB:N 
4.3M 
6,625 
645 
KNGHT 
14.4M 
16,874 
852 
INCPT 
12.1M 
17,155 
705 
AVGR 
3.5M 
6,476 
537 
FRZ 
6.8M 
15,021 
454 
INTRS 
4.2M 
7,846 
538 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table</head><label></label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Negative log likelihood of five stocks 
(Apple, Google, IBM, Microsoft, and Facebook) 
without and with our model per year from 2010 
to 2014. DBO-CPD I represents the experiments 
without 'NASDAQ:' as a search query and DBO-
CPD II is the result of articles searched with 
'NASDAQ:'. Facebook data is not available be-
fore the year 2012. 

</table></figure>

			<note place="foot">T D (t, γ|γ+1) = P (D (γ) t |r t =γ + 1). (7) We represent the distribution of words by the bagof-words model. Let D i t be the set of M words that is part of the ith document at time t, i.e. D i t = {d i,1 t , d i,2 t , ..., d i,M t }. In the model, we assume that the probability of word d i,j t is independent and identically distributed (iid) given a run</note>

			<note place="foot" n="1"> https://www.google.com/finance</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>This work was supported by Basic Science Research Program through the National Re-search Foundation of Korea (NRF) grant funded by the Ministry of Science, ICT &amp; Future</head><p>Planning (MSIP) (NRF-2014R1A1A1002662), the NRF grant funded by the MSIP (NRF-2014M2A8A2074096).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prescott</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mackay</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0710.3742</idno>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
<note type="report_type">Bayesian online changepoint detection. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Product partition models for change point problems. The Annals of Statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Barry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>John A Hartigan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="260" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A bayesian analysis for change point problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Barry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>John A Hartigan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">421</biblScope>
			<biblScope unit="page" from="309" to="319" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Twitter mood predicts the stock market</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huina</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Testing and locating variance changepoints with application to stock prices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">438</biblScope>
			<biblScope unit="page" from="739" to="747" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Estimation and comparison of multiple change-point models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Chib</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of econometrics</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="221" to="241" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Bayesian changepoint analysis of tropical cyclone activity: The central north pacific case</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shin</forename><surname>Pao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Climate</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page" from="4893" to="4901" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Statistical distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Merran</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Hastings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Peacock</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">News sensitive stock trend prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Pui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheong</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">Xu</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in knowledge discovery and data mining</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="481" to="493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Stock prediction: Integrating text mining approach using real-time news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Pui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheong</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">Xu</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computational Intelligence for Financial Engineering</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="395" to="402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Using news articles to predict stock price movements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyozo</forename><surname>Gidófalvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Elkan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<pubPlace>San Diego</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science and Engineering, University of California</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Python-goose-article extractor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Grangier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The predictive power of online chatter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gruhl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramanathan</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasmine</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tomkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the Eleventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="78" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fast change point detection for electricity market analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaesik</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kesheng</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Big Data</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Tests for variance shift at an unknown time point</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Der-Ann</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Statistics</title>
		<imprint>
			<biblScope unit="page" from="279" to="284" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Classifying dialogue acts in one-onone live chats</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Cavedon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="862" to="871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Predicting risk from financial reports with regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shimon</forename><surname>Kogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitry</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><forename type="middle">S</forename><surname>Bryan R Routledge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Sagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>Human Language Technologies: Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="272" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Estimation and forecasting in models with multiple breaks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Koop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><forename type="middle">M</forename><surname>Potter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Review of Economic Studies</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="763" to="789" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Predicting movie sales from blogger sentiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilad</forename><surname>Mishne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalie</forename><forename type="middle">S</forename><surname>Glance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="155" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Event linking: Grounding event reference in a news archive</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Nothman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Hachey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James R</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="228" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Bayesian Gaussian processes for sequential prediction, optimisation and quadrature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Osborne</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
		<respStmt>
			<orgName>Oxford University New College</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">newspaper-news, full-text, and article metadata extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Ou-Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Trending sentimenttopic detection on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kam-Fai</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics and Intelligent Text Processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="66" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Empiricial Methods in Natural Language Processing</title>
		<meeting>the Empiricial Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Textual analysis of stock market prediction using financial news articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Schumaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsinchun</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings</title>
		<imprint>
			<biblScope unit="page">185</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>AMCIS</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Textual analysis of stock market prediction using breaking financial news: The azfin text system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsinchun</forename><surname>Schumaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Exploiting topic based twitter sentiment for stock prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huayi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaotie</forename><surname>Deng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A bayesian approach to inference about a change-point in a sequence of random variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afm</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="407" to="416" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A statistical interpretation of term specificity and its application in retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Sparck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jones</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of documentation</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="21" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Can twitter predict disease outbreaks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Connie</forename><surname>St Louis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gozde</forename><surname>Zorlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMJ</title>
		<imprint>
			<biblScope unit="page">344</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Bayesian retrospective multiplechangepoint identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Stephens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Statistics</title>
		<imprint>
			<biblScope unit="page" from="159" to="178" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Prediction and change detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1281" to="1288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Adaptive sequential bayesian change point detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunus</forename><surname>Saatci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><forename type="middle">Edward</forename><surname>Rasmussen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Bayesian inference in physics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toussaint</forename><surname>Udo Von</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reviews of Modern Physics</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">943</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">François Bar, and Shrikanth Narayanan. 2012. A system for real-time twitter sentiment analysis of 2012 us presidential election cycle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dogan</forename><surname>Can</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abe</forename><surname>Kazemzadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2012 System Demonstrations</title>
		<meeting>the ACL 2012 System Demonstrations</meeting>
		<imprint>
			<biblScope unit="page" from="115" to="120" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Modeling changing dependency structure in multivariate time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Machine Learning (ICML)</title>
		<meeting>the 24th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1055" to="1062" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Bayesian changepoint analysis for extreme events (typhoons, heavy rainfall, and heat waves): An rjmcmc approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pao-Shin</forename><surname>Chu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Climate</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1034" to="1046" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
