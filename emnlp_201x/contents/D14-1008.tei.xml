<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:13+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Constituent-Based Approach to Argument Labeling with Joint Inference in Discourse Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Kong</surname></persName>
							<email>kongfang@suda.edu.cn nght@comp.nus.edu.sg gdzhou@suda.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Soochow University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee</forename><forename type="middle">Tou</forename><surname>Ng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Soochow University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Constituent-Based Approach to Argument Labeling with Joint Inference in Discourse Parsing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="68" to="77"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Discourse parsing is a challenging task and plays a critical role in discourse analysis. In this paper, we focus on labeling full argument spans of discourse con-nectives in the Penn Discourse Treebank (PDTB). Previous studies cast this task as a linear tagging or subtree extraction problem. In this paper, we propose a novel constituent-based approach to argument labeling, which integrates the advantages of both linear tagging and sub-tree extraction. In particular, the proposed approach unifies intra-and inter-sentence cases by treating the immediately preceding sentence as a special constituent. Besides, a joint inference mechanism is introduced to incorporate global information across arguments into our constituent-based approach via integer linear programming. Evaluation on PDT-B shows significant performance improvements of our constituent-based approach over the best state-of-the-art system. It also shows the effectiveness of our joint inference mechanism in modeling global information across arguments.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Discourse parsing determines the internal struc- ture of a text and identifies the discourse rela- tions between its text units. It has attracted in- creasing attention in recent years due to its impor- tance in text understanding, especially since the release of the Penn Discourse Treebank (PDTB) corpus <ref type="bibr" target="#b11">(Prasad et al., 2008)</ref>, which adds a layer of discourse annotations on top of the Penn Treebank *</p><p>The research reported in this paper was carried out while Fang Kong was a research fellow at the National University of Singapore.</p><p>(PTB) corpus <ref type="bibr" target="#b8">(Marcus et al., 1993)</ref>. As the largest available discourse corpus, the PDTB corpus has become the defacto benchmark in recent studies on discourse parsing.</p><p>Compared to connective identification and dis- course relation classification in discourse parsing, the task of labeling full argument spans of dis- course connectives is much harder and thus more challenging. For connective identification, <ref type="bibr" target="#b7">Lin et al. (2014)</ref> achieved the performance of 95.76% and 93.62% in F-measure using gold-standard and automatic parse trees, respectively. For discourse relation classification, <ref type="bibr" target="#b7">Lin et al. (2014)</ref> achieved the performance of 86.77% in F-measure on clas- sifying discourse relations into 16 level 2 types. However, for argument labeling, <ref type="bibr" target="#b7">Lin et al. (2014)</ref> only achieved the performance of 53.85% in F- measure using gold-standard parse trees and con- nectives, much lower than the inter-annotation a- greement of 90.20% ( <ref type="bibr" target="#b9">Miltsakaki et al., 2004)</ref>.</p><p>In this paper, we focus on argument labeling in the PDTB corpus. In particular, we propose a nov- el constituent-based approach to argument label- ing which views constituents as candidate argu- ments. Besides, our approach unifies intra-and inter-sentence cases by treating the immediately preceding sentence as a special constituent. Final- ly, a joint inference mechanism is introduced to incorporate global information across arguments via integer linear programming. Evaluation on the PDTB corpus shows the effectiveness of our ap- proach.</p><p>The rest of this paper is organized as follows. Section 2 briefly introduces the PDTB corpus. Related work on argument labeling is reviewed in Section 3. In Section 4, we describe our constituent-based approach to argument labeling. In Section 5, we present our joint inference mech- anism via integer linear programming (ILP). Sec- tion 6 gives the experimental results and analysis. Finally, we conclude in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>68</head><p>As the first large-scale annotated corpus that fol- lows the lexically grounded, predicate-argument approach in D-LTAG (Lexicalized Tree Adjoin- ing Grammar for Discourse) <ref type="bibr" target="#b14">(Webber, 2004)</ref>, the PDTB regards a connective as the predicate of a discourse relation which takes exactly two text s- pans as its arguments. In particular, the text span that the connective is syntactically attached to is called Arg2, and the other is called Arg1.</p><p>Although discourse relations can be either ex- plicitly or implicitly expressed in PDTB, this pa- per focuses only on explicit discourse relations that are explicitly signaled by discourse connec- tives. Example (1) shows an explicit discourse re- lation from the article wsj 2314 with connective so underlined, Arg1 span italicized, and Arg2 s- pan bolded.</p><p>(1) But its competitors have much broader busi- ness interests and so are better cushioned against price swings .</p><p>Note that a connective and its arguments can ap- pear in any relative order, and an argument can be arbitrarily far away from its corresponding con- nective. Although the position of Arg2 is fixed once the connective is located, Arg1 can occur in the same sentence as the connective (SS), in a sen- tence preceding that of the connective (PS), or in a sentence following that of the connective (FS), with proportions of 60.9%, 39.1%, and less than 0.1% respectively for explicit relations in the PDT- B corpus <ref type="bibr" target="#b11">(Prasad et al., 2008)</ref>. Besides, out of all PS cases where Arg1 occurs in some preced- ing sentence, 79.9% of them are the exact imme- diately preceding sentence. As such, in this paper, we only consider the current sentence containing the connective and its immediately preceding sen- tence as the text span where Arg1 occurs, similar to what was done in ( <ref type="bibr" target="#b7">Lin et al., 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>For argument labeling in discourse parsing on the PDTB corpus, the related work can be classified into two categories: locating parts of arguments, and labeling full argument spans.</p><p>As a representative on locating parts of argu- ments, <ref type="bibr" target="#b15">Wellner and Pustejovsky (2007)</ref> proposed several machine learning approaches to identify the head words of the two arguments for discourse connectives. Following this work, <ref type="bibr" target="#b2">Elwell and Baldridge (2008)</ref> combined general and connec- tive specific rankers to improve the performance of labeling the head words of the two arguments. <ref type="bibr" target="#b12">Prasad et al. (2010)</ref> proposed a set of heuristics to locate the position of the Arg1 sentences for inter- sentence cases. The limitation of locating parts of arguments, such as the positions and head word- s, is that it is only a partial solution to argument labeling in discourse parsing.</p><p>In comparison, labeling full argument spans can provide a complete solution to argument labeling in discourse parsing and has thus attracted increas- ing attention recently, adopting either a subtree extraction approach ( <ref type="bibr" target="#b1">Dinesh et al. (2005)</ref>, <ref type="bibr" target="#b7">Lin et al. (2014)</ref>) or a linear tagging approach <ref type="bibr" target="#b3">(Ghosh et al. (2011)</ref>).</p><p>As a representative subtree extraction approach, <ref type="bibr" target="#b1">Dinesh et al. (2005)</ref> proposed an automatic tree subtraction algorithm to locate argument spans for intra-sentential subordinating connectives. How- ever, only dealing with intra-sentential subordinat- ing connectives is not sufficient since they con- stitute only 40.93% of all cases. Instead, <ref type="bibr" target="#b7">Lin et al. (2014)</ref> proposed a two-step approach. First, an argument position identifier was employed to lo- cate the position of Arg1. For the PS case, it di- rectly selects the immediately preceding sentence as Arg1. For other cases, an argument node iden- tifier was employed to locate the Arg1-and Arg2- nodes. Next, a tree subtraction algorithm was used to extract the arguments. However, as pointed out in <ref type="bibr" target="#b1">Dinesh et al. (2005)</ref>, it is not necessarily the case that a connective, Arg1, or Arg2 is dominated by a single node in the parse tree (that is, it can be dominated by a set of nodes). <ref type="figure" target="#fig_0">Figure 1</ref> shows the gold-standard parse tree corresponding to Exam- ple (1). It shows that Arg1 includes three nodes:  <ref type="formula" target="#formula_1">(1)</ref> mance with integration of the n-best results.</p><formula xml:id="formula_0">[ CC But],</formula><p>While the subtree extraction approach locates argument spans based on the nodes of a parse tree and is thus capable of using rich syntactic informa- tion, the linear tagging approach works on the to- kens in a sentence and is thus capable of capturing local sequential dependency between tokens. In this paper, we take advantage of both subtree ex- traction and linear tagging approaches by propos- ing a novel constituent-based approach. Further- more, intra-and inter-sentence cases are unified by treating the immediately preceding sentence as a special constituent. Finally, a joint inference mechanism is proposed to add global information across arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">A Constituent-Based Approach to Argument Labeling</head><p>Our constituent-based approach works by first casting the constituents extracted from a parse tree as argument candidates, then determining the role of every constituent as part of Arg1, Arg2, or NULL, and finally, merging all the constituents for Arg1 and Arg2 to obtain the Arg1 and Arg2 text spans respectively. Obviously, the key to the success of our constituent-based approach is constituent-based argument classification, which determines the role of every constituent argument candidate.</p><p>As stated above, the PDTB views a connective as the predicate of a discourse relation. Similar to semantic role labeling (SRL), for a given con- nective, the majority of the constituents in a parse tree may not be its arguments ( <ref type="bibr" target="#b16">Xue and Palmer, 2004</ref>). This indicates that negative instances (con- stituents marked NULL) may overwhelm positive instances. To address this problem, we use a simple algorithm to prune out these constituents which are clearly not arguments to the connective in question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Pruning</head><p>The pruning algorithm works recursively in pre- processing, starting from the target connective n- ode, i.e. the lowest node dominating the connec- tive. First, all the siblings of the connective node are collected as candidates, then we move on to the parent of the connective node and collect it- s siblings, and so on until we reach the root of the parse tree. In addition, if the target connec- tive node does not cover the connective exactly, the children of the target connective node are also collected.</p><p>For the example shown in <ref type="figure">Figure</ref>  It is not surprising that the pruning algorithm works better on gold parse trees than automatic parse trees. Using gold parse trees, our pruning al- gorithm can recall 89.56% and 92.98% (489 out of 546 Arg1s, 808 out of 869 Arg2s in the test data) of the Arg1 and Arg2 spans respectively and prune out 81.96% (16284 out of 19869) of the nodes in the parse trees. In comparison, when automatic parse trees (based on the Charniak parser <ref type="bibr" target="#b0">(Charniak, 2000</ref>)) are used, our pruning algorithm can recall 80.59% and 89.87% of the Arg1 and Arg2 spans respectively and prune out 81.70% (16190</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description</head><p>Example CON-Str</p><p>The string of the given connective (case-sensitive) so CON-LStr</p><p>The lowercase string of the given connective so</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CON-Cat</head><p>The syntactic category of the given connective: sub- ordinating, coordinating, or discourse adverbial Subordinating The path from the parent node of the connective to the node of the constituent and whether the number of left siblings of the connective is greater than one RB ↑ V P ↓ V P :&gt;1 <ref type="table">Table 1</ref>: Features employed in argument classification.</p><p>out of 19816) of the nodes in the parse trees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Argument Classification</head><p>In this paper, a multi-category classifier is em- ployed to determine the role of an argument can- didate (i.e., Arg1, Arg2, or NULL). <ref type="table">Table 1</ref> lists the features employed in argument classification, which reflect the properties of the connective and the candidate constituent, and the relationship be- tween them. The third column of <ref type="table">Table 1</ref> shows the features corresponding to <ref type="figure" target="#fig_0">Figure 1</ref>, consider- ing [ RB so] as the given connective and [ V P have much broader business interests] as the constituent in question. Similar to <ref type="bibr" target="#b7">Lin et al. (2014)</ref>, we obtained the syn- tactic category of the connectives from the list pro- vided in <ref type="bibr" target="#b6">Knott (1996)</ref>. However, different from <ref type="bibr" target="#b7">Lin et al. (2014)</ref>, only the siblings of the root path nodes (i.e., the nodes occurring in the path of the connective to root) are collected as the candidate constituents in the pruning stage, and the value of the relative position can be left or right, indicat- ing that the constituent is located on the left-or right-hand of the root path respectively. Besides, we view the root of the previous sentence as a spe- cial candidate constituent. For example, the value of the feature CON-NT-Position is previous when the current constituent is the root of the previous sentence. Finally, we use the part-of-speech (POS) combination of the constituent itself, its parent n- ode, left sibling node and right sibling node to rep- resent the context of the candidate constituent. In- tuitively, this information can help determine the role of the constituent.</p><p>For the example shown in <ref type="figure" target="#fig_0">Figure 1</ref>, we first em- ploy the pruning algorithm to get the candidate constituents, and then employ our argument clas- sifier to determine the role for every candidate. For example, if the five candidates are labeled as Arg1, Arg2, Arg2, Arg1, and Arg1, respectively, we merge all the Arg1 constituents to obtain the Arg1 text span (i.e., But its competitors have much broader business interests). Similarly, we merge the two Arg2 constituents to obtain the Arg2 text s- pan (i.e., and are better cushioned against price swings).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Joint Inference via Integer Linear Programming</head><p>In the above approach, decisions are always made for each candidate independently, ignoring global information across candidates in the final output. For example, although an argument span can be split into multiple discontinuous segments (e.g., the Arg2 span of Example (1) contains two dis- continuous segments, and, are better cushioned against price swings), the number of discontinu- ous segments is always limited. Statistics on the PDTB corpus shows that the number of discontin-uous segments for both Arg1 and Arg2 is generally (&gt;= 99%) at most 2. For Example (1), from left to right, we can obtain the list of constituent can- didates:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[ CC But], [ N P its competitors], [ V P have much broader business interests], [ CC and], [ V P</head><p>are better cushioned against price swings]. If our argument classifier wrongly determines the roles as Arg1, Arg2, Arg1, Arg2, and Arg1 respectively, we can find that the achieved Arg1 span contains three discontinuous segments. Such errors may be corrected from a global perspective. In this paper, a joint inference mechanism is in- troduced to incorporate various kinds of knowl- edge to resolve the inconsistencies in argumen- t classification to ensure global legitimate predic- tions. In particular, the joint inference mechanism is formalized as a constrained optimization prob- lem, represented as an integer linear programming (ILP) task. It takes as input the argument classi- fiers' confidence scores for each constituent can- didate along with a list of constraints, and outputs the optimal solution that maximizes the objective function incorporating the confidence scores, sub- ject to the constraints that encode various kinds of knowledge.</p><p>In this section, we meet the requirement of ILP with focus on the definition of variables, the objec- tive function, and the problem-specific constraints, along with ILP-based joint inference integrating multiple systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Definition of Variables</head><p>Given an input sentence, the task of argumen- t labeling is to determine what labels should be assigned to which constituents corresponding to which connective. It is therefore natural that en- coding the output space of argument labeling re- quires various kinds of information about the con- nectives, the argument candidates corresponding to a connective, and their argument labels.</p><p>Given an input sentence s, we define following variables:</p><p>(1) P : the set of connectives in a sentence.</p><p>(2) p ∈ P : a connective in P . (4) c ∈ C(p): an argument candidate.</p><p>(5) L: the set of argument labels {Arg1, Arg2, NULL }.</p><p>(6) l ∈ L: an argument label in L.</p><p>In addition, we define the integer variables as follows:</p><formula xml:id="formula_1">Z l c,p ∈ {0, 1}<label>(1)</label></formula><p>If Z l c,p = 1, the argument candidate c, which corresponds to connective p, should be assigned the label l. Otherwise, the argument candidate c is not assigned this label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">The Objective Function</head><p>The objective of joint inference is to find the best arguments for all the connectives in one sentence. For every connective, the pruning algorithm is first employed to determine the set of corresponding argument candidates. Then, the argument classifi- er is used to assign a label to every candidate. For an individual labeling Z l c,p , we measure the quality based on the confidence scores, f l,c,p , returned by the argument classifier. Thus, the objective func- tion can be defined as</p><formula xml:id="formula_2">max l,c,p f l,c,p Z l c,p<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Constraints</head><p>As the key to the success of ILP-based joint infer- ence, the following constraints are employed:</p><p>Constraint 1: The arguments corresponding to a connective cannot overlap with the connec- tive. Let c 1 , c 2 ..., c k be the argument candidates that correspond to the same connective and over- lap with the connective in a sentence. 1 Then this constraint ensures that none of them will be as- signed as Arg1 or Arg2.</p><formula xml:id="formula_3">k i=1 Z N U LL c i ,p = k<label>(3)</label></formula><p>Constraint 2: There are no overlapping or em- bedding arguments. Let c 1 , c 2 ..., c k be the argu- ment candidates that correspond to the same con- nective and cover the same word in a sentence. <ref type="bibr">2</ref> Then this constraint ensures that at most one of the constituents can be assigned as Arg1 or Arg2. That is, at least k − 1 constituents should be as- signed the special label NULL.</p><formula xml:id="formula_4">k i=1 Z N U LL c i ,p ≥ k − 1<label>(4)</label></formula><p>Constraint 3: For a connective, there is at least one constituent candidate assigned as Arg2.</p><formula xml:id="formula_5">c Z Arg2 c,p ≥ 1<label>(5)</label></formula><p>Constraint 4: Since we view the previous com- plete sentence as a special Arg1 constituent candi- date, denoted as m, there is at least one candidate assigned as Arg1 for every connective.</p><formula xml:id="formula_6">c Z Arg1 c,p + Z Arg1 m,p ≥ 1<label>(6)</label></formula><p>Constraint 5: The number of discontinuous constituents assigned as Arg1 or Arg2 should be at most 2. That is, if argument candidates c 1 , c 2 ..., c k corresponding to the same connective are discon- tinuous, this constraint ensures that at most two of the constituents can be assigned the same label Arg1 or Arg2.</p><formula xml:id="formula_7">k i=1 Z Arg1 c i ,p ≤ 2, and k i=1 Z Arg2 c i ,p ≤ 2<label>(7)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">System Combination</head><p>Previous work shows that the performance of ar- gument labeling heavily depends on the quality of the syntactic parser. It is natural that combining different argument labeling systems on differen- t parse trees can potentially improve the overall performance of argument labeling.</p><p>To explore this potential, we build two argu- ment labeling systems -one using the Berke- ley parser ( <ref type="bibr" target="#b10">Petrov et al., 2006</ref>) and the other the Charniak parser <ref type="bibr" target="#b0">(Charniak, 2000)</ref>. Previous s- tudies show that these two syntactic parsers tend to produce different parse trees for the same sen- tence ( <ref type="bibr" target="#b17">Zhang et al., 2009</ref>). For example, our pre- liminary experiment shows that applying the prun- ing algorithm on the output of the Charniak parser produces a list of candidates with recall of 80.59% and 89.87% for Arg1 and Arg2 respectively, while achieving recall of 78.6% and 91.1% for Arg1 and Arg2 respectively on the output of the Berkeley parser. It also shows that combining these two can- didate lists significantly improves recall to 85.7% and 93.0% for Arg1 and Arg2, respectively. In subsection 5.2, we only consider the con- fidence scores returned by an argument classifier. Here, we proceed to combine the probabilities pro- duced by two argument classifiers. There are two remaining problems to resolve:</p><p>• How do we unify the two candidate lists?</p><p>In principle, constituents spanning the same sequence of words should be viewed as the same candidate. That is, for different can- didates, we can unify them by adding phan- tom candidates. This is similar to the ap- proach proposed by <ref type="bibr" target="#b13">Punyakanok et al. (2008)</ref> for the semantic role labeling task. For exam- ple, <ref type="figure" target="#fig_4">Figure 2</ref> shows the candidate lists gen- erated by our pruning algorithm based on t- wo different parse trees given the segment "its competitors have much broader business interests". Dashed lines are used for phan- tom candidates and solid lines for true can- didates. Here, system A produces one can- didate a1, with two phantom candidates a2 and a3 added. Analogously, phantom can- didate b3 is added to the candidate list out- put by System B. In this way, we can get the unified candidate list: "its competitors have much broader business interests", "its com- petitors", "have much broader business inter- ests".</p><p>• How do we compute the confidence score for every decision? For every candidate in the unified list, we first determine whether it is a true candidate based on the specific parse tree. Then, for a true candidate, we extrac- t the features from the corresponding parse tree. On this basis, we can determine the confidence score using our argument classi- fier. For a phantom candidate, we set the same prior distribution as the confidence s- core. In particular, the probability of the "NULL" class is set to 0.55, following <ref type="bibr" target="#b13">(Punyakanok et al., 2008)</ref>, and the probabilities of Arg1 and Arg2 are set to their occurrence fre- quencies in the training data. For the example shown in <ref type="figure" target="#fig_4">Figure 2</ref>, since System A return- s "its competitors have much broader busi- ness interests" as a true candidate, we can ob- tain its confidence score using our argumen- t classifier. For the two phantom candidates -"its competitors" and "have much broader business interests" -we use the prior dis- tributions directly. This applies to the candi- dates for System B. Finally, we simply aver- age the estimated probabilities to determine the final probability estimate for every candi- date in the unified list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>In this section, we systematically evaluate our constituent-based approach with a joint inference mechanism to argument labeling on the PDTB corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental settings</head><p>All our classifiers are trained using the OpenNLP maximum entropy package 3 with the default pa- rameters (i.e. without smoothing and with 100 iterations). As the PDTB corpus is aligned with the PTB corpus, the gold parse trees and sentence boundaries are obtained from PTB. Under the au- tomatic setting, the NIST sentence segmenter 4 and the Charniak parser 5 are used to segment and parse the sentences, respectively. lp solve 6 is used for our joint inference. This paper focuses on automatically labeling the full argument spans of discourse connec- tives. For a fair comparison with start-of-the- art systems, we use the NUS PDTB-style end- to-end discourse parser 7 to perform other sub- tasks of discourse parsing except argument label- ing, which includes connective identification, non-explicit discourse relation identification and clas- sification.</p><p>Finally, we evaluate our system on two aspects: (1) the dependence on the parse trees (GS/Auto, using gold standard or automatic parse trees and sentence boundaries); and (2) the impact of errors propagated from previous components (noEP/EP, using gold annotation or automatic results from previous components). In combination, we have four different settings: GS+noEP, GS+EP, Au- to+noEP and Auto+EP. Same as <ref type="bibr" target="#b7">Lin et al. (2014)</ref>, we report exact match results under these four set- tings. Here, exact match means two spans match identically, except beginning or ending punctua- tion symbols.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Experimental results</head><p>We first evaluate the effectiveness of our constituent-based approach by comparing our sys- tem with the state-of-the-art systems, ignoring the joint inference mechanism. Then, the con- tribution of the joint inference mechanism to our constituent-based approach, and finally the contri- bution of our argument labeling system to the end- to-end discourse parser are presented. Effectiveness of our constituent-based ap- proach</p><p>By comparing with two state-of-the-art argu- ment labeling approaches, we determine the effec- tiveness of our constituent-based approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with the linear tagging approach</head><p>As a representative linear tagging approach, <ref type="bibr" target="#b3">Ghosh et al. (2011;</ref><ref type="bibr" target="#b5">2012;</ref><ref type="bibr" target="#b5">2012)</ref> only reported the exact match results for Arg1 and Arg2 using the evaluation script for chunking evaluation 8 under GS+noEP setting with Section 02-22 of the PDTB corpus for training, Section 23-24 for testing, and Section 00-01 for development. It is also worth mentioning that an argument span can contain multiple discontinuous segments (i.e., chunks), so chunking evaluation only shows the exact match of every argument segment but not the exact match of every argument span. In order to fairly compare our system with theirs, we evaluate our system us- ing both the exact metric and the chunking eval- uation. <ref type="table">Table 2</ref> compares the results of our sys- tem without joint inference and the results report- ed by  on the same data split. We can find that our system performs much bet-ter than Ghosh's on both Arg1 and Arg2, even on much stricter metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Systems</head><p>Arg1 Arg2 ours using exact match 65.68 84.50 ours using chunking evaluation 67.48 88.08 reported by  59.39 79.48 <ref type="table">Table 2</ref>: Performance (F1) comparison of our ar- gument labeling approach with the linear tagging approach as adopted in  Comparison with the subtree extracting ap- proach</p><p>For a fair comparison, we also conduct our experiments on the same data split of <ref type="bibr" target="#b7">Lin et al. (2014)</ref> with Section 02 to 21 for training, Sec- tion 22 for development, and Section 23 for test- ing. <ref type="table">Table 3</ref> compares our labeling system without joint inference with <ref type="bibr" target="#b7">Lin et al. (2014)</ref>, a representa- tive subtree extracting approach. From the results, we find that the performance of our argument la- beling system significantly improves under all set- tings. This is because <ref type="bibr" target="#b7">Lin et al. (2014)</ref> considered all the internal nodes of the parse trees, whereas the pruning algorithm in our approach can effec- tively filter out those unlikely constituents when determining Arg1 and Arg2.  <ref type="table">Table 3</ref>: Performance (F1) comparison of our ar- gument labeling approach with the subtree extrac- tion approach as adopted in <ref type="bibr" target="#b7">Lin et al. (2014)</ref> As justified above, by integrating the advan- tages of both linear tagging and subtree extraction, our constituent-based approach can capture both rich syntactic information from parse trees and local sequential dependency between tokens. The results show that our constituent-based approach indeed significantly improves the performance of argument labeling, compared to both linear tagging and subtree extracting approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Setting</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contribution of Joint Inference</head><p>Same as <ref type="bibr" target="#b7">Lin et al. (2014)</ref>, we conduct our ex- periments using Section 02 to 21 for training, Sec- tion 22 for development, and Section 23 for test- ing. <ref type="table" target="#tab_2">Table 4</ref> lists the performance of our argumen- t labeling system without and with ILP inference under four different settings, while <ref type="table" target="#tab_3">Table 5</ref> reports the contribution of system combination. It shows the following:</p><p>• On the performance comparison of Arg1 and Arg2, the performance on Arg2 is much bet- ter than that on Arg1 with the performance gap up to 8% under different settings. This is due to the fact that the relationship between Arg2 and the connective is much closer. This result is also consistent with previous studies on argument labeling.</p><p>• On the impact of error propagation from con- nective identification, the errors propagated from connective identification reduce the per- formance of argument labeling by less than 2% in both Arg1 and Arg2 F-measure under different settings.</p><p>• On the impact of parse trees, using automat- ic parse trees reduces the performance of ar- gument labeling by about 5.5% in both Arg1 and Arg2 F-measure under different settings.</p><p>In comparison with the impact of error prop- agation, parse trees have much more impact on argument labeling.</p><p>• On the impact of joint inference, it improves the performance of argument labeling, espe- cially on automatic parse trees by about 2%. 9</p><p>• On the impact of system combination, the performance is improved by about 1.5%.   Lastly, we focus on the contribution of our ar- gument labeling approach to the overall perfor- mance of the end-to-end discourse parser. This is done by replacing the argument labeling mod- el of the NUS PDTB-style end-to-end discourse parser with our argument labeling model. <ref type="table">Table 6</ref> shows the results using gold parse trees and auto- matic parse trees, respectively. <ref type="bibr">10</ref> From the results, we find that using gold parse trees, our argument labeling approach significantly improves the per- formance of the end-to-end system by about 1.8% in F-measure, while using automatic parse trees, the improvement significantly enlarges to 6.7% in F-measure.  <ref type="table">Table 6</ref>: Performance (F1) of the end-to-end dis- course parser.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we focus on the problem of auto- matically labeling the full argument spans of dis- course connectives. In particular, we propose a constituent-based approach to integrate the advan- tages of both subtree extraction and linear tagging approaches. Moreover, our proposed approach in- tegrates inter-and intra-sentence argument label- ing by viewing the immediately preceding sen- tence as a special constituent. Finally, a join- t inference mechanism is introduced to incorpo- rate global information across arguments into our <ref type="bibr">10</ref> Further analysis found that the error propagated from sentence segmentation can reduce the performance of the end-to-end discourse parser. Retraining the NIST sentence segmenter using Section 02 to 21 of the PDTB corpus, the original NUS PDTB-style end-to-end discourse parser can achieve the performance of 25.25% in F-measure, while the new version (i.e. replace the argument labeling model with our argument labeling model) can achieve the performance of 30.06% in F-measure. constituent-based approach via integer linear pro- gramming.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>[Figure 1 :</head><label>1</label><figDesc>Figure 1: The gold-standard parse tree corresponding to Example (1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>1, we can lo- cate the target connective node [ RB so] and return five constituents -[ V P have much broader busi- ness interests], [ CC and], [ V P are better cushioned against price swings], [ CC But], and [ N P its com- petitors] -as argument candidates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>CON-iLSib Number of left siblings of the connective 2 CON-iRSib Number of right siblings of the connective 1 NT-Ctx The context of the constituent. We use POS combi- nation of the constituent, its parent, left sibling and right sibling to represent the context. When there is no parent or siblings, it is marked NULL. VP-VP-NULL-CC CON-NT-Path The path from the parent node of the connective to the node of the constituent RB ↑ V P ↓ V P CON-NT-Position The position of the constituent relative to the connec- tive: left, right, or previous left CON-NT-Path-iLsib</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>( 3 )</head><label>3</label><figDesc>C(p): the set of argument candidates corre- sponding to connective p. (i.e., the parse tree nodes obtained in the pruning stage).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example on unifying different candidates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Performance (F1) of our argument label-
ing approach. 

Contribution to the end-to-end discourse pars-
er </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Contribution of System Combination in 
Joint Inference. 

</table></figure>

			<note place="foot" n="1"> Only when the target connective node does not cover the connective exactly and our pruning algorithm collects all the children of the target connective node as part of constituent candidates, such overlap can be introduced. 2 This constraint only works in system combination of Section 5.4, where additional phantom candidates may introduce such overlap.</note>

			<note place="foot" n="3"> http://maxent.sourceforge.net/ 4 http://duc.nist.gov/duc2004/software/duc2003 .breakSent.tar.gz 5 ftp://ftp.cs.brown.edu/pub/nlparser/ 6 http://lpsolve.sourceforge.net/ 7 http://wing.comp.nus.edu.sg/ linzihen/parser/</note>

			<note place="foot" n="8"> http://www.cnts.ua.ac.be/conll2000/chunking/ conlleval.txt</note>

			<note place="foot" n="9"> Unless otherwise specified, all the improvements in this paper are significant with p &lt; 0.001.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research is supported by the Singapore Na-tional Research Foundation under its International Research Centre @ Singapore Funding Initiative and administered by the IDM Programme Office. This research is also partially supported by Key project 61333018 and 61331011 under the Nation-al Natural Science Foundation of China.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Addendum to Paper approved by SIGDAT board in October 2015</head><p>This addendum concerns EMNLP 2014 paper Fang Kong;; Hwee Tou Ng;; Guodong Zhou. A Constituent-­Based Approach to Argument Labeling with Joint Inference in Discourse 68 -­ 77. Due to experimental setting and evaluation problems in the code written by the first author for the paper, the reported results can not be replicated and the conclusion that joint inference significantly improves the performance of argument labeling fails to be supported.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A maximum-entropyinspired parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Meeting of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the First Meeting of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="132" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Attribution and the (non-)alignment of syntactic and discourse arguments of connectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Dinesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Miltsakaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rashmi</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Frontiers in Corpus Annotation II: Pie in the Sky</title>
		<meeting>the Workshop on Frontiers in Corpus Annotation II: Pie in the Sky</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="29" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Discourse connective argument identification with connective specific rankers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Elwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second IEEE International Conference on Semantic Computing</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="198" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Shallow discourse parsing with conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sucheta</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Riccardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Tonelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Joint Conference on Natural Language Processing</title>
		<meeting>the 5th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1071" to="1079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Global features for shallow discourse parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sucheta</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Riccardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="150" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">End-to-End Discourse Parsing using Cascaded Structured Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sucheta</forename><surname>Ghosh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
		<respStmt>
			<orgName>University of Trento</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A Data-Driven Methodology for Motivating a Set of Coherence Relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alistair</forename><surname>Knott</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
		<respStmt>
			<orgName>University of Edinburgh</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A PDTB-styled end-to-end discourse parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee</forename><forename type="middle">Tou</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="151" to="184" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of English: The Penn Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Marcinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The Penn Discourse Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Miltsakaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rashmi</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Conference on Language Resources and Evaluation</title>
		<meeting>the Fourth International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="2237" to="2240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning accurate, compact, and interpretable tree annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Thibaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="433" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Penn Discourse TreeBank 2.0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rashmi</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Dinesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Miltsakaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Livio</forename><surname>Robaldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the LREC 2008 Conference</title>
		<meeting>the LREC 2008 Conference</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="2961" to="2968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exploiting scope for shallow discourse parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rashmi</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Conference on Language Resources and Evaluation</title>
		<meeting>the Seventh International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The important of syntactic parsing and inference in semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasin</forename><surname>Punyakanok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="257" to="287" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">D-LTAG: extending lexicalized TAG to discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="751" to="779" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automatically identifying the arguments of discourse connectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Wellner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="92" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Calibrating features for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2004 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>2004 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="88" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">K-best combination of syntactic parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chew</forename><surname>Lim Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haizhou</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1552" to="1560" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
