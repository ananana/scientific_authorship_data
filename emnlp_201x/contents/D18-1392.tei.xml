<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:00+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Residualized Factor Adaptation for Community Social Media Prediction Tasks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammadzaman</forename><surname>Zamani</surname></persName>
							<email>mzamani@cs.stonybrook.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Andrew</forename><surname>Schwartz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronica</forename><forename type="middle">E</forename><surname>Lynn</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salvatore</forename><surname>Giorgi</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niranjan</forename><surname>Balasubramanian</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Residualized Factor Adaptation for Community Social Media Prediction Tasks</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="3560" to="3569"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>3560</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Predictive models over social media language have shown promise in capturing community outcomes, but approaches thus far largely neglect the socio-demographic context (e.g. age, education rates, race) of the community from which the language originates. For example, it may be inaccurate to assume people in Mobile, Alabama, where the population is relatively older, will use words the same way as those from San Francisco, where the median age is younger with a higher rate of college education. In this paper, we present residualized factor adaptation, a novel approach to community prediction tasks which both (a) effectively integrates community attributes, as well as (b) adapts linguistic features to community attributes (factors). We use eleven demographic and socioeconomic attributes, and evaluate our approach over five different community-level predictive tasks, spanning health (heart disease mortality, percent fair/poor health), psychology (life satisfaction), and economics (per-cent housing price increase, foreclosure rate). Our evaluation shows that residualized factor adaptation significantly improves 4 out of 5 community-level outcome predictions over prior state-of-the-art for incorporating socio-demographic contexts.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Adapting to human factors has been shown to ben- efit NLP tasks, especially in tasks that involve pre- dictions over individual social media posts (e.g., sentiment <ref type="bibr" target="#b14">(Hovy, 2015)</ref>, sarcasm, and stance de- tection ( <ref type="bibr" target="#b16">Lynn et al., 2017)</ref>). The main idea be- hind these approaches is that knowing who wrote a piece of text can help models better understand how to process it. This paper develops methods that apply this idea to community-level prediction tasks, which require making decisions over posts from a community of users. Many community- level outcomes and community-wide language are linked to socio-demographic factors (age, gender, race, education, income levels) with many so- cial scientific studies supporting their predictive value ( <ref type="bibr" target="#b3">Cohen et al., 2003)</ref>, and should therefore affect how a model treats social media-based lan- guage features. For example, a high prevalence of the word "bike" in San Francisco, CA might be a signal that exercise is common in the area, while its high prevalence in Mobile, Alabama might in- dicate greater interest in motor bikes. We present a method for building language-based predictive models which integrate in and adapt to attributes of the communities generating the language.</p><p>This work aims to unify two different ap- proaches developed for adapting to human fac- tors and use them for incorporating community at- tributes in community-level prediction tasks: (1) residualized controls: whereby a model is trained in two steps: first over the factors/controls and then fitting the language to the residuals of the control model ( <ref type="bibr">Zamani and Schwartz, 2017)</ref>, and (2) user-factor adaptation: whereby linguistic features are adapted, or treated differently, based on the continuous-valued factors of the authors of the features ( <ref type="bibr" target="#b16">Lynn et al., 2017)</ref>.</p><p>Combining factor adaptation (FA) and residu- alized control (RC) into RFA is a non-trivial task. The intent behind both methods are quite different: whereas RC attempts to address the inherent het- erogeneity between robust control variables and noisy linguistic variables, FA enables a model to treat linguistic features differently depending on the factors. From a statistical learning perspec- tive, RC separates inference over controls from in- ference over language (model level integration), while FA brings controls and language together and makes the inference as one single step (data level integration). Additionally, FA has stricter bounds in the number of factors it can accommo- date because each new factor has a multiplicative effect on the number of learned parameters. On the other hand, each new factor for RC typically only adds one new parameter. Here, we endeavour to develop RFA such that it achieves the benefits of both approaches with little lost to the limitations. RFA inherits the challenges of the FA method with feature explosion. We address this through a sys- tematic exploration of both feature and factor se- lection.</p><p>The main contributions of this work include: (1) the introduction of residualized factor adaptation which effectively combines extra-linguistic and language features, (2) the first empirical evalua- tion of applying factor adaptation for community- level prediction tasks, (3) analysis of the impact of the size of factors and factor selection in adapta- tion, and (4) state-of-the-art accuracies for each of the five tasks for which we evaluate RFA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Social media provides easy access to a vast amount of language written by a diverse group of users, making it an increasingly popular re- source for measuring community health, psychol- ogy, and economics ( <ref type="bibr" target="#b4">Coppersmith et al., 2015;</ref><ref type="bibr" target="#b9">Eichstaedt et al., 2015;</ref><ref type="bibr" target="#b23">Weeg et al., 2015;</ref><ref type="bibr" target="#b17">Mowery et al., 2016;</ref><ref type="bibr" target="#b13">Haimson and Hayes, 2017)</ref>. <ref type="bibr" target="#b4">Coppersmith et al. (2015)</ref>, for instance, examine trends in language use among Twitter users who self- reported one of ten mental health diagnoses. <ref type="bibr" target="#b9">Eichstaedt et al. (2015)</ref> and <ref type="bibr" target="#b23">Weeg et al. (2015)</ref> use Twitter to predict the prevalence rates of various health outcomes, such as heart disease mortality and depression, at the county level. <ref type="bibr" target="#b13">Haimson and Hayes (2017)</ref> tracked changes in the emotional well-being of transgender communities on Tumblr between 2015 and 2016.</p><p>Socio-demographics are often correlated with health outcomes (such as age and heart disease), which is why such variables are often used as con- trols during analysis <ref type="bibr" target="#b4">(Coppersmith et al., 2015;</ref><ref type="bibr" target="#b8">Dos Reis and Culotta, 2015;</ref><ref type="bibr" target="#b9">Eichstaedt et al., 2015;</ref><ref type="bibr" target="#b23">Weeg et al., 2015</ref>). Because of their predic- tive power, socio-demographics and other extra- linguistic information can additionally be lever- aged when building the model itself.</p><p>However, a central challenge in integrating community attributes is that they have very differ- ent properties than linguistic features and can be lost, in essence, like a needle in a haystack. For example, linguistic features like n-grams are high dimensional, with each dimension having high co- variance with other dimensions and likely very lit- tle relationship with the outcome. On the other hand community features may be measured more robustly and are relatively low dimensional, of- ten obtained through well-defined measurements. Not surprisingly, <ref type="bibr">Zamani and Schwartz (2017)</ref> showed a naive combination that simply concate- nates these two sets of features risks losing the ef- fective extra-linguistic features in a sea of weak linguistic features. They go on to show a resid- ualized control approach achieves significantly greater accuracy at economic prediction by first learning a model using extra-linguistic features (i.e. controls or community factors) and then train a language model on top of the residual error of the previous model. It is possible that even when extra-linguistic features are not directly beneficial for prediction, they can still affect people's language. Other re- lated works consider how the meaning of lan- guage changes depending on who states it. For instance, when an NLP PhD student says the word 'paper' he/she usually means something different than when a 5 th grade student uses the same word (i.e. 'research paper' versus 'piece of paper'). <ref type="bibr" target="#b15">Hu et al. (2017)</ref> noted the same words can have different meanings if different people say them. This idea of contextualizing language with extra- linguistic information has been the basis for mul- tiple models: Hovy (2015) learn age-and gender- specific word embeddings, leading to significant improvements for three text classification tasks. <ref type="bibr" target="#b22">Volkova et al. (2013)</ref> found that using gender- specific features lead to improvements in senti- ment analysis over a gender-agnostic model. Most recently, <ref type="bibr" target="#b16">Lynn et al. (2017)</ref> proposed a domain adaptation-inspired method for composing user- level, extra-linguistic information with message- level features, leading to improvements for mul- tiple text classification tasks; we build off of this approach and that of <ref type="bibr">Zamani and Schwartz (2017)</ref> in this paper.</p><p>While <ref type="bibr" target="#b16">Lynn et al. (2017)</ref> injected user-level info into message-level tasks, we are investigat- ing whether same-level adaptation techniques are similarly useful.</p><p>We also try to find the circumstances under which each of the adaptation and residualized con- trol approaches are more powerful, and we take on the non-trivial task of exploiting concepts from both the adaptation and the residualized control techniques at the same time, finding that they add even more power when combined with one an- other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>We describe residualized factor adaptation (RFA), an approach to text-based prediction utilizing extra-linguistic factors (also called controls -often demographic or socioeconomic information). The key challenge for RFA lies in effectively combin- ing two different types of features. The language- based features, extracted from the tweets, are nu- merous but are only weak indicators of the out- comes. The socioeconomic and demographic fea- tures, on the other hand, are strong indicators but fewer in number. Naively combining both sets of features ignores this crucial difference in their pre- dictive abilities, potentially resulting in important features getting drowned out.</p><p>We first describe two methods that effectively combine extra-linguistic factors at two different levels: 1) Residualized control is a model-level combination method which builds different mod- els for each type of feature, then combines the re- sults of these models to make the final outcome prediction. 2) Factor adaptation is a feature-level combination method that composes the two fea- ture sets with one another to produce a trans- formed feature space over which a single model may be built. Finally, we present our combined method of Residualized Factor Adaptation which takes advantage of both concepts without explod- ing model parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Residualized Control Prediction</head><p>Language-based features and community-level at- tributes are qualitatively different modalities. The extra-linguistic variables, while few in number, are mostly unbiased and follow a normal distribution, which can be used to build a strong outcome pre- dictor. However, without special treatment, the signal in extra-linguistic variables can be over- whelmed when combined with a large number of language-based features.</p><p>The residualized control approach ( <ref type="bibr">Zamani and Schwartz, 2017)</ref> avoids this issue by building two models. The first is a prediction model built over the extra-linguistic variables (or controls) alone. The error, or residuals, produced by this first model represents the information that was unable to be predicted using the extra-linguistic variables alone. The language-based features are there- fore brought in to improve upon the initial predic- tions by using the residuals as training labels for a model based on the linguistic features. In this way, the language-based features are able to account for additional information not captured by the initial extra-linguistic feature-only model. At test time, each instance is fed to both prediction models, and the final outcome is given as a sum of the predic- tions from both models -the outcome predicted by the extra-linguistic model adjusted for error by the language-based model.</p><p>Formally, given extra-linguistic features X EL and language features X L , the residualized control models are built as follows:</p><formula xml:id="formula_0">ˆ Y = α × X EL + β (1) = Y − ˆ Y (2) γ × X L + λ (3)</formula><p>The extra-linguistic control model is parameter- ized by α weights and the β bias term. denotes the residual, i.e., the error of the extra-linguistic model. The language-based model aims to predict the residuals, with γ weights and the λ bias term as parameters.</p><p>The motivation for this approach is that extra- linguistic features are more informative and less noisy than the language ones. By exploiting this two-stage learning procedure, the model is biased toward favoring the role of extra-linguistics over language features, which prevents the powerful but rare extra-linguistic features from being lost among thousands of noisy language features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Factor Adaptation</head><p>Lynn et al. <ref type="formula" target="#formula_4">(2017)</ref> introduced user-factor adap- tation, a technique for combining message-level features with user-level information (or factors) at the feature level. User-factor adaptation, which is based on the feature augmentation approach for domain adaptation <ref type="bibr" target="#b7">(Daumé III, 2007)</ref>, uses the extra-linguistic features to transform the language- based features. Each of the language-based fea- tures has additional, corresponding features that are a composite of itself and an extra-linguistic factor. In this way, the model is able to capture both factor-specific and factor-general properties of each of the language-based features.</p><p>Following the work of <ref type="bibr" target="#b16">Lynn et al. (2017)</ref>, we use a multiplicative composition function for com- bining the linguistic and extra-linguistic features.</p><p>Instead of using user-level factors, we use extra- linguistic variables obtained at the community level, as described below. More formally, let V j be a matrix such that:</p><formula xml:id="formula_1">∀j ∈ {0, d} : V j = v j 1 l (4)</formula><p>where d is the number of extra-linguistic fac- tors. With n as the number of data instances, let v j be a column vector of height n where element v j,i is the score of extra-linguistic feature j for in- stance i. Having l as the number of language vari- ables, in Eq. 4 for each factor j we make a matrix of size n × l, named V j , in which every column is equal to v j , and V j has the same dimensions as language feature matrix X L . Now for each factor j we use the Hadamard product to multiply V j with X L . In this way each row of X L will be multi- plied by the corresponding row in V j , which is also equal to the corresponding value in v j . We there- fore can write the factor adaptation as follows:</p><formula xml:id="formula_2">X A = [V 1 X L , V 2 X L , · · · , V d X L ] (5)</formula><p>The adapted features together with the original language-based features are used for building a single prediction model:</p><formula xml:id="formula_3">ˆ Y = α × [X L , X A ] + β<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Residualized Factor Adaptation</head><p>Even though both the residualized control and fac- tor adaptation approaches exploit extra-linguistics, they combine these in very different ways. The former does it at the model level by learning dif- ferent models for different types of features and combining those models together. The latter does it at the data level by first combining both sets of features into a transformed feature set and then learning a single model on the obtained features. In addition, these approaches have different moti- vations and aim to accomplish different objectives. These modeling differences suggest that the two approaches could have complementary ben- efits. Residualized factor adaptation (RFA), our proposed method, inherits the advantages of both the residualized control and adaptation techniques, and is depicted in <ref type="figure" target="#fig_0">Fig. 1</ref>. There are four main steps:</p><p>Step 1: Extra-linguistic control model. We build a regression model solely based on the extra- linguistics, as shown in Equation 1, and then com- pute the residual error of that model as in Equa- tion 2. This error is ultimately used as the outcome label in the final step of RFA.</p><p>Step 2: Factor selection. Adaptation to many fac- tors can increase the model parameters drastically. We explore multiple options for selecting a subset of factors from the available extra-linguistic vari- ables. First, we consider manually selected extra- linguistic factors that are known to influence lan- guage use more than others. Second, we use the correlation of the factors with the outcome. Last, we use PCA, an unsupervised method to gener- ate new, lower-dimensional factors from the orig- inals. The purpose of factor selection is to reduce the variance and chance of overfitting.</p><p>Step 3: Factor adaptation. We modify the orig- inal factor adaptation approach to account for the larger number of factors and features in this task. First, we normalize selected factors by min-max scaling and then multiply the language features by these selected factors as shown in Eq. 5. As we describe later on in Section 4.2, we use n- grams and topics as separate feature sets of lan- guage data, so adaptation gives us two correspond- ing sets of features: adapted n-grams and adapted topics. We then standardize the adapted features using Z-scores and perform feature reduction on each of the four sets of features separately. These reduced features sets are concatenated into a single large set and fed as input to a learning algorithm in the next step.</p><p>Step 4: Residual Prediction. The final step, as shown in Eq. 7, is to learn the residual errors of the extra-linguistic control model, using language and adapted language features. Here, we first ap- ply feature selection and reduction on each lan- guage feature set: topics, n-grams, adapted-topics and adapted-n-grams. Then we put all of them into a single feature space on which we learn a model to predict the residual error from Step 1.</p><p>To produce the final outcome predictions, the pre- dicted error from this model is combined with the predicted outcomes of the extra-linguistic control model from Step 1.</p><p>The choice of feature selection is vital for RFA, both due to the fact that it multiplies the number</p><note type="other">of language features by the number of extra-linguistic features, and because it uses extra- linguistic features at two levels, one separately and one in integration with language features, poten- tially leading to overfitting. In Section 5.2, we in- vestigate different methods for feature selection to improve RFA's performance.</note><p>As <ref type="figure" target="#fig_0">Fig. 1</ref> shows, RFA is structured similarly to residualized control. However, residualized con- trol uses language data at its final step, whereas RFA uses both language and adapted language, which is obtained using the factor adaptation tech- nique. This helps RFA to benefit from the ad- vantages of both residualized control and factor adaptation. In other words, RFA combines lin- guistic and extra-linguistic features on both the feature/data level and the model level. Eq. 7 for- mulates the RFA method, in which comes from Eq. 2 and X A is defined in Eq. 5.</p><formula xml:id="formula_4">γ × [X L , X A ] + λ<label>(7)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation Setup</head><p>Our task is to predict various community-level outcomes based on publicly available data, in- cluding social media and other extra-linguistic data such as socioeconomic and demographic in- formation. We focus on two health-related out- comes: heart disease mortality rate ( </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Set</head><p>Our evaluation dataset includes information from three sources: (1) language data from Twitter messages, (2) extra-linguistic data consisting of 11 socioeconomic and demographic variables, and (3) outcome data consisting of 5 county-wise out- comes from 3 categories: Health, Psychology, and Economy. Our language data can be divided into two groups, (1) for Health and Psychological out- comes and <ref type="formula">(2)</ref>   <ref type="bibr">Zamani and Schwartz (2017)</ref>. This data was derived from Twitter's 1% random stream collected from 2011 to 2013 and includes 131 million tweets. In both cases, the tweets were mapped to counties based on users' self-reported location strings using the procedure proposed by <ref type="bibr" target="#b19">Schwartz et al. (2013a)</ref>.</p><p>The extra-linguistic data consists of 11 variables used in previous work: 4 socioeconomic vari- ables including median income, unemployment rate, percentage of bachelors degrees, and per- centage of high school degree, as well as 7 de- mographic variables including median age; per- centage: female, black, Hispanic, foreign-born, married; and population density (Census Bureau, 2010). All variables were obtained from the US Census (Census Bureau, 2010), and we hence- forth refer to them collectively as extra-linguistic features. This dataset is only collected every 10 years, so the 2010 US Census is the most recent dataset for all of the socioeconomic and demo- graphic variables at the county level.</p><p>We consider 5 county-wise measurements as outcomes, 2 health-related (heart disease mor- tality rate, fair/poor health life), 1 psychologi- cal (life satisfaction), and 2 economic (yearly in- creased real estate price rate, yearly foreclosure rate). Health and psychological data was gath- ered from the Centers for Disease Control and Pre- vention (2010b) and contains between 1,630 to 1,749 counties, depending on the outcome. The   economic outcomes, which have been used previ- ously in <ref type="bibr">(Zamani and Schwartz, 2017)</ref>, were gath- ered for the year 2013 from Zillow 3 . They contain 427 counties' foreclosure rate and 717 counties' increased real estate price rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baselines</head><p>Our baselines consist of a controls-only prediction model and a language-only prediction model. Controls-only. The controls-only model is a sim- ple regression model trained over all the 11 extra- linguistic features.</p><p>Language-only. Building this baseline consists of three main steps: extracting linguistic features, performing feature reduction, and running ridge- regression ( <ref type="bibr" target="#b12">Goeman et al., 2016)</ref>. Our linguis- tic features are n-gram features (1-3 grams) and topic features which include mentions of 2,000 LDA ( <ref type="bibr" target="#b1">Blei et al., 2003</ref>) derived topics previously estimated from social media ( <ref type="bibr" target="#b20">Schwartz et al., 2013b</ref>). For language data, we first pruned the sparse n-gram features to only include those that were <ref type="bibr">3</ref> http://www.zillow.com/research/data/ mentioned in at lease a percentage of the counties, then due to the importance of word count in per- formance of language predictive models( <ref type="bibr">Zamani et al., 2018</ref>) we exploit a word count thresh- old and drop counties with fewer words. Then we run a correlation threshold to only keep the highest correlated features and finally we per- form a randomized principal components analysis (RPCA), an approximate PCA based on stochastic re-sampling ( <ref type="bibr" target="#b18">Rokhlin et al., 2009</ref>). We apply the correlation threshold and RPCA steps for n-grams and topics independently.</p><p>For language data associated with health and psychology outcomes, we pruned the sparse n- gram features to only include those that were men- tioned in at least 95% of the counties, and used 20,000 as the word count threshold, resulting in 27,250 n-grams total.</p><p>With only 1,749 training instances (one per county), feature selection and dimensionality re- duction become necessary for avoiding overfitting. We first limit the features to the top 10,000 n- grams with the highest linear relationships to each outcome. As the topic features are more informa-tive than a single n-gram, we choose to retain all 2,000 topics at this step. Then after performing RPCA we only keep 100 features for each group of ngrams and topcs.</p><p>For the language data associated with economy outcomes, we pruned the n-gram features to only include those that were mentioned in at least 10% of the counties, and used 10,000 as the word-count threshold, resulting in 8,897 n-grams across 717 training instances. We use the top 8,000 n-grams and the top 1,500 topic features with the highest linear relationships to each outcome. at the end by applying RPCA we limit the dimension of each feature set to 100.</p><p>We compare performances of residualized con- trol, factor adaptation and residualized factor adaptation (RFA). For all these models, we use the same settings as above to generate language fea- tures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Comparison of RC, FA, and RFA</head><p>We first compare factor adaptation (FA), residual- ized control (RC), and residualized factor adapta- tion (RFA) using three manually selected factors: age, race (percentage of black population), and ed- ucation (percentage with bachelor's degree) rates. These three factors are often used as "controls" in prior work ( <ref type="bibr" target="#b19">Schwartz et al., 2013a;</ref><ref type="bibr" target="#b5">Culotta, 2014;</ref><ref type="bibr" target="#b9">Eichstaedt et al., 2015;</ref><ref type="bibr" target="#b6">Curtis et al., 2018)</ref>  <ref type="bibr">4</ref> and also represent examples of demographic and so- cioeconomic measurements.</p><p>In order to ensure a fair comparison, we use the same extra-linguistic features for all models. As mentioned earlier, a naive method is to di- rectly combine the extra-linguistic features with language ones in a single feature set. Here, we also compare this simple model, which we call added-controls, with the other three models. In addition, we consider a linear model solely us- ing extra-linguistics, which we call controls only. Evaluation is done using 10-fold cross-validation. R 2 , or variance explained, is used to measure ac- curacy. <ref type="table">Table 1</ref> compares results in terms of variance explained, when using the three hand-picked fac- tors vs. using all 11 extra-linguistic factors (Since past work has also used the Pearson-r metric, Ta- ble 2 shows the same results for all factors in terms <ref type="bibr">4</ref> Income has also been used frequently but it has been shown to correlate strongly with education rates.  of Pearson-r). As the table shows, FA outper- forms controls only, added-controls, and residu- alized control. RFA does even better and out- performs FA on both the hand-picked factors and when using the entire set of factors. These re- sults demonstrate the complementary nature of the residualized control and factor adaptation ap- proaches and the benefits of combining them. Even though adding controls directly, as in the "added-controls" column, works better than language-only and controls-only models, it is worse than any other model that exploits both lan- guage and extra-linguistic data. This motivates the need for combining different types of features in both an additive (residualized control) and multi- plicative (factor adaptation) style.</p><p>Overall, these results show the power of RFA over the other models. RFA's improvement over FA was statistically significant for 4 out of 5 out- comes, and 3 out of 5 for residualized control. Recall that added-controls, residualized control, FA, and RFA all have access to the same set of information. The gains of RFA over FA show that RFA's structure utilizing residualized control is better suited for combining extra-linguistic and language-only features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Feature Selection</head><p>Here we investigate the impact of feature selec- tion on the overall performance of RFA. We con- sider three different combination of adaptation and feature selection, as well as adaptation without any feature selection: (1) SeparatedFS: apply fea- ture selection separately on language features and adapted language features; (2) CombinedFS: com- bine language features and adapted language fea- tures into one feature set and then apply feature selection; (3) EarlyFS: apply feature selection on language features, then apply adaptation on the se- lected features; and (4) NoFS: perform adaptation without any feature selection. <ref type="table" target="#tab_5">Table 3</ref> shows the performance of each method on all 5 outcomes, as well as the the average. SeparatedFS performs better than the others in 3 out of 5 cases, as well as leading the average R 2 across all 5 outcomes. In addition, it produces the most stable results in comparison to the other methods. We therefore use this method for RFA.</p><p>We perform another experiment to find the best parameter for the univariate feature selection, that is, the value of k when selecting the k-best n- gram features. <ref type="figure" target="#fig_2">Figure 2</ref> shows the results of vary- ing the number of features used for FA and RFA. We report the average R 2 across the 3 health-and psychology-related outcomes. In general, select- ing more features leads to better results, though eventually performance does begin to suffer. Re- call that our feature selection approach is to first select the k-best n-gram features based on their linear relationship with the outcome, then do a PCA on these k features to obtain a reduced- dimension vector. Even though the feature selec- tion doesn't directly increase the size of our mod- els, it effectively increases the amount of informa- tion available to the models, leading to the positive trends we see in <ref type="figure" target="#fig_2">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Increasing Factors and Factor Selection</head><p>This experiment has two objectives: first to find out how the number of factors affects perfor- mance, and second to find an automated way to select a good subset from the extra-linguistic fac- tors. Here we vary the number of factors from 1 to 11 (i.e. all factors) and compare the effects on <ref type="figure">Figure 3</ref>: Effect of increasing number of factors on R 2 of residualized factor adaptation (RFA), factor adapta- tion (FA) and residualized controls (RC) for heart dis- ease outcome. Factors are obtained through Recursive Feature Elimination (RFE) or PCA. Left plot is with original factors, and right plot is with interaction fac- tors (the product from pairing factors).</p><p>RFA, FA, and RC. Factor selection in this exper- iment is done in two ways, supervised and unsu- pervised. For the supervised selection we use Re- cursive Feature Elimination, in which for each k, the least significant factors are recursively dropped until only k factors remain. For unsupervised se- lection, we use PCA to build k new factors with the highest variance.</p><p>The left of <ref type="figure">Figure 3</ref> shows how the performance of RFA, FA and RC change for heart disease out- come as the number of factors increase, using both PCA and RFE as factor selection methods.</p><p>RFA outperforms FA at every factor number, and begins to outperform RC as the number of factors increases. RFA's performance, in general, tends to increase as we add more factors. Using PCA, RFA reaches close to its best performance very quickly, requiring only 5 or 6 factors; adding more factors results in longer runtimes for mini- mal gain. However, in the case of RFE, using more factors appears to be worthwhile. FA and RC both quickly plateau, or even decline, as more features are added.</p><p>Since performance generally improved as more factors were added, we explored adding more fac- tors beyond the 11 that are available to us. To this end we create new factors by multiplying the exist- ing factors with one another. To account for vari- ance in the factor ranges, we first min-max nor- malize each factor. Then we consider every pair of factors and multiply their normalized values to- gether and re-normalize these new values to create a new factor. This gives a total of 55 new factors in addition to the original 11. We rerun our exper- iments with this new pool of 66 factors.</p><p>The right of <ref type="figure">Figure 3</ref> shows the results of using this expanded pool of factors. Here, the perfor- mance begins to taper off beyond 15 factors for both FA and RFA. Overall, PCA obtains its best performance with only a few factors, but then be- gins to suffer as more factors are added. RFE, on the other hand, tends to perform worse than PCA initially but remains relatively stable as more factors are added. These newly-created features turned out to be less effective than the original eleven, suggesting that the trade-off in increasing factors via combination is not worthwhile.</p><p>Overall, even though reducing the number of factors through PCA-based factor selection could not beat the best accuracy, it is still very com- petitive. Given the potentially huge number of features obtained through factor adaptation, this slight decrease in performance may be worth po- tential increases in runtime. RFE-based factor se- lection, however, helps with neither the runtime nor the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>Language-based prediction tasks involving com- munities can benefit from both socio-demographic factors and linguistic features. Because this in- formation comes from different sources and has different distributions, effective mechanisms are needed for combining them. In this paper, we present residualized factor adaptation, a method that unites two ways of approaching this prob- lem, one where strong community attributes are augmented (i.e. additive use of factors) with weak but noisy language features, and the other where the contextual differences in language use are me- diated via community attributes (i.e. adaptation to community factors). The proposed method ef- fectively combines the complementary benefits of both residualized control and factor adaptation ap- proaches to yield substantial gains over differing community-level prediction tasks across three do- mains. We see this work as part of a growing need for application-oriented approaches that not only leverage large data effectively by themselves, but do so in the context of other social scientific infor- mation that is already available and valuable.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Components of residualized factor adaptation. X L is language data (topic and n-gram features) and X A is adapted language data.</figDesc><graphic url="image-1.png" coords="4,307.28,62.81,225.75,81.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Domain</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Effect of increasing the number of selected features in univariate feature selection on both factor adaptation (FA) and residualized factor adaptation (RFA) by looking at the average R 2 among health and psychological outcomes. All 11 factors are used in all cases.</figDesc><graphic url="image-2.png" coords="8,82.91,62.81,196.44,114.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>for Economical outcomes. The lan- guage data we use for Health-and Psychology- related outcomes was derived from Twitter's 10% random stream collected from July 2009 to Febru- ary 2015 and includes 1.64 billion tweets (Giorgi et al., 2018) 2 . For Economy outcomes, we used the language data from</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Pearson-r of residualized factor adaptation (RFA) versus baseline models (for comparison to other work 
which uses Pearson-r as the accuracy metric). Results are only shown for all factors. RC is residualized control 
and FA is factor adaptation. Each row is color-coded separately, from red (lowest value) to green (highest values). 
Bold and * indicate a significant (p &lt; .05) reduction in error over the next best model (bold) and over FA (*), 
respectively, according to paired t-tests. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Comparing R 2 using different methods of 
feature selection. Outcomes are heart disease (HD), 
fair/poor health (FP), life satisfaction (LS), increased 
price (IP), and foreclosure rate (FC). FS stands for fea-
ture selection. Bold cells have the highest R 2 for each 
outcome. 

</table></figure>

			<note place="foot" n="1"> Available at https://github.com/dlatk 2 Available at https://github.com/wwbp</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported, in part, by a grant from the Templeton Religion Trust (ID TRT0048). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p></div>
			</div>

			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">underlying cause of death 1999-2010. cdc wonder online database [data set</title>
		<ptr target="http://wonder.cdc.gov/ucd-icd10.html" />
	</analytic>
	<monogr>
		<title level="j">Centers for disease control and prevention</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Profile of general population and housing characteristics: 2010 demographic profile data</title>
		<ptr target="https://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=DEC_10_DP_DPDP1&amp;prodType=table" />
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>United States Census Bureau</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Why is poverty unhealthy? social and physical mediators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deborah</forename><forename type="middle">A</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">A</forename><surname>Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Mason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Science &amp; Medicine</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1631" to="1641" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">From ADHD to SAD: Analyzing the language of mental health on Twitter through self-reported diagnoses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Glen</forename><surname>Coppersmith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristy</forename><surname>Hollingshead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Computational Linguistics and Clinical Psychology</title>
		<meeting>the 2nd Workshop on Computational Linguistics and Clinical Psychology</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Estimating county health statistics with twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aron</forename><surname>Culotta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd annual ACM conference on Human factors in computing systems</title>
		<meeting>the 32nd annual ACM conference on Human factors in computing systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1335" to="1344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Can twitter be used to predict county excessive alcohol consumption rates?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brenda</forename><surname>Curtis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salvatore</forename><surname>Giorgi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K</forename><surname>Anneke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyle</forename><forename type="middle">H</forename><surname>Buffone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">D</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessie</forename><surname>Ashford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hemmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casey</forename><surname>Summers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Andrew</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Frustratingly easy domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Using matched samples to estimate the effects of exercise on mental health from Twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dos</forename><surname>Virgile Landeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aron</forename><surname>Reis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Culotta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Ninth AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="182" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Psychological language on twitter predicts countylevel heart disease mortality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><forename type="middle">C</forename><surname>Eichstaedt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Andrew</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><forename type="middle">L</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darwin</forename><forename type="middle">R</forename><surname>Labarthe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raina</forename><forename type="middle">M</forename><surname>Merchant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sneha</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Megha</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lukasz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Dziurzynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="169" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salvatore</forename><surname>Giorgi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Preotiuc-Pietro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anneke</forename><surname>Buffone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Rieman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyle</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Andrew</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The remarkable benefit of userlevel aggregation for lexical-based population-level predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">L1 and l2 penalized regression models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jelle</forename><surname>Goeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosa</forename><surname>Meijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nimisha</forename><surname>Chaturvedi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Changes in social media affect, disclosure, and sociality for a sample of transgender americans in 2016&apos;s political climate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gillian R</forename><surname>Haimson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICWSM</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="72" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Demographic factors improve classification performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A world of difference: Divergent word interpretations among people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianran</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruihua</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maya</forename><surname>Abtahian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICWSM</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Human centered NLP with user-factor adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronica</forename><forename type="middle">E</forename><surname>Lynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngseo</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niranjan</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Andrew</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1157" to="1166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Towards automatically classifying depressive symptoms from Twitter data for population health</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danielle</forename><surname>Mowery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Conway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Bryan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Computational Modeling of People&apos;s Opinions</title>
		<meeting>the Workshop on Computational Modeling of People&apos;s Opinions</meeting>
		<imprint>
			<publisher>Personality, and Emotions in Social Media</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page">182</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A randomized algorithm for principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Rokhlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Tygert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Matrix Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1100" to="1124" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Characterizing geographic variation in wellbeing using tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H Andrew</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><forename type="middle">C</forename><surname>Eichstaedt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><forename type="middle">L</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Dziurzynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Megha</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gregory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shrinidhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sneha</forename><surname>Lakshmikanth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Seligman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICWSM</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Personality, gender, and age in the language of social media: The open-vocabulary approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><forename type="middle">C</forename><surname>Eichstaedt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><forename type="middle">L</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Dziurzynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><forename type="middle">M</forename><surname>Ramones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Megha</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Achal</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Kosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Stillwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><forename type="middle">E P</forename><surname>Seligman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">73791</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dlatk: Differential language analysis toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salvatore</forename><surname>Giorgi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Crutchley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Eichstaedt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyle</forename><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Exploring demographic language variations to improve multilingual sentiment analysis in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svitlana</forename><surname>Volkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Using Twitter to measure public discussion of diseases: A case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Weeg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shawndra</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raina</forename><forename type="middle">M</forename><surname>Merchant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catalina</forename><surname>Arango</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyle</forename><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMIR Public Health and Surveillance</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
