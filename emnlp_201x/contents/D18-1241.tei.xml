<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">QuAC : Question Answering in Context</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Allen Institute for Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">University of Washington</orgName>
								<orgName type="institution" key="instit2">Stanford University ♦ UMass Amherst ♣</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">♥</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Allen Institute for Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">University of Washington</orgName>
								<orgName type="institution" key="instit2">Stanford University ♦ UMass Amherst ♣</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><forename type="middle">♦</forename><surname>Mohit</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Allen Institute for Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">University of Washington</orgName>
								<orgName type="institution" key="instit2">Stanford University ♦ UMass Amherst ♣</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iyyer</forename><forename type="middle">♣</forename></persName>
							<affiliation key="aff0">
								<orgName type="department">Allen Institute for Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">University of Washington</orgName>
								<orgName type="institution" key="instit2">Stanford University ♦ UMass Amherst ♣</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Allen Institute for Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">University of Washington</orgName>
								<orgName type="institution" key="instit2">Stanford University ♦ UMass Amherst ♣</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Allen Institute for Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">University of Washington</orgName>
								<orgName type="institution" key="instit2">Stanford University ♦ UMass Amherst ♣</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Allen Institute for Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">University of Washington</orgName>
								<orgName type="institution" key="instit2">Stanford University ♦ UMass Amherst ♣</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">♥</forename></persName>
							<affiliation key="aff0">
								<orgName type="department">Allen Institute for Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">University of Washington</orgName>
								<orgName type="institution" key="instit2">Stanford University ♦ UMass Amherst ♣</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Allen Institute for Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">University of Washington</orgName>
								<orgName type="institution" key="instit2">Stanford University ♦ UMass Amherst ♣</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Allen Institute for Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">University of Washington</orgName>
								<orgName type="institution" key="instit2">Stanford University ♦ UMass Amherst ♣</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">QuAC : Question Answering in Context</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2174" to="2184"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>2174</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present QuAC, a dataset for Question Answering in Context that contains 14K information-seeking QA dialogs (100K questions in total). The dialogs involve two crowd workers: (1) a student who poses a sequence of freeform questions to learn as much as possible about a hidden Wikipedia text, and (2) a teacher who answers the questions by providing short excerpts from the text. QuAC introduces challenges not found in existing machine comprehension datasets: its questions are often more open-ended, unanswerable, or only meaningful within the dialog context, as we show in a detailed qualitative evaluation. We also report results for a number of reference models, including a recently state-of-the-art reading comprehension architecture extended to model dialog context. Our best model underperforms humans by 20 F1, suggesting that there is significant room for future work on this data. Dataset, baseline, and leaderboard available at http://quac.ai.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In information-seeking dialog, students repeat- edly ask teachers questions to learn about a topic of interest ( <ref type="bibr" target="#b26">Stede and Schlangen, 2004</ref>). Mod- eling such conversations is challenging, as the questions can be highly context-dependent, ellip- tical, and even unanswerable. To enable learning from rich information-seeking dialog, we present QuAC (henceforth ), a large-scale dataset for Question Answering in Context that contains 14K crowdsourced QA dialogs (100K total QA pairs). 1 <ref type="figure" target="#fig_0">Figure 1</ref> shows an example dialog. The in- teraction is student driven and centered around a short evidence text (a section from Daffy Duck's  <ref type="bibr">STUDENT:</ref> In what other ways did he change? TEACHER: → Daffy's slobbery, exaggerated lisp (...) is barely noticeable in the early cartoons. STUDENT: Why did they add the lisp? TEACHER: → One often-repeated "official" story is that it was modeled after producer Leon Schlesinger's tendency to lisp. STUDENT: Is there an "unofficial" story? TEACHER: → Yes, Mel Blanc (...) contradicts that conventional belief . . . Wikipedia page), which only the teacher can ac- cess. Given just the section's heading, "Origin &amp; History", the student aims to learn as much as pos- sible about its contents by asking questions. The teacher answers these questions with spans from the evidence text, as in existing reading compre- hension tasks <ref type="bibr" target="#b20">(Rajpurkar et al., 2016)</ref>. Addition- ally, the teacher uses dialog acts to provide the stu- dent with feedback (e.g., "ask a follow up ques- tion"), which makes the dialogs more productive.</p><p>We collect the dataset in an interactive set- ting where two crowd workers play the roles of teacher and student. To encourage natural and di- verse questions, we do not follow previous dialog- style QA datasets that semi-automatically generate questions <ref type="bibr" target="#b28">(Talmor and Berant, 2018;</ref><ref type="bibr" target="#b24">Saha et al., 2018)</ref>. Furthermore, unlike QA datasets such as <ref type="bibr">SQuAD and CoQA (Reddy et al., 2018)</ref>, students in do not know the answers to their ques- tions prior to asking them, which lessens the role of string matching and simple paraphrasing in an- swering their questions. This property makes similar to datasets that contain real user queries on search engines <ref type="bibr" target="#b17">(Nguyen et al., 2016)</ref>. contains many challenging phenomena unique to dialog, such as coreference to previous questions and answers and open-ended questions that must be answered without repeating previ- ous information (Section 3). Additionally, despite lacking access to the section text, we find that stu- dents start dialogs by asking questions about the beginning of the section before progressing to ask- ing questions about the end. These observations imply that models built for must incorporate the dialog context to achieve good performance.</p><p>We present a strong neural baseline ) that considers both dialog context and section text. While this model achieves within 6 F1 of human performance on SQuAD, it per- forms 20 F1 points below the human upper bound on , indicating room for future improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dataset collection</head><p>This section describes our data collection process, which involves facilitating QA dialogs between crowd workers. <ref type="table">Table 1</ref> shows shares many of the same positive characteristics of existing QA datasets while expanding upon the dialog aspect.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Interactive Task</head><p>Our task pairs up two workers, a teacher and a student, who discuss a section s (e.g., "Origin &amp; History" in the example from <ref type="figure" target="#fig_0">Figure 1</ref>) from a Wikipedia article about an entity e (Daffy Duck). The student is permitted to see only the section's title t and the first paragraph of the main article b, while the teacher is additionally provided with full access to the section text. The task begins with the student formulating a free-text question q from the limited information they have been given. The teacher is not allowed to answer with free text; instead, they must select a contiguous span of text defined by indices (i, j) into the section text s. <ref type="bibr">2</ref> While this decision lim- its the expressivity of answers, it makes evalua- tion simpler and more reliable; as such, it has been adopted in other reading comprehension datasets such as SQuAD, <ref type="bibr">TriviaQA (Joshi et al., 2017)</ref>, and NewsQA ( <ref type="bibr" target="#b29">Trischler et al., 2016)</ref>.</p><p>To facilitate more natural interactions, teachers must also provide the student with a list of dia- log acts v that indicates the presence of any of n discrete statements. We include three types of di- How does he try to take over the world? alog acts: (1) continuation (follow up, maybe follow up, or don't follow up), (2) affir- mation (yes, no, or neither) and <ref type="formula">(3)</ref> answer- ability (answerable or no answer). The continuation act is crucial for workers to have pro- ductive dialogs, as it allows teachers to guide the student's questioning towards aspects of the article that are especially important or interesting. Al- together, a teacher's complete answer to a ques- tion q includes a pair of indices and dialog indi- cators, a = (i, j, v). If a question is marked no answer, the indices are ignored.</p><p>After receiving an answer from the teacher, the student asks another question. At every turn, the student has more information about the topic than they did previously, which encourages them to ask follow-up questions about what they have just learned. The dialog continues until (1) twelve questions are answered, (2) one of the partners de- cides to end the interaction, or (3) more than two unanswerable questions were asked.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Collection Details</head><p>We used Amazon Mechanical Turk for collection, restricting the task to workers in English-speaking countries and with more than 1000 HITs with at least a 95% acceptance rate. We paid workers per the number of completed turns in the dialog, which encourages workers to have long dialogs with their partners, and discarded dialogs with less than three QA pairs. 3 To ensure quality, we created a qual- ification task and allowed workers to report their partner for various problems. More details on data collection can be found in our datasheet. <ref type="bibr">4</ref> Article selection Our early pilot studies showed that articles about people generally require less background knowledge to write good questions than other categories. To find articles about peo- ple with varied backgrounds, we retrieved articles from a list of category keywords (culture, animal, people associated with event, geography, health, celebrity) using a web interface provided by the Wikimedia foundation. <ref type="bibr">5</ref> We pruned by popular- ity by selecting articles with at least 100 incoming links, and we additionally removed non-person en- tities using YAGO ( <ref type="bibr" target="#b27">Suchanek et al., 2007)</ref>. After article selection, we filtered sections from these ar- ticles based on the number of paragraphs, number of tokens, and average words per sentence. <ref type="bibr">6</ref> Dataset validation To create our evaluation sets, we collected four additional annotations per question. Workers were presented with questions from a previously collected dialog and asked to provide answer spans. 7 Acquiring many annota- tions is important since many questions in have multiple valid answers. <ref type="table" target="#tab_3">Table 2</ref> shows small differences between training, development and testing splits. Sections in the training set are shorter than those in the evaluation folds because we permit multiple dialogs about the same section only in training; since workers preferred reading shorter sections, these were more likely to result in multiple dialogs. Variations in answer span length arise from two sources: (1) having multiple anno- tations in the validation task and (2) differing in- centives between the data collection and validation procedures. 8 An analysis measuring the effect of these variations shows that they result in little dif- ference in evaluation. <ref type="bibr">9</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Train / Dev / Test Differences</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset Analysis</head><p>differs from other reading comprehension datasets due to our dialog-style collection process and the information asymmetry between teacher and student. In the following sections, we pro- vide a qualitative analysis of the dataset in that highlights challenging question types as well as the impact of the dialog context. <ref type="table" target="#tab_3">Table 2</ref> shows dataset summary statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question and answer types</head><p>has long an- swers of 15 tokens on average compared to 3 for SQuAD, which is unsurprising as most SQuAD answers are either entities or numerics <ref type="bibr" target="#b11">(Jurczyk et al., 2018</ref>) while questions can be more open-ended. While the average question length (6.5 tokens) is shorter than that of SQuAD (11 tokens), this does not indicate reduced question complexity, as the student (1) cannot access the section to paraphrase it and (2) can be more con- cise by coreferencing previous interactions. <ref type="figure" target="#fig_1">Figure 2</ref> visualizes the most frequent question types in based on "Wh" words. <ref type="bibr">10</ref> For a more <ref type="bibr">7</ref> After submitting an answer, they were shown the original teacher's answer so that they could understand the context of the subsequent questions.</p><p>8 Validation workers did not have to maintain the dialog and so did not include as much information in the response. <ref type="bibr">9</ref> More specifically, we analyze whether references from the initial data collection significantly differ from references collected during validation. We observe a difference of less than 1 F1 when using the original answer as system output versus using validation answers. <ref type="bibr">10</ref> To more effectively visualize sub-boxes like "what did", we exclude questions from the tail of the distribution.</p><p>Section: Augusto Pinochet : Intellectual life...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STUDENT: Was he known for being intelligent? TEACHER: → No, Pinochet was publicly known</head><p>as a man with a lack of culture. STUDENT: why did people feel that way? TEACHER: → reinforced by the fact that he also portrayed himself as a common man STUDENT: did he have any hobbies? TEACHER: → Yes, Before wresting power from Allende, Pinochet had written two books. STUDENT: what is the name of a book written by him? TEACHER: → Geopolitica (1968) and Campana de <ref type="bibr">Tarapaca (1972)</ref>. STUDENT: what were the books about?  fine-grained analysis, we randomly sampled 100 questions (each from a different dialog) and man- ually labeled different phenomena in <ref type="table">Table 3</ref>. Un- like most current QA datasets that focus on fac- toid questions, our task setup encourages more open-ended questions: about half of questions are non-factoid. Furthermore, 86% of questions are contextual, requiring reading the context to re- solve coreference; of these, 44% refer to entities or events in the dialog history, while 61% refer to the subject of the article.</p><note type="other">TEACHER: → Chile's military literature. STUDENT: was there anything noteworthy re- garding his books? TEACHER: → Yes, In Geopolitica Pinochet pla- giarized (...) Gregorio Rodriguez Tascon STUDENT: did he deny those allegations? TEACHER: → No answer STUDENT: what did he plagiarize in Geopolitica?</note><p>The role of context Dialog context is crucial to understanding and answering questions. <ref type="figure">Fig- ure 5a</ref> shows that the location of the answer within the text is influenced by the number of questions asked previously. Early questions are mostly an- swered in the beginning of the section, while later questions tend to focus on the end of the section. Interestingly, text in the middle of the section is not asked about as frequently <ref type="figure">(Figure 5c</ref>). As more questions get asked, the more likely a question is to be unanswerable. <ref type="figure">Figure 5b</ref> shows how the answers progress through different chunks of the evidence text (where each section is divided into 12 chunks of Section: Gaelic Ireland : Invasion STUDENT: What year did the invasion happen? TEACHER: → in 1169 the main body of Norman, Welsh and Flemish forces landed in Ireland and quickly retook Leinster and the cities of Waterford and Dublin on behalf of Diarmait. STUDENT: Who was Diarmait?</p><note type="other">TEACHER: ¯ → King Diarmait Mac Murchada of Leinster. STUDENT: Where is Leinster located? TEACHER: → landed in Ireland and quickly re- took Leinster. STUDENT: Were invasions common? TEACHER: → No answer STUDENT: Are there any other interesting as- pects about this article? TEACHER: ¯ → Yes, IPope Adrian IV, the only English pope, had already issued a Papal Bull in 1155 giving Henry II of England authority to invade Ireland. STUDENT: Who lead the invasion? TEACHER: → No answer STUDENT: Did England defeat the Irish armies? TEACHER: → No answer Figure 4: A less successful dialog from</note><p>. The stu- dent struggles to get information despite asking good questions. The teacher attempts to provide extra con- text to guide the student, but the dialog ultimately ends because of too many unanswerable questions. equal size). The answer to the next question is most frequently either in the same chunk as the previous question or an adjacent chunk, and most dialogs in the dataset cover three to six of the chunks <ref type="figure">(Figure 5d</ref>). These observations suggest that models for must take into account the di- alog context. However, results in Section 5 show that solely relying on the location of previous an- swers is not sufficient.</p><p>Finally, we examine properties of the questions as a function of the turn position in the dialog ( <ref type="figure">Figure 6</ref>). The frequency of yes/no questions increases significantly as the dialogs progress; again, at the beginning of the dialog, students have very little information, so it is harder to formu- late a yes/no question. The percentage of ques- tions that have multiple answers declines as the dialog progresses, implying students ask general questions first and specific ones later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Qualitative examples Figures 3 and 4 contain two representative dialogs from</head><p>. Longer di- alogs sometimes switch topics (such as in <ref type="figure" target="#fig_3">Figure 3</ref> about "academic work") and often go from gen- eral to specific questions. Students whose ques-  <ref type="table">Table 3</ref>: An analysis of questions. Non-factoid questions do not ask about specific facts, while con- textual questions require reading the history to resolve coreferences to the dialog history and/or article.</p><p>tions go unanswered commonly resort to asking their teacher for any interesting content; even if this strategy fails to prolong the dialog as in <ref type="figure">Fig- ure 4</ref>, models can still use the dialog to learn when to give no answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>We consider the following QA task: given the first k questions and k ground-truth answers in the dia- log, all supporting material (entity e, topic t, back- ground b, and section text s), and question q k+1 , we predict the answer span indices i, j in the sec- tion text s. Since affirmation questions are incom- plete without a yes/no answer and the continuation feedback is important for information-seeking di- alog, we predict the dialog acts v, which with the span form the final answer prediction a k+1 .</p><p>All of our experiments are carried out on a train/dev/test split of 83.5k/7.3k/7.3k ques- tions/answer pairs, where no sections are shared between the different folds. Questions in the training set have one reference answer, while dev and test questions have five references each. For all experiments, we do not evaluate on questions with a human F1 lower than 40, which eliminates roughly 10% of our noisiest annotations. <ref type="bibr">11</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation Metrics</head><p>Our core evaluation metric, word-level F1, is im- plemented similarly to SQuAD (Rajpurkar et al.,  shows that the answer to the next question is more likely to be located within a chunk adjacent to the current answer than in one farther away.</p><p>Occurrence frequency Turn number <ref type="figure">Figure 6</ref>: The number of turns in the dialog influences the student's behavior: they start by asking general questions (i.e., easier to answer, with multiple possible answers) and progress to more specific ones. 2016): precision and recall are computed by con- sidering the portion of words in the prediction and references that overlap after removing stop- words. <ref type="bibr">12</ref> For no answer questions, we give the system an F1 of one if it correctly predicts no answer and zero otherwise. <ref type="bibr">13</ref> Like SQuAD, we compute the maximum F1 among all references; however, since many questions have multiple valid answers, this metric varies significantly with <ref type="bibr">12</ref> Since our answer spans have vaguer boundaries than the shorter ones in SQuAD, exact match is not a useful metric. <ref type="bibr">13</ref> Because the validation task was more susceptible to spam by constant annotation of "no-answer," we only al- low "no-answer" if the majority of references marked "no- answer", removing other answers. If "no-answer" is not the majority answer, we remove all instances of "no-answer". the number of reference annotations. To make or- acle human and system performance comparable, given n references, we report the average of the maximum F1 computed from each n − 1 subset with respect to the heldout reference.</p><p>Additionally, since averaged F1 can be mislead- ing for questions with multiple valid answers, we introduce the human equivalence score (HEQ), a performance measure for judging whether a sys- tem's output is as good as that of an average hu- man. <ref type="bibr">14</ref> HEQ measures the percentage of examples for which system F1 exceeds or matches human F1. We compute two variants: (1) the percentage of questions for which this is true (HEQ-Q), and (2) the percentage of dialogs for which this is true for every question in the dialog (HEQ-D). A sys- tem that achieves a value of 100 on HEQ-D can by definition maintain average human quality output over full dialogs.</p><p>For dialog acts, we report accuracy with respect to the majority annotation, breaking ties randomly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Sanity checks</head><p>Random sentence This baseline selects a ran- dom sentence in the section text s as the answer (including no answer).</p><p>Majority The majority answer outputs no answer and the majority class for all other di- alog acts (neither for affirmation and don't follow up for continuation).</p><p>Transition matrix We divide the supporting text into 12 chunks (with a special chunk for no answer) and use the transition matrix (computed from the training set) in <ref type="figure">Figure 5b</ref> to select an an- swer given the position of the previous answer. This baseline does not output other dialog acts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Upper bounds</head><p>Gold NA + TM This is the same transition ma- trix (TM) baseline as before, except that for ques- tions whose gold annotations are no answer, we always output no answer.</p><p>Gold sentence + NA To see if can be treated as an answer sentence selection problem, we output the sentence from s with the maximal F1 with respect to references, or no answer for unanswerable questions.</p><p>Human performance We pick one reference as a system output and compute the F1 with respect to the remaining references using the method de- scribed in Section 4.1. By definition, all HEQ measures are 100, and we report agreement for the affirmation dialog act. <ref type="bibr">15</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Baselines</head><p>Pretrained InferSent To test the importance of lexical matching in our dataset, we output the sen- tence in s whose pretrained InferSent representa- tion ( <ref type="bibr" target="#b1">Conneau et al., 2017</ref>) has the highest cosine similarity to that of the question.</p><p>Feature-rich logistic regression We train a lo- gistic regression using Vowpal Wabbit ( <ref type="bibr" target="#b13">Langford et al., 2007</ref>) to select answer sentences. We use simple matching features (e.g., n-gram overlap be- tween questions and candidate answers), bias fea- tures (position and length of a candidate), and con- textual features (e.g., matching features computed with previous questions / answers, turn number).</p><p>BiDAF++ We use a re-implementation of a top- performing SQuAD model ( <ref type="bibr" target="#b18">Peters et al., 2018</ref>) that augments bidirectional attention flow <ref type="bibr">(Seo et al., 2016, BiDAF)</ref> with self-attention ) and contextualized embeddings. <ref type="bibr">16</ref> A token for no answer is appended to s to enable its prediction following <ref type="bibr" target="#b14">Levy et al. (2017)</ref>. Additionally, we modify the model for our task to also predict dialog acts, placing a classifier over the same representation used to predict the end po- sition of the predicted span.</p><p>BiDAF++ w/ k-ctx As BiDAF++ does not model any dialog context, we modify the passage and question embedding processes to consider the dialog history. We consider context from the pre- vious k QA pairs. 17</p><p>• Passage embedding We explicitly identify the previous k answers within the section text by concatenating marker embeddings to the existing word embeddings.</p><p>• Question embedding Naively prepending the previous k questions to the current ques- tion did not show gains in initial experiments.</p><p>We opt instead to simply encode the dialog turn number within the question embedding. Sanity check Overall, the poor sanity check re- sults imply that is very challenging. Of these, following the transition matrix (TM) gives the best performance, reinforcing the observation that the dialog context plays a significant role in the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results</head><p>Upper bounds The human upper bound (80.8 F1) demonstrates high agreement. While Gold sentence + NA does perform well, indicating that significant progress can be made by treating the problem as answer sentence selection, HEQ mea- sures show that span-based approaches will be needed achieve average human equivalence. Fi- nally, the Gold NA + TM shows that cannot be solved by ignoring question and answer text.   <ref type="table" target="#tab_6">Table 4</ref>: Experimental results of sanity checks (top), baselines (middle) and upper bounds (bottom) on . Simple text matching baselines perform poorly, while models that incorporate the dialog context significantly outperform those that do not. Humans outperform our best model by a large margin, indicating room for future improvement.</p><p>Baselines Text similarity methods such as bag- of-ngrams overlap and InferSent are largely inef- fective on , which shows that questions have little direct overlap with their answers. On the other hand, BiDAF++ models make significant progress, demonstrating that existing models can already capture a significant portion of phenom- ena in . The addition of information from previous turns (w/ 1-ctx) helps significantly, in- dicating that integration of context is essential to solving the task. While increasing the context size in BiDAF++ continues to help, we observe saturation using contexts of length 3, suggesting that more sophisticated models are necessary to take full advantage of the context. Finally, even our best model underperforms humans: the sys- tem achieves human equivalence on only 60% of questions and 5% of full dialogs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Error Analysis</head><p>In this section, we analyze the development set performance of our best context-aware model (BiDAF++ w/ 2-ctx), our best context-agnostic model (BiDAF++), and humans. <ref type="figure" target="#fig_7">Figure 7</ref> contains three plots showing how F1 scores of baseline models and human agreement vary with (1) turn number, (2) distance from previous answer, 18 and (3) answer length in tokens. Taken as a whole, our analysis reveals significant qualitative differences between our context-aware and context-agnostic models beyond simply F1; additionally, human <ref type="bibr">18</ref> We divide the text into 12 equally-sized chunks and com- pute the difference of the current and previous chunk indices.</p><p>behavior differs from that of both models.</p><p>In the first plot, human agreement is unchanged throughout the dialog while the performance of both models decreases as the number of turns increases, although the context-aware model de- grades less. While continuing a dialog for more turns does not affect human agreement, the sec- ond plot shows that human disagreement increases as the distance between the current answer's loca- tion within the section text and that of the previous answer increases. Larger distances indicate shifts in the student's line of questioning (e.g., if the teacher told the student not to follow up on the pre- vious question). The plot also shows that model performance suffers (significantly more than hu- mans) as distance increases, although the context- aware model can tolerate smaller shifts better than the context-agnostic model. In the last plot, hu- man agreement is higher when the answer span is short; in contrast, our model struggles to pin down short answers compared to longer ones.</p><p>The plots demonstrate the increased robust- ness of the context-aware model compared to BiDAF++. This finding is reinforced by examin- ing the difference in model performance on ques- tions where previously the teacher recommended the student to "follow up" vs. not to follow up. The context-aware baseline performs 6 HEQ-Q higher on the "follow up" questions; in contrast, the context-agnostic baseline shows no HEQ-Q difference between the two types of questions. This discrepancy stems from the context-agnostic model's inability to take advantage of the location of the previous answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Reading Comprehension Our work builds on span based reading comprehension <ref type="bibr" target="#b20">(Rajpurkar et al., 2016;</ref><ref type="bibr" target="#b10">Joshi et al., 2017;</ref><ref type="bibr" target="#b29">Trischler et al., 2016)</ref>, while also incorporating innovations such as curating questions independently of support- ing text to reduce trivial lexical overlap ( <ref type="bibr" target="#b10">Joshi et al., 2017;</ref><ref type="bibr" target="#b12">Kocisk´yKocisk´y et al., 2017)</ref> and allowing for unanswerable questions <ref type="bibr" target="#b29">(Trischler et al., 2016;</ref><ref type="bibr" target="#b19">Rajpurkar et al., 2018)</ref>. We handle open-ended ques- tions like in MSMARCO ( <ref type="bibr" target="#b17">Nguyen et al., 2016)</ref>, with multiple references, but we are the first to in- corporate these into information-seeking dialog.</p><p>Sequential QA Our work is similar to se- quential question answering against knowledge bases <ref type="bibr" target="#b9">(Iyyer et al., 2017</ref>) and the web <ref type="bibr" target="#b28">(Talmor and Berant, 2018)</ref>, but instead of decomposing a single question into smaller questions, we rely on the curiosity of the student to generate a se- quence of questions. Such open information seek- ing was studied in semantic parsing on knowledge bases ( <ref type="bibr">Dahl et al., 1994)</ref> and more recently with modern approaches ( <ref type="bibr" target="#b24">Saha et al., 2018)</ref>, but with questions paraphrased from templates. Concur- rent to our work, <ref type="bibr" target="#b23">Saeidi et al. (2018)</ref> proposed a task of generating and answering yes/no questions for rule focused text (such as traffic laws) by in- teracting with a user through dialog. Also con- currently, <ref type="bibr" target="#b21">Reddy et al. (2018)</ref> propose conversa- tional question answering (CoQA) from text but allow both students and questioners to see the ev- idence. As a result, a large percentage of CoQA answers are named entities or short noun phrases, much like those in SQuAD. In contrast, the asym- metric nature of forces students to ask more exploratory questions whose answers can be po- tentially be followed up on. <ref type="bibr">19</ref> Dialog fits into an increasing interest in open domain dialog, mostly studied in the con- text of social chit-chat ( <ref type="bibr" target="#b22">Ritter et al., 2011;</ref><ref type="bibr" target="#b5">Fang et al., 2017;</ref><ref type="bibr">Ghazvininejad et al., 2018)</ref>. Most related to our effort is visual dia- log ( <ref type="bibr" target="#b4">Das et al., 2017)</ref>, which relies on images as evidence instead of text. More explicit goal driven scenarios, such as bargaining ( <ref type="bibr" target="#b15">Lewis et al., 2017)</ref> and item guessing ( <ref type="bibr" target="#b8">He et al., 2017</ref>) have also been explored, but the language is more constrained than in . Information-seeking dialog specif- ically was studied in <ref type="bibr" target="#b26">Stede and Schlangen (2004)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we introduce , a large scale dataset of information-seeking dialogs over sec- tions from Wikipedia articles. Our data collection process, which takes the form of a teacher-student interaction between two crowd workers, encour- ages questions that are highly contextual, open- ended, and even unanswerable from the text. Our baselines, which include top performers on exist- ing machine comprehension datasets, significantly underperform humans on . We hope this dis- crepancy will spur the development of machines that can more effectively participate in informa- tion seeking dialog.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example dialog about a Wikipedia section. The student, who does not see the section text, asks questions. The teacher provides a response in the form of a text span (or No answer ), optionally yes or no ( Yes / No ), and encouragement about continuing a line of questioning (should, → , could ¯ → , or should not → ask a follow-up question).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A treemap visualization of the eight most frequent "Wh" words in , where box area is proportional to number of occurrences. Compared to other machine comprehension datasets, we observe increased contextuality and open-endedness, as well as a variety of both general and specific questions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: An example successful dialog from . Questions build on each other and interesting aspects (e.g., plagiarism) are explored as they are discovered.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Turn number Answer chunk (c) % dialogs that visit n th answer chunk (d) # unique answer chunks visited per dialog</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>(</head><label></label><figDesc>Figure 5: Heatmaps depicting the importance of context in dialogs, where (a) and (b) share the same color scale. The student's earlier questions are answered mostly by the first few chunks, while the end of the section is covered in later turns (a). The middle is the least covered portion (c), and dialogs cover around five unique chunks of the section on average (d). The transition matrix (b) shows that the answer to the next question is more likely to be located within a chunk adjacent to the current answer than in one farther away.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>F1</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: The F1 scores of baseline models and human agreements based on dialog turn number, answer's distance from previous answer, and the answer span token length.</figDesc><graphic url="image-35.png" coords="9,72.00,57.83,453.55,138.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Statistics summarizing the 
dataset. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>countries if any did he visit? What type of museum did Peggy plan to open? What were her troubles in 2016? What do critics say about them? What other movies did she do? How was perversion handled? How long was he there? How popular did she become?</head><label></label><figDesc></figDesc><table>why 

who 

where 
when 
did 
when 

what 
was 

what 
is 

what 
happened 
what 
else 

what 
did 
what 

was 
PRN 

was 
how 
did 
how 

did 
PRN 
did 

what 

did 

how 
was 

when 

who 

where 

why 

what did 
what is 

what was 
what happened 
what else 

when did 

how did 
was PRN 

did PRN 

What team was he with? 
What station did it air on? 

What was it about? 
What was the name of the single? 
What was Takemitsu's opinion of Debussy? 
What was their first album? 
What was one of his reforms? 
What was the driving force behind the name change? 

What is 
notable about 
his player 
profile? 
What is 
Refused's 
musical style? 

What did they try next? 
What did Doris 
contribute to? 
What did they record? 
What did he do in there? 
What did she do after 
college? 

What happened 
after that? 
What happened 
in 1983? 

What else must 
one do? 
What else is 
notable? 

Did the albums do well? 
Did Huxley teach his 
beliefs? 
Did she rise in the 
company? 
Did Pamela cheat on 
Churchill? 

Did they have a lot of followers? 
Did she go on any tours after this? 
Did they win against Cuba? 
Did he marry? 
Did they serve any prison time? 
Did he have any conflicts with team mates? 
Did she win an award? 
Did he actually get a Muslim state started? 

What other How did Mark Felt 
contact Woodword? 
How did the meeting go? 
How did it do on the charts? 

When was she born? 
When was it founded? 
When was the 
breakup? 

When did he 
get started 
in politics? 
When did he 
die? 

Where was the club 
based? 
Where was she from? 
Where did Julianne 
Hough tour? 

Why did they meet at 
Woodside Hotel? 
Why did he represent 
her? 

Why did 
he retire? 

Who promoted the film? 
Who was in The Go-Go's? 
Who was their father? 
Who acquired the rights to the 
band's back catalogs? 
Who was Emily influenced by? 

Was he very mean to these 
relatives? 
Was she a happy child? 

Was it a 
success? 

Was Villa ever the 
governor of Chihuahua? 
Was there another 
lawsuit? 

Was this report 
helpful? 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 summarizes</head><label>4</label><figDesc></figDesc><table>our results (each cell displays 
dev/test scores), where dialog acts are Yes/No (af-
firmation) and Follow up (continuation). For com-
parison to other datasets, we report F1 without fil-
tering low-agreement QA pairs (F1'). 

</table></figure>

			<note place="foot" n="1"> We use &quot;dialog&quot; to refer to a sequence of QA pairs. Authors contributed equally.</note>

			<note place="foot" n="2"> We set the maximum answer length to 30 tokens to prevent teachers from revealing the full article all at once.</note>

			<note place="foot" n="3"> On average, we paid $0.33 per question, increasing pay per question as dialogs got longer to encourage completion. 4 http://quac.ai/datasheet.pdf 5 https://petscan.wmflabs.org/ 6 These filtering steps bias our data towards entertainers; see datasheet for details.</note>

			<note place="foot" n="11"> A manual inspection of annotations below this threshold revealed many lower quality questions; however, we also report unthresholded F1 in the final column of Table 4.</note>

			<note place="foot" n="14"> In cases with lower human agreement on F1, if a system produces one reference exactly (F1 = 100), it will get points that it can use to offset poor performance on other examples.</note>

			<note place="foot" n="15"> We did not collect multiple annotations for the continuation dialog act and so omit it.</note>

			<note place="foot" n="16"> The AllenNLP (Gardner et al., 2017) implementation we use reaches 82.7 on the SQuAD development set, compared to the paper&apos;s reported 85.8 on SQuAD; regardless, this implementation would have been state-of-the-art less than a year ago, making it an extremely strong baseline. 17 Our implementation is available in AllenNLP.</note>

			<note place="foot" n="19"> On average, CoQA answers are 2.7 tokens long, while SQuAD&apos;s are 3.2 tokens and &apos;s are over 14 tokens.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>was jointly funded by the Allen Institute for Artificial Intelligence and the DARPA CwC pro-gram through ARO (W911NF-15-1-0543). We would like to thank anonymous reviewers and Hsin-Yuan Huang who helped improve the draft.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Simple and effective multi-paragraph reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Supervised learning of universal sentence representations from natural language inference data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loic</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deborah</forename><forename type="middle">A</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madeleine</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">M</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Hunicke-Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>David</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Expanding the scope of the atis task: The atis-3 corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Pallett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">I</forename><surname>Pao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Rudnicky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shriberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the workshop on Human Language Technology</title>
		<meeting>the workshop on Human Language Technology</meeting>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satwik</forename><surname>Kottur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khushi</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avi</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deshraj</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Batra</surname></persName>
		</author>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Visual dialog</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Sounding board-university of washingtons alexa prize submission</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>Alexa Prize Proceedings</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Allennlp: A deep semantic natural language processing platform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Grus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nelson</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<title level="m">Wen-tau Yih, and Michel Galley. 2018. A knowledge-grounded neural conversation model. Association for the Advancement of Artificial Intelligence</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning symmetric collaborative dialogue agents with dynamic knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anusha</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihail</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Search-based neural structured learning for sequential question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Wen Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Analysis of wikipedia-based corpora for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Jurczyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Deshmane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinho</forename><forename type="middle">D</forename><surname>Choi</surname></persName>
		</author>
		<idno>arXiv:abs/1801.02073</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The narrativeqa reading comprehension challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomás</forename><surname>Kocisk´ykocisk´y</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gábor</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<idno>abs/1712.07040</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Vowpal wabbit online learning project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Strehl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Zero-shot relation extraction via reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computational Natural Language Learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Deal or no deal? end-to-end learning for negotiation dialogues. Proceedings of Empirical Methods in Natural Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Batra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Deep reinforcement learning for dialogue generation. Proceedings of Empirical Methods in Natural Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Ms marco: A human generated machine reading comprehension dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<idno>arXiv, abs/1611.09268</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Matthew E Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
		<title level="m">Deep contextualized word representations. Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Know what you don&apos;t know: Unanswerable questions for squad</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Coqa: A conversational question answering challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ArXiv</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Data-driven response generation in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Interpretation of natural language rules in conversational machine reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marzieh</forename><surname>Saeidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Bartolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Signh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rocktschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Sheldon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bouchard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Complex sequential question answering: Towards learning to converse over linked question answer pairs with a knowledge graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amrita</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vardaan</forename><surname>Pahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarath</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chandar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Information-seeking chat: Dialogues driven by topic-structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Stede</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Schlangen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth workshop on the semantics and pragmatics of dialogue</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>SemDial</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Yago: a core of semantic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjergji</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the World Wide Web Conference</title>
		<meeting>the World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The web as knowledgebase for answering complex questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingdi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaheer</forename><surname>Suleman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.09830</idno>
		<title level="m">Newsqa: A machine comprehension dataset</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
