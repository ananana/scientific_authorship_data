<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:28+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Exploring Semantic Representation in Brain Activity Using Word Embeddings</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>November 1-5, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Ping</forename><surname>Ruan</surname></persName>
							<email>ypruan@mail.ustc.edu.cn, zhling@ustc.edu.cn, yuhu@iflytek.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">National Engineering Laboratory for Speech and Language Information Processing</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">National Engineering Laboratory for Speech and Language Information Processing</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Hu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">National Engineering Laboratory for Speech and Language Information Processing</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">iFLYTEK Research</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Exploring Semantic Representation in Brain Activity Using Word Embeddings</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="669" to="679"/>
							<date type="published">November 1-5, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we utilize distributed word representations (i.e., word embeddings) to analyse the representation of semantics in brain activity. The brain activity data were recorded using functional magnetic resonance imaging (fMRI) when subjects were viewing words. First, we analysed the functional selectivity of different cortex areas by calculating the correlations between neural responses and several types of word representations, including skip-gram word embeddings, visual semantic vectors , and primary visual features. The results demonstrated consistency with existing neu-roscientific knowledge. Second, we utilized behavioural data as the semantic ground truth to measure their relevance with brain activity. A method to estimate word embeddings under the constraints of brain activity similarities is further proposed based on the semantic word embedding (SWE) model. The experimental results show that the brain activity data are significantly correlated with the behavioural data of human judgements on semantic similarity. The correlations between the estimated word embeddings and the semantic ground truth can be effectively improved after integrating the brain activity data for learning, which implies that semantic patterns in neural representations may exist that have not been fully captured by state-of-the-art word embeddings derived from text corpora.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, the topic of exploring semantic represen- tation in human brain has attracted the attention of researchers from both neuroscience and computa- tional linguistics fields. In these studies, concepts are represented in terms of neural activation patterns in the brain that can be recorded by functional magnetic resonance imaging (fMRI) ( <ref type="bibr" target="#b9">Haxby et al., 2001</ref>). It has been found that the semantic space shared among different individuals is distributed continuously across the cortex ( <ref type="bibr" target="#b11">Huth et al., 2012)</ref>. A recent study proposed an efficient way to measure and visualize the semantic selectivity of different cortex areas ( <ref type="bibr" target="#b12">Huth et al., 2016</ref>).</p><p>Similar to the distributed semantic representation in the brain, describing the meaning of a word using a dense low-dimensional and continuous vec- tor (i.e., word embedding) is currently a popular approach in computational linguistics ( <ref type="bibr" target="#b10">Hinton et al., 1986;</ref><ref type="bibr" target="#b26">Turney et al., 2010)</ref>. Word embeddings are commonly estimated from large text corpora utilizing statistics concerning the co-occurrences of words ( <ref type="bibr" target="#b19">Mikolov et al., 2013a;</ref><ref type="bibr" target="#b19">Mikolov et al., 2013b;</ref><ref type="bibr" target="#b22">Pennington et al., 2014</ref>). To investigate the correlation between word embeddings and the brain activity involved in viewing words, <ref type="bibr" target="#b21">Mitchell et al. (2008)</ref> designed a computational model to predict brain responses using hand-tailored word embeddings as input. Further, <ref type="bibr" target="#b5">Fyshe et al. (2014)</ref> proposed a joint non-negative sparse embedding (JNNSE) method to combine fMRI data and textual data to estimate word embeddings. This work improved the correlation between word embeddings and human behavioural data, which lends support to the view that fMRI data can provide additional semantic information that may not exist in textual data.</p><p>The factors that can influence the activities of cortex areas are diverse. Recent studies show that vi- sual semantic features such as bag-of-visual-words (BoVW) are significantly correlated with the fMRI data captured when viewing words ( <ref type="bibr" target="#b0">Anderson et al., 2013</ref>). The primary visual features derived using Gabor wavelets can be used to determine the images presented to the subjects from their recorded brain activity ( <ref type="bibr" target="#b14">Kay et al., 2008;</ref><ref type="bibr" target="#b22">Naselaris et al., 2009)</ref>. Some other research work also indicates that visual experiences <ref type="bibr">(Nishimoto et al., 2011</ref>) and speech information ( <ref type="bibr" target="#b23">Ryali et al., 2010)</ref> can affect neural responses in cortex areas.</p><p>In this paper, we first study the semantic repre- sentation of words in brain activity by correlation analysis <ref type="bibr" target="#b0">(Anderson et al., 2013;</ref><ref type="bibr" target="#b1">Carlson et al., 2014</ref>). Then, we calculate the correlations between subjects' neural responses when viewing words and three types of word representations: skip-gram word embeddings, primary visual features, and visual semantic vectors. The goal of doing this is to in- vestigate whether these representations can account for the brain data and the functional selectivity of different cortex areas. Then, we utilize behavioural data as the semantic ground truth to measure the semantic relevance of brain activity. A method of estimating word embeddings within the constraints of similar brain activities is proposed. This method is based on the semantic word embedding (SWE) model ( <ref type="bibr">Liu et al., 2015</ref>) which develops from the skip-gram model. It aims at verifying whether textu- al data and brain activity data can be complementary to derive word embeddings that are more consistent with human judgement.</p><p>The contributions of this study are twofold. First, this study involved a comprehensive correlation analysis on brain activity data and state-of-the-art skip-gram word embeddings at both whole-brain and brain lobe levels. Primary visual features and visual semantic vectors are also introduced as auxiliary representations to better understand the functional selectivity across the cortex. Some results of this analysis are interpretable using existing neuroscience knowledge. Second, to our knowledge, this study marks the first attempt to integrate brain activity data into the skip-gram model for estimating word embeddings.</p><p>The experimental results show that the correlation between the estimated word embeddings and the behavioural measure of semantics can be effectively improved after integrating brain activity data for learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>The correlation between brain data and word vectors has been studied in previous work. The experiments in <ref type="bibr" target="#b1">Carlson et al. (2014)</ref> adopted brain activity data for correlation analysis from only the ventral tempo- ral pathway, not from the whole brain. <ref type="bibr" target="#b0">Anderson et al. (2013)</ref> performed correlation analysis using the voxels of the whole brain and compared the HAL- based textual semantic model <ref type="bibr" target="#b18">(Lund and Burgess, 1996</ref>) with the BoVW-based visual semantic model ( <ref type="bibr">Sivic and Zisserman, 2003;</ref><ref type="bibr" target="#b3">Csurka et al., 2004</ref>) in terms of these two model's ability to account for the patterns found in the neural data. However, the experiments in <ref type="bibr" target="#b0">Anderson et al. (2013)</ref> failed to detect differential interactions of semantic models with brain areas. In this paper, considering the popularity of word embedding estimation approach- es based on neural networks in recent years, we adopt skip-gram word embeddings ( <ref type="bibr" target="#b19">Mikolov et al., 2013a</ref>) for correlation analysis. To our knowledge, this is the first time that the association between skip-gram word embeddings and brain activity data have been studied. Furthermore, our work improves on the voxel selection strategy used in <ref type="bibr" target="#b0">Anderson et al. (2013)</ref>, leading to more interpretable results when demonstrating the functional selectivity of brain areas.</p><p>To our knowledge, the first and only attempt to integrate brain activity data into the acquisition of textual word embedding is the JNNSE method ( <ref type="bibr" target="#b5">Fyshe et al., 2014</ref>). In this method, word em- beddings were estimated as latent representations using matrix factorization. The objective functions contained additional constraints for reconstructing brain activity data. In this paper, we adopt the SWE model ( <ref type="bibr">Liu et al., 2015</ref>) to incorporate brain activity knowledge into word embedding estimation. The SWE model was developed from the skip-gram model. In SWE, semantically related knowledge is converted into inequality constraints for learning word embeddings. The experimental results show that our proposed method using SWE can improve the semantic consistency between word embeddings and human judgements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">From Skip-Gram to SWE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Skip-gram model</head><p>The skip-gram model ( <ref type="bibr" target="#b19">Mikolov et al., 2013b</ref>) adopts a neural network structure to derive the distributed representation of words from textual corpus. The word vectors are learned based on the distribution- al hypothesis <ref type="bibr" target="#b8">(Harris, 1954;</ref><ref type="bibr" target="#b19">Miller and Charles, 1991)</ref>, which assumes that words with similar con- texts tend to have similar semantic meanings. For a sequence of training data of T words, denoted as {w 1 , w 2 , w 3 , · · · , w T }, the skip-gram model is trained to maximize the following objective function</p><formula xml:id="formula_0">Q = 1 T T t=1 −c≤j≤c,j =0 log p(w t+j |w t ),<label>(1)</label></formula><p>where w t and w w+j are the central word and neigh- bouring words in a context window respectively, and c denotes the size of the context window. The condi- tional probability p(w t+j |w t ) in Eq.</p><p>(1) is calculated as</p><formula xml:id="formula_1">p(w t+j |w t ) = exp(w (2) t+j · w (1) t ) V k=1 exp(w (2) k · w (1) t ) ,<label>(2)</label></formula><p>where w </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Semantic word embedding (SWE)</head><p>The skip-gram model learns word embeddings based on the distributional hypothesis; however, this hypothesis still has some limitations. For example, antonyms often appear in similar contexts although they have opposite meanings. The semantic word embedding (SWE) model ( <ref type="bibr">Liu et al., 2015</ref>) has been proposed to address this issue by incorporating external semantic knowledge into the text-based learning process for word embeddings.</p><p>In this method, semantic knowledge is repre- sented as a set of ranking inequalities. Each in- equality contains a triplet (i, j, k) of three words {w i , w j , w k } with a similarity relation</p><formula xml:id="formula_2">similarity(w i , w j ) &gt; similarity(w i , w k ), (3)</formula><p>which can be notated in simplified form as s ij &gt; s ik . Then, the learning method of SWE is defined as the following constrained optimization problem</p><formula xml:id="formula_3">{W (1) , W (2) } = arg max W (1) ,W (2) Q(W (1) , W (2) ), s.t. s ij &gt; s ik , ∀(i, j, k) ∈ S,<label>(4)</label></formula><p>where function Q is defined in Eq. <ref type="formula" target="#formula_0">(1)</ref> and S denotes the inequality set. Then, the constrained optimization problem in Eq. <ref type="formula" target="#formula_3">(4)</ref> is simplified into an unconstrained problem by introducing a penalty term into the objective function of the skip-gram model. The penalty term is defined as</p><formula xml:id="formula_4">D = (i,j,k)∈S f (i, j, k),<label>(5)</label></formula><p>where f (i, j, k) = max(0, s ik − s ij ) is a Hinge loss function. Finally, the object function to be maximized in SWE can be written as follows:</p><formula xml:id="formula_5">Q = Q − β · D,<label>(6)</label></formula><p>where β is a parameter to control the contribution of the penalty term. Similar to the skip-gram model, the Q function in the SWE model is optimized using SGD to estimate word embeddings. The detailed formulae can be found in Liu et al. (2015).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Integrating brain activity into SWE</head><p>In the implementation of the SWE model in <ref type="bibr">Liu et al. (2015)</ref>, the ranking inequalities were collected us- ing hypernym-hyponym and synonym-antonym re- lationships extracted from WordNet <ref type="bibr">(Fellbaum and others, 1998)</ref>. In this paper, the SWE model is utilized as a tool to explore the semantic relevance of brain activity by examining the performance of the estimated word embeddings after integrating brain- activity-related knowledge. Therefore, we construct the ranking inequalities in Eq. (3) using brain activity data. When a subject is viewing a word, the neural response in the cortex is captured using fMRI and further stored as a vector. After collecting the fMRI data for a set of words, the inequalities in Eq. <ref type="formula">(3)</ref> can be constructed by using a similarity measure on the neural response vectors of word pairs. Here, we adopt Pearson correlation as the similarity measure. The details will be introduced in Section 5.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Brain data</head><p>The fMRI data used in our experiments was record- ed and preprocessed by <ref type="bibr" target="#b21">Mitchell et al. (2008)</ref>. It includes the recorded data of 9 subjects. To record the data, each of 60 concrete nouns was presented visually to each subject with a textual label and a simple line drawing. The subjects were asked to think about the properties of the objects indicated by the words during fMRI scanning. This procedure repeated 6 times, and the stimuli of the 60 nouns were presented in a random order in each run. More details about the data acquisition and preprocessing procedures can be found in <ref type="bibr" target="#b21">Mitchell et al. (2008)</ref> and its supplement materials. Finally, an fMRI vector measuring the neural response at all voxels across the cortex was created for each word and each subject.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Behavioural data</head><p>The behavioural data collects human judgements on the semantic similarity between word pairs. The approach to behavioural data collection in our exper- iment is similar to the one used in the WordSim-353 dataset ( <ref type="bibr" target="#b5">Finkelstein et al., 2001</ref>). For the 60 concrete nouns used in Section 4.1, we obtained C 2 60 = 1, 770 word pairs. Then, we asked 15 participants to score the semantic similarity of each word pair on a scale from 0 to 10, in which "0" signified that the two words were totally unrelated and "10" signified that the two words were highly related or had identical meanings. This collection procedure was conducted on the Amazon Mechanical Turk 1 crowdsourcing platform. We tested the average Spearman correlation coefficient among the scores 1 http://www.mturk.com/ given by different annotators and found that it was approximately 0.4873 with a p-value of 1.1e-02. After gathering the scores for all the word pairs, the highest and lowest scores for each word pair were discarded, and the average of the remaining 13 scores was calculated as the similarity score for each word pair 2 .</p><p>To verify the reliability of the above data col- lection process, we also added 15 word pairs from the WordSim-353 dataset into our 1,770 word pairs during score collection. Then, we calculated the similarity scores of these 15 word pairs using the collected scores and compared them with the scores in the WordSim-353 dataset using Spearman cor- relation analysis. The correlation coefficient was 0.8451 with a p-value of 2.7e − 04. This high correlation verifies the reliability of our behavioural data collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Correlations between brain activity and word vectors</head><p>We calculated the correlations between the fMRI vectors and the different types of word represen- tations to investigate whether these representations can account for the brain activity and the functional selectivity of different cortex areas. We adopted the method of representational similarity analysis ( <ref type="bibr" target="#b15">Kriegeskorte et al., 2008</ref>) in our experiments. For a specific word representation, we calculated the cosine similarity for each word pair in a set of n words, resulting in a similarity vector with a total length of C 2 n . For the fMRI data 3 , we constructed a similarity vector for each subject using the Pear- son correlation coefficients between pairs of fMRI vectors ( <ref type="bibr" target="#b0">Anderson et al., 2013)</ref>. Then, the 9 vectors of the 9 subjects were averaged to obtain an overall similarity vector in the fMRI space <ref type="bibr" target="#b0">(Anderson et al., 2013</ref>). Finally, the Spearman rank correlation coefficient between the similarity vectors given by the fMRI data and each word representation was calculated together with a p-value for significance analysis. The p-value was calculated using a per- mutation test under a positive hypothesis with the word pair labels randomly shuffled 10,000 times. Empirically, two similarity vectors are considered to be correlated when p &lt; 0.05, and they are considered significantly correlated when p &lt; 0.01.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Word vectors</head><p>Three types of word representations, i.e., skip- gram word embeddings, visual semantic vectors, and primary visual features, were used in the correlation analysis.</p><p>Some details about the acquisitions of these three word representations will be introduced in the following paragraphs.</p><p>Skip-gram word embeddings The Wikipedia text corpus 4 , containing 130 million words, was adopted to train our skip-gram word embeddings, and the hierarchical softmax scheme was followed. The dimension of word embedding was 200. The window size, learning rate, and negative sampling number were set to 8, 0.05, and 8, respectively. The model was trained for one iteration using a single execution thread.</p><p>Visual semantic vectors On one hand, distributed word representations are usually learnt from text corpora. On the other hand, visual perception also contributes to semantic cognition according to some neuroscience research <ref type="bibr" target="#b16">(Louwerse, 2011)</ref>, and it has been utilized to complement the semantic representation learned from texts ( <ref type="bibr" target="#b1">Bruni et al., 2012)</ref>.</p><p>One approach to constructing visual semantic vectors is to first extract the low-level visual features from images and then convert them into higher-level semantic representations using the bag-of-visual-words (BoVW) (Grauman and Leibe, 2011) model. In our experiments, we built the BoVW representations from ImageNet ( <ref type="bibr" target="#b5">Deng et al., 2009</ref>) using the VSEM 5 toolkit. Due to coverage limitations, only 57 of the 60 concrete nouns in the fMRI data could be found in ImageNet <ref type="bibr">6</ref> and each noun has approximately 1000 image samples. Similar to <ref type="bibr" target="#b0">Anderson et al. (2013)</ref>, we adopted the Scale Invariant Feature Transform (SIFT) <ref type="bibr" target="#b17">(Lowe, 2004)</ref> to extract lower-level visual features; however, we did not use the "object" box to discriminate "object" and "context" areas during the extraction. Then, we clustered the SIFT features into 1000 classes to construct the visual vocabulary, and each image was divided into 8 regions. Thus, the BoVW representation of an image was a vector of 8000 dimensions. The BoVW vectors of all images in ImageNet corresponding to the same word were averaged to obtain the BoVW representation of that word. Finally, we transformed the BoVW representation matrix of the 57 nouns to nonnegative point-wise mutual information (PMI) association scores <ref type="bibr">(Church and Hanks, 1990</ref>) to obtain the final visual semantic vectors.</p><p>Primary visual features As introduced in Section 4.1, a line drawing of each word was presented to subjects together with the textual label when collecting the fMRI data ( <ref type="bibr" target="#b21">Mitchell et al., 2008)</ref>. This presentation led to neural responses in visual cortices that may be irrelevant to semantic representation. Because the receptive fields of simple cells in the primary visual cortex of mammalian brains can be modelled by Gabor functions <ref type="bibr" target="#b19">(MarˆceljaMarˆcelja, 1980;</ref><ref type="bibr" target="#b4">Daugman, 1985)</ref>, we adopted Gabor wavelets to extract the primary visual features from the line drawings of the 60 nouns and further analysed their correlations with fMRI data. The original resolution of the image stimuli used in <ref type="bibr" target="#b21">Mitchell et al. (2008)</ref> was 500 x 500 pixels. These images were converted to 64 x 64 pixels after trimming the black borders and downsampling. The Gabor wavelet filter bank was designed using an open source tool <ref type="bibr" target="#b6">(Haghighat et al., 2015</ref>). The number of scales and orientations were set to 5 and 8, respectively. Thus, we represented the primary visual features of each noun as a vector of 163,840 dimensions. The singular value decomposition (SVD) technique was employed to reduce the dimension of each vector to 60.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Correlation analysis at the whole-brain level</head><p>The fMRI recording measures the neural respons- es of more than 20,000 voxels across the cortex. To perform dimensionality reduction, we selected 500 voxels from all voxels for each subject according to word representation rho (p-value) skip-gram 0.0065 (4.0e-01) BoVW 0.3515 (0.0e-00) Gabor 0.3924 (0.0e-00)  <ref type="table">Table 2</ref>: The proportions of the regional distribu- tions of the 500 selected voxels.</p><p>the stability of the voxel responses across 6 runs of fMRI recordings. This selection strategy was the same as the one used in <ref type="bibr" target="#b21">Mitchell et al. (2008)</ref> and <ref type="bibr" target="#b0">Anderson et al. (2013)</ref>. The correlation analysis followed the method described at the beginning of Section 5.1. <ref type="table" target="#tab_0">Table 1</ref> shows the results, where skip- gram, BoVW, and Gabor denote the skip-gram word embeddings, visual semantic vectors, and primary visual features introduced above, respectively. As <ref type="table" target="#tab_0">Table 1</ref> shows, the visual semantic vectors and primary visual features are significantly correlated with the fMRI vectors at the whole-brain level; however, the skip-gram word embeddings are not correlated with the fMRI data. To investigate the reason for this lack of correlation, we analysed the distribution of the 500 selected voxels across the four brain lobes (i.e., frontal, temporal, parietal and occipital) using the automated anatomical labeling scheme <ref type="bibr" target="#b27">(Tzourio-Mazoyer et al., 2002)</ref>. From the results shown in <ref type="table">Table 2</ref>, we can find that most of the selected voxels are located in the occipital lobe although it is the smallest of the four main lobes in the human brain. The occipital lobe occupies most of the anatomical area of the visual cortex and is considered to be the visual processing centre of the mammalian brain. This unbalanced distribution led to the conclusion that the semantic information related to skip-gram word embeddings is not well represented by the 500 selected voxels. Thus, an al- ternative strategy to select stable voxels at the brain lobe level for correlation analysis was necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Correlation analysis at the brain lobe level</head><p>As an alternative approach, rather than selecting the 500 most stable voxels from the whole-brain data as in ( <ref type="bibr" target="#b21">Mitchell et al., 2008;</ref><ref type="bibr" target="#b0">Anderson et al., 2013)</ref>, we selected the 100 most stable voxels at each of the four main brain lobes independently for this experiment. Then, the correlations between the fMRI vectors measuring different lobes and word representations were calculated and are shown in <ref type="table">Table 3</ref>.</p><p>From this table, we can observe the association differences of different word representations with brain lobe level activities. First, the primary visual features (Gabor) are highly correlated with the oc- cipital fMRI data and are uncorrelated with the other three lobes. This is reasonable considering that the primary visual cortex (V1) is located in the occipital lobe. Second, the skip-gram word embeddings are significantly correlated with the fMRI data of all brain lobes except the occipital lobe. Previous neuroscience research has revealed that the frontal, temporal, and parietal lobes all play important roles in semantic cognition, including high-level and ab- stract knowledge processing ( <ref type="bibr" target="#b20">Miller et al., 2002</ref>), integration of lexical information <ref type="bibr" target="#b7">(Hagoort, 2005)</ref>, speech comprehension <ref type="bibr">(Hickok and Poeppel, 2007)</ref>, and knowledge retrieval ( <ref type="bibr" target="#b1">Binder et al., 2009)</ref>. This indicates that the skip-gram word embeddings can partly account for the semantic processing in the cortex and contain little visual information about words. Third, the visual sematic vectors (BoVW) are significantly correlated with all four brain lobes. It has been found that the temporal lobe plays a key role in both the formation of long-term visual memories <ref type="bibr" target="#b25">(Smith and Kosslyn, 2007)</ref> and in the recognition of visual stimuli and objects <ref type="bibr" target="#b2">(Chao et al., 1999;</ref><ref type="bibr">Kanwisher and Yovel, 2006</ref>). The parietal lobe is relevant to high-level vision and is part of the dorsal visual stream correlated with spatial cognition <ref type="bibr" target="#b24">(Sack, 2009;</ref><ref type="bibr">Vannini et al., 2004</ref>). This indicates that the visual sematic vectors used in our experiment may contain not only low-level but also high-level and semantically related visual informa- tion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Frontal</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Temporal</head><p>Parietal Occipital Skip-gram 0.1450 (0.0e+00) 0.1483 (0.0e+00) 0.2317 (0.0e+00) -0.0385 (9.4e-01) BoVW 0.0601 (8.2e-03) 0.2053 (0.0e+00) 0.2750 (0.0e+00) 0.3120 (0.0e+00) Gabor -0.0823 (1.0e+00) -0.0879 (1.0e+00) 0.0111 (3.4e-01) 0.5116 (0.0e+00) <ref type="table">Table 3</ref>: Spearman's rank correlation coefficients (rho) between different word representations and the fMRI data at four main brain lobes and their corresponding p-values.</p><p>fMRI data rho (p-value) whole brain 0.1266 (0.0e+00) frontal lobe 0.0160 (2.5e-01) temporal lobe 0.0694 (1.7e-03) parietal lobe 0.0698 (1.6e-03) occipital lobe 0.0814 (4.0e-04) <ref type="table">Table 4</ref>: Spearman's rank correlation coefficients (rho) between the behaviour data and the fMRI data of different brain lobes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Correlations between brain activity and behavioural data</head><p>After analysing the correlation between brain activi- ty and the three types of word vectors in the previous experiments, we further examined the correlations between brain activity and the behavioural data introduced in Section 4.2. Here, the behavioural data were used as the semantic ground truth to evaluate the semantic relevance of the brain activity and word embeddings. The results are shown in <ref type="table">Table 4</ref>. In this subsection, the fMRI data at the whole-brain and brain lobe levels adopted the voxel selection strategies introduced in Sections 5.1.2 and 5.1.3, respectively. As <ref type="table">Table 4</ref> shows, the behavioural data are significantly correlated with the fMRI data of the whole brain and the occipital lobe, and they are also correlated with the fMRI data of the temporal and parietal lobes. Furthermore, we utilized the SWE model in- troduced in Section 3.2 to explore the semantic relevance of brain activity by examining the per- formance of the estimated word embeddings after integrating brain activity related knowledge. The inequality set used in Eq. (3) was created using the fMRI data, where the similarity score s ij was calcu- lated as the Pearson correlation coefficient between the fMRI vectors of the i-th and the j-th words. For the 60 nouns (a total of 12 categories with 5 words in each category), we produced 12 × 3 × C 3 5 = 360 intra-category inequalities and 3 × C 3 12 = 660 inter- category inequalities. To collect the inter-category inequalities, we first used the label words of each category and averaged the fMRI vectors of the 5 words belonging to each category to obtain the fMRI data for these label words. Then, the inter-category inequalities were produced from the triplets of these label words. The text corpus and parameter settings we used to train SWE were the same as those used for training the skip-gram word embeddings as described in Section 5.1.1. The penalty term β in Eq. (6) was tuned through experiments.</p><p>We evaluated the word embeddings estimated with brain activity constraints using the collected behavioural data for the 60 nouns and the WordSim- 353 dataset. WordSim-353 is a behavioural dataset containing semantic similarity scores for 353 word- pairs ( <ref type="bibr" target="#b5">Finkelstein et al., 2001</ref>). We checked to ensure these word-pairs have no overlap with the 60 nouns used in our experiments. The purpose of using the WordSim-353 dataset is to explore the effects of utilizing the brain data of the 60 nouns on other words for which we had no brain data.  <ref type="table">Table 5</ref>: Spearman's rank correlation coefficients between different word embeddings and the be- havioural data of the two datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="60">nouns WordSim353</head><p>The performance of the word embeddings esti- mated using the SWE model and the whole-brain fMRI data are shown in <ref type="figure" target="#fig_1">Figure 1</ref>. In this figure, the SWE model becomes a conventional skip-gram model when β = 0. The correlation coefficient between the skip-gram word embeddings and the behavioural data of the 60 nouns was 0.2232. As β was increased, this correlation coefficient increased significantly. The maximum correlation efficient was 0.3814 when β = 2.8. This result implies that textual data and brain activity data can be used in a complementary fashion to derive word embeddings that are more consistent with human judgements. On one hand, semantic patterns may exist in neural representations that have not been fully captured by state-of-the-art word embeddings derived from text corpora. On the other hand, we can see that the variation of the correlation coefficients for the WordSim-353 dataset with different β values is small. This indicates that our SWE training did- n't negatively affect the word embeddings without fMRI observations. Furthermore, we produced ranking inequalities using the fMRI data measuring each brain lobe to estimate word embeddings under the SWE frame- work. The correlations between the learned word embeddings and the behavioural data of the two datasets were calculated and are shown in <ref type="table">Table 5</ref>. For each SWE model in this table, the value of β was tuned to obtain the highest correlation on the 60 nouns. Comparing the correlation coefficients of the different models on the 60 nouns, we can see that the fMRI data at all brain lobes can contribute to learning more semantically related word embed- dings using the SWE model. The improvement from using the fMRI data of the temporal lobe is the most significant among the four lobes, but the highest correlation coefficient is achieved when utilizing the fMRI data of whole brain.</p><p>Finally, we compared the performance of our SWE models with the JNNSE model proposed by <ref type="bibr" target="#b5">Fyshe et al. (2014)</ref> on the two datasets. The word embeddings estimated by the JNNSE model utilized either fMRI or magnetoencephalography (MEG) measures of the 60 nouns. We adopted the best JNNSE word embeddings reported by the authors 7 for these comparisons, and the results are shown in the last row of <ref type="table">Table 5</ref> 8 . As <ref type="table">Table  5</ref> shows, the performance of the JNNSE word embeddings on the WordSim-353 dataset is not as good as those of the skip-gram and SWE results. Examining the correlation coefficients on the 60 nouns with brain activity data, we can see that the JNNSE model achieves better performance than the skip-gram model, but is still below that of the SWE models. It should be noted that it is unfair to directly compare the SWE models and the JNNSE model because they used different training corpora and word embedding dimensions. Moreover, the β values of the SWE models were tuned to achieve the best performance on these 60 nouns. Here, the motivation behind introducing the JNNSE model as a reference is to help readers better understand the effects of integrating brain data into SWE training. These experimental results demonstrate that the SWE model is an effective model structure for integrating external knowledge into the estimation of word embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This study utilized word embeddings to investigate the semantic representations in brain activity as measured by fMRI. First, the functional selectivity of different cortex areas is explored by calculating the correlations between neural responses and three types of word vectors: skip-gram word embeddings, visual semantic vectors, and primary visual features.</p><p>Experimental results demonstrate the differences between the associations of different word vectors with brain-lobe-level brain activities. The skip- gram word embeddings are significantly correlated with the fMRI data of all brain lobes except the occipital lobe. Furthermore, we utilized behavioural data as the semantic ground truth to measure its relevance to brain activity. The SWE model was employed to explore the semantic relevance of brain activity by examining the performances of word embeddings after integrating brain-activity-related knowledge into their estimations. Experimental results show that whole-brain fMRI data are sig- nificantly correlated with human judgement with respect to semantic similarity. The correlations between the estimated word embeddings and the human-assigned similarity scores are effectively im- proved after integrating brain activity data into SWE training.</p><p>The experiments in this paper provide information about how semantic features correlate with brain ac- tivities, laying foundations for further investigations of higher-level semantic processing in the human brain. Furthermore, our experiments with SWE modelling show the potential of applying fMRI data to obtain better word embeddings. Although this approach is still far from being a practical engineering application due to issues such as the high costs and low signal-to-noise ratio of fMRI recordings and the diversity among individuals, it provides us with an alternative method for verifying the semantic relevance of brain activities and with evidence for recognizing the limitations of estimat- ing word embeddings using only text corpora.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>denote row vectors in the matrices W (1) and W (2) respectively, and V is the vocabulary size of the corpus. The matrix W (1) stores the word vectors of input central words, and the matrix W (2) stores the word vectors of predicted neighbouring words. The optimization of the objective function Q is solved by the stochastic gradient descent (SGD) method (Mikolov et al., 2013b). Finally, the learned matrix W (1) is used as the estimated word embeddings of all words in the vocabulary.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Spearman's rank correlation coefficients between the estimated word embeddings with different β values and the behavioural data of two datasets.</figDesc><graphic url="image-1.png" coords="7,313.22,163.23,226.78,153.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Spearman's rank correlation coefficients 
(rho) between different word representations and 
whole-brain fMRI data for 57 nouns and their 
corresponding p-values. 

Lobe 
Proportion (%) 
frontal 
5.89 
temporal 
6.96 
parietal 
10.13 
occipital 
58.40 
other 
18.62 

</table></figure>

			<note place="foot" n="2"> The behavioural data are available at http: //home.ustc.edu.cn/ ˜ ypruan/work/emnlp2016/ behaviour_data/ 3 Before using the fMRI data, we first regularized its mean value to 0 and variance to 1.</note>

			<note place="foot" n="4"> http://mattmahoney.net/dc/enwik9.zip 5 http://clic.cimec.unitn.it/vsem/ 6 The three missing words are arm, eye and saw.</note>

			<note place="foot" n="7"> http://www.cs.cmu.edu/ ˜ afyshe/papers/ acl2014/ 8 Because there were 32 word-pairs in the WordSim-353 dataset that were not covered by the vocabulary of the JNNSE word embeddings, the value 0.1795 in the last row of Table 5 was calculated using only 321 word-pairs.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported in part by the Science and Technology Development of Anhui Province, China (Grant No. 2014z02006), the Fundamental Research Funds for the Central Universities (Grant No. WK2350000001) and the CAS Strategic Prior-ity Research Program (Grant No. XDB02070006). The authors also want to thank Quan Liu for his help and wonderful suggestions during the experiments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Of words, eyes and brains: Correlating image-based distributional semantic models with neural representations of concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Andrew J Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulisse</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Bordignon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Poesio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<biblScope unit="page" from="1960" to="1970" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Distributional semantics with eyes: Using image analysis to improve computational representations of word meaning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Binder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM international conference on Multimedia</title>
		<meeting>the 20th ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="120" to="131" />
		</imprint>
	</monogr>
	<note>Cerebral Cortex</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Attribute-based neural substrates in temporal cortex for perceiving and knowing about objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Chao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="22" to="29" />
			<date type="published" when="1990" />
			<publisher>Kenneth Ward Church and Patrick Hanks</publisher>
		</imprint>
	</monogr>
	<note>Nature neuroscience</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Visual categorization with bags of keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Csurka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on statistical learning in computer vision, ECCV</title>
		<meeting><address><addrLine>Prague</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1" to="2" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Uncertainty relation for resolution in space, spatial frequency, and orientation optimized by two-dimensional visual cortical filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>John G Daugman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JOSA A</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1160" to="1169" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Interpretable semantic vectors from a joint model of brain-and textbased meaning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference. Association for Computational Linguistics. Meeting</title>
		<meeting>the conference. Association for Computational Linguistics. Meeting</meeting>
		<imprint>
			<publisher>NIH Public Access</publisher>
			<date type="published" when="1998" />
			<biblScope unit="volume">2014</biblScope>
			<biblScope unit="page" from="1" to="181" />
		</imprint>
	</monogr>
	<note>Proceedings of the 10th international conference on World Wide Web. Grauman and Leibe2011] Kristen Grauman and Bastian Leibe. 2011. Visual object recognition. Synthesis lectures on artificial intelligence and machine learning</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Cloudid: Trustworthy cloud-based and cross-enterprise biometric identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Haghighat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mohammad Haghighat, Saman Zonouz, and Mohamed Abdel-Mottaleb</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="7905" to="7916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On broca, brain, and binding: a new framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Hagoort</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="416" to="423" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zellig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harris</surname></persName>
		</author>
		<title level="m">Distributional structure. Word</title>
		<imprint>
			<date type="published" when="1954" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="146" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Distributed and overlapping representations of faces and objects in ventral temporal cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Haxby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<editor>Hickok and Poeppel2007] Gregory Hickok and David Poeppel</editor>
		<imprint>
			<biblScope unit="volume">293</biblScope>
			<biblScope unit="issue">5539</biblScope>
			<biblScope unit="page" from="393" to="402" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note>Science</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Distributed representations, parallel distributed processing: explorations in the microstructure of cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>foundations</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A continuous semantic space describes the representation of thousands of object and action categories across the human brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinji</forename><surname>Alexander G Huth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">An</forename><forename type="middle">T</forename><surname>Nishimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack L</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gallant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1210" to="1224" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Huth et al.2012</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Natural speech reveals the semantic maps that tile human cerebral cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">532</biblScope>
			<biblScope unit="issue">7600</biblScope>
			<biblScope unit="page" from="453" to="458" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The fusiform face area: a cortical region specialized for the perception of faces</title>
	</analytic>
	<monogr>
		<title level="m">Philosophical Transactions of the Royal Society of London B: Biological Sciences</title>
		<imprint>
			<date type="published" when="1476" />
			<biblScope unit="volume">361</biblScope>
			<biblScope unit="page" from="2109" to="2128" />
		</imprint>
	</monogr>
	<note>Nancy Kanwisher and Galit Yovel</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Identifying natural images from human brain activity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kendrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Naselaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack L</forename><surname>Prenger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gallant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">452</biblScope>
			<biblScope unit="issue">7185</biblScope>
			<biblScope unit="page" from="352" to="355" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Representational similarity analysis-connecting the branches of systems neuroscience. Frontiers in systems neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Kriegeskorte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<editor>4. [Liu et al.2015] Quan Liu, Hui Jiang, Si Wei, Zhen-Hua Ling, and Yu Hu</editor>
		<meeting>ACL<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>Learning semantic word embeddings based on ordinal knowledge constraints</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Symbol interdependency in symbolic and embodied cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Max M Louwerse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="273" to="302" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>David G Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Producing high-dimensional semantic spaces from lexical co-occurrence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Curt</forename><surname>Burgess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods, Instruments, &amp; Computers</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="208" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">] S Marˆceljamarˆcelja ;</forename><surname>Marˆcelja1980</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
	</analytic>
	<monogr>
		<title level="m">Mathematical description of the responses of simple cortical cells*. JOSA</title>
		<editor>Mikolov et al.2013b] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean</editor>
		<imprint>
			<date type="published" when="1980" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1" to="28" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
	<note>Contextual correlates of semantic similarity</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The prefrontal cortex: categories, concepts and cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Philosophical Transactions of the Royal Society of London B: Biological Sciences</title>
		<imprint>
			<date type="published" when="1424" />
			<biblScope unit="volume">357</biblScope>
			<biblScope unit="page" from="1123" to="1136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Predicting human brain activity associated with the meanings of nouns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">science</title>
		<imprint>
			<biblScope unit="volume">320</biblScope>
			<biblScope unit="issue">5880</biblScope>
			<biblScope unit="page" from="1191" to="1195" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bayesian reconstruction of natural images from human brain activity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Naselaris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Shinji Nishimoto, An T Vu</title>
		<meeting><address><addrLine>Thomas Naselaris, Yuval Benjamini</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
	<note>EMNLP</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sparse logistic regression for whole-brain classification of fMRI data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Ryali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="752" to="764" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Parietal cortex and spatial cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioural brain research</title>
		<imprint>
			<biblScope unit="volume">202</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="153" to="161" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Video google: A text retrieval approach to object matching in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision, 2003. Proceedings. Ninth IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="1470" to="1477" />
		</imprint>
	</monogr>
	<note>Sivic and Andrew Zisserman</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">From frequency to meaning: Vector space models of semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pearson Prentice Hall ;</forename><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of artificial intelligence research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="141" to="188" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Task demand modulations of visuospatial processing measured with functional magnetic resonance imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tzourio-Mazoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Patrizia Vannini, Ove Almkvist, Anders Franck, Tomas Jonsson, Umberto Volpe, Maria Kristoffersen Wiberg, Lars-Olof Wahlund, and Thomas Dierks</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="58" to="68" />
		</imprint>
	</monogr>
	<note>Neuroimage</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
