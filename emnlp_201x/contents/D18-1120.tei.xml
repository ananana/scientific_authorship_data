<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Attention-Based Capsule Networks with Dynamic Routing for Relation Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ningyu</forename><surname>Zhang</surname></persName>
							<email>zhangningyu@zju.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Zhejiang Lab</orgName>
								<orgName type="institution">Artificial Intelligence Research Institute</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shumin</forename><surname>Deng</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Alibaba-Zhejiang University Frontier Technology Research Center</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanlin</forename><surname>Sun</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Alibaba-Zhejiang University Frontier Technology Research Center</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huajun</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Attention-Based Capsule Networks with Dynamic Routing for Relation Extraction</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="986" to="992"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>986</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>A capsule is a group of neurons, whose activity vector represents the instantiation parameters of a specific type of entity. In this paper , we explore the capsule networks used for relation extraction in a multi-instance multi-label learning framework and propose a novel neural approach based on capsule networks with attention mechanisms. We evaluate our method with different benchmarks, and it is demonstrated that our method improves the precision of the predicted relations. Particularly , we show that capsule networks improve multiple entity pairs relation extraction 1 .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper focus on the task of relation extrac- tion. One popular method for relation extraction is the multi-instance multi-label learning frame- work (MIML) ( <ref type="bibr" target="#b18">Surdeanu et al., 2012</ref>) with dis- tant supervision, where the mentions for an en- tity pair are aligned with the relations in Free- base <ref type="bibr" target="#b1">(Bollacker et al., 2008</ref>). The recently pro- posed neural network (NN) models ( <ref type="bibr" target="#b25">Zeng et al., 2014;</ref><ref type="bibr" target="#b22">Ye et al., 2017;</ref><ref type="bibr" target="#b19">Wang et al., 2018a</ref>) achieve state-of-the-art performance. However, despite the great success of these NNs, some disadvantages remain. First, the existing models focus on, and heavily rely on, the quali- ty of instance representation. Using a vector to represent a sentence is limited because languages are delicate and complex. Second, CNN subsam- pling fails to retain the precise spatial relationship- s between higher-level parts. The structural re- lationships such as the positions in sentences are valuable. Besides, existing aggregation operations summarizing the sentence meaning into a fixed- size vector such as max or average pooling are lack of guidance by task information. Self-attention ( <ref type="bibr" target="#b10">Lin et al., 2017)</ref> can select task-dependent infor- mation. However, the context vectors are fixed once learned ( <ref type="bibr" target="#b3">Gong et al., 2018)</ref>.</p><p>More importantly, most state-of-the-art systems can only predict one most likely relation for a s- ingle entity pair. However, it is very common that one sentence may contain multiple entity pairs and describe multiple relations. It is beneficial to con- sider other relations in the context while predicting the relations <ref type="bibr" target="#b17">(Sorokin and Gurevych, 2017)</ref>. For example, given the sentence " <ref type="bibr">[Swag It Out]</ref> is the official debut single by American <ref type="bibr">[singer]</ref> [Zen- daya]", our model can predict multi-relations for these multiple entity pairs simultaneously.</p><p>In our work, we present a novel architecture based on capsule networks ( <ref type="bibr" target="#b15">Sabour et al., 2017)</ref> for relation extraction. We regard the aggregation as a routing problem of how to deliver the mes- sages from source nodes to target nodes. This pro- cess enables the capsule networks to decide what and how much information need to be transferred as well as identify complex and interleaved fea- tures. Furthermore, the capsule networks convert the multi-label classification problem into a multi- ple binary classification problem. We also import word-level attention by considering the different contribution of the words. The experimental re- sults show that our model achieves improvements in both single and multiple relation extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Neural Relation Extraction: In the recent years, NN models have shown superior performance over approaches using hand-crafted features in various tasks. CNN is the first one of the deep learn- ing models that have been applied to relation ex-   <ref type="bibr" target="#b20">Wang et al., 2018b</ref>) proposed a capsule model based on RNN for sentiment anal- ysis. To the best of our knowledge, there has been no work that investigates the performance of capsule networks in relation extraction tasks at present.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>In this section, we first introduce the MIML frame- work, and then describe the model architecture we propose for relation extraction, which is shown in <ref type="figure" target="#fig_0">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preliminaries</head><p>In MIML, the set of text sentences for the single entity pair or multiple entity pairs 2 (maximum t- wo entity pairs in this paper) is denoted by X = {x 1 , x 2 , ..., x n }. Assumed that there are E pre- defined relations (including NA) to extract. For- mally, for each relation r, the prediction target is denoted by P (r|x 1 , ..., x n ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Neural Architectures</head><p>Input Representation: For each sentence x i , we use pretrained word embeddings to project each word token onto the d w -dimensional space. We adopt the position features as the combination- s of the relative distances from the current word to M entities and encode these distances in M d p -dimensional vectors <ref type="bibr">3</ref> . For single entity pair relation extraction, M = 2; for multiple entity pairs relation extraction, we limit the maximum number of entities in a sentence to four (i.e. t- wo entity pairs). As three entities in one in- stance is possible when two tuples have a com- mon entity, we set the relative distance to the missing entity to a very large number. Finally, each sentence is transformed into a matrix</p><formula xml:id="formula_0">x i = {w 1 , w 2 , ..., w L } ∈ R L×V ,</formula><p>where L is the sen- tence length with padding and</p><formula xml:id="formula_1">V = d w + d p * M .</formula><p>Bi-LSTM Layer: We make use of LSTMs to deeply learn the semantic meaning of a sentence. We concatenate the current memory cell hidden s- tate vector h t of LSTM from two directions as the output vector</p><formula xml:id="formula_2">h t = [ − → h t , ← − h t ] ∈ R 2B at time t,</formula><p>where B denotes the dimensionality of LSTM.</p><p>We import word-level attention mechanism as only a few words in a sentence that are relevant to the relation expressed <ref type="bibr" target="#b7">(Jat et al., 2018)</ref>. The scor- ing function is g t = h t × A × r, where A ∈ R E×E is a square matrix and r ∈ R E×1 is a relation vec- tor. Both A and r are learned. After obtaining g t , we feed them to a softmax function to calculate the final importance α t = sof tmax(g t ). Then, we get the representatioñ x t = α t h t . For a given bag of sentences, the learning is done using the setting proposed by <ref type="bibr" target="#b24">(Zeng et al., 2015)</ref>, where the sentence with highest probabili- ty of expressing the relation in a bag is selected to train the model in each iteration.</p><p>Primary Capsule Layer: Suppose u i ∈ R d denotes the instantiated parameters set of a cap- sule, where d is the dimension of the capsule. Let W b ∈ R 2×2B be the filter shared across different windows. We have a window sliding each 2-gram vector in the sequence˜xsequence˜ sequence˜x ∈ R L×2B with stride 1 to produce a list of capsules U ∈ R (L+1)×C×d , totally C × d filters.</p><formula xml:id="formula_3">u ij = squash(W b i ⊗ S j−1:j + b 1 )<label>(1)</label></formula><p>where</p><formula xml:id="formula_4">0 ≤ i ≤ C × d, 0 ≤ j ≤ L + 1, squash(x) = ||x|| 2 0.5+||x|| 2 x</formula><p>||x|| , b 1 is the bias ter- m. For all C × d filters, the generated cap- sule feature maps can be rearranged as U = {u 1 , u 2 , ..., u (L+1)×C }, where totally (L + 1) × C d-dimensional vectors are collected as capsules. for all capsule i in layer l and capsule j in layer l + 1 do 5:</p><formula xml:id="formula_5">c j|i = ˆ a j|i · sof tmax(b j|i ) 6:</formula><p>for all capsule j in layer l + 1 do 7:</p><formula xml:id="formula_6">v j = squash( i c j|î u j|i ), a j = ||v j || 8:</formula><p>for all capsule i in layer l and capsule j in layer l + 1 do 9:</p><formula xml:id="formula_7">b j|i = b j|i + ˆ u j|i · v j return v j , a j</formula><p>Dynamic Routing: We explore the transfor- mation matrices to generate the prediction vector u j|i ∈ R d from a child capsule i to its parent cap- sule j. The transformation matrices share weights W c ∈ R E×d×d across the child capsules, where E is the number relations (parent capsules) in the layer above. Formally, each corresponding vote can be computed by:</p><formula xml:id="formula_8">ˆ u j|i = W c j u i + ˆ b j|i ∈ R d<label>(2)</label></formula><p>The basic idea of dynamic routing is to design a nonlinear map:</p><formula xml:id="formula_9">{û j|i ∈ R d } i=1,...,H,j=1,...,E → {v j ∈ R d } E j=1</formula><p>where H = (L + 1) × C. Inspired by ( <ref type="bibr" target="#b26">Zhao et al., 2018)</ref>, we attempt to use the probability of existence of parent cap- sules to iteratively amend the connection strength, which is summarized in Algorithm 1. The length of the vector v j represents the probability of each relation. We use a separate margin loss L k for each relation capsule k:</p><formula xml:id="formula_10">L k = Y k max(0, m + − ||v k ||) 2 + λ(1 − Y k )max(0, ||v k || − m − ) 2<label>(3)</label></formula><p>where Y k = 1 if the relation k is present, m + = 0.9 , m − = 0.1 and λ = 0.5. The total loss can be formulated as:</p><formula xml:id="formula_11">L total = E k=1 L k</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Prediction</head><p>For single entity pair relation extraction, we cal- culate the length of the vector v j which repre- sents the probability of each relation. For multi- ple entity pairs relation extraction, we choose re- lations with top two probability meanwhile bigger than the threshold (We empirically set the thresh- old 0.7). Finally, we may get one or two predicted relations r. Given entity pair (e 1 , e 2 ), in order to choose which relationship the tuple belongs to, we adopt the pretrained embeddings of entities and re- lations 4 and calculate r k = arg min</p><formula xml:id="formula_12">k |t − h − r k |</formula><p>, where t, h are the embeddings of entities e 1 , e 2 respectively and r k is the relation embedding. The relation with the closest embedding to the entity embedding difference is the predicted category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We test our model on the NYT dataset (NYT) de- veloped by ( <ref type="bibr" target="#b14">Riedel et al., 2010</ref>) for single entity pair relation extraction and the Wikidata dataset (Sorokin and Gurevych, 2017) for multiple enti- ty pairs relation extraction. We exclude sentences longer than L . All code is implemented in Ten- sorflow ( <ref type="bibr" target="#b0">Abadi et al., 2016)</ref>. We adopt the Adam optimizer ( <ref type="bibr" target="#b8">Kingma and Ba, 2014</ref>) with learning rate 0.001, batch size 128, LSTMs' unit size 300, L = 120, d p = 5, d = 8, C = 32, dropout rate 0.5, routing iteration 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Practical Performance</head><p>NYT dataset (Single entity pair): We utilize the word embeddings released by ( <ref type="bibr" target="#b9">Lin et al., 2016)</ref>  <ref type="bibr">5</ref> . The precision-recall curves for different models on the test set are shown in <ref type="figure" target="#fig_2">Figure 2</ref>. Our model BiLSTM+Capsule achieves comparable results compared with all baselines, where Mintz refers to ( <ref type="bibr" target="#b11">Mintz et al., 2009</ref>), Hoff- mann refers to ( <ref type="bibr" target="#b6">Hoffmann et al., 2011</ref>), MIMLRE refers to ( <ref type="bibr" target="#b18">Surdeanu et al., 2012)</ref>, CNN+ATT refers to ( <ref type="bibr" target="#b24">Zeng et al., 2015)</ref>, PCNN+ATT refers to ( <ref type="bibr" target="#b9">Lin et al., 2016)</ref>, Rank+ExATT refers to ( <ref type="bibr" target="#b22">Ye et al., 2017)</ref> and Memory refers to ). We also show the precision numbers for some par- ticular recalls as well as the AUC in <ref type="table">Table 1</ref>, where our model generally leads to better precision. In- terestingly, we observe our model achieve com- parable results to predict multi-relation compared with Rank+ExATT in <ref type="figure" target="#fig_4">Figure 3</ref>. Given an entity tuple (South Korea, Seoul) which has two rela- tions: /location/./administrative divisions and /lo- cation/./capital. We observe these two relations have the highest scores among the other relation- s in our model which demonstrate the ability of multi-relations prediction.</p><p>Wikidata dataset (Multiple entity pairs):</p><p>We train word embeddings using Glove <ref type="bibr" target="#b13">(Pennington et al., 2014</ref>) 6 on the Wikipedia Corpus.  We show the precision numbers for some partic- ular recalls as well as the AUC in <ref type="table" target="#tab_1">Table 2</ref>, where PCNN+ATT (1) refers to train sentences with two entities and one relation label, PCNN+ATT (m) refers to train sentences with four entities 7 and two relation labels. We observe that our model exhibits the best performances. Moreover, in the process of predicting the existence of relations for a sentence, our approach is more convenient , as the PCNN- ATT (1) has to predict all possible pairs of enti- ties in the sentence while our approach can predict multiple relations simultaneously.  Ablation study: To better demonstrate the per- formance of capsule net and attention mechanism, we remove the primary capsule layer and dynam- ic routing to make Bi-LSTM layer followed by a fully connected layer instead. We also remove the word-level attention separately. The experimental results on Wikidata dataset are summarized in Ta- ble 3. The results of "-Word-ATT" row refers to the results without word-level attention. Accord- ing to the table, the drop of precision demonstrates that the word-level attention is quite useful. Gen- erally, all two proposed strategies contribute to the effectiveness of our model. In fact, the capsule combines features by cluster- ing. A nonlinear map is constructed in an itera- tive manner, ensuring the output of each capsule to be sent to an appropriate parent in the subse- quent layer. Dynamic routing may be more effec- tive than the strategies such as max-pooling in C- NN, which essentially detects whether a feature is present in any position of the text or not, but los- es spatial information of the feature. Additional- ly, capsule achieves comparable results to predict multi-relations in the case of single entity pair, and performs better in the case of multiple entity pairs relation extraction. Choice of d: In the experiments, the larger the dimension of the capsule, the more the capabili- ties of the feature information it contains. Howev- er, larger dimension increases the computational complexity. We test different levels of dimensions of capsules. The model is trained on two Nvidi- a GTX1080ti GPUs with 64G RAM and six In- tel(R) Core(TM) i7-6850K CPU 3.60GHz. As the table 4 depicts, the training time increases with the growth of d. When d = 32, we observe that the loss decreases very slowly and the model is diffi- cult to converge. So we only train 2 epochs and stop training. We set the parameter d = 8 em- pirically to balance the precision and training time cost.  Effects of Iterative Routing: We also study how the iteration number affec- t the performance on the Wikidata dataset. <ref type="table">Table   Table 5</ref>: Precisions on the Wikidata dataset with differ- ent number of dynamic routing iterations. 5 shows the comparison of 1 -5 iterations. We find that the performance reach the best when it- eration is set to 3. The results indicate the dy- namic routing is contributing to improve the per- formance. Specifically, in the iteration algorith- m, the b j|i = b j|i + ˆ u j|i · v j . When the number of iteration is very large, v j becomes either 0 or 1, which means each underlying capsule is only linked to a single upper capsule. Therefore, the iteration times should not be too large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recall</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Conclusion</head><p>We propose a relation extraction approach based on capsule networks with attention mechanism. Although we use Bi-LSTM as sentence encod- ing in this paper, the other encoding method, such as convolved n-gram, could be alternatively used. Experimental results of two benchmarks show that the model improves the precision of the predicted relations.</p><p>In the future, we tend to resolve the situation of how to assign predicted relationship to multi en- tity pairs when two entities have multi-relations by utilizing prior knowledge such as entity type and joint training with named entity recognition. We will also try to optimize the model in terms of speed and focus on other problems by leverag- ing class ties between labels, specially on multi- label learning problems. Besides, dynamic rout- ing could also be useful to improve other natural language processing tasks such as the sequence- to-sequence task and so on.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Architecture of capsule networks for relation extraction</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1</head><label>1</label><figDesc>Dynamic Routing Algorithm 1: procedure ROUTING(ˆ u j|i , ˆ a j|i , r, l) 2: Initialize the logits of coupling coefficients b j|i = 0 3: for r iterations do 4:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Performance comparison on the NYT dataset.</figDesc><graphic url="image-1.png" coords="4,72.28,169.14,217.70,163.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>5</head><label></label><figDesc>dw = 50 6 dw = 200</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Normalized output relation scores.</figDesc><graphic url="image-2.png" coords="4,307.28,62.81,222.24,84.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : Precisions on the Wikidata dataset.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 : Ablation study of capsule net and word-level attention on Wikidata dataset.</head><label>3</label><figDesc></figDesc><table>Recall 
0.1 
0.2 
0.3 AUC 
-Word-ATT 
0.648 0.515 0.395 0.389 
-Capsule 
0.635 0.507 0.413 0.386 
Our Model 
0.650 0.519 0.422 0.405 

4.2 Discussion 

CNN vs Capsule: Capsule networks achieve 
comparable results compared with baselines. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Precisions on the Wikidata dataset with differ-
ent choice of d. 

</table></figure>

			<note place="foot" n="2"> Since the number of sentences with multiple entity pairs is relatively small, we make use of all the sentences as training samples. 3 We also adopt an attention mechanism similar to wordlevel attention in Bi-LSTM layer by considering the different contribution of the M position embeddings.</note>

			<note place="foot" n="4"> http://openke.thunlp.org</note>

			<note place="foot" n="7"> Two additional position embeddings.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We want to express gratitude to the anonymous reviewers for their hard work and kind com-ments, which will further improve our work in the future. This work is funded by NS-FC 61673338/61473260, and partly supported by Alibaba-Zhejiang University Joint Institute of Frontier Technologies.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGMOD international conference on Management of data</title>
		<meeting>the 2008 ACM SIGMOD international conference on Management of data</meeting>
		<imprint>
			<publisher>AcM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Effective deep memory networks for distant supervised relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaocheng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjie</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI</title>
		<meeting>the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="19" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Information aggregation via dynamic routing for sequence encoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.01501</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">See: Syntax-aware entity embedding for neural relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengqiu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.03603</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Matrix capsules with em routing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Frosst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Sabour</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Knowledgebased weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congle</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="541" to="550" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Improving distantly supervised relation extraction using word and entity based attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharmistha</forename><surname>Jat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhesh</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.06987</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural relation extraction with selective attention over instances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Long Papers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2124" to="2133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A structured self-attentive sentence embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouhan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cicero</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.03130</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Cross-sentence n-ary relation extraction with graph lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.03743</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Modeling relations and their mentions without labeled text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="148" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dynamic routing between capsules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Sabour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Frosst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3859" to="3869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cicero</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
		<idno>arX- iv:1504.06580</idno>
		<title level="m">Classifying relations by ranking with convolutional neural networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Contextaware representations for knowledge base relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniil</forename><surname>Sorokin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1784" to="1789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multi-instance multi-label learning for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning</title>
		<meeting>the 2012 joint conference on empirical methods in natural language processing and computational natural language learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="455" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Label-free distant supervision for relation extraction via knowledge graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanying</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoxu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huajun</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sentiment analysis by capsules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yequan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aixin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 World Wide Web Conference on World Wide Web</title>
		<meeting>the 2018 World Wide Web Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1165" to="1174" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Ensemble neural relation extraction with adaptive boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongdong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Senzhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhoujun</forename><surname>Li</surname></persName>
		</author>
		<idno>arX- iv:1801.09334</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Jointly extracting relations with class ties via effective deep ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhunchen</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhoujun</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th</title>
		<meeting>the 55th</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1810" to="1820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction via piecewise convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1753" to="1762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Relation classification via convolutional deep neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2335" to="2344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Investigating capsule networks with dynamic routing for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyang</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suofei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.00538</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Attentionbased bidirectional long short-term memory networks for relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenyu</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingchen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="207" to="212" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
