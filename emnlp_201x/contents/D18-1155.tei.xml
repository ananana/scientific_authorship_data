<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Temporal Information Extraction by Predicting Relative Time-lines</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artuur</forename><surname>Leeuwenberg</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science KU Leuven</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science KU Leuven</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Temporal Information Extraction by Predicting Relative Time-lines</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1237" to="1246"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>1237</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The current leading paradigm for temporal information extraction from text consists of three phases: (1) recognition of events and temporal expressions, (2) recognition of temporal relations among them, and (3) time-line construction from the temporal relations. In contrast to the first two phases, the last phase, time-line construction, received little attention and is the focus of this work. In this paper, we propose a new method to construct a linear time-line from a set of (extracted) temporal relations. But more importantly, we propose a novel paradigm in which we directly predict start and end-points for events from the text, constituting a time-line without going through the intermediate step of prediction of temporal relations as in earlier work. Within this paradigm, we propose two models that predict in linear complexity, and a new training loss using TimeML-style annotations, yielding promising results.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The current leading perspective on temporal infor- mation extraction regards three phases: (1) a tem- poral entity recognition phase, extracting events (blue boxes in <ref type="figure">Fig. 1</ref>) and their attributes, and ex- tracting temporal expressions (green boxes), and normalizing their values to dates or durations, (2) a relation extraction phase, where temporal links (TLinks) among those entities, and between events and the document-creation time (DCT) are found (arrows in <ref type="figure">Fig. 1</ref>, left). And (3), construction of a time-line ( <ref type="figure">Fig. 1, right)</ref> from the extracted tempo- ral links, if they are temporally consistent. Much research concentrated on the first two steps, but very little research looks into step 3, time-line con- struction, which is the focus of this work.</p><p>In this paper, we propose a new time-line con- struction paradigm that evades phase 2, the re- lation extraction phase, because in the classical paradigm temporal relation extraction comes with many difficulties in training and prediction that arise from the fact that for a text with n tempo- ral entities (events or temporal expressions) there are n 2 possible entity pairs, which makes it likely for annotators to miss relations, and makes infer- ence slow as n 2 pairs need to be considered. Tem- poral relation extraction models consistently give lower performance than those in the entity recog- nition phase <ref type="bibr" target="#b29">(UzZaman et al., 2013;</ref><ref type="bibr" target="#b3">Bethard et al., 2016</ref>, introducing errors in the time-line construction pipe-line.</p><p>The ultimate goal of our proposed paradigm is to predict from a text in which entities are already detected, for each entity: (1) a probability distribu- tion on the entity's starting point, and (2) another distribution on the entity's duration. The proba- bilistic aspect is crucial for time-line based deci- sion making. Constructed time-lines allow for fur- ther quantitative reasoning with the temporal in- formation, if this would be needed for certain ap- plications.</p><p>As a first approach towards this goal, in this pa- per, we propose several initial time-line models in this paradigm, that directly predict -in a linear fashion -start points and durations for each entity, using text with annotated temporal entities as input (shown in <ref type="figure">Fig. 1</ref>). The predicted start points and durations constitute a relative time-line, i.e. a total order on entity start and end points. The time-line is relative, as start and duration values cannot (yet) be mapped to absolute calender dates or durations expressed in seconds. It represents the relative temporal order and inclusions that temporal enti- ties have with respect to each other by the quanti- tative start and end values of the entities. Relative time-lines are a first step toward our goal, building models that predict statistical absolute time-lines. To train our relative time-line models, we define novel loss functions that exploit TimeML-style an-notations, used in most existing temporal corpora.</p><p>This work leads to the following contributions:</p><p>• A new method to construct a relative time-line from a set of temporal relations (TL2RTL).</p><p>• Two new models that, for the first time, di- rectly predict (relative) time-lines -in lin- ear complexity -from entity-annotated texts without doing a form of temporal relation ex- traction (S-TLM &amp; C-TLM).</p><p>• Three new loss functions based on the map- ping between Allen's interval algebra and the end-point algebra to train time-line models from TimeML-style annotations.</p><p>In the next sections we will further discuss the related work on temporal information extraction. We will describe the models and training losses in detail, and report on conducted experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Temporal Information Extraction</head><p>The way temporal information is conveyed in lan- guage has been studied for a long time. It can be conveyed directly through verb tense, explicit temporal discourse markers (e.g. during or af- terwards) <ref type="bibr" target="#b10">(Derczynski, 2017)</ref> or temporal expres- sions such as dates, times or duration expressions (e.g. 10-05-2010 or yesterday). Temporal infor- mation is also captured in text implicitly, through background knowledge about, for example, dura- tion of events mentioned in the text (e.g. even without context, walks are usually shorter than journeys).</p><p>Most temporal corpora are annotated with TimeML-style annotations, of which an example is shown in <ref type="figure">Fig 1,</ref> indicating temporal entities, their attributes, and the TLinks among them.</p><p>The automatic extraction of TimeML-style tem- poral information from text using machine learn- ing was first explored by <ref type="bibr" target="#b18">Mani et al. (2006)</ref>. They proposed a multinomial logistic regression classi- fier to predict the TLinks between entities. They also noted the problem of missed TLinks by anno- tators, and experimented with using temporal rea- soning (temporal closure) to expand their training data.</p><p>Since then, much research focused on further improving the pairwise classification models, by exploring different types of classifiers and fea- tures, such as (among others) logistic regression and support vector machines <ref type="bibr" target="#b1">(Bethard, 2013;</ref><ref type="bibr" target="#b17">Lin et al., 2015)</ref>, and different types of neural network models, such as long short-term memory networks (LSTM) ( <ref type="bibr" target="#b26">Tourille et al., 2017;</ref><ref type="bibr" target="#b8">Cheng and Miyao, 2017)</ref>, and convolutional neural networks (CNN) ( <ref type="bibr" target="#b11">Dligach et al., 2017)</ref>. Moreover, different sieve- based approaches were proposed ( <ref type="bibr" target="#b19">Mirza and Tonelli, 2016)</ref>, facilitating mix- ing of rule-based and machine learning compo- nents.</p><p>Two major issues shared by these existing ap- proaches are: (1) models classify TLinks in a pair- wise fashion, often resulting in an inference com- plexity of O(n 2 ), and (2) the pair-wise predictions are made independently, possibly resulting in pre- diction of temporally inconsistent graphs. To ad- dress the second, additional temporal reasoning can be used at the cost of computation time, dur- ing inference <ref type="bibr" target="#b7">(Chambers and Jurafsky, 2008;</ref><ref type="bibr" target="#b9">Denis and Muller, 2011;</ref><ref type="bibr" target="#b12">Do et al., 2012)</ref>, or dur- ing both training and inference <ref type="bibr" target="#b31">(Yoshikawa et al., 2009;</ref><ref type="bibr" target="#b15">Laokulrat et al., 2015;</ref><ref type="bibr" target="#b21">Ning et al., 2017;</ref><ref type="bibr" target="#b16">Leeuwenberg and Moens, 2017)</ref>. In this work, we circumvent these issues, as we predict time-lines -in linear time complexity -that are temporally consistent by definition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Temporal Reasoning</head><p>Temporal reasoning plays a central role in tempo- ral information extraction, and there are roughly two approaches: (1) Reasoning directly with Allen's interval relations (shown in <ref type="table" target="#tab_2">Table 1</ref>), by constructing rules like: If event X occurs before Y, and event Y before Z then X should happen be- fore Z <ref type="bibr" target="#b0">(Allen, 1990</ref>). Or (2), by first mapping the temporal interval expressions to expressions about interval end-points (start and endings of entities) ( <ref type="bibr" target="#b30">Vilain et al., 1990</ref>). An example of such map- ping is that If event X occurs before Y then the end of X should be before the start of Y. Then rea- soning can be done with end-points in a point al- gebra, which has only three point-wise relations (=, &lt;, &gt;), making reasoning much more efficient compared to reasoning with Allen's thirteen inter- val relations.</p><p>Mapping interval relations to point-wise expres- sions has been exploited for model inference by <ref type="bibr" target="#b9">Denis and Muller (2011)</ref>, and for evaluation by <ref type="bibr" target="#b28">UzZaman and Allen (2011)</ref>. In this work, we ex- Last week, John jogged for many hours. Figure 1: An overview of two paradigms: (1) The indirect approach (dashed arrows), where first TLinks are predicted from which we can build a relative time-line using TL2RTL. And (2), the direct approach (solid arrow), where a relative time-line is predicted directly from the input by S-TLM or C-TLM.</p><p>ploit it for the first time for model training, in our loss functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Models</head><p>We propose two model structures for direct time-line construction: (1) a simple context- independent model (S-TLM), and <ref type="formula" target="#formula_1">(2)</ref> a contex- tual model (C-TLM). Their structures are shown in <ref type="figure">Fig. 2</ref>. Additionally, we propose a method to con- struct relative time-lines from a set of (extracted) TLinks (TL2RTL). In this section we first explain the first two direct models S-TLM and C-TLM, and afterwards the indirect method TL2RTL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Direct Time-line Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word representation</head><p>In both S-TLM and C-TLM, words are repre- sented as a concatenation of a word embedding, a POS embedding, and a Boolean feature vector containing entity attributes such as the type, class, aspect, following <ref type="bibr" target="#b12">(Do et al., 2012</ref>). Further details on these are given in the experiments section.</p><p>Simple Time-line Model (S-TLM)</p><p>For the simple context-independent time-line model, each entity is encoded by the word repre- sentation of the last word of the entity (generally the most important). From this representation we have a linear projection to the duration d, and the start s. S-TLM is shown by the dotted edges in <ref type="figure">Fig 2.</ref> An advantage of S-TLM is that it has very few parameters, and each entity can be placed on the time-line independently of the others, allow- ing parallelism during prediction. The downside is that S-TLM is limited in its use of contextual information.</p><p>Contextual Time-line Model (C-TLM) To better exploit the entity context we also propose a contextual time-line model C-TLM (solid edges in <ref type="figure">Fig 2)</ref>, that first encodes the full text using two bi-directional recurrent neural networks, one for entity starts (BiRNN s ), and one for entity dura- tions (BiRNN d ). <ref type="bibr">1</ref> On top of the encoded text we learn two linear mappings, one from the BiRNN d output of the last word of the entity mention to its duration d, and similarly for the start time, from the BiRNN s output to the entity's start s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Predicting Start, Duration, and End</head><p>Both proposed models use linear mappings 2 to predict the start value s i and duration d i for the encoded entity i. By summing start s i and dura- tion d i we can calculate the entity's end-point e i .</p><formula xml:id="formula_0">e i = s i + max(d i , d min )<label>(1)</label></formula><p>Predicting durations rather than end-points makes it easy to control that the end-point lies after the start-point by constraining the duration d i by a constant minimum duration value d min above 0, as shown in Eq. 1. Figure 2: Schematic overview of our two time-line models: C-TLM (solid edges), exploiting entity context, and the simpler S-TLM (dotted edges), which is context independent. The models predict a starting point (s) and duration (d) for each given temporal entity (t 1 , e 1 , and t 2 ) in the input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modeling Document-Creation Time</head><p>In contrast, DCT duration d DCT is modeled as a single variable that is learned (initialized with 1). Since multiple entities may be included in the DCT, and entities have a minimum duration d min , a constant d DCT could possibly prevent the model from fitting all entities in the DCT. Modeling d DCT as a variable allows growth of d DCT and averts this issue. <ref type="bibr">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training Losses</head><p>We propose three loss functions to train time-line models from TimeML-style annotations: a regular time-line loss L τ , and two slightly expanded dis- criminative time-line losses, L τ ce and L τ h .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Regular Time-line Loss (L τ )</head><p>Ground-truth TLinks can be seen as constraints on correct positions of entities on a time-line. The regular time-line loss L τ expresses the degree to which these constraints are met for a predicted time-line. If all TLinks are satisfied in the time- line for a certain text, L τ will be 0 for that text.</p><p>As TLinks relate entities (intervals), we first convert the TLinks to expressions that relate the start and end points of entities. How each TLink is translated to its corresponding point-algebraic constraints is given in <ref type="table" target="#tab_2">Table 1</ref>, following Allen (1990).</p><p>As can be seen in the last column there are only two point-wise operations in the point-algebraic constraints: an order operation (&lt;), and an equal- ity operation (=). To model to what degree each point-wise constraint is met, we employ hinge losses, with a margin m τ , as shown in Eq. 2. To explain the intuition and notation: If we have a point-wise expression ξ of the form x &lt; y (first case of Eq. 2), then the predicted pointˆxpointˆ pointˆx should be at least a distance m τ smaller (or earlier on the time-line) than predicted pointˆypointˆ pointˆy in order for the loss to be 0. Otherwise, the loss represents the dis- tancê x orˆyorˆ orˆy still has to move to makê x smaller thanˆythanˆ thanˆy (and satisfy the constraint). For the sec- ond case, if ξ is of the form x = y, then pointˆxpointˆ pointˆx andˆyandˆ andˆy should lie very close to each other, i.e. at most a distance m τ away from each other. Any distance further than the margin m τ is counted as loss. Notice that if we set margin m τ to 0, the second case becomes an L1 loss |ˆx|ˆx − ˆ y|. How- ever, we use a small margin m τ to promote some distance between ordered points and prevent con-fusion with equality. <ref type="figure" target="#fig_1">Fig. 3</ref>   </p><formula xml:id="formula_1">L p (ξ|t, θ) = max(ˆ x + m τ − ˆ y, 0) iff x &lt; y max(|ˆx|ˆx − ˆ y| − m τ , 0) iff x = y<label>(2)</label></formula><p>The total time-line loss L τ (t|θ) of a model with parameters θ on text t with ground-truth TLinks R(t), is the sum of the TLink-level losses of all TLinks r ∈ R(t). Each TLink-level loss L r (r|t, θ) for TLink r is the sum of the point- wise losses L p (ξ|t, θ) of the corresponding point- algebraic constraints ξ ∈ I P A (r) from <ref type="table" target="#tab_2">Table 1</ref>. 5</p><formula xml:id="formula_2">L r (r|t, θ) = ξ∈I P A (r) L p (ξ|t, θ)<label>(3)</label></formula><formula xml:id="formula_3">L τ (t, θ) = r∈R(t) L r (r|t, θ)<label>(4)</label></formula><p>Discriminative Time-line Losses To promote a more explicit difference between the relations on the time-line we introduce two dis- criminative loss functions, L τ ce and L τ h , which build on top of L r . Both discriminative loss func- tions use an intermediate score S(r|t, θ) for each TLink r based on the predicted time-line. As scor- ing function, we use the negative L r loss, as shown in Eq. 5.</p><formula xml:id="formula_4">S(r|t, θ) = −L r (r|t, θ)<label>(5)</label></formula><p>Then, a lower time-line loss L r (r|t, θ) results in a higher score for relation type r. Notice that the maximum score is 0, as this is the minimum L r .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Probabilistic Loss (L τ ce )</head><p>Our first discriminative loss is a cross-entropy based loss. For this the predicted scores are nor- malized using a soft-max over the possible rela- tion types (T L). The resulting probabilities are used to calculate a cross-entropy loss, shown in Eq. 6. This way, the loss does not just promote the correct relation type but also distantiates from the other relation types.</p><formula xml:id="formula_5">L τ ce (t|θ) = r∈R(t) r · log e S(r|t,θ) r ∈T L e S(r |t,θ) (6) Ranking Loss (L τ h )</formula><p>When interested in discriminating relations on the time-line, we want the correct relation type to have the highest score from all possible relation types T L. To represent this perspective, we also define a ranking loss with a score margin m h in Eq. 7.</p><formula xml:id="formula_6">L τ h (t|θ) = r∈R(t)</formula><p>r ∈T L\{r} max(S(r |t, θ)−S(r|t, θ)+m h , 0)</p><p>Training Procedure S-TLM and C-TLM are trained by by iterating through the training texts, sampling mini-batches of 32 annotated TLinks. For each batch we (1) perform a forward pass, (2) calculate the total loss (for one of the loss functions), (3) derive gradients using Adam <ref type="bibr">6</ref> ( <ref type="bibr" target="#b14">Kingma and Ba, 2014)</ref>, and (4) up- date the model parameters θ via back-propagation. After each epoch we shuffle the training texts. As stopping criteria we use early stopping <ref type="bibr" target="#b20">(Morgan and Bourlard, 1990)</ref>, with a patience of 100 epochs and a maximum number of 1000 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">From TLinks to Time-lines (TL2RTL)</head><p>To model the indirect route, we construct a novel method, TL2RTL, that predicts relative time lines from a subset of TLinks, shown in <ref type="figure">Fig 1.</ref> One can choose any method to obtain a set of TLinks R(t) from a text t, serving as input to TL2RTL. TL2RTL constructs a relative time-line, by assign- ing start and end values to each temporal entity, such that the resulting time-line satisfies the ex- tracted TLinks R(t) by minimizing a loss function that is 0 when the extracted TLinks are satisfied. TL2RTL on itself is a method and not a model. The only variables over which it optimizes the loss are the to be assigned starts and duration values.</p><p>In detail, for a text t, with annotated entities E(t), we first extract a set of TLinks R(t). In this work, to extract TLinks, we use the current state-of-the-art structured TLink extraction model by <ref type="bibr" target="#b21">Ning et al. (2017)</ref>. Secondly, we assign a start variable s i , and duration variable d i to each en- tity i ∈ E(t). Similar to S-TLM and C-TLM, for each i ∈ E(t), d i is bounded by a minimum dura- tion d min to ensure start s i always lies before end e i . Also, we model the DCT start s DCT as a con- stant, and its duration d DCT as a variable. Then we minimize one of the loss functions L τ , L τ ce , or L τ h on the extracted TLinks R(t), obtaining three TL2RTL variants, one for each loss. If the initially extracted set of TLinks R(t) is consistent, and the loss is minimized sufficiently, all s i and d i form a relative time-line that satisfies the TLinks R(t), but from which we can now also derive consistent TLinks for any entity pair, also the pairs that were not in R(t). To minimize the loss we use Adam for 10k epochs until the loss is zero for each doc- ument. <ref type="bibr">7</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation and Data</head><p>Because prediction of relative time-lines trained on TimeML-style annotations is new, we cannot compare our model directly to relation extraction or classification models, as the latter do not pro- vide completely temporally consistent TLinks for all possible entity pairs, like the relative time- lines do. Neither can we compare directly to ex- isting absolute time-line prediction models such as <ref type="bibr" target="#b25">Reimers et al. (2018)</ref> because they are trained on different data with a very different annotation scheme.</p><p>To evaluate the quality of the relative time-line models in a fair way, we use TimeML-style test sets as follows: (1) We predict a time-line for each test-text, and (2) we check for all ground-truth an-notated TLinks that are present in the data, what would be the derived relation type based on the predicted time-line, which is the relation type that gives the lowest time-line loss L r . This results in a TLink assignment for each annotated pair in the TimeML-style reference data, and there- for we can use similar metrics. As evaluation metric we employ the temporal awareness met- ric, used in TempEval-3, which takes into account temporal closure ( <ref type="bibr" target="#b29">UzZaman et al., 2013)</ref>. Notice that although we use the same metric, compari- son against relation classification systems would be unfair, as our model assigns consistent labels to all pairs, whereas relation classification systems do not.</p><p>For training and evaluation we use two data splits, TE ‡ and TD ‡ , exactly following <ref type="bibr" target="#b21">Ning et al. (2017)</ref>. Some statistics about the data are shown in <ref type="table" target="#tab_4">Table 2</ref>. <ref type="bibr">8</ref> The splits are constituted from various smaller datasets: the TimeBank (TB) ( <ref type="bibr" target="#b23">Pustejovsky et al., 2002</ref>), the AQUANT dataset (AQ), and the platinum dataset (PT) all from TempEval-3 (Uz- Zaman et al., 2013). And, the TimeBank Dense (  , and the Verb-Clause dataset (VC) ( <ref type="bibr" target="#b2">Bethard et al., 2007</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Hyper-parameters and Preprocessing</head><p>Hyper-parameters shared in all settings can be found in <ref type="table" target="#tab_5">Table 3</ref>. The following hyper-parameters are tuned using grid search on a development set (union of TB and AQ): d min is chosen from {1, 0.1, 0.01}, m τ from {0, 0.025, 0.05, 0.1}, α d from {0, 0.1, 0.2, 0.4, 0.8}, and α rnn from {10, 25, 50}. We use LSTM <ref type="bibr" target="#b13">(Hochreiter and Schmidhuber, 1997</ref>) as RNN units 9 and em- ploy 50-dimensional GloVe word-embeddings pre-trained 10 on 6B words (Wikipedia and NewsCrawl) to initialize the models' word embed- dings.</p><p>We use very simple tokenization and consider punctuation <ref type="bibr">11</ref> or newline tokens as individual to- kens, and split on spaces. Additionally, we low- ercase the text and use the Stanford POS Tagger ( <ref type="bibr" target="#b27">Toutanova et al., 2003</ref>) to obtain POS.   </p><formula xml:id="formula_8">TE3 ‡ TD ‡ Model P R F P R F Indirect: O(n 2 ) TL2RTL (L τ )</formula><p>53.5 51.1 52.3 59.1 61.2 60.1 TL2RTL (L τ ce ) 53.9 51.7 52.8 61.2 60.7 60.9 TL2RTL (L τ h ) 52.8 51.1 51.9 57.9 60.6 59.2 TL2RTL (L * ) 52.6 52.0 52.3 62.3 62.3 62.3</p><p>Direct: O(n) S-TLM (L τ ) 50.1 50.4 50.2 57.8 59.5 58.6 S-TLM (L τ ce ) 50.1 50.0 50.1 53.4 53.5 53.5 S-TLM (L τ h ) 51.5 51.7 51.6 55.1 56.4 55.7 S-TLM (L * ) 50.9 51.0 51.0 56.5 55.3 55.9</p><p>C-TLM (L τ ) 56.2 56.1 56.1 57.1 59.7 58.4 C-TLM (L τ ce ) 54.4 55.4 54.9 52.4 57.3 54.7 C-TLM (L τ h ) 55.7 55.5 55.6 55.3 54.9 55.1 C-TLM (L * ) 54.0 54.3 54.1 54.6 53.5 54.1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>We compared our three proposed models for the three loss functions L τ , L τ ce , and L τ h , and their linear (unweighted) combination L * , on TE3 ‡ and TD ‡ , for which the results are shown in <ref type="table" target="#tab_6">Table 4</ref>. A trend that can be observed is that overall per- formance on TD ‡ is higher than that of TE3 ‡ , even though less documents are used for training. We inspected why this is the case, and this is caused by a difference in class balance between both test sets. In TE3 ‡ there are many more TLinks of type simultaneous (12% versus 3%), which are very difficult to predict, resulting in lower scores for TE3 ‡ compared to TD ‡ . The difference in perfor- mance between the datasets is probably also be re- lated to the dense annotation scheme of TD ‡ com- pared to the sparser annotations of TE3 ‡ , as dense annotations give a more complete temporal view of the training texts. For TL2RTL better TLink extraction 12 is also propagated into the final time- line quality.</p><p>If we compare loss functions L τ , L τ ce , and L τ h , and combination L * , it can be noticed that, although all loss functions seem to give fairly similar performance, L τ gives the most robust results (never lowest), especially noticeable for the smaller dataset TD ‡ . This is convenient, be- cause L τ is fastest to compute during training, as it requires no score calculation for each TLink type. L τ is also directly interpretable on the time- line. The combination of losses L * shows mixed results, and has lower performance for S-TLM and C-TLM, but better performance for TL2RTL. However, it is slowest to compute, and less inter- pretable, as it is a combined loss.</p><p>Moreover, we can clearly see that on TE3 ‡ , C- TLM performs better than the indirect models, across all loss functions. This is a very interesting result, as C-TLM is an order of complexity faster in prediction speed compared to the indirect mod- els (O(n) compared to O(n 2 ) for a text with n entities). <ref type="bibr">13</ref> We further explore why this is the case through our error analysis in the next section.</p><p>On TD ‡ , the indirect models seem to perform slightly better. We suspect that the reason for this is that C-TLM has more parameters (mostly the LSTM weights), and thus requires more data (TD ‡ has much fewer documents than TE3 ‡ ) compared to the indirect methods. Another result supporting this hypothesis is the fact that the difference be- tween C-TLM and S-TLM is small on the smaller B A II I S B 24.8% 4.7% 2.8% 1.6% 0.1% A 5.0% 15.8%</p><p>3.2% 0.5% 0.0% II 3.2%</p><p>3.2% 13.0% 0.6% 0.1% I 4.0% 1.2% 1.0% 3.2% 0.0% S 4.4% 3.0% 2.6% 1.3% 0.4% B A II I S B 23.0% 8.2%</p><p>1.3% 0.9% 0.8% A 4.7% 17.1%</p><p>1.8% 0.3% 0.5% II 4.3% 4.4% 11.1% 0.4% 0.0% I</p><p>1.6% 5.4% 0.5% 1.3% 0.5% S 4.3% 4.1% 1.8% 0.6% 0.9% TD ‡ , indicating that C-TLM does not yet utilize contextual information from this dataset, whereas, in contrast, on TE3 ‡ , the larger dataset, C-TLM clearly outperforms S-TLM across all loss func- tions, showing that when enough data is available C-TLM learns good LSTM weights that exploit context substantially.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Error Analysis</head><p>We compared predictions of TL2RTL(L τ ) with those of C-TLM (L τ ), the best models of each paradigm. In <ref type="table" target="#tab_6">Table 4</ref>, we show the confusion ma- trices of both systems on TE3 ‡ . When looking at the overall pattern in errors, both models seem to make similar confusions on both datasets (TD ‡ was excluded for space con- straints). Overall, we find that simultaneous is the most violated TLink for both models. This can be explained by two reasons: (1) It is the least fre- quent TLink in both datasets. And (2), simulta- neous entities are often co-referring events. Event co-reference resolution is a very difficult task on its own.</p><p>We also looked at the average token-distance between arguments of correctly satisfied TLinks by the time-lines of each model. For TL2RTL (L τ ) this is 13 tokens, and for C-TLM (L τ ) 15. When looking only at the TLinks that C-TLM (L τ ) satisfied and TL2RTL (L τ ) did not, the average distance is 21. These two observations suggest that the direct C-TLM (L τ ) model is better at po- sitioning entities on the time-line that lie further away from each other in the text. An explana- tion for this can be error propagation of TLink ex- traction to the time-line construction, as the pair- wise TLink extraction of the indirect paradigm ex- tracts TLinks in a contextual window, to prune the O(n 2 ) number of possible TLink candidates. This To get more insight in what the model learns we calculated mean durations and mean starts of C- TLM (L τ ) predictions. <ref type="table" target="#tab_7">Table 5</ref> contains examples from the top-shortest, and top-longest duration as- signments and earliest and latest starting points. We observe that events that generally have more events included are assigned longer duration and vice versa. And, events with low start values are in the past tense and events with high start values are generally in the present (or future) tense.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>A characteristic of our model is that it assumes that all events can be placed on a single time- line, and that it does not assume that unlabeled pairs are temporally unrelated. This has big ad- vantages: it results in fast prediction, and missed annotation do not act as noise to the training, as they do for pairwise models. <ref type="bibr" target="#b22">Ning et al. (2018)</ref> ar- gue that actual, negated, hypothesized, expected or opinionated events should possibly be annotated on separate time-axis. We believe such multi-axis representations can be inferred from the generated single time-lines if hedging information is recog- nized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions</head><p>This work leads to the following three main contri- butions 14 : (1) Three new loss functions that con- nect the interval-based TimeML-annotations to points on a time-line, (2) A new method, TL2RTL, to predict relative time-lines from a set of pre- dicted temporal relations. And (3), most impor- tantly, two new models, S-TLM and C-TLM, that -to our knowledge for the first time -predict (rel- ative) time-lines in linear complexity from text, by evading the computationally expensive (often O(n 2 )) intermediate relation extraction phase in earlier work. From our experiments, we conclude that the proposed loss functions can be used effec- tively to train direct and indirect relative time-line models, and that, when provided enough data, the -much faster -direct model C-TLM outperforms the indirect method TL2RTL.</p><p>As a direction for future work, it would be very interesting to extend the current models, div- ing further into direct time-line models, and learn to predict absolute time-lines, i.e. making the time-lines directly mappable to calender dates and times, e.g. by exploiting complementary data sources such as the EventTimes Corpus ( <ref type="bibr" target="#b24">Reimers et al., 2016</ref>) and extending the current loss func- tions accordingly. The proposed models also pro- vide a good starting point for research into prob- abilistic time-line models, that additionally model the (un)certainty of the predicted positions and du- rations of the entities.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Visualization of the time-line loss L τ with margin m τ , for two events X and Y, and TLinks simultaneous, before, and includes. The red arrows' lengths indicate the loss per relation, i.e. how much the points should be shifted to satisfy each relation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: On the left, the confusion matrix of C-TLM (L τ ), and on the right of TL2RTL (L τ ce ), on TE3 ‡ for the top-5 most-frequent TLinks (together 95% of data): BEFORE (B), AFTER (A), IS INCLUDED (II), INCLUDES (I), and SIMULTANEOUS (S). Predictions are shown on the x-axis and ground-truth on the y-axis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Point algebraic interpretation (I P A ) of 
temporal links used to construct the loss function. 
The start and end points of event X are indicated 
by s x and e x respectively. 

Allen Algebra 
Temporal Links 
Point Algebra 

X precedes Y 
Y preceded by X 

X before Y 
Y after X 
e x &lt; s y 

X starts Y 
Y started by X 

X begins Y 
Y begun by X 

s x = s y 
e x &lt; e y 

X finishes Y 
Y finished by X 

X ends Y 
Y ended by X 

e x = e y 
s y &lt; s x 

X during Y 
Y includes X 

X is included Y 
Y includes X 

s y &lt; s x 
e x &lt; e y 

X meets Y 
Y met by X 

X immediately before Y 
Y immediately after X 
e x = s y 

X overlaps Y 
Y overlapped by X 

absent 4 
absent 4 

s x &lt; s y 
s y &lt; e x 
e x &lt; e y 

X equals Y 
X simultaneous Y 
X identity Y 

s x = s y 
e x = e y 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 2 : Dataset splits used for evaluation (indicated with ‡).</head><label>2</label><figDesc></figDesc><table>Split Training data 
#TLinks #Documents Test data #TLinks #Documents 

TD  ‡ 
TD (train+dev) 
4.4k 
27 
TD (test) 
1.3k 
9 
TE3  ‡ TB, AQ, VC, TD (full) 
17.5k 
256 
PT 
0.9k 
20 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Hyper-parameters from the experiments. 

Hyper-parameter 
Value 

Document-creation starting time (s DCT ) 
0 
Minimum event duration (d min ) 
0.1 
Time-line margin (m τ ) 
0.025 
Hinge loss margin (m h ) 
0.1 

Dropout (α d ) 
0.1 
Word-level RNN units (α rnn ) 
25 
Word-embedding size (α wemb ) 
50 
POS-embedding size 
10 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Evaluation of relative time-lines for each 
model and loss function, where L  *  indicates the 
(unweighted) sum of L τ , L τ ce , and L τ h . 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Example events from the top-
shortest/longest durations and top-earliest/latest 
start values assigned by the model. 

Short d Long d 
Early s 
Late s 

started 
going 
destroyed 
realize 
meet 
expects 
finished 
bring 
entered recession invaded 
able 
told 
war 
pronounced got 
arrived support 
created 
work 
allow 
make 
took 
change 
send 
think 
appeared 
start 
asked 
created 
leaving 
reenergize 

consequently prevents TL2RTL to properly posi-
tion distant events with respect to each other. 
</table></figure>

			<note place="foot" n="1"> We also experimented with sharing weights among BiRNN d and BiRNNs. In our experiments, this gave worse performance, so we propose to keep them separate. 2 Adding more layers did not improve results.</note>

			<note place="foot" n="3"> Other combinations of modeling sDCT and dDCT as variable or constant decreased performance. 4 No TLink for Allen&apos;s overlap relation is present in TimeML, also concluded by UzZaman and Allen (2011).</note>

			<note place="foot" n="5"> The TLink during and its inverse are mapped to simultaneous, following the evaluation of TempEval-3.</note>

			<note place="foot" n="6"> Using the default parameters from the paper.</note>

			<note place="foot" n="7"> For some documents the extracted TLinks were temporally inconsistent, resulting in a non-zero loss. Nevertheless, &gt; 96% of the extracted TLinks were satisfied.</note>

			<note place="foot" n="8"> We explicitly excluded all test documents from training as some corpora annotated the same documents. 9 We also experimented with GRU as RNN type, obtaining similar results. 10 https://nlp.stanford.edu/projects/glove 11 , ./\&quot;&apos;=+-;:()!?&lt;&gt;%&amp;$ * |[]{}</note>

			<note place="foot" n="12"> F1 of 40.3 for TE3 ‡ and 48.5 for TD ‡ (Ning et al., 2017) 13 We do not directly compare prediction speed, as it would result in unfair evaluation because of implementation differences. However, currently, C-TLM predicts at ∼100 w/s incl. POS tagging, and ∼2000 w/s without. When not using POS, overall performance decreases consistently with 2-4 points.</note>

			<note place="foot" n="14"> Code is available at: liir.cs.kuleuven.be/software.php</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank Geert Heyman and the review-ers for their constructive comments which helped us to improve the paper. This work was funded by the KU Leuven C22/15/16 project "MAchine Reading of patient recordS (MARS)", and by the IWT-SBO 150056 project "ACquiring CrUcial Medical information Using LAnguage TEchnol-ogy" (ACCUMULATE).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Maintaining knowledge about temporal intervals. Readings in Qualitative Reasoning about Physical Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>James F Allen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="361" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">ClearTK-TimeML: A minimalist approach to tempeval 2013</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval</title>
		<meeting>SemEval</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="10" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Timelines from text: Identification of syntactic temporal relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">H</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Klingenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICSC</title>
		<meeting>ICSC</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semeval-2016 task 12: Clinical tempeval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guergana</forename><surname>Savova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Te</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval</title>
		<meeting>SemEval</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1052" to="1062" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">SemEval-2017 Task 12: Clinical TempEval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guergana</forename><surname>Savova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval</title>
		<meeting>SemEval</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="565" to="572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An annotation framework for dense event ordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Cassidy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Mcdowell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="501" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dense event ordering with a multi-pass architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Cassidy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Mcdowell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="273" to="284" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Jointly combining implicit constraints improves temporal ordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="698" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Classifying temporal relations by bidirectional LSTM over dependency paths</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Predicting globally-coherent temporal structures from texts via endpoint inference and graph decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Denis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1788" to="1793" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Automatically Ordering Events and Times in Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Leon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Derczynski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>Springer</publisher>
			<biblScope unit="volume">677</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Neural temporal relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitriy</forename><surname>Dligach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guergana</forename><surname>Savova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EACL</title>
		<meeting>EACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Joint inference for event timeline construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Quang Xuan Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-CoNLL</title>
		<meeting>EMNLP-CoNLL</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="677" to="687" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Stacking approach to temporal relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natsuda</forename><surname>Laokulrat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Natural Language Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="171" to="196" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Structured learning for temporal relation extraction from clinical records</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artuur</forename><surname>Leeuwenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EACL</title>
		<meeting>EACL</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1150" to="1158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multilayered temporal modeling for the clinical domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitriy</forename><surname>Dligach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guergana K</forename><surname>Savova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="387" to="395" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Machine learning of temporal relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inderjeet</forename><surname>Mani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Wellner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><forename type="middle">Min</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING-ACL</title>
		<meeting>COLING-ACL</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="753" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">CATENA : Causal and temporal relation extraction from natural language texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paramita</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Tonelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="64" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Generalization and parameter estimation in feedforward nets: Some experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nelson</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hervé</forename><surname>Bourlard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A structured learning approach to temporal relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhili</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1038" to="1048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A multiaxis annotation scheme for event temporal relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1318" to="1328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Hanks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roser</forename><surname>Saurí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Setzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beth</forename><surname>Sundheim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Day</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename></persName>
		</author>
		<title level="m">The TIMEBANK Corpus. Natural Language Processing and Information Systems</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">4592</biblScope>
			<biblScope unit="page" from="647" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Temporal anchoring of events for the timebank corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nazanin</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2195" to="2204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Event time extraction with a decision tree of neural classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nazanin</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="77" to="89" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Neural architecture for temporal relation extraction: A Bi-LSTM approach for detecting narrative containers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Tourille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Ferret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelie</forename><surname>Neveol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Tannier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="224" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Feature-rich partof-speech tagging with a cyclic dependency network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="173" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Temporal evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naushad</forename><surname>Uzzaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">F</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL, HLT &apos;11</title>
		<meeting>ACL, HLT &apos;11<address><addrLine>Stroudsburg, PA, USA. ACL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="351" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naushad</forename><surname>Uzzaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hector</forename><surname>Llorens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
		<title level="m">Semeval-2013 task 1: Tempeval-3: Evaluating time expressions, events, and temporal relations. Second joint conference on lexical and computational semantics (* SEM)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Constraint propagation algorithms for temporal reasoning: A revised report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Vilain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Van Beek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Readings in Qualitative Reasoning about Physical Systems</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1990" />
			<biblScope unit="page" from="373" to="381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Jointly identifying temporal relations with markov logic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katsumasa</forename><surname>Yoshikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayuki</forename><surname>Asahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-IJCNLP</title>
		<meeting>ACL-IJCNLP</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="405" to="413" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
