<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:55+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">What can we learn from Semantic Tagging?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Abdou</surname></persName>
							<email>abdou@di.ku.dk, a.kulmizev@student.rug.nl, vinit.ravishankar@gmail.com,</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">CLCG</orgName>
								<orgName type="institution" key="instit2">University of Groningen CoAStaL DIKU</orgName>
								<orgName type="institution" key="instit3">University of Copenhagen † LTG</orgName>
								<orgName type="institution" key="instit4">University of Oslo</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artur</forename><surname>Kulmizev</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">CLCG</orgName>
								<orgName type="institution" key="instit2">University of Groningen CoAStaL DIKU</orgName>
								<orgName type="institution" key="instit3">University of Copenhagen † LTG</orgName>
								<orgName type="institution" key="instit4">University of Oslo</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinit</forename><surname>Ravishankar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">CLCG</orgName>
								<orgName type="institution" key="instit2">University of Groningen CoAStaL DIKU</orgName>
								<orgName type="institution" key="instit3">University of Copenhagen † LTG</orgName>
								<orgName type="institution" key="instit4">University of Oslo</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasha</forename><surname>Abzianidze</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">CLCG</orgName>
								<orgName type="institution" key="instit2">University of Groningen CoAStaL DIKU</orgName>
								<orgName type="institution" key="instit3">University of Copenhagen † LTG</orgName>
								<orgName type="institution" key="instit4">University of Oslo</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Bos</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">CLCG</orgName>
								<orgName type="institution" key="instit2">University of Groningen CoAStaL DIKU</orgName>
								<orgName type="institution" key="instit3">University of Copenhagen † LTG</orgName>
								<orgName type="institution" key="instit4">University of Oslo</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">What can we learn from Semantic Tagging?</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="4881" to="4889"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>4881</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We investigate the effects of multi-task learning using the recently introduced task of semantic tagging. We employ semantic tagging as an auxiliary task for three different NLP tasks: part-of-speech tagging, Universal Dependency parsing, and Natural Language Inference. We compare full neural network sharing , partial neural network sharing, and what we term the learning what to share setting where negative transfer between tasks is less likely. Our findings show considerable improvements for all tasks, particularly in the learning what to share setting, which shows consistent gains across all tasks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Multi-task learning (MTL) is a recently resurgent approach to machine learning in which multiple tasks are simultaneously learned. By optimising the multiple loss functions of related tasks at once, multi-task learning models can achieve superior results compared to models trained on a single task. The key principle is summarized by <ref type="bibr">Caruana (1998)</ref> as "MTL improves generalization by lever- aging the domain-specific information contained in the training signals of related tasks". Neural MTL has become an increasingly successful ap- proach by exploiting similarities between Natural Language Processing (NLP) tasks <ref type="bibr">(Collobert and Weston, 2008;</ref><ref type="bibr">Søgaard and Goldberg, 2016;</ref><ref type="bibr" target="#b4">Plank et al., 2016)</ref>. Our work builds upon <ref type="bibr" target="#b4">Bjerva et al. (2016)</ref>, who demonstrate that employing seman- tic tagging as an auxiliary task for Universal De- pendency ( <ref type="bibr">McDonald et al., 2013</ref>) part-of-speech tagging can lead to improved performance.</p><p>The objective of this paper is to investigate whether learning to predict lexical semantic cat- egories can be beneficial to other NLP tasks. To achieve this we augment single-task models (ST) 1 <ref type="bibr">1</ref> We replicate models which perform at or close to the with an additional classifier to predict semantic tags and jointly optimize for both the original task and the auxiliary semantic tagging task. Our hy- pothesis is that learning to predict semantic tags as an auxiliary task can improve performance of single-task systems. We believe that this is, among other factors, due to the following:</p><p>• Providing the main task's model with a useful inductive bias, encouraging it to prefer repre- sentations that lead to semantically plausible hypotheses over those that are not.</p><p>• Putting the focus of the main task model's attention on features that actually matter by providing additional evidence for the rele- vance or irrelevance of those features.</p><p>• Reducing the risk of overfitting by mini- mizing the model's Rademacher Complexity 2 Representations which are learned for multi- ple tasks have been shown to generalize bet- ter ( <ref type="bibr" target="#b2">Baxter et al., 2000</ref>).</p><p>We test our hypothesis on three disparate NLP tasks: (i) Universal Dependency part-of-speech tagging (UPOS), (ii) Universal Dependency pars- ing (UD DEP), a complex syntactic task; and (iii) Natural Language Inference (NLI), a complex task requiring deep natural language understanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Related work 2.1 Semantic Tagging</head><p>Semantic tagging ( <ref type="bibr" target="#b4">Bjerva et al., 2016;</ref>) is the task of assigning language- neutral semantic categories to words. It is de- signed to overcome a lack of semantic information syntax-oriented part-of-speech tagsets, such as the state-of-the-art. Our choice of models is based on replica- bility. <ref type="bibr">2</ref> The ability to fit random noise.</p><p>Figure 1: Our three multi-task learning settings: (A) fully shared networks, (B) partially shared networks, and (C) Learning What to Share. Layers are mathematically denoted by vectors and the connections between them, represented by arrows, are mathematically denoted by matrices of weights. S indicates a shared layer, P a private layer, and X a layer with shared and private subspaces.</p><p>Penn Treebank tagset <ref type="bibr">(Marcus et al., 1993)</ref>, usu- ally have. Such tagsets exclude important seman- tic distinctions, such as negation and modals, types of quantification, named entity types, and the con- tribution of verbs to tense, aspect, or event.</p><p>The semantic tagset is language-neutral, ab- stracts over part-of-speech and named-entity classes, and includes fine-grained semantic in- formation. The tagset consists of 80 seman- tic tags grouped in 13 coarse-grained classes. The tagset originated in the Parallel Meaning Bank (PMB) project ( , where it contributes to compositional semantics and cross-lingual projection of semantic represen- tations. Recent work has highlighted the utility of the tagset as a conduit for evaluating the seman- tics captured by vector representations <ref type="bibr" target="#b3">(Belinkov et al., 2018)</ref>, or employed it in an auxiliary tagging task ( <ref type="bibr" target="#b4">Bjerva et al., 2016)</ref>, as we do in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Learning What to Share</head><p>Recently, there has been an increasing interest in the development of models which are trained to learn what to (and what not to) share between a set of tasks, with the general aim of preventing negative transfer when the tasks are not closely re- lated ( <ref type="bibr">Meyerson and Miikkulainen, 2017;</ref><ref type="bibr">Ruder et al., 2017;</ref><ref type="bibr">Lu et al., 2017;</ref><ref type="bibr">Misra et al., 2016)</ref>. Our Learning What to Share setting is based on this idea and closely related to <ref type="bibr">Liu et al. (2016)</ref>'s shared layer architecture.</p><p>Specifically, a layer h X which is shared be- tween the main task and the auxiliary task is split into two subspaces: a shared subspace h X S and a private subspace h X P . The interaction between the shared subspaces is modulated via a sigmoidal gating unit applied to a set of learned weights, as seen in Equations <ref type="formula">(1)</ref> and <ref type="formula">(2)</ref> where h X S(main) and h X S(aux) are the main and auxiliary tasks' shared layers, W a→m and W m→a are learned weights, and σ is a sigmoidal function.</p><formula xml:id="formula_0">h X S(main) = h X S(main) σ( h X S(aux) W a→m ) (1) h X S(aux) = h X S(aux) σ( h X S(main) W m→a ) (2)</formula><p>Unlike <ref type="bibr">Liu et al. (2016)</ref>'s Shared-Layer Archi- tecture, in our setup each task has its own shared subspace rather than one common shared layer. This enables the sharing of different parameters in each direction (i.e., from main to auxiliary task and from auxiliary to main task), allowing each task to choose what to learn from the other, rather than having "one shared layer to capture the shared information for all the tasks" as in <ref type="bibr">Liu et al. (2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Multi-Task Learning Settings</head><p>We implement three neural MTL settings, shown in <ref type="figure">Figure 1</ref>. They differ in the way the network's parameters are shared between the tasks:</p><p>• Fully shared network (FSN): All hidden layers are entirely shared among the tasks, each task has a separate output layer. The transformation of our input vector x into a shared hidden layer h S is described by Equa- tion (3):</p><formula xml:id="formula_1">h S = σ( xW )<label>(3)</label></formula><p>• Partially shared network (PSN): A subset of hidden layers is shared among the tasks;</p><p>each task has at least one private hidden layer and a separate output layer. The trans- formation of a shared hidden layer h S into private hidden layers, denoted by h P <ref type="bibr">(main)</ref> and h P (aux) is described in Equations <ref type="formula" target="#formula_2">(4)</ref> and <ref type="formula" target="#formula_3">(5)</ref>.</p><formula xml:id="formula_2">h P (main) = σ( h S W (main) )<label>(4)</label></formula><formula xml:id="formula_3">h P (aux) = σ( h S W (aux) )<label>(5)</label></formula><p>• Learning What to Share (LWS): Each task has a dedicated set of hidden layers. For sharing, a hidden layer is split into a shared subspace and a private subspace. A gating unit modulates the transfer of information between the shared subspaces as shown in Equations <ref type="formula">(1)</ref> and (2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data</head><p>In the UPOS tagging experiments, we utilize the UD 2.0 English corpus ( <ref type="bibr">Nivre et al., 2017</ref>) for the POS tagging and the semantically tagged PMB release 0.1.0 (sem-PMB) <ref type="bibr">3</ref> for the MTL settings. Note that there is no overlap between the two datasets. Conversely, for the UD DEP and NLI experiments there is a complete overlap between the datasets of main and auxiliary tasks, i.e., each instance is labeled with both the main task's labels and semantic tags. We use the Stanford POS Tag- ger ( <ref type="bibr">Toutanova et al., 2003</ref>) trained on sem-PMB to tag the UD corpus and NLI datasets with seman- tic tags, and then use those assigned tags for the MTL settings of our dependency parsing and NLI models. We find that this approach leads to better results when the main task is only loosely related to the auxiliary task. The UD DEP experiments use the English UD 2.0 corpus, and the NLI ex- periments use the SNLI (Bowman et al., 2015) and SICK-E 4 datasets ( <ref type="bibr">Marelli et al., 2014</ref>). The pro- vided train, development, and test splits are used for all datasets. For sem-PMB, the silver and gold parts are used for training and testing respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We run four experiments for each of the four tasks (UPOS, UD DEP, SNLI, SICK-E), one using the ST model and one for each of the three MTL set- tings. Each experiment is run five times, and the average of the five runs is reported. We briefly de- scribe the ST models and refer the reader to the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Universal Dependency POS Tagging</head><p>Our tagging model uses a basic contextual one- layer bi-LSTM <ref type="bibr">(Hochreiter and Schmidhuber, 1997</ref>) that takes in word embeddings and produces a sequence of recurrent states which can be viewed as contextualized representations. The recurrent r n state from the bi-LSTM corresponding to each time-step t n is passed through a dense layer with a softmax activation to predict the token's tag.</p><p>In each of the MTL settings a softmax classifier is added to predict a token's semantic tag and the model is then jointly trained on the concatenation of the sem-PMB and UPOS tagging data to min- imize the sum of softmax cross-entropy losses of both the main (UPOS tagging) and auxiliary (se- mantic tagging) tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Universal Dependency Parsing</head><p>We employ a parsing model that is based on <ref type="bibr">Dozat and Manning (2016)</ref>. The model's embeddings layer is a concatenation of randomly initialized word embeddings 6 and character-based word rep- resentations added to pre-trained word embed- dings, which are passed through a 4-layer stacked bi-LSTM. Unlike <ref type="bibr">Dozat and Manning (2016)</ref>, our model jointly learns to perform UPOS tagging and parsing, instead of treating them as separate tasks. Therefore, instead of tag embeddings, we add a softmax classifier to predict UPOS tags after the first bi-LSTM layer. The outputs from that layer and the UPOS softmax prediction vectors are both concatenated to the original embedding layer and passed to the second bi-LSTM layer. The output of the last bi-LSTM is then used as input for four dense layers with a ReLU activation, producing four vector representations: a word as a depen- dent seeking its head; a word as a head seeking all its dependents; a word as a dependent decid- ing on its label; a word as head deciding on the labels of its dependents. These representations are then passed to biaffine and affine softmax classi- fiers to produce a fully-connected labeled prob- abilistic dependency graph <ref type="bibr">(Dozat and Manning, 2016)</ref>. Finally, a non-projective maximum span- ning tree parsing algorithm <ref type="bibr">(Chu, 1965;</ref><ref type="bibr">Edmonds, 1967)</ref> is used to obtain a well-formed dependency tree. <ref type="bibr">7</ref> Similarly to UPOS tagging, an additional soft- max classifier is used to predict a token's seman- tic tag in each of the MTL settings, as both tasks are jointly learned. In the FSN setting, the 4-layer stacked bi-LSTM is entirely shared. In the PSN setting the semantic tags are predicted from the second layer's hidden states, and the final two lay- ers are devoted to the parsing task. In the LWS setting, the first two layers of the bi-LSTM are split into a private bi-LSTM private and a shared bi-LSTM shared for each of the tasks with the inter- action between the shared subspaces being modu- lated via a gating unit. Then, two bi-LSTM layers that are devoted to parsing only are stacked on top.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Natural Language Inference</head><p>We base our NLI model on <ref type="bibr">Chen et al. (2017)</ref>'s Enhanced Sequential Inference Model which uses a bi-LSTM to encode the premise and hypothe- sis, computes a soft-alignment between premise and hypothesis' representations using an attention mechanism, and employs an inference composi- tion bi-LSTM to compose local inference infor- mation sequentially. <ref type="bibr">8</ref> The MTL settings are im- plemented by adding a softmax classifier to pre- dict semantic tags at the level of the encoding bi- LSTM, with rest of the model unaltered. In the FSN setting, the hidden states of the encoding bi- LSTM are directly passed as input to the soft- max classifier. In the PSN setting an earlier bi- LSTM layer is used to predict the semantic tags and the output from that is passed on to the en- coding bi-LSTM which is stacked on top. This follows <ref type="bibr">Hashimoto et al. (2016)</ref>'s hierarchical ap- proach. In the LWS setting, a bi-LSTM layer with private and shared subspaces is used for semantic tagging and for the ESIM model's encoding layer. In all MTL settings, the bi-LSTM used for seman- tic tagging is pre-trained on the sem-PMB data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and Discussion</head><p>Results for all tasks are shown in <ref type="table">Table 1</ref>. In line with <ref type="bibr" target="#b4">Bjerva et al. (2016)</ref>'s findings, the FSN set-ting leads to an improvement for UPOS tagging. POS tagging, a sequence labeling task, can be seen as the most closely related to semantic tagging, therefore negative transfer is minimal and the full sharing of parameters is beneficial. Surprisingly, the FSN setting also leads improvements for UD As a sentence-level task, NLI is functionally dissimilar to semantic tagging. However, it is a task which requires deep understanding of natural language semantics and can therefore conceivably benefit from the signal provided by semantic tag- ging. Our results demonstrate that it is possible to leverage this signal given a selective sharing setup where negative transfer can be minimized. In- deed, for the NLI tasks, only the LWS setting leads to improvements over the ST models. <ref type="bibr">9</ref> The im- provement is larger for the SICK-E task which has a much smaller training set and therefore stands to learn more from the semantic tagging signal. For all tasks, it can be observed that the LWS models outperform the rest of the models. This is in line with our expectations with the findings from previous work (Ruder et al., 2017; Liu et al., 2016) that selective sharing outperforms full net- work and partial network sharing.</p><note type="other">DEP. Indeed, for UD DEP, all of the MTL models outperform the ST model by increasing margins. For the NLI tasks, however, there is a clear degra- dation in performance. The PSN setting shows mixed results and does not show a clear advantage over FSN for UPOS and UD DEP. This suggests that adding task- specific layers after fully-shared ones does not al- ways enable sufficient task specialization. For the NLI tasks however, PSN is clearly preferable to FSN, especially for the small-sized SICK-E dataset where the FSN model fails to adequately learn. Model SNLI SICK-E</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Analysis</head><p>In addition to evaluating performance directly, we attempt to qualify how semtags affect performance with respect to each of the SNLI MTL settings 10 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Qualitative analyses</head><p>The fact that NLI is a sentence-level task, while se- mantic tags are word-level annotations presents a difficulty in measuring the effect of semantic tags on the systems' performance, as there is no one- to-one correspondence between a correct label and a particular semantic tag. We therefore employ the following method in order to assess the con- tribution of semantic tags. Given the performance ranking of all our systems -F SN &lt; ST &lt; P SN &lt; LW S -we make a pairwise compar- ison between the output of a superior system S sup and an inferior system S inf . This involves tak- ing the pairs of sentences that every S sup classi- fies correctly, but some S inf does not. Given that FSN is the worst performing system and, as such, has no 'worse' system for comparison, we are left with six sets of sentences: ST-FSN, PSN-FSN, PSN-ST, LWS-PSN, LWS-ST, and LWS-FSN.</p><p>To gain insight as to where a given system S sup performs better than a given S inf , we then sort each comparison sentence set by the frequency of semtags predicted therein, which are normalized by dividing by their frequency in the full SNLI test set. We notice interesting patterns, visible in <ref type="figure" target="#fig_0">Fig- ure 2</ref>. Specifically, PSN appears markedly bet- ter at sentences with named entities (ART, PER, GEO, ORG) and temporal entities (DOM) than both ST and the FSN. Marginal improvements are also observed for sentences with negation and reflexive pronouns. The LWS setting continues this pattern, with additional improvements observable for sen- tences with the HAP tag for names of events, SST for subsective attributes, and the ROL tag for role nouns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Contribution of semantic tagging</head><p>To assess the contribution of the semantic tagging auxiliary task independent of model architecture and complexity we run three additional SNLI ex- periments -one for each MTL setting -where the model architectures are unchanged but the aux- iliary tasks are assigned no weight (i.e. do not af- fect the learning). The results confirm our previ- ous findings that, for NLI, the semantic tagging auxiliary task only improves performance in a se- lective sharing setting, and hurts it otherwise: i) the FSN system which had performed below ST improves to equal it and ii) the PSN and LWS set- tings both see a drop to ST-level performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions</head><p>We present a comprehensive evaluation of MTL using a recently proposed task of semantic tag- ging as an auxiliary task. Our experiments span three types of NLP tasks and three MTL settings. The results of the experiments show that employ- ing semantic tagging as an auxiliary task leads to improvements in performance for UPOS tagging and UD DEP in all MTL settings. For the SNLI tasks, requiring understanding of phrasal seman- tics, the selective sharing setup we term Learning What to Share holds a clear advantage. Our work offers a generalizable framework for the evalua- tion of the utility of an auxiliary task. A MTL setting Diagrams, Preprocessing, and Hyperparameters UPOS Tagging <ref type="figure" target="#fig_1">Figure 3a</ref> shows the three MTL models used for UPOS. All hyperparameters were tuned with re- spect to loss on the English UD 2.0 UPOS vali- dation set. We trained for 20 epochs with a batch size of 128 and optimized using Adam ( <ref type="bibr">Kingma and Ba, 2014</ref>) with a learning rate of 0.0001. We weight the auxiliary semantic tagging loss with λ = 0.1. The pre-trained word embeddings we used are GloVe embeddings ( <ref type="bibr">Pennington et al., 2014</ref>) of dimension 100 trained on 6 billion tokens of Wikipedia 2014 and Gigaword 5. We applied dropout and recurrent dropout with a probability of 0.3 to all bi-LSTMs. <ref type="figure" target="#fig_1">Figure 3b</ref> shows the three MTL models for UD DEP. We use the gold tokenization. All hyper- parameters were tuned with respect to loss on the English UD 2.0 UD validation set. We trained for 15 epochs with a batch size of 50 and optimized using Adam with a learning rate of 2e − 3. We weight the auxiliary semantic tagging loss with λ = 0.5. The pre-trained word embeddings we use are GloVe embeddings of dimension 100 trained on 6 billion tokens of Wikipedia 2014 and Giga- word 5. We applied dropout with a probability of 0.33 to all bi-LSTM, embedding layers, and non- output dense layers.   <ref type="figure" target="#fig_1">Figure 3c</ref> shows the three MTL models for NLI. All hyperparameters were tuned with respect to loss on the SNLI and SICK-E validation datasets (separately). For the SNLI experiments, we trained for 37 epochs with a batch size of 128. For the SICK-E experiments, we trained for 20 epochs with a batch size of 8. Note that the ESIM model was designed for the SNLI dataset, therefore per- formance is non-optimal for SICK-E. For both sets of experiments: we optimized using Adam with a learning rate of 0.00005; we weight the auxiliary semantic tagging loss with λ = 0.1; the pre-trained word embeddings we use are GloVe embeddings of dimension 300 trained on 840 billion tokens of Common Crawl; and we applied dropout and re- current dropout with a probability of 0.3 to all bi- LSTM, and non-output dense layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UD DEP</head><p>B SNLI model output analysis <ref type="table">Table 2</ref> shows demonstrative examples from the SNLI test set on which the Learning What to Share (LWS) model outperforms the single-task (ST) model. The examples cover all possible combi- nations of entailment classes. <ref type="table" target="#tab_3">Table 3</ref> explains the relevant part of the semantic tagset. <ref type="table" target="#tab_4">Table 4</ref> shows the per-label precision and recall scores.    <ref type="table">Table 2</ref>: Examples of the entailment problems from SNLI which are incorrectly classified by the ST model but correctly classified by the LWS model. Automatically assigned semantic tags are in superscript.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Normalized semantic tag frequencies for all six sets of sentences. X-Y denotes the set of sentences correctly classified by model X but misclassified by model Y.</figDesc><graphic url="image-2.png" coords="5,91.95,62.81,136.06,102.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The three MTL settings for each task. Layers dimensions are displayed in brackets.</figDesc><graphic url="image-7.png" coords="8,306.91,451.25,226.77,272.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>NLI</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Tag category Semantic tag with examples Anaphoric DEF: definite; the, lo IT , der DE HAS: possessive pronoun; my, her</head><label></label><figDesc></figDesc><table>Attribute COL: colour; red, crimson, light blue, chestnut brown 
QUC: concrete quantity; two, six million, twice 
IST: intersective; open, vegetarian, quickly 
REL: relation; in, on, 's, of, after 

Unnamed entity CON: concept; dog, person 

Logical ALT: alternative &amp; repetitions; another, different, again 
DIS: disjunction &amp; exist. quantif.; a, some, any, or 

Discourse SUB: subordinate relations; that, while, because 

Events ENS: present simple; we walk, he walks 
EPS: past simple; ate, went 
EXG: untensed progessive; is running 
EXS: untensed simple; to walk, is eaten, destruction 

Tense &amp; aspect NOW: present tense; is skiing, do ski, has skied, now 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 3 : The list of semantic tags found in Table 2.</head><label>3</label><figDesc></figDesc><table>Model 
Label 
Entailment Contradiction 
Neutral 

FSN 80.64/93.23 91.64/83.63 83.97/77.63 
ST 84.86/91.54 90.10/88.04 84.74/79.71 
PSN 84.08/92.70 91.17/88.63 85.96/79.15 
LWS 84.45/92.87 91.74/88.91 85.95/79.65 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :The DEF man CON is NOW being EXS given EXS respect CON P: Men CON wearing EXG hats CON walk EXS on REL the DEF street CON C E H: The DEF men CON having EXS hats CON on REL their HAS head CON P: Three QUC men CON in REL orange IST suits CON are NOW doing EXG street CON repairs CON at REL night CON N C H: Three QUC men CON in REL orange IST suits CON escaped EPS from REL prison CON P: A DIS toddler CON sits ENS on REL a DIS stone CON wall CON surrounded EXS by REL fallen EXS leaves CON E C H: An DIS child CON is NOW throwing EXG stones CON at REL a DIS leaf CON wall CON P: An DIS old IST shoemaker CON in REL his HAS factory CON C N H: The DEF shoemaker CON is NOW wealthy IST P: A DIS kid CON slides CON down IST a DIS yellow COL slide CON into REL a DIS swimming CON pool CON E N H: The DEF kid CON is NOW playing EXS at REL the DEF waterpark CON</head><label>4</label><figDesc></figDesc><table>Per-label precision (left) and recall (right) 
for all models. 

Premise-hypothesis pairs 
ST LWS/GOLD 

P: The DEF gentleman CON is NOW speaking EXS while SUB the DEF others ALT are NOW listening EXS 
N 
E 
H: </table></figure>

			<note place="foot" n="3"> http://pmb.let.rug.nl/data.php 4 SICK-E refers to the entailment part of the SICK dataset. original work for further details due to a lack of space. 5 For reproducibility, detailed diagrams of the MTL models for each task and their hyperparameters can be found in Appendix A.</note>

			<note place="foot" n="5"> This applies to UD DEP and NLI only, as the POS tagger is not based on any one particular work. 6 This replaces the holistic word embeddings for frequent words in Dozat and Manning (2016).</note>

			<note place="foot" n="7"> This is recommended but not implemented by Dozat et al. (2017). 8 We do not implement the additional tree-LSTM model used in Chen et al. (2017) as we focus on the effect of MTL with semantic tagging rather than on absolute performance.</note>

			<note place="foot" n="9"> Demonstrative examples of the SNLI models&apos; outputs can be found in Appendix B.</note>

			<note place="foot" n="10"> We also provide a per-label report of the standard precision and recall metrics in Appendix B.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The parallel meaning bank: Towards a multilingual corpus of translations annotated with compositional meaning representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasha</forename><surname>Abzianidze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Bjerva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><surname>Evang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hessel</forename><surname>Haagsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rik</forename><surname>Van Noord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Ludmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duc-Duy</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Bos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<meeting>the 15th Conference of the European Chapter</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="242" to="247" />
		</imprint>
	</monogr>
	<note>Short Papers. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Towards universal semantic tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasha</forename><surname>Abzianidze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Bos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Computational Semantics (IWCS 2017)-Short Papers</title>
		<meeting>the 12th International Conference on Computational Semantics (IWCS 2017)-Short Papers<address><addrLine>France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note>Montpellier</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A model of inductive bias learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Baxter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res.(JAIR)</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Evaluating layers of representation in neural machine translation on part-of-speech and semantic tagging tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hassan</forename><surname>Sajjad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadir</forename><surname>Durrani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahim</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Glass</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.07772</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semantic tagging with deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Bjerva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Bos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3531" to="3541" />
		</imprint>
	</monogr>
	<note>The COLING 2016 Organizing Committee</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
