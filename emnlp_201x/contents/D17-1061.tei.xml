<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Task-Oriented Query Reformulation with Reinforcement Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>September 7-11, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
							<email>rodrigonogueira@nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Tandon School of Engineering</orgName>
								<orgName type="department" key="dep2">Courant Institute of Mathematical Sciences Center for Data Science</orgName>
								<orgName type="institution" key="instit1">New York University</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
							<email>kyunghyun.cho@nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Tandon School of Engineering</orgName>
								<orgName type="department" key="dep2">Courant Institute of Mathematical Sciences Center for Data Science</orgName>
								<orgName type="institution" key="instit1">New York University</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Task-Oriented Query Reformulation with Reinforcement Learning</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="574" to="583"/>
							<date type="published">September 7-11, 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Search engines play an important role in our everyday lives by assisting us in finding the information we need. When we input a complex query, however, results are often far from satisfactory. In this work, we introduce a query reformula-tion system based on a neural network that rewrites a query to maximize the number of relevant documents returned. We train this neural network with reinforcement learning. The actions correspond to selecting terms to build a reformulated query, and the reward is the document recall. We evaluate our approach on three datasets against strong baselines and show a relative improvement of 5-20% in terms of recall. Furthermore, we present a simple method to estimate a conservative upper-bound performance of a model in a particular environment and verify that there is still large room for improvements.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Search engines help us find what we need among the vast array of available data. When we request some information using a long or inexact descrip- tion of it, these systems, however, often fail to de- liver relevant items. In this case, what typically follows is an iterative process in which we try to express our need differently in the hope that the system will return what we want. This is a major issue in information retrieval. For instance, <ref type="bibr" target="#b5">Huang and Efthimiadis (2009)</ref> estimate that 28-52% of all the web queries are modifications of previous ones.</p><p>To a certain extent, this problem occurs be- cause search engines rely on matching words in the query with words in relevant documents, to Figure 1: A graphical illustration of the proposed framework for query reformulation. A set of doc- uments D 0 is retrieved from a search engine using the initial query q 0 . Our reformulator selects terms from q 0 and D 0 to produce a reformulated query q which is then sent to the search engine. Docu- ments D are returned, and a reward is computed against the set of ground-truth documents. The re- formulator is trained with reinforcement learning to produce a query, or a series of queries, to maxi- mize the expected return.</p><p>perform retrieval. If there is a mismatch between them, a relevant document may be missed. One way to address this problem is to automati- cally rewrite a query so that it becomes more likely to retrieve relevant documents. This technique is known as automatic query reformulation. It typi- cally expands the original query by adding terms from, for instance, dictionaries of synonyms such as WordNet <ref type="bibr" target="#b11">(Miller, 1995)</ref>, or from the initial set of retrieved documents ( <ref type="bibr" target="#b19">Xu and Croft, 1996)</ref>. This latter type of reformulation is known as pseudo (or blind) relevance feedback (PRF), in which the rel- evance of each term of the retrieved documents is automatically inferred.</p><p>The proposed method is built on top of PRF but differs from previous works as we frame the query reformulation problem as a reinforcement learn- ing (RL) problem. An initial query is the natural language expression of the desired goal, and an agent (i.e. reformulator) learns to reformulate an initial query to maximize the expected return (i.e. retrieval performance) through actions (i.e. select- ing terms for a new query). The environment is a search engine which produces a new state (i.e. re- trieved documents). Our framework is illustrated in <ref type="figure">Fig. 1</ref>.</p><p>The most important implication of this frame- work is that a search engine is treated as a black box that an agent learns to use in order to retrieve more relevant items. This opens the possibility of training an agent to use a search engine for a task other than the one it was originally intended for. To support this claim, we evaluate our agent on the task of question answering (Q&amp;A), citation recommendation, and passage/snippet retrieval.</p><p>As for training data, we use two publicly avail- able datasets (TREC-CAR and Jeopardy) and in- troduce a new one (MS Academic) with hundreds of thousands of query/relevant document pairs from the academic domain.</p><p>Furthermore, we present a method to estimate the upper bound performance of our RL-based model. Based on the estimated upper bound, we claim that this framework has a strong potential for future improvements.</p><p>Here we summarize our main contributions:</p><p>• A reinforcement learning framework for au- tomatic query reformulation.</p><p>• A simple method to estimate the upper-bound performance of an RL-based model in a given environment.</p><p>• A new large dataset with hundreds of thou- sands of query/relevant document pairs. 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A Reinforcement Learning Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Model Description</head><p>In this section we describe the proposed method, illustrated in <ref type="figure">Fig. 2</ref>. The inputs are a query q 0 consisting of a se- quence of words (w 1 , ..., w n ) and a candidate term t i with some context words (t i−k , ..., t i+k ), where k ≥ 0 is the context window size. Candidate terms <ref type="bibr">1</ref> The dataset and code to run the experiments are available at https://github.com/nyu-dl/ QueryReformulator.</p><formula xml:id="formula_0">CNN/RNN CNN/RNN Candidate Terms q 0 ⋃ D 0 Original Query q 0 W P(t i | q 0 ) + U V + S v 1 v 2 v n ... e i+2 e i+1 e i e i-1 e i-2</formula><p>Value Network w 1 w 2 w n ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>t i-2 t i-1 t i t i+1 t i+2</head><p>Figure 2: An illustration of our neural network- based reformulator.</p><p>are from q 0 ∪ D 0 , the union of the terms in the original query and those from the documents D 0 retrieved using q 0 .</p><p>We use a dictionary of pretrained word embed- dings ( <ref type="bibr" target="#b10">Mikolov et al., 2013</ref>) to convert the sym- bolic terms w j and t i to their vector representa- tions v j and e i ∈ R d , respectively. We map out- of-vocabulary terms to an additional vector that is learned during training.</p><p>We convert the sequence {v j } to a fixed-size vector φ a (v) by using either a Convolutional Neu- ral Network (CNN) followed by a max pooling op- eration over the entire sequence <ref type="bibr" target="#b6">(Kim, 2014)</ref> or by using the last hidden state of a Recurrent Neural Network (RNN). <ref type="bibr">2</ref> Similarly, we fed the candidate term vectors e i to a CNN or RNN to obtain a vector repre- sentation φ b (e i ) for each term t i . The convolu- tional/recurrent layers serve an important role of capturing context information, especially for out- of-vocabulary and rare terms. CNNs can pro- cess candidate terms in parallel, and, therefore, are faster for our application than RNNs. RNNs, on the other hand, can encode longer contexts.</p><p>Finally, we compute the probability of selecting t i as:</p><formula xml:id="formula_1">P (t i |q 0 ) = σ(U T tanh(W (φ a (v)φ b (e i )) + b)),<label>(1)</label></formula><p>where σ is the sigmoid function, is the vector concatenation operation, W ∈ R d×2d and U ∈ R d are weights, and b ∈ R is a bias.</p><p>At test time, we define the set of terms used in the reformulated query as T = {t i | P (t i |q 0 ) &gt; }, where is a hyper-parameter. At training time, we sample the terms according to their probability distribution, T = {t i | α = 1∧α ∼ P (t i |q 0 )}. We concatenate the terms in T to form a reformulated query q , which will then be used to retrieve a new set of documents D .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Sequence Generation</head><p>One problem with the method previously de- scribed is that terms are selected independently. This may result in a reformulated query that con- tains duplicated terms since the same term can ap- pear multiple times in the feedback documents. Another problem is that the reformulated query can be very long, resulting in a slow retrieval.</p><p>To solve these problems, we extend the model to sequentially generate a reformulated query, as pro- posed by <ref type="bibr" target="#b0">Buck et al. (2017)</ref>. We use a Recurrent Neural Network (RNN) that selects one term at a time from the pool of candidate terms and stops when a special token is selected. The advantage of this approach is that the model can remember the terms previously selected through its hidden state. It can, therefore, produce more concise queries.</p><p>We define the probability of selecting t i as the k-th term of a reformulated query as:</p><formula xml:id="formula_2">P (t k i |q 0 ) ∝ exp(φ b (e i ) T h k ),<label>(2)</label></formula><p>where h k is the hidden state vector at the k-th step, computed as:</p><formula xml:id="formula_3">h k = tanh(W a φ a (v) + W b φ b (t k−1 ) + W h h k−1 ),<label>(3)</label></formula><p>where t k−1 is the term selected in the previous step and W a ∈ R d×d , W b ∈ R d×d , and W h ∈ R d×d are weight matrices. In practice, we use an LSTM <ref type="bibr" target="#b4">(Hochreiter and Schmidhuber, 1997</ref>) to en- code the hidden state as this variant is known to perform better than a vanilla RNN.</p><p>We avoid normalizing over a large vocabulary by using only terms from the retrieved documents. This makes inference faster and training practi- cal since learning to select words from the whole vocabulary might be too slow with reinforcement learning, although we leave this experiment for a future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Training</head><p>We train the proposed model using <ref type="bibr">REINFORCE (Williams, 1992)</ref> algorithm. The per- example stochastic objective is defined as</p><formula xml:id="formula_4">C a = (R − ¯ R) t∈T − log P (t|q 0 ),<label>(4)</label></formula><p>where R is the reward and ¯ R is the baseline, com- puted by the value network as:</p><formula xml:id="formula_5">¯ R = σ(S T tanh(V (φ a (v)¯ e) + b)),<label>(5)</label></formula><p>where</p><formula xml:id="formula_6">¯ e = 1 N N i=1 φ b (e i ), N = |q 0 ∪ D 0 |, V ∈ R d×2d</formula><p>and S ∈ R d are weights and b ∈ R is a bias. We train the value network to minimize</p><formula xml:id="formula_7">C b = α||R − ¯ R|| 2 ,<label>(6)</label></formula><p>where α is a small constant (e.g. 0.1) multiplied to the loss in order to stabilize learning. We conjec- ture that the stability is due to the slowly evolving value network which directly affects the learning of the policy. This effectively prevents the value network to fit extreme cases (unexpectedly high or low reward.) We minimize C a and C b using stochastic gra- dient descent (SGD) with the gradient computed by backpropagation <ref type="bibr" target="#b15">(Rumelhart et al., 1988)</ref>. This allows the entire model to be trained end-to-end directly to optimize the retrieval performance.</p><p>Entropy Regularization We observed that the probability distribution in Eq.(1) became highly peaked in preliminary experiments. This phe- nomenon led to the trained model not being able to explore new terms that could lead to a better- reformulated query. We address this issue by reg- ularizing the negative entropy of the probability distribution. We add the following regularization term to the original cost function in Eq. <ref type="formula" target="#formula_4">(4)</ref>:</p><formula xml:id="formula_8">C H = −λ t∈q 0 ∪D 0 P (t|q 0 ) log P (t|q 0 ),<label>(7)</label></formula><p>where λ is a regularization coefficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>Query reformulation techniques are either based on a global method, which ignores a set of doc- uments returned by the original query, or a local method, which adjusts a query relative to the doc- uments that initially appear to match the query. In this work, we focus on local methods. A popular instantiation of a local method is the relevance model, which incorporates pseudo-relevance feedback into a language model form <ref type="bibr" target="#b9">(Lavrenko and Croft, 2001</ref>). The proba- bility of adding a term to an expanded query is proportional to its probability of being generated by the language models obtained from the orig- inal query and the document the term occurs in. This framework has the advantage of not requiring query/relevant documents pairs as training data since inference is based on word co-occurrence statistics.</p><p>Unlike the relevance model, algorithms can be trained with supervised learning, as proposed by <ref type="bibr" target="#b1">Cao et al. (2008)</ref>. A training dataset is auto- matically created by labeling each candidate term as relevant or not based on their individual contri- bution to the retrieval performance. Then a binary classifier is trained to select expansion terms. In Section 4, we present a neural network-based im- plementation of this supervised approach.</p><p>A generalization of this supervised framework is to iteratively reformulate the query by selecting one candidate term at each retrieval step. This can be viewed as navigating a graph where the nodes represent queries and associated retrieved results and edges exist between nodes whose queries are simple reformulations of each other <ref type="bibr" target="#b2">(Diaz, 2016)</ref>. However, it can be slow to reformulate a query this way as the search engine must be queried for each newly added term. In our method, on the con- trary, the search engine is queried with multiple new terms at once.</p><p>An alternative technique based on supervised learning is to learn a common latent representation of queries and relevant documents terms by us- ing a click-through dataset ( <ref type="bibr" target="#b17">Sordoni et al., 2014</ref>). Neighboring document terms of a query in the la- tent space are selected to form an expanded query. Instead of using a click-through dataset, which is often proprietary, it is possible to use an alterna- tive dataset consisting of anchor text/title pairs. In contrast, our approach does not require a dataset of paired queries as it learns term selection strategies via reinforcement learning.</p><p>Perhaps the closest work to ours is that by <ref type="bibr" target="#b12">Narasimhan et al. (2016)</ref>, in which a reinforce- ment learning based approach is used to reformu- late queries iteratively. A key difference is that in their work the reformulation component uses domain-specific template queries. Our method, on the other hand, assumes open-domain queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section we describe our experimental setup, including baselines against which we compare the proposed method, metrics, reward for RL-based models, datasets and implementation details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baseline Methods</head><p>Raw: The original query is given to a search engine without any modification. We evaluate two search engines in their default configura- tion: Lucene 3 (Raw-Lucene) and Google Search 4 (Raw-Google).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pseudo Relevance Feedback (PRF-TFIDF):</head><p>A query is expanded with terms from the docu- ments retrieved by a search engine using the orig- inal query. In this work, the top-N TF-IDF terms from each of the top-K retrieved documents are added to the original query, where N and K are selected by a grid search on the validation data.</p><p>PRF-Relevance Model (PRF-RM): This is a popular relevance model for query expansion by <ref type="bibr" target="#b9">Lavrenko and Croft (2001)</ref>. The probability of using a term t in an expanded query is given by:</p><formula xml:id="formula_9">P (t|q 0 ) = (1 − λ)P (t|q 0 ) + λ d∈D 0 P (d)P (t|d)P (q 0 |d), (8)</formula><p>where P (d) is the probability of retrieving the document d, assumed uniform over the set, P (t|d) and P (q 0 |d) are the probabilities assigned by the language model obtained from d to t and q 0 , re- spectively. P (t|q 0 ) = tf(t∈q) |q| , where tf(t, d) is the term frequency of t in d. We set the interpolation parameter λ to 0.5, following <ref type="bibr" target="#b20">Zhai and Lafferty (2001)</ref>.</p><p>We use a Dirichlet smoothed language model <ref type="bibr" target="#b20">(Zhai and Lafferty, 2001)</ref> to compute a language model from a document d ∈ D 0 :</p><formula xml:id="formula_10">P (t|d) = tf(t, d) + uP (t|C) |d| + u ,<label>(9)</label></formula><p>where u is a scalar constant (u = 1500 in our ex- periments), and P (t|C) is the probability of t oc- curring in the entire corpus C. We use the N terms with the highest P (t|q 0 ) in an expanded query, where N is a hyper-parameter.</p><p>Embeddings Similarity: Inspired by the meth- ods proposed by <ref type="bibr" target="#b14">Roy et al. (2016)</ref> and <ref type="bibr" target="#b8">Kuzi et al. (2016)</ref>, the top-N terms are selected based on the cosine similarity of their embeddings against the original query embedding. Candidate terms come from documents retrieved using the orig- inal query (PRF-Emb), or from a fixed vocab- ulary (Vocab-Emb). We use pretrained embed- dings from <ref type="bibr" target="#b10">Mikolov et al. (2013)</ref>, and it contains 374,000 words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Proposed Methods</head><p>Supervised Learning (SL): Here we detail a deep learning-based variant of the method pro- posed by <ref type="bibr" target="#b1">Cao et al. (2008)</ref>. It assumes that query terms contribute independently to the retrieval per- formance. We thus train a binary classifier to se- lect a term if the retrieval performance increases beyond a preset threshold when that term is added to the original query. More specifically, we mark a term as relevant if (R − R)/R &gt; 0.005, where R and R are the retrieval performances of the orig- inal query and the query expanded with the term, respectively.</p><p>We experiment with two variants of this method: one in which we use a convolutional net- work for both original query and candidate terms (SL-CNN), and the other in which we replace the convolutional network with a single hidden layer feed-forward neural network (SL-FF). In this vari- ant, we average the output vectors of the neural network to obtain a fixed size representation of q 0 .</p><p>Reinforcement Learning (RL): We use multi- ple variants of the proposed RL method. RL-CNN and RL-RNN are the models described in Sec- tion 2.1, in which the former uses CNNs to encode query and term features and the latter uses RNNs (more specifically, bidirectional LSTMs). RL-FF is the model in which term and query vectors are encoded by single hidden layer feed-forward neu- ral networks. In the RL-RNN-SEQ model, we add the sequential generator described in Section 2.2 to the RL-RNN variant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Datasets</head><p>We summarize in <ref type="table">Table 1</ref> the datasets. TREC -Complex Answer Retrieval (TREC- CAR) This is a publicly available dataset auto- matically created from Wikipedia whose goal is to encourage the development of methods that re- spond to more complex queries with longer an- swers ( <ref type="bibr" target="#b3">Dietz and Ben, 2017)</ref>. A query is the con- catenation of an article title and one of its section titles. The ground-truth documents are the para- graphs within that section. For example, a query is "Sea Turtle, Diet" and the ground truth docu- ments are the paragraphs in the section "Diet" of the "Sea Turtle" article. The corpus consists of all the English Wikipedia paragraphs, except the ab- stracts. The released dataset has five predefined folds, and we use the first three as the training set and the remaining two as validation and test sets, respectively.</p><p>Jeopardy This is a publicly available Q&amp;A dataset introduced by <ref type="bibr" target="#b13">Nogueira and Cho (2016)</ref>. A query is a question from the Jeopardy! TV Show and the corresponding document is a Wikipedia article whose title is the answer. For example, a query is "For the last eight years of his life, Galileo was under house arrest for espousing this mans theory" and the answer is the Wikipedia arti- cle titled "Nicolaus Copernicus". The corpus con- sists of all the articles in the English Wikipedia.</p><p>Microsoft Academic (MSA) This dataset con- sists of academic papers crawled from Microsoft Academic API. <ref type="bibr">5</ref> The crawler started at the pa- per <ref type="bibr" target="#b16">Silver et al. (2016)</ref> and traversed the graph of references until 500,000 papers were crawled. We then removed papers that had no reference within or whose abstract had less than 100 characters. We ended up with 480,000 papers.</p><p>A query is the title of a paper, and the ground- truth answer consists of the papers cited within. Each document in the corpus consists of its title and abstract. <ref type="bibr">6</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Metrics and Reward</head><p>Three metrics are used to evaluate performance:</p><p>Recall@K: Recall of the top-K retrieved docu- ments:  Precision@K: Precision of the top-K retrieved documents:</p><formula xml:id="formula_11">R@K = |D K ∩ D * | |D * | ,<label>(10)</label></formula><formula xml:id="formula_12">P@K = |D K ∩ D * | |D K |<label>(11)</label></formula><p>Precision captures the proportion of relevant doc- uments among the returned ones. Despite not be- ing the main goal of a reformulation method, im- provements in precision are also expected with a good query reformulation method. Therefore, we include this metric.</p><p>Mean Average Precision: The average preci- sion of the top-K retrieved documents is defined as:</p><formula xml:id="formula_13">AP@K = K k=1 P@k × rel(k) |D * | ,<label>(12)</label></formula><p>where rel(k) = 1, if the k-th document is relevant; 0, otherwise.</p><p>The mean average precision of a set of queries Q is then:</p><formula xml:id="formula_15">MAP@K = 1 |Q| q∈Q AP@K q ,<label>(14)</label></formula><p>where AP@K q is the average precision at K for a query q. This metric values the position of a rele- vant document in a returned list and is, therefore, complementary to precision and recall.</p><p>Reward We use R@K as a reward when train- ing the proposed RL-based models as this metric has shown to be effective in improving the other metrics as well.</p><p>SL-Oracle In addition to the baseline methods and proposed reinforcement learning approach, we report two oracle performance bounds. The first oracle is a supervised learning oracle (SL- Oracle). It is a classifier that perfectly selects terms that will increase performance according to the procedure described in Section 4.2. This mea- sure serves as an upper-bound for the supervised methods. Notice that this heuristic assumes that each term contributes independently from all the other terms to the retrieval performance. There may be, however, other ways to explore the de- pendency of terms that would lead to a higher per- formance.</p><p>TREC-CAR Jeopardy MSA <ref type="table" target="#tab_2">SL-Oracle  13%  5%  11%  RL-Oracle  29%  27%  31%   Table 3</ref>: Percentage of relevant terms over all the candidate terms according to SL-and RL-Oracle.</p><p>RL-Oracle Second, we introduce a reinforce- ment learning oracle (RL-Oracle) which estimates a conservative upper-bound performance for the RL models. Unlike the SL-Oracle, it does not assume that each term contributes independently to the retrieval performance. It works as follows: first, the validation or test set is divided into N small subsets {A i } N i=1 (each with 100 examples, for instance). An RL model is trained on each sub- set A i until it overfits, that is, until the reward R * i stops increasing or an early stop mechanism ends training. <ref type="bibr">7</ref> Finally, we compute the oracle perfor- mance R * as the average reward over all the sub- sets:</p><formula xml:id="formula_16">R * = 1 N N i=1 R *</formula><p>i . This upper bound by the RL-Oracle is, however, conservative since there might exist better refor- mulation strategies that the RL model was not able to discover.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Implementation Details</head><p>Search engine We use Lucene and BM25 as the search engine and the ranking function, respec- tively, for all PRF, SL and RL methods. For Raw- Google, we restrict the search to the wikipedia.org domain when evaluating its performance on the Jeopardy dataset. We could not apply the same re- striction to the two other datasets as Google does not index Wikipedia paragraphs, and as it is not trivial to match papers from MS Academic to the ones returned by Google Search.</p><p>Candidate terms We use Wikipedia articles as a source for candidate terms since it is a well cu- rated, clean corpus, with diverse topics.</p><p>At training and test times of SL methods, and at test time of RL methods, the candidate terms are from the first M words of the top-K Wikipedia articles retrieved. We select M and K using grid search on the validation set over {50, 100, 200, 300} and {1, 3, 5, 7}, respectively. The best values are M = 300 and K = 7. These correspond to the maximum number of terms we could fit in a single GPU. At training time of an RL model, we use only one document uniformly sampled from the top-K retrieved ones as a source for candidate terms, as this leads to a faster learning.</p><p>For the PRF methods, the top-M terms ac- cording to a relevance metric (i.e., TF-IDF for PRF-TFIDF, cosine similarity for PRF-Emb, and conditional probability for PRF-RM) from each of the top-K retrieved documents are added to the original query. We select M and K using grid search over {10, 50, 100, 200, 300, 500} and {1, 3, 5, 9, 11}, respectively. The best values are M = 300 and K = 9.</p><p>Multiple Reformulation Rounds Although our framework supports multiple rounds of search and reformulation, we did not find any significant im- provement in reformulating a query more than once. Therefore, the numbers reported in the re- sults section were all obtained from models run- ning two rounds of search and reformulation.</p><p>Neural Network Setup For SL-CNN and RL- CNN variants, we use a 2-layer convolutional net- work for the original query. Each layer has a win- dow size of 3 and 256 filters. We use a 2-layer con- volutional network for candidate terms with win- dow sizes of 9 and 3, respectively, and 256 filters in each layer. We set the dimension d of the weight matrices W, S, U , and V to 256. For the opti- mizer, we use ADAM ( <ref type="bibr" target="#b7">Kingma and Ba, 2014</ref>) with α = 10 −4 , β 1 = 0.9, β 2 = 0.999, and = 10 −8 . We set the entropy regularization coefficient λ to 10 −3 .</p><p>For RL-RNN and RL-RNN-SEQ, we use a 2- layer bidirectional LSTM with 256 hidden units in each layer. We clip the gradients to unit norm. For RL-RNN-SEQ, we set the maximum possible number of generated terms to 50 and we use beam search of size four at test time.</p><p>We fix the dictionary of pre-trained word em- beddings during training, except the vector for out- of-vocabulary words. We found that this led to faster convergence and observed no difference in the overall performance when compared to learn- ing embeddings during training. <ref type="table" target="#tab_2">Table 2</ref> shows the main result. As expected, re- formulation based methods work better than us- ing the original query alone. Supervised methods (SL-FF and SL-CNN) have in general a better per- formance than unsupervised ones (PRF-TFIDF, PRF-RM, PRF-Emb, and Emb-Vocab), but per- form worse than RL-based models (RL-FF, RL- CNN, RL-RNN, and RL-RNN-SEQ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>RL-RNN-SEQ performs slightly worse than RL-RNN but produces queries that are three times shorter, on average (15 vs 47 words). Thus, RL- RNN-SEQ is faster in retrieving documents and therefore might be a better candidate for a produc- tion implementation.</p><p>The performance gap between the oracle and best performing method ( <ref type="table" target="#tab_2">Table 2</ref>, RL-Oracle vs. RL-RNN) suggests that there is a large room for improvement. The cause for this gap is unknown but we suspect, for instance, an inherent difficulty in learning a good selection strategy and the par- tial observability from using a black box search engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Relevant Terms per Document</head><p>The proportion of relevant terms selected by the SL-and RL-Oracles over the total number of can- didate terms <ref type="table">(Table 3)</ref> indicates that only a small subset of terms are useful for the reformulation. Thus, we may conclude that the proposed method was able to learn an efficient term selection strat- egy in an environment where relevant terms are infrequent. <ref type="figure" target="#fig_0">Fig. 3</ref> shows the improvement in recall as more candidate terms are provided to a reformulation method. The RL-based model benefits from more candidate terms, whereas the classical PRF method quickly saturates. In our experiments, the best performing RL-based model uses the maxi- mum number of candidate terms that we could fit   on a single GPU. We, therefore, expect further im- provements with more computational resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Scalability: Number of Terms vs Recall</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Qualitative Analysis</head><p>We show two examples of queries and the proba- bilities of each candidate term of being selected by the RL-CNN model in <ref type="figure" target="#fig_2">Fig. 4</ref>. Notice that terms that are more related to the query have higher probabilities, although common words such as "the" are also selected. This is a consequence of our choice of a reward that does   not penalize the selection of neutral terms.</p><p>In <ref type="table" target="#tab_4">Table 4</ref> we show an original and reformu- lated query examples extracted from the MS Aca- demic and TREC-CAR datasets, and their top-3 retrieved documents. Notice that the reformulated query retrieves more relevant documents than the original one. As we conjectured earlier, we see that a search engine tends to return a document simply with the largest overlap in the text, neces- sitating the reformulation of a query to retrieve se- mantically relevant documents.</p><p>Same query, different tasks We compare in Ta- ble 5 the reformulation of a sample query made by models trained on different datasets. The model trained on TREC-CAR selects terms that are sim- ilar to the ones in the original query, such as "serves" and "accreditation". These selections are expected for this task since similar terms can be effective in retrieving similar paragraphs. On the other hand, the model trained on Jeopardy prefers to select proper nouns, such as "Tunxis", as these have a higher chance of being an answer to the question. The model trained on MSA selects terms that cover different aspects of the entity being queried, such as "arts center" and "library", since retrieving a diverse set of documents is necessary for the task the of citation recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Training and Inference Times</head><p>Our best model, RL-RNN, takes 8-10 days to train on a single K80 GPU. At inference time, it takes approximately one second to reformulate a batch of 64 queries. Approximately 40% of this time is to retrieve documents from the search engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We introduced a reinforcement learning frame- work for task-oriented automatic query reformu- lation. An appealing aspect of this framework is that an agent can be trained to use a search en- gine for a specific task. The empirical evaluation has confirmed that the proposed approach outper- forms strong baselines in the three separate tasks. The analysis based on two oracle approaches has revealed that there is a meaningful room for fur- ther development. In the future, more research is necessary in the directions of (1) iterative refor- mulation under the proposed framework, (2) using information from modalities other than text, and (3) better reinforcement learning algorithms for a partially-observable environment.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Our RL-based model continues to improve recall as more candidate terms are added, whereas a classical PRF method saturates.</figDesc><graphic url="image-7.png" coords="7,307.28,62.81,218.27,120.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Query</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Probabilities assigned by the RL-CNN to candidate terms of two sample queries: "Learning Intersections of Halfspaces with a Margin" (top) and "Sea Turtle Diet" (bottom). We show the original query terms and the top-10 and bottom-10 document terms with respect to their probabilities.</figDesc><graphic url="image-9.png" coords="9,81.50,165.43,434.54,95.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>q' Scorer Reformulator Ground Truth D' Search Engine q' : cancer treatment state-of-the-art frontiers survey Reward q 0 :</head><label></label><figDesc></figDesc><table>What are the most promising directions to cure 
cancer and why? 

D 0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Results on Test sets. We use R@40 as a reward to the RL-based models. 

where D K are the top-K retrieved documents and 
D  *  are the relevant documents. Since one of the 
goals of query reformulation is to increase the pro-
portion of relevant documents returned, recall is 
our main metric. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Top-3 retrieved documents using the orig-
inal query and a query reformulated by our RL-
CNN model. In the first example, we only show 
the titles of the retrieved MSA papers. In the 
second example, we only show some words of 
the retrieved TREC-CAR paragraphs. Bold cor-
responds to ground-truth documents. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Given the query "Northwestern Con-
necticut Community College", models trained on 
different tasks choose different terms. </table></figure>

			<note place="foot" n="2"> To deal with variable-length inputs in a mini-batch, we pad smaller ones with zeros on both ends so they end up as long as the largest sample in the mini-batch.</note>

			<note place="foot" n="3"> https://lucene.apache.org/ 4 https://cse.google.com/cse/</note>

			<note place="foot" n="5"> https://www.microsoft.com/cognitive-services/enus/academic-knowledge-api 6 This was done to avoid a large computational overhead for indexing full papers.</note>

			<note place="foot" n="7"> The subset should be small enough, or the model should be large enough so it can overfit.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>RN is funded by Coordenao de Aperfeioamento de Pessoal de Nvel Superior (CAPES). KC thanks support by Facebook, Google and NVIDIA. This work was partly funded by the Defense Advanced Research Projects Agency (DARPA) D3M pro-gram. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jannis</forename><surname>Bulian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Gesmundo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Gajewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07830</idno>
		<title level="m">Ask the right questions: Active question reformulation with reinforcement learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Selecting good expansion terms for pseudo-relevance feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guihong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 31st annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="243" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Pseudo-query reformulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="521" to="532" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Trec car: A data set for complex answer retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Dietz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gamari</forename><surname>Ben</surname></persName>
		</author>
		<ptr target="http://trec-car.cs.unh.edu" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Analyzing and evaluating query reformulation strategies in web search logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Efthimis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Efthimiadis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM conference on Information and knowledge management</title>
		<meeting>the 18th ACM conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="77" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5882</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Query expansion using word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saar</forename><surname>Kuzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Shtok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Kurland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 25th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1929" to="1932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Relevance based language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 24th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Improving information extraction by acquiring external evidence with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Yala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.07954</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Endto-end goal-driven web navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1903" to="1911" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Using word embeddings for automatic query expansion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dwaipayan</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debjyoti</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Utpal</forename><surname>Garain</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.07608</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning representations by backpropagating errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>David E Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald J</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive modeling</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Mastering the game of go with deep neural networks and tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aja</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Driessche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veda</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Panneershelvam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lanctot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="issue">7587</biblScope>
			<biblScope unit="page" from="484" to="489" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning concept embeddings for query expansion by quantum entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1586" to="1592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Simple statistical gradientfollowing algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Query expansion using local and global document analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 19th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="4" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A study of smoothing methods for language models applied to ad hoc information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 24th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="334" to="342" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
