<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:03+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Human Effort and Machine Learnability in Computer Aided Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 25-29, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spence</forename><surname>Green</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sida</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chuang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Heer</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Schuster</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Human Effort and Machine Learnability in Computer Aided Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1225" to="1236"/>
							<date type="published">October 25-29, 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Analyses of computer aided translation typically focus on either frontend interfaces and human effort, or backend translation and machine learnability of corrections. However , this distinction is artificial in practice since the frontend and backend must work in concert. We present the first holis-tic, quantitative evaluation of these issues by contrasting two assistive modes: post-editing and interactive machine translation (MT). We describe a new translator interface , extensive modifications to a phrase-based MT system, and a novel objective function for re-tuning to human corrections. Evaluation with professional bilingual translators shows that post-edit is faster than interactive at the cost of translation quality for French-English and English-German. However, re-tuning the MT system to interactive output leads to larger, statistically significant reductions in HTER versus re-tuning to post-edit. Analysis shows that tuning directly to HTER results in fine-grained corrections to subsequent machine output.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The goal of machine translation has always been to reduce human effort, whether by partial assistance or by outright replacement. However, preoccupa- tion with the latter-fully automatic translation-at the exclusion of the former has been a feature of the research community since its first nascent steps in the 1950s. Pessimistic about progress during that decade and future prospects, Bar-Hillel <ref type="bibr">(1960, p.3)</ref> argued that more attention should be paid to a "machine-post-editor partnership," whose decisive problem is "the region of optimality in the contin- uum of possible divisions of labor." Today, with human-quality, fully automatic machine translation (MT) elusive still, that decades-old recommenda- tion remains current.</p><p>This paper is the first to look at both sides of the partnership in a single user study. We compare two common flavors of machine-assisted transla- tion: post-editing and interactive MT. We analyze professional, bilingual translators working in both modes, looking first at user productivity. Does the additional machine assistance available in the inter- active mode affect translation time and/or quality?</p><p>Then we turn to the machine side of the part- nership. The user study results in corrections to the baseline MT output. Do these corrections help the MT system, and can it learn from them quickly enough to help the user? We perform a re-tuning experiment in which we directly optimize human Translation Edit Rate (HTER), which correlates highly with human judgments of fluency and ade- quacy ( <ref type="bibr" target="#b48">Snover et al., 2006</ref>). It is also an intuitive measure of human effort, making fine distinctions between 0 (no editing) and 1 (complete rewrite).</p><p>We designed a new user interface (UI) for the experiment. The interface places demands on the MT backend-not the other way around. The most significant new MT system features are prefix de- coding, for translation completion based on a user prefix; and dynamic phrase table augmentation, to handle target out-of-vocabulary (OOV) words. Dis- criminative re-tuning is accomplished with a novel cross-entropy objective function.</p><p>We report three main findings: (1) post-editing is faster than interactive MT, corroborating <ref type="bibr" target="#b30">Koehn (2009a)</ref>; (2) interactive MT yields higher quality translation when baseline MT quality is high; and (3) re-tuning to interactive feedback leads to larger held-out HTER gains relative to post-edit. Together these results show that a human-centered approach to computer aided translation (CAT) may involve tradeoffs between human effort and machine learnability. For example, if speed is the top priority, then a design geared toward post-editing is appropriate. However, if reductions in HTER ultimately correspond to lower human effort, then investing slightly more time in the interactive mode, which results in more learnable output, may be op- timal. Mixed UI designs may offer a compromise. Code and data from our experiments are available at:</p><p>http://nlp.stanford.edu/software/phrasal/ A holistic comparison with human subjects nec- essarily involves many moving parts. Section 2 briefly describes the interface, focusing on NLP components. Section 3 describes changes to the backend MT system. Section 4 explains the user study, and reports human translation time and qual- ity results. Section 5 describes the MT re-tuning experiment. Analysis (section 6) and related work (section 7) round out the paper. <ref type="figure" target="#fig_0">Figure 1</ref> shows the translator interface, which is designed for expert, bilingual translators. Previ- ous studies have shown that expert translators work and type quickly <ref type="bibr" target="#b9">(Carl, 2010)</ref>, so the interface is designed to be very responsive, and to be primar- ily operated by the keyboard. Most aids can be accessed via either typing or four hot keys. The current design focuses on the point of text entry and does not include conventional translator work- bench features such as workflow management, spell checking, and text formatting tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">New Translator User Interface</head><p>In the trivial post-edit mode, the interactive aids are disabled and a 1-best translation pre-populates the text entry box. We have described the HCI-specific motivations for and contributions of this new interface in <ref type="bibr" target="#b25">Green et al. (2014c)</ref>. This section focuses on interface elements built on NLP components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">UI Overview and Walkthrough</head><p>We categorized interactions into three groups: source comprehension: word lookups, source cov- erage highlighting; target gisting: 1-best transla- tion, real-time target completion; target genera- tion: real-time autocomplete, target reordering, in- sert complete translation. The interaction designs are novel; those in italic have, to our knowledge, never appeared in a translation workbench.</p><p>Source word lookup When the user hovers over a source word, a menu of up to four ranked trans- lation suggestions appears <ref type="figure" target="#fig_1">(Figure 2</ref>). The menu is populated by a phrase-table query of the word plus one token of left context. This query usually returns in under 50ms. The width of the horizontal bars indicates confidence, with the most confident suggestion 'regularly' placed at the bottom, near- est to the cursor. The user can insert a translation suggestion by clicking.</p><p>Source coverage highlighting The source cover- age feature ( <ref type="figure" target="#fig_0">Figure 1C</ref>) helps the user quickly find untranslated words in the source. The interaction is based on the word alignments between source and target generated by the MT system. We found that the raw alignments are too noisy to show users, so the UI filters them with phrase-level heuristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1-best translation</head><p>The most common use of MT output is gisting <ref type="bibr">(Koehn, 2010, p.21)</ref>. The gray text below each black source input shows the best MT system output ( <ref type="figure" target="#fig_0">Figure 1B</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Real-time target completion</head><p>When the user ex- tends the black prefix, the gray text will update to the most probable completion ( <ref type="figure" target="#fig_0">Figure 1E</ref>). This up- date comes from decoding under the full translation model. All previous systems performed inference in a word lattice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Real-time autocomplete</head><p>The autocomplete dropdown at the point of text entry is the main translation aid <ref type="figure" target="#fig_0">(Figures 1D and 2)</ref>. Each real-time update actually contains a distinct 10-best list for the full source input. The UI builds up a trie from these 10-best lists. Up to four distinct suggestions are then shown at the point of translation. The suggestion length is based on a syntactic parse of the fixed source input. As an offline, pre-processing step, we parse each source input with Stanford CoreNLP ( <ref type="bibr" target="#b35">Manning et al., 2014</ref>). The UI combines those parses with word alignments from the full translation suggestions to project syntactic con- stituents to each item on the n-best list. Syntactic projection is a very old idea that underlies many MT systems (see: <ref type="bibr" target="#b28">Hwa et al. (2002)</ref>). Here we make novel use of it for suggestion prediction filtering. 1 Presently, we project noun phrases, verb phrases (minus the verbal arguments), and prepositional phrases. Crucially, these units are natural to humans, unlike statistical target phrases. <ref type="bibr" target="#b9">Carl (2010)</ref> showed that ex- pert translators tend to adopt local planning: they read a few words ahead and then translate in a roughly online fashion. However, word order differ- ences between languages will necessarily require longer range planning and movement. To that end, the UI supports keyboard-based reordering. Sup- pose that the user wants to move a span in gray text to the insertion position for editing. Typing the prefix of this string will update the autocom- plete dropdown with matching strings from the gray text. Consequently, sometimes the autocomplete dropdown will contain suggestions from several positions in the full suggested translation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Target Reordering</head><p>Insert complete translation The user can insert the full completion via a hot key. Notice that if the user presses this hot key immediately, all gray text becomes black, and the interface effectively switches to post-edit mode. This feature greatly ac- celerates translation when the MT is mostly correct, and the user only wants to make a few changes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">User Activity Logging</head><p>A web application serves the Javascript-based in- terface, relays translation requests to the MT sys- tem, and logs user records to a database. Each user record is a tuple of the form (f, ˆ e, h, u), where f is the source sequence, ˆ e is the latest 1-best ma- chine translation of f , h is the correction ofêofˆofê, and u is the log of interaction events during the transla- tion session. Our evaluation corpora also include independently generated references e for each f .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Interactive MT Backend</head><p>Now we describe modifications to <ref type="bibr">Phrasal (Green et al., 2014b</ref>), the phrase-based MT system that sup- ports the interface. Phrasal follows the log-linear approach to phrase-based translation ( <ref type="bibr" target="#b37">Och and Ney, 2004</ref>) in which the decision rule has the familiar linear formê</p><formula xml:id="formula_0">formˆformê = arg max e w φ(e, f )<label>(1)</label></formula><p>where w ∈ R d is the model weight vector and φ(·) ∈ R d is a feature map.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Decoding</head><p>The default Phrasal search algorithm is cube prun- ing ( <ref type="bibr" target="#b27">Huang and Chiang, 2007</ref>). In the post-edit con- dition, search is executed as usual for each source input, and the 1-best output is inserted into the tar- get textbox. However, in interactive mode, the full search algorithm is executed each time the user modifies the partial translation. Machine sugges- tionsêtionsˆtionsê must match user prefix h. Define indicator function pref(ˆ e, h) to return true ifêifˆifê begins with h, and false otherwise. Eq. 1 becomes:</p><formula xml:id="formula_1">ˆ e = arg max e s.t. pref(e,h) w φ(e, f )<label>(2)</label></formula><p>Cube pruning can be straightforwardly modified to satisfy this constraint by simple string matching of candidate translations. Also, the pop limit must be suspended until at least one legal candidate appears on each beam, or the priority queue of candidates is exhausted. We call this technique prefix decoding. <ref type="bibr">2</ref> There is another problem. Human translators are likely to insert unknown target words, including new vocabulary, misspellings, and typographical errors. They might also reorder source text so as to violate the phrase-based distortion limit. To solve these problems, we perform dynamic phrase table augmentation, adding new synthetic rules specific to each search. Rules allowing any source word to align with any unseen or ungeneratable (due to the distortion limit) target word are created. 3 These synthetic rules are given rule scores lower than any other rules in the set of queried rules for that source input f . Then candidates are allowed to compete on the beam. Candidates with spurious alignments will likely be pruned in favor of those that only turn to synthetic rules as a last resort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Tuning</head><p>We choose BLEU ( <ref type="bibr" target="#b43">Papineni et al., 2002</ref>) for base- line tuning to independent references, and HTER for re-tuning to human corrections. Our rationale is as follows: <ref type="bibr" target="#b10">Cer et al. (2010)</ref> showed that BLEU- tuned systems score well across automatic metrics and also correlate with human judgment better than systems tuned to other metrics. Conversely, sys- tems tuned to edit-distance-based metrics like TER tend to produce short translations that are heavily penalized by other metrics.</p><p>When human corrections become available, we switch to HTER, which correlates with human judg- ment and is an interpretable measure of editing effort. Whereas TER is computed as TER(e, ˆ e), HTER is HTER(h, ˆ e). HBLEU is an alternative, but since BLEU is invariant to some permutations <ref type="bibr" target="#b8">(Callison-Burch et al., 2006</ref>), it is less interpretable. We find that it also does not work as well in practice.</p><p>We previously proposed a fast, online tuning al- gorithm <ref type="bibr" target="#b22">(Green et al., 2013b</ref>) based on AdaGrad ( <ref type="bibr" target="#b16">Duchi et al., 2011</ref>). The default loss function is expected error (EE) <ref type="bibr" target="#b39">(Och, 2003;</ref><ref type="bibr" target="#b11">Cherry and Foster, 2012)</ref>. Expected BLEU is an example of EE, which we found to be unstable when switching metrics. This may result from direct incorporation of the error metric into the gradient computation.</p><p>To solve this problem, we propose a cross- entropy loss which, to our knowledge, is new in MT. LetˆELetˆ LetˆE = {ê i } n i=1 be an n-best list ranked by a gold metric G(e, ˆ e) ≥ 0. Assume we have a preference of a higher G (e.g., BLEU or 1−HTER). Define the model distribution overˆEoverˆ overˆE as q(ˆ e|f ) ∝ exp[w φ(ˆ e, f )] normalized so thatê∈ˆE thatˆthatê∈thatê∈ˆ thatê∈ˆE q(ˆ e|f ) = 1; q indicates how much the model prefers each translation. Similarly, define p(ˆ e|f ) based on any function of the gold metric so thatê∈ˆE thatˆthatê∈thatê∈ˆ thatê∈ˆE p(ˆ e|f ) = 1; p indicates how much the met- ric prefers each translation. We choose a DCG- style 4 parameterization that skews the p distribu- tion toward higher-ranked items on the n-best list: p(ˆ e i |f ) ∝ G(e, ˆ e i )/ log(1 + i) for the ith ranked item. The cross-entropy (CE) loss function is:</p><formula xml:id="formula_2">CE (w; E) = E p(ˆ e|f ) [− log(q(ˆ e|f )]<label>(3)</label></formula><p>It turns out that if p is simply the posterior distribu- tion of the metric, then this loss is related to the log of the standard EE loss: 5</p><formula xml:id="formula_3">EE (w; E) = − log[E p(ˆ e|f ) [q(ˆ e|f )]]<label>(4)</label></formula><p>We can show that CE ≥ EE by applying Jensen's inequality to the function − log(·). So minimizing CE also minimizes a convex upper bound of the log expected error. This convexity given the n-best list does not mean that the overall MT tuning loss is convex, since the n-best list contents and order depend on the parameters w. However, all regret bounds and other guarantees of online con- vex optimization would now apply in the CE case since CE,t (w t−1 ; E t ) is convex for each t. This is attractive compared to expected error, which is non-convex even given the n-best list. We empiri- cally observed that CE converges faster and is less sensitive to hyperparameters than EE.</p><p>Faster decoding trick We found that online tun- ing also permits a trick that speeds up decoding during deployment. Whereas the Phrasal default beam size is 1,200, we were able to reduce the beam size to 800 and run the tuner longer to achieve the same level of translation quality. For example, at the default beam size for French-English, the algo- rithm converges after 12 iterations, whereas at the lower beam size it achieves that level after 20 itera- tions. In our experience, batch tuning algorithms seem to be more sensitive to the beam size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Feature Templates</head><p>The baseline system contains 19 dense feature tem- plates: the nine Moses ( <ref type="bibr" target="#b29">Koehn et al., 2007</ref>) baseline features, the eight-feature hierarchical lexicalized re-ordering model of <ref type="bibr" target="#b20">Galley and Manning (2008)</ref>, the (log) count of each rule in the bitext, and an indicator for unique rules. We found that sparse features, while improving translation quality, came at the cost of slower decoding due to feature extrac- tion and inner products with a higher dimensional feature map φ. During prototyping, we observed that users found the system to be sluggish unless it responded in approximately 300ms or less. This budget restricted us to dense features.</p><p>When re-tuning to corrections, we extract fea- tures from the user logs u and add them to the baseline dense model. For each tuning input f , the MT system produces candidate derivations d = (f, ˆ e, a), where a is a word alignment. The user log u also contains the last MT derivation 6 accepted by the user d u = (f, ˆ e u , a u ). We extract features by comparing d and d u . The heuristic we take is intersection:</p><formula xml:id="formula_4">φ(d) ← φ(d) ∩ φ(d u ).</formula><p>Lexicalized and class-based alignments Con- sider the alignment in <ref type="figure" target="#fig_2">Figure 3</ref>. We find that user derivations often contain many unigram rules, <ref type="bibr">6</ref> Extracting features from intermediate user editing actions is an interesting direction for future work. which are less powerful than larger phrases, but nonetheless provide high-precision lexical choice information. We fire indicators for both unigram links and multiword cliques. We also fire class- based versions of this feature.</p><p>Source OOV blanket Source OOVs are usually more frequent when adapting to a new domain. In the case of European languages-our experimental setting-many of the words simply transfer to the target, so the issue is where to position them. In <ref type="figure" target="#fig_2">Fig- ure 3</ref>, the proper noun tarceva is unknown, so the de- coder OOV model generates an identity translation rule. We add features in which the source word is concatenated with the left, right, and left/right con- texts in the target, e.g., {&lt;s&gt;-tarceva, tarceva- was, &lt;s&gt;-tarceva-was}. We also add versions with target words mapped to classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Differences from Previous Work</head><p>Our backend innovations support the UI and enable feature-based learning from human corrections. In contrast, most previous work on incremental MT learning has focused on extracting new translation rules, language model updating, and modifying translation model probabilities (see: <ref type="bibr" target="#b14">Denkowski et al. (2014a)</ref>). We regard these features as ad- ditive to our own work: certainly extracting new, unseen rules should help translation in a new do- main. Moreover, to our knowledge, all previous work on updating the weight vector w has consid- ered simulated post-editing, in which the indepen- dent references e are substituted for corrections h. Here we extract features from and re-tune to actual corrections to the baseline MT output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Translation User Study</head><p>We conducted a human translation experiment with a 2 (translation conditions) × n (source sentences) mixed design, where n depended on the language pair. Translation conditions (post-edit and interac- tive) and source sentences were the independent variables (factors). Experimental subjects saw all factor levels, but not all combinations, since one exposure to a sentence would influence another.</p><p>Subjects completed the experiment remotely on their own hardware. They received personalized login credentials for the translation interface, which administered the experiment. Subjects first com- pleted a demographic questionnaire about prior ex- perience with CAT and language proficiency. Next, they completed a training module that included a 4-minute tutorial video and a practice "sandbox" for developing proficiency with the UI. Then subjects completed the translation experiment. Finally, they completed an exit questionnaire.</p><p>Unlike the experiment of Koehn (2009a), sub- jects were under time pressure. An idle timer pre- vented subjects from pausing for more than three minutes while the translator interface was open. This constraint eliminates a source of confound in the timing analysis.</p><p>We randomized the order of translation condi- tions and the assignment of sentences to conditions. At most five sentences appeared per screen, and those sentences appeared in the source document order. Subjects could move among sentences within a screen, but could not revise previous screens. Sub- jects received untimed breaks both between trans- lation conditions and after about every five screens within a translation condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Linguistic Materials</head><p>We chose two language pairs: French-English (Fr- En) and English-German (En-De). Anecdotally, French-English is an easy language pair for MT, whereas English-German is very hard due to re- ordering and complex German morphology.</p><p>We chose three text genres: software, medical, and informal news. The software text came from the graphical interfaces of Autodesk AutoCAD and Adobe Photoshop. The medical text was a drug re- view from the European Medicines Agency. These two data sets came from TAUS 7 and included inde- pendent reference translations. The informal news text came from the WMT 2013 shared task test set ( <ref type="bibr" target="#b6">Bojar et al., 2013</ref>). The evaluation corpus was con- structed from equal proportions of the three genres.</p><p>The Fr-En dataset contained 3,003 source tokens (150 segments); the En-De dataset contained 3,002 (173 segments). As a rule of thumb, a human trans- lator averages about 2,700 source tokens per day <ref type="bibr">(Ray, 2013, p.36)</ref>, so the experiment was designed to replicate a slightly demanding work day.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Selection of Subjects</head><p>For each language pair, we recruited 16 profes- sional, freelance translators on Proz, which is the largest online translation community. <ref type="bibr">8</ref> We posted ads for both language pairs at a fixed rate of $0.085 per source word, an average rate in the industry. In addition, we paid $10 to each translator for complet- ing the training module. All subjects had significant prior experience with a CAT workbench.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>We analyze the translation conditions in terms of two response variables: time and quality. We ex- cluded one Fr-En subject and two En-De subjects from the models. One subject misunderstood the in- structions of the experiment and proceeded without clarification; another skipped the training module entirely. The third subject had a technical problem that prevented logging. Finally, we also filtered segment-level sessions for which the log of transla- tion time was greater than 2.5 standard deviations from the mean.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Translation Time</head><p>We analyze time with a linear mixed effects model (LMEM) estimated with the lme4 (Bates, 2007) R package. When experimental factors are sampled from larger populations-e.g., humans, sentences, words-LMEMs are more robust to type II errors (see: <ref type="bibr" target="#b1">Baayen et al. (2008)</ref>). The log-transformed time is the response variable and translation condi- tion is the main independent variable. The maximal random effects structure ( <ref type="bibr" target="#b3">Barr et al., 2013</ref>) contains intercepts for subject, sentence id, and text genre, each with random slopes for translation condition.</p><p>We found significant main effects for translation condition (Fr-En, p &lt; 0.05; En-De, p &lt; 0.01). The orientation of the coefficients indicates that interactive is slower for both language pairs. For Fr- En, the LMEM predicts a mean time (intercept) of 46.0 sec/sentence in post-edit vs. 54.6 sec/sentence We found other predictive covariates that reveal more about translator behavior. When subjects did not edit the MT suggestion, they were significantly faster. When token edit distance from MT or source input length increased, they were slower. Subjects were usually faster as the experiment progressed, a result that may indicate increased proficiency with practice. Note that all subjects reported profes- sional familiarity with post-edit, whereas the in- teractive mode was entirely new to them. In the exit survey many translators suggested that with more practice, they could have been as fast in the interactive mode. 9</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fr-En</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>En-De TER HTER TER HTER</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Translation Quality</head><p>We evaluated translation quality with both auto- matic and manual measures. <ref type="table">Table 1</ref> shows that in the interactive mode, TER is lower and HTER is higher: subjects created translations closer to the references (lower TER), but performed more editing (higher HTER). This result suggests better translations in the interactive mode.</p><p>To confirm that intuition, we elicited judgments from professional human raters. The setup followed the manual quality evaluation of the WMT 2014 shared task ( <ref type="bibr" target="#b7">Bojar et al., 2014</ref>). We hired six raters- three for each language pair-who were paid be- tween $15-20 per hour. The raters logged into Ap- praise <ref type="bibr" target="#b18">(Federmann, 2010)</ref> and for each source seg- ment, ranked five randomly selected translations. From these 5-way rankings we extracted pairwise judgments π = {&lt;, =}, where u 1 &lt; u 2 indicates that subject u 1 provided a better translation than subject u 2 for a given source input <ref type="table" target="#tab_1">(Table 2)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fr-En</head><p>En- <ref type="table" target="#tab_1">De  #pairwise  14,211  15,001  #ties (=)</ref> 5,528 2,964 IAA 0.419 <ref type="bibr">(0.357)</ref> 0.407 (0.427) EW (inter.) 0.512 0.491  <ref type="table">Table 3</ref>: LMEM manual translation quality results for each fixed effect with contrast conditions for binary predictors in (). The signs of the coefficients can be interpreted as in ordinary regression. edit distance is token-level edit distance from baseline MT. session order is the order in which the subject translated the sentence during the experiment. Sta- tistical significance was computed with a likelihood ratio test: ••• p &lt; 0.001; • p &lt; 0.05.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fr-En En-De</head><formula xml:id="formula_5">sign p sign p ui (interactive) + • − log edit distance − ••• + ••• gender (female) − + • log session order − + •</formula><p>In WMT the objective is to rank individual sys- tems; here we need only compare interface condi- tions. However, we should control for translator variability. Therefore, we build a binomial LMEM for quality. The model is motivated by the simple and intuitive expected wins (EW) measure used at WMT. Let S be the set of pairwise judgments and wins(u 1 , u 2 ) = |{(u 1 , u 2 , π) ∈ S | π = &lt;}|. The standard EW measure is: <ref type="bibr" target="#b46">Sakaguchi et al. (2014)</ref> showed that, despite its sim- plicity, Eq. (5) is nearly as effective as model-based methods given sufficient high-quality judgments. Since we care only about the two translation condi- tions, we reinterpret the u i as interface conditions, i.e., u 1 = int and u 2 = pe. We can then disregard the normalizing term to obtain:</p><formula xml:id="formula_6">e(u 1 ) = 1 |S| u 1 =u 2 wins(u 1 , u 2 ) wins(u 1 , u 2 ) + wins(u 2 , u 1 ) (5)</formula><formula xml:id="formula_7">e(u 1 ) = wins(u 1 , u 2 ) wins(u 1 , u 2 ) + wins(u 2 , u 1 )<label>(6)</label></formula><p>which is the expected value of a Bernoulli distribu- tion (so e(u 2 ) = 1 − e(u 1 )). The intercept-term of the binomial LMEM will be approximately this value subject to other fixed and random effects. To estimate the model, we convert each pairwise judgment u 1 &lt; u 2 to two examples where the re- sponse is 1 for u 1 and 0 for u 2 . We add the fixed effects shown in <ref type="table">Table 3</ref>, where the numeric effects are centered and scaled by their standard deviations. The maximal random effects structure contains in- tercepts for sentence id nested within subject along with random slopes for interface condition. <ref type="table">Table 3</ref> shows the p-values and coefficient orien- tations. The models yield probabilities that can be interpreted like Eq. (6) but with all fixed predictors set to 0. For Fr-En, the value for post-edit is 0.472 vs. 0.527 for interactive. For En-De, post-edit is 0.474 vs. 0.467 for interactive. The difference is statistically significant for Fr-En, but not for En-De.</p><p>When MT quality was anecdotally high (Fr-En), high token-level edit distance from the initial sug- gestion decreased quality. When MT was poor (En- De), significant editing improved quality. Female En-De translators were better than males, possibly due to imbalance in the subject pool (12 females vs. 4 males). En-De translators seemed to improve with practice (positive coefficient for session order).</p><p>The Fr-En results are the first showing an inter- active UI that improves over post-edit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">MT Re-tuning Experiment</head><p>The human translators corrected the output of the BLEU-tuned, baseline MT system. No updating of the MT system occurred during the experiment to eliminate a confound in the time and quality analy- ses. Now we investigate re-tuning the MT system to the corrections by simply re-starting the online learning algorithm from the baseline weight vector w, this time scoring with HTER instead of BLEU.</p><p>Conventional incremental MT learning experi- ments typically resemble domain adaptation: small- scale baselines are trained and tuned on mostly out- of-domain data, and then re-tuned incrementally on in-domain data. In contrast, we start with large- scale systems. This is more consistent with a pro- fessional translation environment where translators receive suggestions from state-of-the-art systems like Google Translate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bilingual Monolingual</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>#Segments #Tokens #Tokens</head><p>En-De 4.54M 224M 1.7B Fr-En 14.8M 842M 2.24B <ref type="table">Table 4</ref>: Gross statistics of MT training corpora.  <ref type="table">Table 5</ref>: Tuning, development, and test corpora (#segments). tune and dev were used for baseline system preparation. Re-tuning was performed on int-tune and pe-tune, respectively. We report held- out results on the two test data sets. All sets are supplied with independent references. <ref type="table">Table 4</ref> shows the monolingual and parallel train- ing corpora. Most of the data come from the con- strained track of the WMT 2013 shared task ( <ref type="bibr" target="#b6">Bojar et al., 2013</ref>). We also added 61k parallel segments of TAUS data to the En-De bitext, and 26k TAUS segments to the Fr-En bitext. We aligned the par- allel data with the Berkeley Aligner ( <ref type="bibr" target="#b34">Liang et al., 2006</ref>) and symmetrized the alignments with the grow-diag heuristic. For each target language we used lmplz <ref type="bibr" target="#b26">(Heafield et al., 2013</ref>) to estimate unfil- tered, 5-gram Kneser-Ney LMs from the concate- nation of the target side of the bitext and the mono- lingual data. For the class-based features, we esti- mated 512-class source and target mappings with the algorithm of <ref type="bibr" target="#b23">Green et al. (2014a)</ref>. The upper part of <ref type="table">Table 5</ref> shows the baseline tuning and development sets, which also contained 1/3 TAUS medical text, 1/3 TAUS software text, and 1/3 WMT newswire text (see section 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>En-De Fr-En</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>The lower part of <ref type="table">Table 5</ref> shows the organization of the human corrections for re-tuning and testing. Recall that for each unique source input, eight hu- man translators produced a correction in each con- dition. First, we filtered all corrections for which a log u was not recorded (due to technical problems). Second, we de-duplicated the corrections so that each h was unique. Finally, we split the unique (f, h) tuples according to a natural division in the  <ref type="table">Table 6</ref>: Main re-tuning results for interactive data. baseline is the BLEU-tuned system used in the translation user study. re-tune is the base- line feature set re-tuned to HTER on int-tune. re- tune+feat adds the human feature templates de- scribed in section 3.3. bold indicates statistical significance relative to the baseline at p &lt; 0.001; italic at p &lt; 0.05 by the permutation test of <ref type="bibr" target="#b45">Riezler and Maxwell (2005)</ref>.</p><p>data. There were five source segments per docu- ment, and each document was rendered as a single screen during the translation experiment. Segment order was not randomized, so we could split the data as follows: assign the first three segments of each screen to tune, and the last two to test. This is a clean split with no overlap. This tune/test split has two attractive properties. First, if we can quickly re-tune on the first few sen- tences on a screen and provide better translations for the last few, then presumably the user experience improves. Second, source inputs f are repeated- eight translators translated each input in each condi- tion. This means that a reduction in HTER means better average suggestions for multiple human trans- lators. Contrast this experimental design with tun- ing to the corrections of a single human translator. There the system might overfit to one human style, and may not generalize to other human translators. <ref type="table">Table 6</ref> contains the main results for re-tuning to in- teractive MT corrections. For both language pairs, we observe large statistically significant reductions in HTER. However, the results for BLEU and TER- which are computed with respect to the independent references-are mixed. The lower En-De BLEU score is explained by a higher brevity penalty for the re-tuned output (0.918 vs. 0.862). However, the re-tuned 4-gram and 3-gram precisions are signif-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head><p>HTER↓ System HTER↓ int pe baseline 44.05 baseline 41.05 re-tune (int) 43.99 re-tune (pe) 40.34 re-tune+feat 42.35 - - ∆ −1.80 −0.71 <ref type="table">Table 7</ref>: En-De test results for re-tuning to post-edit (pe) vs. interactive (int). Features cannot be ex- tracted from the post-edit data, so the re-tune+feat system cannot be learned. The Fr-En results are similar but are omitted due to space.</p><p>icantly higher. The unchanged Fr-En TER value can be explained by the observation that no human translators produced TER scores higher than the baseline MT. This odd result has also been observed for BLEU <ref type="bibr" target="#b12">(Culy and Riehemann, 2003)</ref>, although here we do observe a slight BLEU improvement. The additional features (854 for Fr-En; 847 for En-De) help significantly and do not slow down decoding. We used the same L 1 regularization strength as the baseline, but feature growth could be further constrained by increasing this parame- ter. Tuning is very fast at about six minutes for the whole dataset, so tuning during a live user session is already practical. <ref type="table">Table 7</ref> compares re-tuning to interactive vs. post-edit corrections. Recall that the int-test and pe-test datasets are different and contain different references. The post-edit baseline is lower because humans performed less editing in the baseline con- dition (see <ref type="table">Table 1</ref>). Features account for the great- est reduction in HTER. Of course, the features are based mostly on word alignments, which could be obtained for the post-edit data by running an online word alignment tool (see: <ref type="bibr" target="#b17">Farajian et al. (2014)</ref>). However, the interactive logs contain much richer user state information that we could not exploit due to data sparsity. We also hypothesize that the fi- nal interactive corrections might be more useful since suggestions prime translators ( <ref type="bibr" target="#b21">Green et al., 2013a)</ref>, and the MT system was able to refine its suggestions. <ref type="table">Tables 6 and 7</ref> raise two natural questions: what accounts for the reduction in HTER, and why are the TER/BLEU results mixed? Comparison of the BLEU-tuned baseline to the HTER re-tuned sys- tems gives some insight. For both questions, fine-grained corrections appear to make the difference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Re-tuning Analysis</head><p>Consider this French test example (with gloss):</p><p>( <ref type="table">1)  une  one  ligne  line  de  of  chimiothérapie  chemotherapy  antérieure  previous</ref> The independent reference for une ligne de chimio- thérapie is 'previous chemotherapy treatment', and the baseline produces 'previous chemotherapy line.'</p><p>The source sentence appears seven times with the following user translations: 'one line or more of chemotherapy', 'one prior line of chemother- apy', 'one previous line of chemotherapy' (2), 'one line of chemotherapy before' (2), 'one protocol of chemotherapy'. The re-tuned, feature-based sys- tem produces 'one line of chemotherapy before', matching two of the humans exactly, and six of the humans in terms of idiomatic medical jargon ('line of chemotherapy' vs. 'chemotherapy treatment'). However, the baseline output would have received better BLEU and TER scores. Sometimes re-tuning improves the translations with respect to both the reference and the human corrections. This English phrase appears in the En-De test set:</p><p>(2) depending abhängig on von the der file datei</p><p>The baseline produces exactly the gloss shown in Ex.</p><p>(2). The human translators produced: 'je nach datei' (6), 'das dokument', and 'abhängig von der datei'. The re-tuned system rendered the phrase 'je nach dokument', which is closer to both the independent reference 'je nach datei' and the human corrections. This change improves TER, BLEU, and HTER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Work</head><p>The process study most similar to ours is that of <ref type="bibr" target="#b30">Koehn (2009a)</ref>, who compared scratch, post-edit, and simple interactive modes. However, he used un- dergraduate, non-professional subjects, and did not consider re-tuning. Our experimental design with professional bilingual translators follows our previ- ous work <ref type="bibr" target="#b21">Green et al. (2013a)</ref> comparing scratch translation to post-edit. Many research translation UIs have been pro- posed including TransType ( <ref type="bibr" target="#b33">Langlais et al., 2000</ref>), Caitra <ref type="bibr" target="#b31">(Koehn, 2009b)</ref>, Thot (Ortiz- <ref type="bibr" target="#b40">Martínez and Casacuberta, 2014</ref>), <ref type="bibr">TransCenter (Denkowski et al., 2014b)</ref>, and CasmaCat ( <ref type="bibr" target="#b0">Alabau et al., 2013)</ref>. However, to our knowledge, none of these inter- faces were explicitly designed according to mixed- initiative principles from the HCI literature.</p><p>Incremental MT learning has been investigated several times, usually starting from no data ( <ref type="bibr" target="#b4">Barrachina et al., 2009;</ref><ref type="bibr" target="#b42">Ortiz-Martínez et al., 2010)</ref>, via simulated post-editing ( <ref type="bibr" target="#b36">Martínez-Gómez et al., 2012;</ref><ref type="bibr" target="#b14">Denkowski et al., 2014a</ref>), or via re-ranking ( <ref type="bibr">Wäschle et al., 2013)</ref>. No previous experiments combined large-scale baselines, full re-tuning of the model weights, and HTER optimization.</p><p>HTER tuning can be simulated by re- parameterizing an existing metric. <ref type="bibr" target="#b49">Snover et al. (2009)</ref> tuned TERp to correlate with HTER, while <ref type="bibr" target="#b13">Denkowski and Lavie (2010)</ref> did the same for METEOR. <ref type="bibr" target="#b51">Zaidan and Callison-Burch (2010)</ref> showed how to solicit MT corrections for HTER from Amazon Mechanical Turk.</p><p>Our learning approach is related to coactive learn- ing <ref type="bibr" target="#b47">(Shivaswamy and Joachims, 2012)</ref>. Their basic preference perceptron updates toward a correction, whereas we use the correction for metric scoring and feature extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We presented a new CAT interface that supports post-edit and interactive modes. Evaluation with professional, bilingual translators showed post-edit to be faster, but prior subject familiarity with post- edit may have mattered. For French-English, the interactive mode enabled higher quality translation. Re-tuning the MT system to interactive corrections also yielded large HTER gains. Technical contri- butions that make re-tuning possible are a cross- entropy objective, prefix decoding, and dynamic phrase table augmentation. Larger quantities of cor- rections should yield further gains, but our current experiments already establish the feasibility of Bar- Hillel's virtuous "machine-post-editor partnership" which benefits both humans and machines.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Main translation interface. The user sees the full document context, with French source inputs (A) interleaved with suggested English translations (B). The sentence in focus is indicated by the blue rectangle, which can be moved via two hot keys. Source coverage (C) of the user prefix-shaded in blue-updates as the user works, as do autocomplete suggestions (D) and a full completion (E).</figDesc><graphic url="image-1.png" coords="2,134.24,62.81,331.80,207.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Source word lookup and target autocomplete menus. The menus show different suggestions. The word lookup menu (top) is not dependent on the target context Teachers, whereas the autocomplete dropdown (bottom) is.</figDesc><graphic url="image-2.png" coords="3,99.25,62.81,166.50,127.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: User translation word alignment obtained via prefix decoding and dynamic phrase table augmentation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>post-edit 47.32 23.51 56.16 37.15 interactive 47.05 24.14 55.89 39.55 Table 1: Automatic assessment of translation qual- ity. Here we change the definitions of TER and HTER slightly. TER is the human translations com- pared to the independent references. HTER is the baseline MT compared to the human corrections. in interactive, or 18.7% slower. For En-De, the mean is 51.8 sec/sentence vs. 63.3 sec/sentence in interactive, or 22.1% slower.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Pairwise judgments for the manual qual-
ity assessment. Inter-annotator agreement (IAA) 
κ scores are measured with the official WMT14 
script. For comparison, the WMT14 IAA scores 
are given in parentheses. EW (inter.) is expected 
wins of interactive according to Eq. (6). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>42.35 (a) En-De int-test results.</head><label></label><figDesc></figDesc><table>System 

tune 
BLEU↑ TER↓ HTER 
baseline 
bleu 
23.12 60.29 44.05 
re-tune 
hter 
22.18 60.85 43.99 
re-tune+feat hter 
21.73 59.71 System 
tune 
BLEU↑ TER↓ HTER 
baseline 
bleu 
39.33 45.29 28.28 
re-tune 
hter 
39.99 45.73 26.96 
re-tune+feat hter 
40.30 45.28 26.40 

(b) Fr-En int-test results. 

</table></figure>

			<note place="foot" n="1"> The classic TransType system included a probabilistic prediction length component (Foster et al., 2002), but we find that the simpler projection technique works well in practice.</note>

			<note place="foot" n="2"> Och et al. (2003) describe a similar algorithm for word graphs. 3 Ortiz-Martínez et al. (2009) describe a related technique in which all source and target words can align, with scores set by smoothing.</note>

			<note place="foot" n="4"> Discounted cumulative gain (DCG) is widely used in information retrieval learning-to-rank settings. n-best MT learning is standardly formulated as a ranking task. 5 For expected error, p(ˆ ei) = G(e, ˆ ei) is not usually normalized. Normalizing p adds a negligible constant.</note>

			<note place="foot">t a r c e v a w a s t h u s a b l e t o h a l t t h e g r o w t h</note>

			<note place="foot" n="7"> http://www.tausdata.org/</note>

			<note place="foot" n="8"> http://www.proz.com</note>

			<note place="foot" n="9"> See (Green et al., 2014c) for significance levels of the other covariates along with analysis of subject learning rates, subject behavior, and qualitative feedback.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank TAUS for access to their data reposi-tory. We also thank John DeNero, Chris Dyer, Alon Lavie, and Matt Post for helpful conversa-tions. The first author is supported by a National Science Foundation Graduate Research Fellowship. This work was also supported by the Defense Ad-</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Advanced computer aided translation with a web-based workbench</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Alabau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bonk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Casacuberta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>García-Martínez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd Workshop on Post-Editing Technologies and Practice</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Mixed-effects modeling with crossed random effects for subjects and items</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Baayen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Bates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="390" to="412" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The present status of automatic translation of languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Computers</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="91" to="163" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Random effects structure for confirmatory hypothesis testing: Keep it maximal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Scheepers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Tily</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="255" to="278" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Statistical approaches to computer-assisted translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Barrachina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Casacuberta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Civera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cubel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khadivi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="28" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">lme4: Linear mixedeffects models using S4 classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Bates</surname></persName>
		</author>
		<ptr target="http://cran.r-project.org/package=lme4" />
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
	<note>R package version 1.1-5</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<title level="m">Findings of the 2013 Workshop on Statistical Machine Translation</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>WMT</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leveling</surname></persName>
		</author>
		<title level="m">Findings of the 2014 Workshop on Statistical Machine Translation</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>WMT</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Re-evaluating the role of BLEU in machine translation research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A computational framework for a cognitive model of human translation processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Aslib Translating and the Computer Conference</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The best lexical metric for phrase-based statistical MT system optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Batch tuning strategies for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The limits of ngram translation evaluation metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Culy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Riehemann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<pubPlace>In MT Summit IX</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Extending the METEOR machine translation evaluation metric to the phrase level</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning from post-editing: Online model adaptation for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Real time adaptive machine translation for post-editing with cdec and TransCenter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lacruz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Humans and Computer-assisted Translation</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Online word alignment for online adaptive machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Farajian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Humans and Computerassisted Translation</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Appraise: An open-source toolkit for manual phrase-based evaluation of translations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Federmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Userfriendly text prediction for translators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Langlais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lapalme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A simple and effective hierarchical phrase reordering model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The efficacy of human post-editing for language translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fast and adaptive online training of feature-rich translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An empirical comparison of features and tuning for phrasebased machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WMT</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Phrasal: A toolkit for new directions in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WMT</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Predictive Translation Memory: A mixed-initiative system for human language translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UIST</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Scalable modified Kneser-Ney language model estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Pouzyrevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<editor>ACL, Short Papers</editor>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Forest rescoring: Faster decoding with integrated language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Evaluating translational correspondence using annotation projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Resnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Weinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kolak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bertoldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL, Demonstration Session</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A process study of computer-aided translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Translation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="241" to="263" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A web-based interactive computer aided translation tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL-IJCNLP, Software Demonstrations</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">TransType: a computer-aided translation typing system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Langlais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lapalme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Embedded Machine Translation Systems</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Alignment by agreement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL, System Demonstrations</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Online adaptation strategies for statistical machine translation in post-editing scenarios</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Martínez-Gómez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sanchis-Trilles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Casacuberta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3193" to="3203" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The alignment template approach to statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="417" to="449" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Efficient search for interactive statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Minimum error rate training for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The new Thot toolkit for fully automatic and interactive statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ortiz-Martínez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Casacuberta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL, System Demonstrations</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Interactive machine translation based on partial statistical phrase-based alignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ortiz-Martínez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>García-Varea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Casacuberta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RANLP</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Online learning for interactive statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ortiz-Martínez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>García-Varea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Casacuberta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Ten essential research findings for 2013</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Resource Directory &amp; Index. Multilingual</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">On some pitfalls in automatic evaluation and significance testing in MT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riezler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Maxwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Efficient elicitation of annotations for human evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WMT</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Online structured prediction via coactive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shivaswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A study of translation edit rate with targeted human annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Micciulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AMTA</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Fluency, adequacy, or HTER? Exploring different human judgments with a tunable MT metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Madnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WMT</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Generative and discriminative methods for online adaptation in SMT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wäschle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Simianer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riezler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MT Summit XIV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Predicting human-targeted translation edit rate via untrained human annotators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">F</forename><surname>Zaidan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
