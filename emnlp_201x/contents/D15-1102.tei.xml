<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Joint Mention Extraction and Classification with Mention Hypergraphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
							<email>luwei@sutd.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
							<email>danr@illinois.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Joint Mention Extraction and Classification with Mention Hypergraphs</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a novel model for the task of joint mention extraction and classification. Unlike existing approaches, our model is able to effectively capture overlapping mentions with unbounded lengths. The model is highly scalable, with a time complexity that is linear in the number of words in the input sentence and linear in the number of possible mention classes. Our model can be extended to additionally capture mention heads explicitly in a joint manner under the same time complexity. We demonstrate the effectiveness of our model through extensive experiments on standard datasets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>One of the essential goals in natural language pro- cessing (NLP) is the development of effective sys- tems that can capture the underlying semantics conveyed by human languages. An important step towards such a goal is the development of practi- cal systems that can efficiently extract useful shal- low semantic information such as entities and at the same time identify their semantic classes (e.g., person, organization, etc).</p><p>Such a task is often known as named entity recognition and classification (NERC), one of the standard tasks in information extraction (IE). While such a task focuses on the extraction and classification of entities in the texts which are named, recently researchers also showed inter- est in a closely related task -mention extraction and classification/typing. Unlike a named entity, a mention is typically defined as a reference to an entity in natural language text that can be ei- ther named, nominal or pronominal ( <ref type="bibr" target="#b12">Florian et al., 2004</ref>). The task of mention detection and track- ing has received substantial attention, largely due to its important role in conducting several down- stream tasks, such as relation extraction <ref type="bibr" target="#b22">(Mintz et al., 2009)</ref>, entity linking ( <ref type="bibr" target="#b13">Guo et al., 2013)</ref>, and coreference resolution ( .</p><p>While most existing work on named entity recognition and mention extraction and classifi- cation have been effective, there remain several key limitations associated with existing models. In fact, one can view these problems as instances of the more general problem of semantic tagging - the task of assigning appropriate semantic tags to certain text spans for a given input sentence. Un- like part-of-speech (POS) tagging, which has been extensively studied in the past few decades by the community, such a semantic tagging task presents several additional new challenges. First, a men- tion can consist of multiple words, so its length can be arbitrarily long. Second, the mentions can overlap with one another. Popular models used for POS tagging, such as linear-chain conditional ran- dom fields ( <ref type="bibr" target="#b16">Lafferty et al., 2001</ref>) or semi-Markov conditional random fields ( <ref type="bibr" target="#b30">Sarawagi and Cohen, 2004</ref>) have difficulties coping with these issues. While approaches on addressing these issues ex- ist, current algorithms typically suffer from high time complexity <ref type="bibr" target="#b10">(Finkel and Manning, 2009)</ref> and are therefore difficult to scale to large datasets. On the other hand, the problem of designing ef- ficient and scalable models for mention extraction and classification from natural language texts be- comes increasingly important in this era where a large volume of textual data is becoming available on the Web every day -users need systems which are able to scale to extremely large datasets to sup- port efficient semantic analysis for timely decison- making.</p><p>In this paper, we tackle the above-mentioned is- sue by introducing a novel model for joint mention extraction and classification. We make the follow- ing major contributions in this work:</p><p>• We propose a model that is able to effectively handle overlapping mentions with unbounded lengths.</p><p>• The learning and inference algorithms of our proposed model have a time complexity that is linear in the number of words in the input sen- tence and also linear in the number of possi- ble semantic classes/types, making our model scalable to extremely large datasets.</p><p>• Our model can additionally capture mentions' head information in a joint manner under the same time complexity.</p><p>Our system and code are available for download from http://statnlp.org/research/ie/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Existing work has been largely focused on the task of named entity recognition and classifica- tion (NERC). The survey of ( <ref type="bibr" target="#b23">Nadeau and Sekine, 2007</ref>) is a comprehensive study of this topic.</p><p>Most prior work took a supervised learning ap- proach. Zhou and Su (2002) presented a system for recognizing named entities using an HMM- based approach. <ref type="bibr" target="#b11">Florian et al. (2003)</ref> presented a system for named entity recognition by combining different classifiers. <ref type="bibr" target="#b21">McDonald and Pereira (2005)</ref> used conditional random fields for extracting gene and protein mentions from biomedical texts. <ref type="bibr" target="#b28">Ratinov and Roth (2009)</ref> presented a systematic anal- ysis over several issues related to the design of a named entity recognition and classification system where issues such as chunk representations and the choice of inference algorithms were discussed. Researchers also looked into semi-supervised and unsupervised approaches for such a task <ref type="bibr" target="#b7">(Cucchiarelli and Velardi, 2001;</ref><ref type="bibr" target="#b9">Etzioni et al., 2005</ref>). Additional efforts on addressing the NERC prob- lem under a multilingual or cross lingual setting also exist ( <ref type="bibr" target="#b12">Florian et al., 2004;</ref>).</p><p>As pointed out by <ref type="bibr" target="#b10">Finkel and Manning (2009)</ref>, named entities are often nested. This fact was of- ten ignored by the community largely due to tech- nical reasons. They therefore proposed to use a constituency parser with a O(n 3 ) time complexity (n is the number of words in the input sentence) to handle nested entities, and showed its effective- ness across several datasets. <ref type="bibr" target="#b0">Alex et al. (2007)</ref> also presented several approaches by building models on top of linear-chain conditional random fields for recognizing nested entities in biomedical texts. <ref type="bibr" target="#b14">Hoffmann et al. (2011)</ref> looked into a separate issue, which is to identify overlapping relations amongst entities.</p><p>Named entity recognition and classification still remains a popular topic in the field of statistical natural language processing. <ref type="bibr" target="#b29">Ritter et al. (2011)</ref> looked into recognizing entities from social me- dia data that involves informal and potentially noisy texts. <ref type="bibr" target="#b26">Pasupat and Liang (2014)</ref> looked into the issue of zero-shot entity extraction from Web pages with natural language queries where minimal supervision was used. <ref type="bibr" target="#b24">Neelakantan and Collins (2014)</ref> looked into the problem of auto- matically constructing dictionaries with minimal supervision for improved named entity extraction. <ref type="bibr" target="#b17">Li and Ji (2014)</ref> presented an approach to perform the task of extraction of mentions and their rela- tions in a joint and incremental manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Mentions and Their Combinations</head><p>Typically, a mention that appears in a natural lan- guage sentence consists of a contiguous sequence of natural language words. Consider a sentence that consists of n words where each word is in- dexed with its position in the sentence. A men- tion m can be uniquely represented with a tuple b m , e m , τ , where b m and e m are the indices of the first and last word of the mention, respectively, and τ is its semantic class (type).</p><p>We can see that for a given sentence consisting of n words, there are altogether tn(n + 1)/2 pos- sible different mention candidates, where t is the total number of possible mention types. Now, for each such candidate in the given sentence, it can be either a mention, or not a mention. This leads to a total number of 2 tn(n+1)/2 possible mention combinations. This number is prohibitively large even for small values of n and t, which prevents us from exhaustively enumerating all of them during learning and inference.</p><p>One approach to performing inference over such a large space is to introduce compact rep- resentations that are able to encode exponentially many mentions that would enable tractable infer- ence algorithms to be employed. We discuss in the next section our novel mention hypergraph repre- sentation proposed for such a purpose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Mention Hypergraphs</head><p>Central to our approach is the introduction of the novel mention hypergraphs that allow us to   Links that belong to the same hyperedge are highlighted with the same color, and different hyperedges are highlighted with different col- ors, e.g., the green link that connects two I nodes forms a single hyperedge, while the two brown links that connect two I nodes and one X node form a separate single hyperedge.</p><p>compactly represent exponentially many possible combinations of potentially overlapping, length- unbounded mentions of different types.</p><p>A hypergraph is a generalization of a conven- tional graph, whose edges (a.k.a. hyperedges) can connect two or more nodes. In this work, we con- sider a special class of hypergraphs, where each hyperedge consists of a designated parent node and an ordered list of child nodes. Hypergraphs have also been used in other fields, such as syntac- tic parsing <ref type="bibr" target="#b15">(Klein and Manning, 2001</ref>), semantic parsing (Lu, 2015) and machine translation <ref type="bibr" target="#b6">(Cmejrek et al., 2013</ref>).</p><p>Our mention hypergraphs consist of five types of nodes which are used to compactly represent many mentions of different semantic types and boundaries, namely, A nodes, E nodes, T nodes, I nodes, and X nodes. A partial mention hypergraph is depicted in <ref type="figure" target="#fig_2">Figure 1</ref>. We describe the definition of each type of nodes next.</p><p>• A nodes. These nodes are used to sequentially arrange mentions with different left bound- aries. Specifically, each A node at position k (the k-th word), or A k , is used to com- pactly represent all such mentions in the sen- tence whose left boundaries are exactly at or strictly after k.</p><p>• E nodes. The node E k is used to compactly represent all possible mentions (possibly of length zero) whose left boundaries are exactly at the current position k.</p><p>• T nodes. The node T k j is used to compactly represent all mentions (possibly of length zero) whose left boundaries are exactly at po- sition k, and have the mention type j.</p><p>• I nodes. The node I k j is used to compactly represent all incomplete mentions which con- tain the current word at position k as part of the mention, and have the mention type j.</p><p>• X nodes. These are the "terminal" nodes indi- cating the completion of a path. No additional node will be attached to such nodes as a child.</p><p>There are also various hyperedges that con- nect different nodes in the mention hypergraph. We use α ← β 1 , . . . , β n to denote a hyperedge which connects a parent node α and child nodes β 1 , . . . , β n . Each hyperedge essentially provides one possible way of re-expressing the semantics conveyed by the parent node using the child nodes. For example, as shown in <ref type="figure" target="#fig_2">Figure 1</ref>, the hyperedge connecting the parent node A k and the child nodes E k , A k+1 explains the fact that any mention cov- ered by A k either has a left boundary that is "ex- actly at k" (E k ), or "exactly at or strictly after k + 1" (A k+1 ).</p><p>Similarly, for each I node, there exist 3 hyper- edges that connect it to other child nodes. The top hyperedge (in green) encodes the fact that the cur- rent word appears in the middle of a mention; the bottom hyperedge (in yellow) encodes the fact that the current word appears in a mention as the last word; the middle hyperedge (in brown) encodes the fact that both cases can occur at the same time (i.e., the current word belongs to multiple over- lapping mentions of the same type). We have the following theorem: Theorem 3.1 Any combination of mentions in a sentence can be represented with exactly one sub- hypergraph of the complete mention hypergraph.</p><p>Proof For each mention, there exists a unique path in the mention hypergraph to represent it. For any combination of mentions, there exist unique paths in the mention hypergraph to represent such a combination. These paths altogether form a unique sub-hypergraph of the original hypergraph.</p><p>For example, consider the following sentence: "he also talked with the egyptian president ." This sentence contains three mentions. The first is "he" with type PER, the second is "the egyptian pres- ident'' with type PER, and the third mention is "egyptian" with type GPE. <ref type="figure">Figure 2</ref> gives the sub- hypergraph structure showing how these mentions [PER]</p><p>[ PER ]</p><p>[GPE] <ref type="table" target="#tab_1">T2  T2  T2  T2  T2  T2  T2  T2   T1  T1  T1  T1  T1  T1  T1  T1   I2  I2  I2  I2</ref> I1 <ref type="figure">Figure 2</ref>: An example sub-hypergraph structure for jointly representing all the three mentions that appear in the sentence "He also talked with the Egyptian president ." For simplicity and the ease of illustration, we assume there are only two possible mention types: PER and GPE.</p><formula xml:id="formula_0">A A A A A A A A E E E E E E E E</formula><formula xml:id="formula_1">X X X X X X X X X X X X X X X X</formula><p>are jointly represented. The mention hypergraph defined over the input sentence contains exponen- tially many such sub-hypergraph structures.</p><p>We note that the converse of Theorem 3.1 is not true. In certain cases, it is possible for two differ- ent overlapping mention combinations to share the same mention hypergraph.</p><formula xml:id="formula_2">A B C D [ PER ]</formula><p>[ PER ]</p><p>[GPE] <ref type="table" target="#tab_1">T2  T2  T2  T2   T1  T1  T1  T1   I2  I2  I2  I2   I1</ref>  For example, consider a toy example sentence A B C D shown in <ref type="figure" target="#fig_4">Figure 3</ref>, both B C and A B C D are mentions of the same type PER (i.e. one is strictly contained by the other. We call such combinations type-I combinations). The above sub-hypergraph shows how to encode such a combination. How- ever, if both A B C and B C D are mentions of the same type PER (i.e., two mentions overlap but no one is contained by the other. We call such com- binations type-II combinations), such a combina- tion shares the same representation as the above sub-hypergraph. Note that such an ambiguity hap- pens only when two overlapping mentions have the same type, and one mention is strictly con- tained by the other and their boundaries are all dif- ferent. In practice, however, we found that in the two datasets that we used for evaluations, if two mentions overlap with one another, they almost al- ways form a type-I combination, and type-II com- binations are very rare. Empirically, as we will see later in our experiments, our model is effective in handling overlapping mentions.</p><formula xml:id="formula_3">A A A A E E E E</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Log-Linear Modeling</head><p>Following the conditional random fields ( <ref type="bibr" target="#b16">Lafferty et al., 2001</ref>), we adopted a log-linear approach for such a joint mention extraction and typing task. Specifically, for a given input sentence x, the prob- ability of predicting a possible output y (a mention sub-hypergraph that represents a particular combi- nation of mentions) is given as follows:</p><formula xml:id="formula_4">p(y|x) = exp(w T f (x, y)) y exp(w T f (x, y ))<label>(1)</label></formula><p>where f (x, y) is the feature vector defined over the input-output pair (x, y), and the weight vector w gives the parameters of the model. Our objective is to minimize the regularized negative joint log-likelihood of the dataset:</p><formula xml:id="formula_5">L(w) = i log y exp(w T f (x i , y )) − i w T f (x i , y i ) + λw T w<label>(2)</label></formula><p>where (x i , y i ) refers to the i-th training instance, and the last term is a L 2 regularization term with λ being a positive scalar (fixed to 0.01 in this work). The gradient of the above objective function is:</p><formula xml:id="formula_6">∂L(w) ∂w k = i E p(y |x i ) [f k (x i , y )] − i f k (x i , y i ) + 2λw k<label>(3)</label></formula><p>where w k is the weight of the k-th feature f k . We note that unlike many recent latent-variable approaches to structured prediction ( <ref type="bibr" target="#b27">Petrov and Klein, 2007;</ref><ref type="bibr" target="#b1">Blunsom et al., 2008)</ref>, we are able to represent each of our outputs y with a single fully- observed structure. Thus, our objective function essentially defines a standard regularized softmax regression model, and is therefore convex ( <ref type="bibr" target="#b2">Boyd and Vandenberghe, 2004)</ref>, where a global opti- mum can be found.</p><p>The objective function defined in Equation 2 can be optimized with standard gradient-based methods. We used L-BFGS ( <ref type="bibr" target="#b19">Liu and Nocedal, 1989)</ref> as our optimization method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Algorithms</head><p>In order to solve the optimization problem de- scribed above, one needs to compute the values of the gradient scores in Equation 3. Computa- tion of the second and third terms in this equa- tion is straightforward. The first term in Equa- tion 3 involves the computation of an expecta- tion of feature values over all possible mention combinations for a given input sentence. Follow- ing classic dynamic programming algorithms used in graphical models, we develop analogous effi- cient dynamic programming algorithms that work on hypergraphs and generalize the conventional forward-backward/inside-outside algorithm to ef- ficiently compute such values.</p><p>Time Complexity At each time step k, we need to compute scores for m I nodes, m T nodes, 1 E node, and 1 A node. Hence, the overall time com- plexity for our algorithm is in O(mn) (assuming computation of the feature scores at each node in- volves a constant time), where m is the total num- ber of possible mention types, and n is the total number of words in the given sentence. <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Features</head><p>The features that we use are inspired by the work of ( <ref type="bibr" target="#b3">Carreras et al., 2002</ref>). Specifically, we consider the following features defined over the inputs:</p><p>• Words (and POS tags, if available) that appear around the current word (with position infor- mation), with a window of size 3.</p><p>• Word n-grams (and POS n-grams, if available) that contain the current word (with position in- formation), for n = 2, 3, 4.</p><p>• Bag of words around the current word, with a window of size 5.</p><p>• Word pattern features 2 .</p><p>Note that these are the indicator functions de- fined over the inputs. The final set of features are defined over (x, y) tuples, which is obtained as a cross-product between the above indicator func- tions and the following indicator function:</p><p>• The type of the node (such as T or I).</p><p>In addition, we also introduce the following fea- ture defined over the output structure only:</p><p>• The number of such hyperedges that exactly connect one T node and one I node.</p><p>We call this feature mention penalty. This fea- ture learns a global preference of the number of mentions that should appear in any input sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Joint Modeling of Mention Heads</head><p>One additional assumption for the mention extrac- tion and typing task is that each mention comes with a head. A head is strictly a substring of the mention and provides important information about the mention. It is possible to extend our model to support joint modeling of mention heads, while still maintaining the same time complexity.</p><p>Due to space limitations, we could only give a relatively brief description of this extension in this section. The idea is to replace the I nodes with three different types of nodes, namely I j -B nodes (used to represent words that appear within a mention of type j and before its head), I j -W nodes (used to represent words that appear within the head of a mention of type j), and I j -A nodes (used to represent words that appear within a men- tion of type j and after its head). The hyperedges also need to be established accordingly in order to properly model all possible mention and head <ref type="table" target="#tab_1">ACE2004   ACE2005  TRAIN  DEV  TEST  TRAIN  DEV  TEST  Documents  356  41  46  370  43  51  Sentences  6,799  829  879  7,336  958</ref> 1,047 with o.l.  combinations. Since in such a new hypergraph, at each time step, only a constant number (2) of addi- tional nodes are involved, the time complexity for learning and inference with such a model remains the same, which is in O(mn).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>mentions 2,683 (39%) 293 (35%) 373 (42%) 2,683 (37%) 340 (35%) 330 (32%) Mentions 22,207 2,511 3,031 24,687 3,217 3,027 length &gt; 6 1,439 (6%) 179 (7%) 199 (7%) 1,343 (5%) 148 (5%) 160 (6%) max length</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Optimization of F measure</head><p>One standard evaluation metric for named entity recognition is the F (F 1 ) measure. In our task, the F measure is defined as the harmonic mean of the precision (P ) and recall (R) scores, where precision is the ratio between the number of cor- rectly predicted mentions and the total number of predicted mentions, and recall is the ratio between the number of correctly predicted mentions and the total number of gold mentions. We will also adopt these metrics in our evaluations later. Un- fortunately, the model only optimizes its objec- tive function defined in Equation 2, which is the negative (regularized) joint log-likelihood. Previ- ous work showed it was possible to optimize the F measure in a log-linear model ( <ref type="bibr" target="#b31">Suzuki et al., 2006</ref>). <ref type="bibr" target="#b8">Culotta and McCallum (2004)</ref> also pro- posed a method for optimizing information extrac- tion performance based on confidence estimation. Their work is based on linear-chain CRF and es- timate the confidence of extracted fields based on marginal probabilities. The technique is not di- rectly applicable to our task where a hypergraph representation is used to encode overlapping men- tions. In this work, we used a very simple and intuitive technique for optimizing the F measure. The idea is to further tune the weight of a single parameter -mention penalty based on the devel- opment set, after the training process completes. This is based on the observation that by increas- ing the value of the mention penalty, we are essen- tially forcing our model to predict more mentions. Therefore the recall is a monotonic function with respect to the mention penalty. Based on this fact, we use a simple search algorithm with a fixed step size (we set it to 0.01) to determine the optimal value of the modified mention penalty so that the F measure of the development set is optimized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we present empirical evaluations.</p><p>Our main experiments were conducted on the stan- dard ACE2004 and ACE2005 datasets which contain overlapping mentions. Two additional ex- periments on the GENIA and CONLL2003 dataset were also conducted .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Results on ACE</head><p>Our primary experiments were conducted based on the English portion of the ACE2004 dataset <ref type="bibr">3</ref> and the ACE2005 dataset <ref type="bibr">4</ref> . Following previous work, for ACE2004, we considered all documents from arabic treebank, bnews, chinese treebank, and nwire, and for ACE2005, we considered all documents from bc, bn, nw, and wl . We randomly split the documents for each dataset into three por- tions: 80% for training, 10% for development, and the remaining 10% for evaluations. The statistics of the datasets are summarized in <ref type="table">Table 1</ref> 5 . We can observe that overlapping mentions are com- mon -over 30% of the sentences contain overlap- ping mentions <ref type="table" target="#tab_3">(see row 3 of the table)</ref>. Mentions can also be very long -over 5% of the mentions consist of more than 6 words, and the longest men- tion consists of 57 words. We compared our system's performance with those of several baseline approaches. We first built two simple baseline approaches based on se- quence labelling models using the conditional ran- dom fields (CRFs). Such approaches can not han- dle overlapping mentions. To train such mod- els, whenever two mentions overlap with one an- other in the training set, we remove the mention that is shorter in length. Following <ref type="bibr" target="#b28">(Ratinov and Roth, 2009)</ref>, we considered the BIO (Begin, In- side, Outside) approach and the BILOU (Begin, Inside, Last, Outside, Unit) approach for design- ing the output labels. Results show the BILOU ap- proach yields better results. Similar observations were reported in <ref type="bibr" target="#b28">Ratinov and Roth (2009)</ref>.</p><p>In the work of ( <ref type="bibr" target="#b0">Alex et al., 2007)</ref>, the authors proposed several approaches for building mod- els to handle nested named entities in biomedi- cal texts. Their best results were obtained from a cascaded approach where they built one model for each named entity class. Outputs from one model can then served as the inputs to the next model for predicting the named entity class of a differ- ent type. One fundamental limitation of such an approach is that it being unable to handle overlap- ping mentions of the same type. Nevertheless, this approach worked very well on both datasets. The results are shown in the row of "CRF (CC)". <ref type="bibr">6</ref> Another class of models that is often used in in- formation extraction are the semi-Markov condi- tional random fields (semi-CRFs) ( <ref type="bibr" target="#b30">Sarawagi and Cohen, 2004</ref>). Semi-CRF models are able to cap- ture the non-Markovian properties of mentions. However, they are unable to handle nested or over- lapping mentions. We thus used the same method as discussed above to exclude certain mentions for training. Such semi-CRF models typically as- sume there is a length restriction for the mentions -each mention can consist of up to c words -in order to scale linearly. When such a restriction is lifted, the time complexity of such models be- comes quadratic in the number of words in the in-  put sentence. We train two models: one with a length restriction, where c = 6, and the other with- out a length restriction (c = ∞). For features de- fined over the inputs, besides the Markovian fea- tures described in Sec 3.5, we also used the sur- face forms of complete mention spans as features.</p><p>The results of these two models are reported in the fourth and fifth row of <ref type="table" target="#tab_1">Table 2</ref>, respectively. Inter- estingly, imposing the length restriction appears to be helpful for precision, and as a result it makes a positive contribution towards the final F measure. Our basic model (MH: mention hypergraph) that optimizes the negative joint log likelihood is able to obtain the best precision across these two datasets. When the model is further augmented with the F measure optimization step described in Sec 3.7 (MH (F )) it consistently yields the best results in terms of both recall score and F measure across these two datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Running Time</head><p>We also conducted controlled experiments to re- port the actual execution time of our model and make a comparison with the linear-chain CRF model (BILOU approach). The experiments are all conducted on the ACE2004 dataset on the same machine. To make a proper comparison here, we implemented the linear-chain CRF model us- ing Java (the same language is used when imple- menting our model), and employed the same data structures for creating features as well as the same learning and inference routines used by our men- tion hypergraph model.</p><p>To understand how the features and speed change as we increase the number of mention types (i.e., semantic types), we also conducted ex- periments where we increase the number of possi- ble mention types. Specifically, we created sub- types from each original type annotated in the dataset. For example, we randomly replaced the type "GPE" by sub-types "GPE1" or "GPE2" in the dataset. This gave us 14 different mention types. Similarly, we could randomly replace the type "GPE" by sub-types "GPE1" -"GPE4", re- <ref type="table" target="#tab_1">ACE2004   ACE2005  DEV  TEST  DEV  TEST  P  R  F  P  R  F  P  R  F  P  R  F  CRF (CC-S)</ref> 57.0 35.9 44.1 52.7 31.2 39.2 56.5 38.3 45.6 54.2 35.5 42.9 CRF (CC-F) 51.5 32.5 39.9 47.4 28.0 35.2 53.3 36.1 43.1 51.3 33.6 40.6 CRF (CC-L) 64.4 40.6 49.9 61.6 36.4 45.8 66.6 45.1 53.8 65.3 42.8 51.7 CRF (CC-CC) 63.6 40.5 49.5 60.8 36.1 45.3 65.9 44.8 53.3 64.2 42.0 50.7 MH (L) 66.7 41.9 51.5 64.7 38.2 48.1 70.5 45.0 55.0 69.2 43.0 53.0 MH (Joint)</p><p>78.6 47.4 59.1 79.0 44.1 56.6 79.2 48.7 60.3 70.1 45.1 54.8 MH (Joint F ) 73.9 52.4 61.3 74.4 50.0 59.8 70.2 57.4 63.2 63.4 53.8 58.3 <ref type="table">Table 4</ref>: Results on joint mention boundary, type, and head prediction on ACE2004 and ACE2005. sulting in 28 different mention types in total. Our purpose of doing so is to understand how the mod- els behave when the number of possible mention types becomes large. We found that training on the entire training set of ACE2004 using the linear- chain CRF model with a large number of men- tion types was very expensive due to the extremely large number of features involved. We instead trained the models on the development set and pre- sented decoding time on the test set. <ref type="table" target="#tab_3">Table 3</ref> shows the results. We empirically cap- tured the relationship between the speed of each system (average number of words processed per second) and the number of mention types. Specif- ically, we found that as we linearly increased the number of mention types, for the linear-chain CRF model, the number of features grew quadratically and the speed dropped quadratically, whereas for our model, the number of features grew linearly and the speed dropped linearly. This indicates that our model is more scalable to large, practical datasets with a large number of fine-grained men- tion types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Joint Modeling of Heads</head><p>We also conducted experiments on these two datasets for the task of joint modeling of mention boundaries, types and heads. We used the same training and tuning methodology for optimizing the F measure. In such experiments, we adopted a very strict evaluation criterion: a predicted men- tion is regarded as correct iff and only if its bound- aries, type and head all exactly match those of the gold standard.</p><p>We compared our system's results with those of several baseline approaches based on CRF where the cascaded BILOU approach described above was always used. Specifically, we considered ap- proaches that always regarded the complete span (CC-S), the first word (CC-F), and the last word (CC-L) as the predicted mention's head, respec- tively. We also considered a cascaded approach (CC-CC) where we first predicted mentions, and then predicted their heads by following a simi- lar approach used for predicting overlapping men- tions discussed above. The first four rows of <ref type="table">Ta- ble 4</ref> give the results of these baseline approaches. We can observe that always predicting the last word as the head gives the best performance. In- spired by this, we performed a simple approach by training a model presented in the previous sec- tion without considering head information. When making predictions, we always regarded the last word of each predicted mention as its head. The results for such an approach are given in the fifth row of <ref type="table">Table 4</ref>. The sixth row shows the results ob- tained by optimizing our model's objective func- tion. The last row gives the results obtained by tuning the mention penalty based on the develop- ment set. As seen, our joint models significantly outperformed all those baseline approaches. We are not aware of any prior work in the literature that performs joint modeling of mention bound- aries, types, and heads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Additional Experiments</head><p>We also additionally evaluated on the GENIA dataset (v3.02) whose focus was on biomedical related named entity recognition and classifica- tion, where the entities may overlap with one an- other. Furthermore, to see how our model works on datasets where mentions do not overlap with one another, we also conducted evaluations on the standard CONLL2003 NER dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Results on GENIA</head><p>We followed the description of <ref type="bibr" target="#b10">Finkel and Manning (2009)</ref> to set up our experiments on the GE- NIA dataset. Specifically, we used the first 90% of the sentences as the training data and the remain- ing 10% as the evaluation data. We also adhered to the paper's prescription of collapsing all DNA subtypes into DNA; RNA subtypes into RNA; and all protein subtypes into protein. We kept cell line and cell type, and removed all other entities.</p><p>To optimize the F measure, we further split the  <ref type="table">Table 5</ref>: Results on the GENIA dataset training set into two portions. We trained a model using the first 90% of the training data, and used the remaining 10% for development. For features, no POS and no bag-of-words features are used. We compared our model's performance with that of a model based on a constituency parser pro- posed by <ref type="bibr" target="#b10">(Finkel and Manning, 2009)</ref>, as well as the semi-CRF model reported there. The results are shown in <ref type="table">Table 5</ref>. Our model yields a better F measure than the semi-CRF model, but gives a lower performance than the model of <ref type="bibr" target="#b10">(Finkel and Manning, 2009)</ref>. We note that, however, these results are not directly comparable. Specifically, both of these two previous models relied on an ad- ditional 200 million words from PubMed abstracts to learn word clusters as additional features, which we do not have access to.</p><p>One distinctive advantage of our model is the efficiency and scalability. The model of <ref type="bibr" target="#b10">(Finkel and Manning, 2009</ref>) had a time complexity that is cubic in the number of words in the input sentence. In contrast, our model scales linearly as the length of the input sentence increases. <ref type="bibr">7</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Results on CONLL2003</head><p>To understand how well our model works on datasets where mentions or entities do not overlap with one another, we conducted additional experi- ments on the standard dataset used in the CONLL 2003 shared task <ref type="bibr" target="#b32">(Tjong Kim Sang and De Meulder, 2003)</ref>, where the named entities strictly do not overlap with one another. We compared our system's performance against that of a baseline version of the state-of-the-art Illinois NER sys- tem ( <ref type="bibr" target="#b28">Ratinov and Roth, 2009)</ref>. Their system per- formed sequential prediction over the input words and adopted the BILOU approach. Their full model also incorporates external knowledge re- sources (e.g., gazetteers and word class).</p><p>In order to make a proper comparison with the baseline version of their model, besides the gen- eral features we mentioned earlier, we also fol- <ref type="bibr">7</ref> In our experiments, for this dataset our model tagged over 5,000 words/second. In ( <ref type="bibr" target="#b10">Finkel and Manning, 2009)</ref>, the authors mentioned that their model tagged about 38 words/second, and the semi-CRF model tagged about 45 words/second. However, we note these numbers are not di- rectly comparable due to the advancement of CPU speed.  <ref type="table">Table 6</ref>: Results on the CONLL2003. Illinois (b): baseline version of <ref type="bibr" target="#b28">(Ratinov and Roth, 2009</ref>).</p><p>lowed <ref type="bibr" target="#b28">(Ratinov and Roth, 2009</ref>) in incorporat- ing word's prefixes and suffixes (of length up to 5) as features, and normalized words referring to months, dates and numbers. <ref type="table">Table 6</ref> shows that our system gives an F measure that is compara- ble to that of the baseline version of their system, where no external resources are used. This additional experiment showed that while our model is designed for handling more real- istic scenarios where mentions can overlap, it yields a performance competitive to a state-of-the- art system which only handles datasets with non- overlapping mentions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this work, we have introduced a novel model for the task of joint modeling of mention bound- aries, types, as well as their heads. Unlike many previous research efforts for mention extraction and classification, our novel mention hypergraph representations for compactly representing expo- nentially many possible mentions enables a men- tion's boundaries, type and head information to be jointly learned in a single framework. The model scales linearly with respect to the number of words in the input sentence, and performs exact learning where a unique global optimum can be found. Em- pirically, we have demonstrated the effectiveness of such a model across several standard datasets.</p><p>Future work include explorations of efficient al- gorithms for other information extraction tasks, such as joint mention and relation extraction ( <ref type="bibr" target="#b17">Li and Ji, 2014</ref>) and event extraction ( <ref type="bibr" target="#b18">Li et al., 2013)</ref>. Our system and code can be downloaded from http://statnlp.org/research/ie/.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The (partial) hypergraph for representing all possible combinations of mention occurrences. Links that belong to the same hyperedge are highlighted with the same color, and different hyperedges are highlighted with different colors, e.g., the green link that connects two I nodes forms a single hyperedge, while the two brown links that connect two I nodes and one X node form a separate single hyperedge.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: An example illustrating the converse of Theorem 3.1 is not true.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Results on ACE2004 and ACE2005. The last two rows give the results of this work.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>The decoding time and the number of features 
change as we increase the number of possible types. (#f: 
number of features created (in millions). w/s: number of 
words processed per second.) Experiments are conducted on 
the ACE 2004 dataset. 

</table></figure>

			<note place="foot" n="1"> Note that the time complexity for the linear chain CRF is in O(m 2 n) due to their first-order assumption.</note>

			<note place="foot" n="2"> all-caps, all-digits, all-alphanumeric, contains-digits, contains-dots, contains-hyphen, initial-caps, lonely-initial, punctuaion-mark, roman-number, single-character, URL.</note>

			<note place="foot" n="3"> https://catalog.ldc.upenn.edu/LDC2005T09 4 https://catalog.ldc.upenn.edu/LDC2006T06 5 Exact train/dev/test splits information can be found on http://statnlp.org/research/ie/.</note>

			<note place="foot" n="6"> For all such linear chain CRF-related experiments, we used the CRF++ toolkit (https://code.google.com/p/crfpp/) with L-BFGS, which gives us the most competitive results over several different CRF implementations (see: http://www.chokkan.org/software/crfsuite/benchmark.html).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Kian Ming A. Chai, Hai Leong Chieu and the three anonymous reviewers for their comments on this work. This work is sup-ported by Temasek Lab of Singapore University of Technology and Design project IGDSS1403011 and IGDST1403013, and is partly supported by DARPA (under agreement number FA8750-13-2-0008).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Recognising nested named entities in biomedical text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Alex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Grover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BioNLP</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Discriminative Latent Variable Model for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miles</forename><surname>Osborne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="200" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lieven</forename><surname>Vandenberghe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Named entity extraction using adaboost. CONLL</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluis</forename><surname>Marquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Padró</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="167" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Constrained Latent Variable Model for Coreference Resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajhans</forename><surname>Samdani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="601" to="612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Named Entity Recognition with Bilingual Constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="52" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Flexible and efficient hypergraph interactions for joint hierarchical and forest-to-string decoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Cmejrek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitao</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="545" to="555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unsupervised named entity recognition using syntactic and semantic contextual evidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Cucchiarelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paola</forename><surname>Velardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="123" to="131" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Confidence estimation for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aron</forename><surname>Culotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="109" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unsupervised named-entity extraction from the web: An experimental study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anamaria</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Daniel S Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="134" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="141" to="150" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Named entity recognition through classifier combination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abe</forename><surname>Ittycheriah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyan</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CONLL</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="168" to="171" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A statistical model for multilingual entity detection and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hany</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><surname>Ittycheriah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyan</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanda</forename><surname>Kambhatla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nicolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<publisher>DTIC Document</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">To Link or Not to Link? A Study on End-toEnd Tweet Entity Linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emre</forename><surname>Kiciman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1020" to="1030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Knowledgebased weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congle</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="541" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Parsing and hypergraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IWPT</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="123" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando Cn</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Incremental Joint Extraction of Entity Mentions and Relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="402" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Joint Event Extraction via Structured Prediction with Global Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="73" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On the limited memory BFGS method for large scale optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nocedal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical programming</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="503" to="528" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Constrained semantic forests for improved discriminative semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Identifying gene and protein mentions in text using conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="issue">S6</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL-IJCNLP</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
	<note>Rion Snow, and Dan Jurafsky. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A survey of named entity recognition and classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Nadeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lingvisticae Investigationes</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="3" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning Dictionaries for Named Entity Recognition using Minimal Supervision</title>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Zero-shot Entity Extraction from Web Pages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="391" to="401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Discriminative log-linear grammars with latent variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1153" to="1160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Design challenges and misconceptions in named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="147" to="155" />
		</imprint>
	</monogr>
	<note>CONLL</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Named entity recognition in tweets: an experimental study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1524" to="1534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Semimarkov conditional random fields for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>William W Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1185" to="1192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Training conditional random fields with multivariate evaluation measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Isozaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING/AC</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="217" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik F Tjong Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fien De</forename><surname>Meulder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
	<note>CONLL</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Joint Word Alignment and Bilingual Named Entity Recognition Using Dual Decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1073" to="1082" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Named entity recognition using an hmm-based chunk tagger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="473" to="480" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
