<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Guided Neural Language Generation for Abstractive Summarization using Abstract Meaning Representation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hardy</surname></persName>
							<email>hhardy2@sheffield.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">The University of Sheffield</orgName>
								<orgName type="institution" key="instit2">The University of Sheffield</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
							<email>a.vlachos@sheffield.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">The University of Sheffield</orgName>
								<orgName type="institution" key="instit2">The University of Sheffield</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Guided Neural Language Generation for Abstractive Summarization using Abstract Meaning Representation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="768" to="773"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>768 Code is available at https://github. com/sheffieldnlp/AMR2Text-summ</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Recent work on abstractive summarization has made progress with neural encoder-decoder architectures. However, such models are often challenged due to their lack of explicit semantic modeling of the source document and its summary. In this paper, we extend previous work on abstractive summa-rization using Abstract Meaning Representation (AMR) with a neural language generation stage which we guide using the source document. We demonstrate that this guidance improves summarization results by 7.4 and 10.5 points in ROUGE-2 using gold standard AMR parses and parses obtained from an off-the-shelf parser respectively. We also find that the summarization performance using the latter is 2 ROUGE-2 points higher than that of a well-established neural encoder-decoder approach trained on a larger dataset.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Abstractive summarization is the task of automat- ically producing the summary of a source doc- ument through the process of paraphrasing, ag- gregating and/or compressing information. Re- cent work in abstractive summarization has made progress with neural encoder-decoder architec- tures ( <ref type="bibr" target="#b15">See et al., 2017;</ref><ref type="bibr" target="#b2">Chopra et al., 2016;</ref><ref type="bibr" target="#b14">Rush et al., 2015</ref>). However, these models are of- ten challenged when they are required to com- bine semantic information in order to generate a longer summary <ref type="bibr" target="#b19">(Wiseman et al., 2017)</ref>. To ad- dress this shortcoming, several works have ex- plored the use of Abstract Meaning Representa- tion ( <ref type="bibr">Banarescu et al., 2013, AMR)</ref>. These were motivated by AMR's capability to capture the predicate-argument structure which can be utilized in information aggregation during summarization.</p><p>However, the use of AMR also has its own shortcomings. While AMR is suitable for infor- mation aggregation, it ignores aspects of language such as tense, grammatical number, etc., which are important for the natural language generation (NLG) stage that normally occurs in the end of the summarization process. Due to the lack of such information, approaches for NLG from AMR typ- ically infer it from regularities in the training data ( <ref type="bibr" target="#b13">Pourdamghani et al., 2016;</ref><ref type="bibr" target="#b8">Konstas et al., 2017;</ref><ref type="bibr" target="#b16">Song et al., 2016;</ref><ref type="bibr" target="#b3">Flanigan et al., 2016)</ref>, which however is not suitable in the context of summa- rization. Consequently, the main previous work on AMR-based abstractive summarization ( <ref type="bibr" target="#b9">Liu et al., 2015)</ref> only generated bag-of-words from the sum- mary AMR graph.</p><p>In this paper, we propose an approach to guide the NLG stage in AMR-based abstractive summa- rization using information from the source docu- ment. Our objective is twofold: (1) to retrieve the information missing from AMR but needed for NLG and (2) improve the quality of the summary. We achieve this in a two-stages process: (1) esti- mating the probability distribution of the side in- formation, and (2) using it to guide a <ref type="bibr" target="#b10">Luong et al. (2015)</ref>'s seq2seq model for NLG.</p><p>Our approach is evaluated using the Proxy Re- port section from the AMR dataset ( <ref type="bibr" target="#b7">Knight et al., 2017</ref>) which contains manually an- notated document and summary AMR graphs. Us- ing our proposed guided AMR-to-text NLG, we improve summarization results using both gold standard AMR parses and parses obtained using the RIGA ( <ref type="bibr" target="#b1">Barzdins and Gosko, 2016</ref>) parser by 7.4 and 10.5 ROUGE-2 points respectively. Our model also outperforms a strong baseline seq2seq model ( <ref type="bibr" target="#b15">See et al., 2017</ref>) for summarization by 2 ROUGE-2 points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Abstractive Summarization using AMR: In <ref type="bibr" target="#b9">Liu et al. (2015)</ref> work, the source document's sen- tences were parsed into AMR graphs, which were then combined through merging, collapsing and graph expansion into a single AMR graph repre- senting the source document. Following this, a summary AMR graph was extracted, from which a bag of concept words was obtained without at- tempting to form fluent text. <ref type="bibr" target="#b18">Vilca and Cabezudo (2017)</ref> performed a summary AMR graph extrac- tion augmented with discourse-level information and the PageRank ( <ref type="bibr" target="#b12">Page et al., 1998</ref>) algorithm. For text generation, <ref type="bibr" target="#b18">Vilca and Cabezudo (2017)</ref> used a rule-based syntactic realizer <ref type="bibr" target="#b5">(Gatt and Reiter, 2009</ref>) which requires substantial human input to perform adequately.</p><p>Seq2seq using Side Information: In Neural Machine Translation (NMT) field, recent work ( <ref type="bibr" target="#b20">Zhang et al., 2018</ref>) explored modifications to the decoder of seq2seq models to improve translation results. They used a search engine to retrieve sen- tences and their translation (referred to as trans- lation pieces) that have high similarity with the source sentence. When similar n-grams from a source document were found in the translation pieces, they rewarded the presence of those n- grams during the decoding process through a scor- ing mechanism calculating the similarity between source sentence and the source side of the transla- tion pieces. <ref type="bibr" target="#b20">Zhang et al. (2018)</ref> reported improve- ments in translation results up to 6 BLEU points over their seq2seq NMT baseline. In this paper we use the same principle and reward n-grams that are found in the source document during the AMR- to-Text generation process. However we use a simpler approach using a probabilistic language model in the scoring mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Guiding NLG for AMR-based summarization</head><p>We first briefly describe the AMR-based summa- rization method of <ref type="bibr" target="#b9">Liu et al. (2015)</ref> and then our guided NLG approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">AMR-based summarization</head><p>In <ref type="bibr" target="#b9">Liu et al. (2015)</ref>'s work, each of the sentence of the source document was parsed into an AMR graph, and combined into a source graph, G = (V, E) where v ∈ V and e ∈ E are the unique concepts and the relations between pairs of con- cepts. They then extracted a summary graph, G using the following sub-graph prediction:</p><formula xml:id="formula_0">G = arg maxˆG= maxˆ maxˆG=( ˆ V , ˆ E) v∈ˆVv∈ˆ v∈ˆV θ f(v) + e∈ˆEe∈ˆ e∈ˆE ψ f(e) (1)</formula><p>where f(v) and f(e) are the feature representations of node v and edge e respectively. The final sum- mary produced was a bag of concept words ex- tracted from G . This output we will be replacing with our proposed guided NLG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Unguided NLG from AMR</head><p>Our baseline is a standard (unguided) seq2seq model with attention ( <ref type="bibr" target="#b10">Luong et al., 2015</ref>) which consists of an encoder and a decoder. The encoder computes the hidden representation of the input, {z 1 , z 2 , . . . , z k }, which is the linearized summary AMR graph, G from <ref type="bibr" target="#b9">Liu et al. (2015)</ref>, follow- ing Van Noord and Bos (2017)'s preprocessing steps. Following this, the decoder generates the target words, {y 1 , y 2 , . . . , y m }, using the condi- tional probability P s2s (y j |y &lt;j , z), which is calcu- lated using the equation</p><formula xml:id="formula_1">P s2s (y j |y &lt;j , z) = softmax(W s ˜ h t )<label>(2)</label></formula><p>, where the attentional hidden state, ˜ h t is calcu- lated using the equatioñ</p><formula xml:id="formula_2">equatioñ h t = tanh(W c [c t ; h t ])<label>(3)</label></formula><p>, where c t is the source context vector, and h t is the target RNN hidden state. The source context vector is defined as the weighted average over all the source RNN hidden states, ¯ h s , given the align- ment vector, a t where a t is defined as</p><formula xml:id="formula_3">a t (s) = exp(score(h t , ¯ h s )) s exp(score(h t , ¯ h s ))<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Guided NLG from AMR</head><p>Our goal is to improve the text generated from the summary AMR graph by the probability distribu- tion of the seq2seq model, P s2s using the source document. Since not all sentences in the source document will be used in generating the summary, we prune the source document to a set of k sen- tences which have the highest similarity with the summary AMR graph. For graph-to-graph sim- ilarity comparison, we use the source document AMR parses and calculate the Longest Common Subsequence (LCS) between the linearized AMR parses and the summary AMR graph. We keep the top-k sentences sorted by LCS length. To distin- guish this pruned document from the source docu- ment, we refer to the former as side information. Our aim is is to combine P s2s with the probabil- ity distribution estimated using words in the side information, P side , in order to score each word given its context during decoding. We estimate P side as the linear interpolation of 2-gram to 4- gram probabilities in the form of</p><formula xml:id="formula_4">P side (x j |x j−1 j−3 ) = λ 3 P LM (x j |x j−1 j−3 ) + λ 2 P LM (x j |x j−1 j−2 ) + λ 1 P LM (x j |x j−1 )<label>(5)</label></formula><p>, where x j is a word occurring in side information document, P LM is an N -gram LM estimated using Maximum Likelihood:</p><formula xml:id="formula_5">P LM (x j |x j−1 j−N −1 ) = count(x j−N −1 . . . x j ) count(x j−N −1 . . . x j−1 )<label>(6)</label></formula><p>and λ i is defined as</p><formula xml:id="formula_6">λ i = θλ i−1 where θ ∈ R, λ i &gt; 0 and i λ i = 1 (7)</formula><p>where θ is a hyper-parameter that we tune using the dev dataset during the experiments.</p><p>Lastly, we combine the probability distribution of the decoder, P s2s with that provided by the side information, P side , as follows:</p><formula xml:id="formula_7">s(y j |y &lt;j , z) = log a + ψ * log( b a + 1)<label>(8)</label></formula><p>where ψ is a hyper-parameter determining the influence of the side information on the de- coding process, a is P s2s (y j |y &lt;j , z) and b is P side (y j |y j−1 j−3 ). s(y j |y &lt;j , z) is used during beam search replacing P s2s (y j |y &lt;j , z) for all words that occur in the side information. The intuition behind Eq. 8 is that we are rewarding word y j when it ap- pears in similar context in the side information, i.e. the source document being summarized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We conduct experiments in order to answer the following questions about our proposed approach: (1) Is our baseline model comparable with the state-of-the-art AMR-to-text approaches? (2) Does the guidance from the source document im- prove the result of AMR-to-Text in the context Model BLEU Our model (unguided NLG) 21.1 NeuralAMR ( <ref type="bibr" target="#b8">Konstas et al., 2017)</ref> 22.0 TSP ( <ref type="bibr" target="#b16">Song et al., 2016)</ref> 22.4 TreeToStr ( <ref type="bibr" target="#b3">Flanigan et al., 2016)</ref> 23.0 <ref type="table">Table 1</ref>: Results for AMR-to-text of summarization? (3) Does the improvement in AMR-to-Text hold when we use the generator for abstractive summarization using AMR? We an- swer each of these in the following paragraphs.</p><p>AMR-to-Text baseline comparison We com- pare our baseline model (described in §3.2) against previous works in AMR-to-text using the data from the recent SemEval-2016 Task 8 (May, 2016, LDC2015E86). <ref type="table">Table 1</ref> reports BLEU scores comparing our model against previous works.</p><p>Here, we see that our model achieves a BLEU score comparable with the state-of-the-art, and thus we argue that it is sufficient to be used in our subsequent experiments with guidance.</p><p>Guided NLG for AMR-to-Text In this exper- iment we apply our guided NLG mechanism de- scribed in §3.3 to our baseline seq2seq model. To isolate the effects of guidance we skip the actual summarization process and proceed to directly generating the summary text from the gold stan- dard summary AMR graphs from the Proxy Re- port section. To determine the hyper-parameters, we perform a grid search using the dev dataset, where we found the best combination of ψ, θ and k are 0.95, 2.5 and 15 respectively. We have two different settings for this experiment: the oracle and non-oracle settings. In the oracle setting, we directly use the gold standard summary text as the guidance for our model. The intuition is that in this setting, our model knows precisely which words should appear in the summary text, thus providing an upper bound for the performance of our guided NLG approach. In the non-oracle setting, we use the mechanism described in §3.3. We also com- pare them against the baseline (unguided) model from §3.2. <ref type="table" target="#tab_1">Table 2</ref> reports performance for all models. The difference between the guided and the unguided model is 16.2 points in BLEU and 9.9 points in ROUGE-2, while there is room for improvement as evidenced by the difference be- tween the oracle and non-oracle result.</p><p>Guided NLG for full summarization In this experiment we combine our guided NLG model  with <ref type="bibr" target="#b9">Liu et al. (2015)</ref>'s work in order to gener- ate fluent texts from their summary AMR graphs using the hyper-parameters tuned in the previous paragraph. <ref type="bibr" target="#b9">Liu et al. (2015)</ref> used parses from both the manual annotation of the Proxy dataset as well as those obtained using the JAMR parser ( <ref type="bibr" target="#b4">Flanigan et al., 2014</ref>). Instead of JAMR we use the RIGA parser ( <ref type="bibr" target="#b1">Barzdins and Gosko, 2016</ref>) which had the highest accuracy in the <ref type="bibr">SemEval 2016</ref><ref type="bibr">Task 8 (May, 2016</ref>. We compare our result against <ref type="bibr" target="#b9">Liu et al. (2015)</ref>'s bag of words 1 , the unguided AMR- to-text model from §3.2, and a seq2seq summa- rization model (OpenNMT BRNN) 2,3 which sum- marizes directly from the source document to sum- mary sentence without using AMR as an interlin- gua and is trained on CNN/DM corpus ( <ref type="bibr" target="#b6">Hermann et al., 2015</ref>) using the same settings as See et al.  In <ref type="table" target="#tab_3">Table 3</ref>, we can see that our approach results <ref type="bibr">1</ref> We were able to obtain comparable AMR summariza- tion subgraph prediction to their reported results using their published software but not to match their bag-of-word gener- ation results. <ref type="bibr">2</ref> We use the OpenNMT-pytorch implementation https://github.com/OpenNMT/OpenNMT-py and a pre-trained model downloaded from http://opennmt. net/OpenNMT-py/Summarization.html which has higher result than <ref type="bibr" target="#b15">See et al. (2017)</ref>'s summarizer.in improvements over both the unguided AMR-to- text and the standard seq2seq summarization. One interesting note is that using the RIGA parses re- sult in higher ROUGE scores than the gold parses for the guided model in our experiment. This phe- nomenon was also observed in <ref type="bibr" target="#b9">Liu et al. (2015)</ref>'s experiment where the summary graphs extracted from automatic parses had higher accuracy than those extracted from manual parses. We hypothe- size this can be attributed to how the AMR dataset is annotated as there might be discrepancies in dif- ferent annotator's choices of AMR concepts and relations for sentences with similar wording. In contrast, the AMR parsers introduce errors, but they are consistent in their choices of AMR con- cepts and relations. The discrepancies in the man- ual annotation could have impacted the perfor- mance of the AMR summarizer that we use more negatively than the noise introduced due to the AMR parsing errors.  In <ref type="table" target="#tab_5">Table 4</ref>, we show sample summaries from the different models, where we can see that our guided model improves the unguided model by correcting a wrong word (a softening) into a cor- rect one (airstrikes) and introducing a better suited word from the source document (georgian instead of georgia 's).  We also evaluated manually by asking human evaluators to judge sentences' fluency (grammat- ical and naturalness) on a scale of 1 (worst) to 6 (best) for the guided and unguided model (see <ref type="table" target="#tab_7">Ta-ble 5</ref>). While the manual evaluation shows im- provement over the unguided model, on the other hand, grammatical mistakes and redundant repeti- tion in the generated text are still major problems (see <ref type="table">Table 6</ref>) in our AMR generation.</p><formula xml:id="formula_8">Model BLEU F1 ROUGE R-1 R-2 R-L Guided NLG (Oracle) 61</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NLG Model Generated Summary</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NLG Model Fluency</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Guided NLG Model</head><p>Problems the soldiers were injured when a attempt to defuse the bombs .</p><p>grammatical mistake on 20 october 2002 the state -run radio nepal reported on 20 october 2002 that at the evening -run radio nepal re- ported on 20 october 2002 that the guerrillas were killed and killed . redundant repetition <ref type="table">Table 6</ref>: Problems in guided model's summaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Works</head><p>In this paper we proposed a guided NLG approach that substantially improves the output of AMR- based summarization. Our approach uses a simple guiding process based on a probabilistic language model. In future work we aim to improve summa- rization performance by jointly training the guid- ing process with the AMR-based summarization process.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : BLEU and ROUGE results for guided and un</head><label>2</label><figDesc></figDesc><table>-
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>.</head><label></label><figDesc></figDesc><table>AMR 
NLG Model 
F1 ROUGE 
parses 
R-1 
R-2 
R-L 

Gold 

Guided 
40.4 
20.3 
31.4 
Unguided 
38.9 
12.9 
27.0 
Liu et al. (2015) 
39.6 
6.2 
22.1 

RIGA 

Guided 
42.3 
21.2 
33.6 
Unguided 
37.8 
10.7 
26.9 
Liu et al. (2015) 
40.9 
5.5 
21.4 
Directly 
from 
Text 

OpenNMT 
BRNN 2 layer, 
emb 256, hidden 
1024 

36.1 
19.2 
31.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>The F 1 ROUGE scores for guided, unguided, 
Liu et al. (2015) (BoW) results in Gold and RIGA 
parses, and seq2seq summarization. All models are run 
using test dataset. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Result summaries of guided, unguided and 
seq2seq models compared with gold summary. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 : Fluency scores on test dataset.</head><label>5</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="3"> The pre-trained model generates multiple sentences summary, but we use only the first sentence summary for evaluation in accordance with the AMR dataset.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are thankful for Gerasimos Lampouras for his help with the manual evaluation process and all volunteers who participated in it. We would also like to thank the Indonesian government that has sponsored the first author's studies through the Indonesia Endowment Fund for Education (LPDP). The second author is supported by the EU H2020 SUMMA project (grant agreement number 688139) and the EPSRC grant eNeMILP (EP/R021643/1).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Abstract meaning representation for sembanking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Banarescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Bonial</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madalina</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse</title>
		<meeting>the 7th Linguistic Annotation Workshop and Interoperability with Discourse</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="178" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">RIGA at SemEval-2016 Task 8: Impact of Smatch Extensions and Character-Level Neural Translation on AMR Parsing Accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guntis</forename><surname>Barzdins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Didzis</forename><surname>Gosko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval2016)</title>
		<meeting>the 10th International Workshop on Semantic Evaluation (SemEval2016)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1143" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Abstractive Sentence Summarization with Attentive Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual Conference of the NAACL HLT</title>
		<meeting>the 15th Annual Conference of the NAACL HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="93" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Generation from Abstract Meaning Representation using Tree Transducers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carbonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the NAACL</title>
		<meeting>the 2016 Conference of the NAACL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="731" to="739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Discriminative Graph-Based Parser for the Abstract Meaning Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52th Annual Meeting of the ACL</title>
		<meeting>the 52th Annual Meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1426" to="1436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">SimpleNLG : A realisation engine for practical applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Reiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th European Workshop on NLG</title>
		<meeting>the 12th European Workshop on NLG</meeting>
		<imprint>
			<date type="published" when="2009-03" />
			<biblScope unit="page" from="90" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Teaching Machines to Read and Comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomáš</forename><surname>Kočisk´kočisk´y</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Abstract Meaning Representation (AMR) Annotation Release 2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bianca</forename><surname>Badarau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Baranescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Bonial</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madalina</forename><surname>Bardocz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>O&amp;apos;gorman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural AMR: Sequence-to-Sequence Models for Parsing and Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Konstas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivasan</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the NAACL HLT</title>
		<meeting>the 2015 Conference of the NAACL HLT</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1077" to="1086" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Toward Abstractive Summarization Using Semantic Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><surname>Sadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the NAACL HLT</title>
		<meeting>the 2015 Conference of the NAACL HLT</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1077" to="1086" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Effective Approaches to Attentionbased Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>The Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">SemEval-2016 Task 8: Meaning Representation Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
		<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)</meeting>
		<imprint>
			<date type="published" when="2016-05" />
			<biblScope unit="page" from="1063" to="1073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The PageRank Citation Ranking: Bringing Order to the Web. World Wide Web Internet And Web Information Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajeev</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Winograd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Generating English from Abstract Meaning Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Pourdamghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Natural Language Generation</title>
		<meeting>the 9th International Natural Language Generation</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="21" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A Neural Attention Model for Abstractive Sentence Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Alexander M Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on EMNLP</title>
		<meeting>the Conference on EMNLP</meeting>
		<imprint>
			<date type="published" when="2015-09" />
			<biblScope unit="page" from="379" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Get To The Point: Summarization with Pointer-Generator Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abigail</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the ACL</title>
		<meeting>the 55th Annual Meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">AMR-to-text generation as a Traveling Salesman Problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linfeng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaochang</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on EMNLP</title>
		<meeting>the 2016 Conference on EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2084" to="2089" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neural semantic parsing by character-based translation: Experiments with abstract meaning representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rik</forename><surname>Van Noord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Bos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics in the Netherlands Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="93" to="108" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A Study of Abstractive Summarization Using Semantic Representations and Discourse Level Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Cesar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valderrama</forename><surname>Vilca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco Antonio Sobrevilla</forename><surname>Cabezudo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Text, Speech, and Dialogue</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="482" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Challenges in Data-to-Document Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stuart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander M</forename><surname>Shieber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on EMNLP</title>
		<meeting>the 2017 Conference on EMNLP<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2253" to="2263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Guiding Neural Machine Translation with Retrieved Translation Pieces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masao</forename><surname>Utiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichro</forename><surname>Sumita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual Conference of the NAACL HLT</title>
		<meeting>the 16th Annual Conference of the NAACL HLT<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>The Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
