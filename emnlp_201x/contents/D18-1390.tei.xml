<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:13+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Legal Judgment Prediction via Topological Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoxi</forename><surname>Zhong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology State Key Lab on Intelligent Technology and Systems Institute for Artificial Intelligence</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhipeng</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology State Key Lab on Intelligent Technology and Systems Institute for Artificial Intelligence</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cunchao</forename><surname>Tu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology State Key Lab on Intelligent Technology and Systems Institute for Artificial Intelligence</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaojun</forename><surname>Xiao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology State Key Lab on Intelligent Technology and Systems Institute for Artificial Intelligence</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology State Key Lab on Intelligent Technology and Systems Institute for Artificial Intelligence</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology State Key Lab on Intelligent Technology and Systems Institute for Artificial Intelligence</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Legal Judgment Prediction via Topological Learning</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="3540" to="3549"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>3540</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Legal Judgment Prediction (LJP) aims to predict the judgment result based on the facts of a case and becomes a promising application of artificial intelligence techniques in the legal field. In real-world scenarios, legal judgment usually consists of multiple subtasks, such as the decisions of applicable law articles , charges, fines, and the term of penalty. Moreover, there exist topological dependencies among these subtasks. While most existing works only focus on a specific sub-task of judgment prediction and ignore the dependencies among subtasks, we formalize the dependencies among subtasks as a Directed Acyclic Graph (DAG) and propose a topo-logical multi-task learning framework, TOP-JUDGE, which incorporates multiple subtasks and DAG dependencies into judgment prediction. We conduct experiments on several real-world large-scale datasets of criminal cases in the civil law system. Experimental results show that our model achieves consistent and significant improvements over baselines on all judgment prediction tasks. The source code can be obtained from https://github. com/thunlp/TopJudge.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Legal Judgment Prediction (LJP) aims to predict the judgment results of legal cases according to the fact descriptions. It is a critical technique for the legal assistant system. On the one hand, LJP can provide low-cost but high-quality legal consulting services to the masses who are unfamiliar with le- gal terminology and the complex judgment pro- cedures. On the other hand, it can serve as the handy reference for professionals (e.g., lawyers and judges) and improve their work efficiency. * Indicates equal contribution. The order is determined by dice rolling. â€  Corresponding author. LJP has been studied for decades <ref type="bibr" target="#b16">(Kort, 1957;</ref><ref type="bibr" target="#b36">Ulmer, 1963;</ref><ref type="bibr" target="#b27">Nagel, 1963;</ref><ref type="bibr" target="#b13">Keown, 1980;</ref><ref type="bibr" target="#b30">Segal, 1984;</ref><ref type="bibr" target="#b17">Lauderdale and Clark, 2012;</ref><ref type="bibr" target="#b39">Ye et al., 2018;</ref>, and most existing works for- malize LJP as a text classification task. For ex- ample, some works ( <ref type="bibr" target="#b19">Liu et al., 2004</ref>; <ref type="bibr" target="#b20">Liu and Hsieh, 2006</ref>) propose to extract shallow textual features (e.g. characters, words, and phrases) for charge prediction. <ref type="bibr" target="#b12">Katz et al. (2017)</ref> predict the US Supreme Court's decisions based on efficient features from case profiles. <ref type="bibr" target="#b23">Luo et al. (2017)</ref> pro- pose an attention-based neural model for charge prediction by incorporating the relevant law arti- cles.</p><p>Despite these efforts in designing efficient fea- tures and employing advanced NLP techniques, LJP is still confronted with two major challenges:</p><p>Multiple Subtasks in Legal Judgment: Prac- tically, legal judgment usually consists of detailed and complicated subclauses, such as charges, the term of penalty, and fines. Specifically, for those countries with the civil law system (e.g., China, France, and Germany), the prediction of relevant articles is also considered to be one of the funda- mental subtasks, which will guide the prediction for other subtasks. In other words, all these sub- tasks compose the complete form of judgment pre-diction. Nevertheless, existing works on LJP usu- ally focus on one specific subtask of judgments, which does not conform to the real scenarios. Al- though some methods ( <ref type="bibr" target="#b23">Luo et al., 2017)</ref> are devel- oped to predict law articles and charges at the same time, their models are designed for a specific set of subtasks which are hard to scale to other subtasks.</p><p>Topological Dependencies between Subtasks: For human judges, there exists a strict order among the subtasks of legal judgment. As illus- trated in <ref type="figure">Fig. 1</ref>, given the fact description of a spe- cific case, a judge in the civil law system first de- cides which law articles are relevant to the sce- nario, and then determines the charges according to the instructions of relevant law articles. Based on these results, the judge further confirms the term of penalty and fines. How to simulate the ju- dicial logic of human judges and model the topo- logical dependencies among legal subtasks will deeply influence the creditability and interpretabil- ity of judgment prediction.</p><p>As stated above, conventional works cannot handle these two challenges due to both the lim- itation of specific tasks and neglecting topological dependencies. To address these issues, we propose to model the multiple subtasks in judgment pre- diction jointly under a novel multi-task learning framework.</p><p>We model the topological dependencies among these subtasks with a Directed Acyclic Graph (DAG), which means all subtasks are arranged in topological order. If the judgment of the j-th sub- task t j depends on the output of the i-th subtask t i , then t i appears earlier than t j in such order. It is notable that such formulation provides an ex- plicit explanation of dependency relations among subtasks.</p><p>Accordingly, we introduce topological learning for LJP and propose a unified framework, named as TOPJUDGE. Specifically, given the encoded representation of the fact description, TOPJUDGE predicts the outputs of all the subtasks following the topological order, and the output of a specific subtask will be affected by all the subtasks it de- pends on. In contrast with conventional multi-task learning, our model takes the explicit topological dependencies of LJP subtasks into consideration and is flexible to handle other LJP subtasks. More- over, the topological order of legal dependencies renders our model interpretable and reliable.</p><p>To verify the effectiveness and flexibility of TOPJUDGE, we conduct a series of experiments on several real-world large-scale datasets. Exper- imental results show that our model achieves sig- nificant and consistent improvements over state- of-the-art models on all tasks and datasets. To summarize, we make several noteworthy contribu- tions as follows:</p><p>(1) We are the first to explore and formalize the multiple subtasks of legal judgment under a joint learning framework. Moreover, we formulate the dependencies among the subtasks of LJP as a form of DAG and introduce this prior knowledge to en- hance judgment prediction.</p><p>(2) We propose a novel judgment prediction framework, TOPJUDGE, to unify multiple sub- tasks and make judgment predictions through topological learning. This model can handle any form of DAG dependent subtasks, which has been verified in the experiments.</p><p>(3) We carry out experiments on several large- scale real-world datasets, and our model signifi- cantly and consistently outperforms all the base- lines on all subtasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Judgment Prediction</head><p>Employing automatic analysis techniques for legal judgment has drawn attention from researchers in the legal field for decades. Early works usually focus on analyzing existing legal cases in specific scenarios with mathematical and statistical algo- rithms <ref type="bibr" target="#b16">(Kort, 1957;</ref><ref type="bibr" target="#b36">Ulmer, 1963;</ref><ref type="bibr" target="#b27">Nagel, 1963;</ref><ref type="bibr" target="#b13">Keown, 1980;</ref><ref type="bibr" target="#b30">Segal, 1984;</ref><ref type="bibr" target="#b17">Lauderdale and Clark, 2012)</ref>.</p><p>With the development of machine learning and text mining techniques, more researchersformal- ize this task under text classification frameworks. Most of these studies attempt to extract efficient features from text content ( <ref type="bibr" target="#b20">Liu and Hsieh, 2006;</ref><ref type="bibr" target="#b18">Lin et al., 2012;</ref><ref type="bibr" target="#b0">Aletras et al., 2016;</ref><ref type="bibr" target="#b32">Sulea et al., 2017</ref>) or case annotations (e.g., dates, terms, lo- cations, and types) ( <ref type="bibr" target="#b12">Katz et al., 2017)</ref>. However, these conventional methods can only utilize shal- low textual features and manually designed fac- tors, both require massive human efforts and usu- ally suffer from the generalization issue when ap- plied to other scenarios.</p><p>Inspired by the success of neural networks on NLP tasks <ref type="bibr" target="#b14">(Kim, 2014;</ref><ref type="bibr" target="#b2">Baharudin et al., 2010;</ref><ref type="bibr" target="#b35">Tang et al., 2015)</ref>, researchers began to handle LJP by incorporating neural models with legal knowl-edge. For example, <ref type="bibr" target="#b23">Luo et al. (2017)</ref> present an attention-based neural network that jointly mod- els charge prediction and relevant article extrac- tion.  incorporate 10 discrimina- tive legal attributes to predict few-shot and con- fusing charges. Nevertheless, these models are de- signed for specific subtasks and thus non-trivial to be extended to more subtasks of LJP with complex dependencies. Besides, <ref type="bibr" target="#b39">Ye et al. (2018)</ref> utilize a Seq2Seq model to generate court views with fact descriptions and predicted charges in Chinese civil law.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Multi-task Learning</head><p>Multi-task learning (MTL) aims to exploit the commonalities and differences across relevant tasks by solving them at the same time. It can transfer useful information among various tasks and has been applied to a wide range of ar- eas, including NLP ( <ref type="bibr" target="#b3">Collobert and Weston, 2008)</ref>, speech recognition ( <ref type="bibr" target="#b4">Deng et al., 2013)</ref>, and com- puter vision <ref type="bibr" target="#b8">(Girshick, 2015;</ref><ref type="bibr" target="#b25">Mao et al., 2017)</ref>.</p><p>There have been numerous successful usages of MTL in NLP tasks. Most works follow the hard parameter sharing setting by sharing repre- sentations or some encoding layers among rele- vant tasks. For example, <ref type="bibr" target="#b3">Collobert and Weston (2008)</ref> use shared word embeddings in solving part-of-speech tagging and semantic role labeling tasks.  share the encoding lay- ers of input queries to address query classification and information retrieval. <ref type="bibr" target="#b5">Dong et al. (2015)</ref> and <ref type="bibr" target="#b24">Luong et al. (2016)</ref> propose to share encoders or decoders to improve one (many) to many neural machine translation. <ref type="bibr" target="#b7">Firat et al. (2016)</ref> propose to share attention mechanism in multi-way, multilin- gual machine translation. Besides hard parameter sharing, soft parameter sharing is another com- mon approach in MTL. It assumes that each task owns its specific parameters and the distance be- tween parameters in different tasks should be close to each other.  In this work, we introduce a topological learn- ing framework TOPJUDGE to handle multiple sub- tasks in LJP. Different to conventional MTL mod- els which focus on how to share parameters among relevant tasks, TOPJUDGE models the explicit de- pendencies among these subtasks with scalable DAG forms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>In the following parts, we will first give the essen- tial definitions of LJP task. We then introduce the DAG dependencies of the subtasks in LJP. And fi- nally, we describe the neural encoder for fact rep- resentation and the judgment predictor for the sub- tasks with DAG dependencies. The overall frame- work of TOPJUDGE has been shown in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Formulation</head><p>We will focus on the LJP tasks in civil law. Sup- pose the fact description of a case is a word se- quence x = {x 1 , x 2 , . . . , x n }, where n is the length of x and each word x i comes from a fixed vocabulary W . Based on the fact description x, the task of LJP T aims to predict judgment results of applicable law articles, charges, term of penalty, fines and so on. Formally, we assume T contains |T | subtasks, i.e., T = {t 1 , t 2 , . . . , t |T | }, each of which is a classification task. For the i-th subtask t i âˆˆ T , we aim to predict the corresponding result y i âŠ† Y i , where Y i is a subtask-specific label set. Take the subtask of charge prediction for example, the corresponding label set should contain Theft, Traffic Violation, Intentional Homicide and so on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">DAG Dependencies of Subtasks</head><p>We assume that the dependencies among multiple subtasks of LJP form a DAG. As a result, the task list T should satisfy topological constraints. For- mally, we use the notation t i Â¡ t j to denote that  the j-th subtask depends on the i-th subtask, and D j = {t i | t i Â¡ t j } to denote the dependency set. The task list T can be ordered to satisfy the fol- lowing constraint</p><formula xml:id="formula_0">i &lt; j, âˆ€(i, j) âˆˆ {(i, j) | ti âˆˆ Dj}.<label>(1)</label></formula><p>We demonstrate the flexibility of our formula- tion by describing two special cases: (1) As shown in <ref type="figure" target="#fig_4">Fig. 3 (a)</ref>, if no dependencies exist, i.e., D j = âˆ…, it corresponds to the typical MTL setting where we simultaneously make predictions for all sub- tasks. (2) As shown in <ref type="figure" target="#fig_4">Fig. 3 (b)</ref>, if each task only depends on its previous task, i.e., D j = {t jâˆ’1 }, it forms a sequential learning process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Neural Encoder for Fact Descriptions</head><p>We employ a fact encoder to generate the fact de- scription's vector representation as the input of TOPJUDGE. In the following part, we briefly in- troduce an encoder based on Convolutional Neural Networks (CNN) <ref type="bibr" target="#b14">(Kim, 2014)</ref>.</p><p>Taking a word sequence x as input, the CNN encoder computes the text representation through three layers, i.e., lookup layer, convolution layer and pooling layer.</p><p>Lookup We first convert each word x i in x into its word embedding x i âˆˆ R k , where k is the di- mension of word embeddings. The word embed- ding sequence is then represented asË†x</p><formula xml:id="formula_1">asË† asË†x = {x1, x2, . . . , xn}.<label>(2)</label></formula><p>Convolution A convolution operation involves a convolution matrix W âˆˆ R mÃ—(hÃ—k) , which is applied to a sliding window of length h with num- ber of filters m to produce a feature map by</p><formula xml:id="formula_2">ci = W Â· x i:i+hâˆ’1 + b,<label>(3)</label></formula><p>where x i:i+hâˆ’1 is the concatenation of word em- beddings within the i-th window and b âˆˆ R m is the bias vector. By applying convolution over each window, we obtain c = {c 1 , . . . , c nâˆ’h+1 }.</p><p>Pooling We apply per-dimension max-pooling over c and obtain the final fact</p><formula xml:id="formula_3">representation d = [d 1 , . . . , d m ] by dt = max(c1,t, . . . , c nâˆ’h+1,t ), âˆ€t âˆˆ [1, m].<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Judgment Predictor over DAG</head><p>Based on the DAG assumption, we obtain an or- dered task list T * = [t 1 , t 2 , . . . , t |T | ]. For each task t j âˆˆ T , we aim to predict its judgment result y j based on the fact representation vector d and the judgment results of its dependent tasks. For prediction, we employ a specific LSTM cell for each task and get the output of each task in the topological order. More specifically, for each task t j âˆˆ T , we obtain its final judgment result through three steps, i.e., cell initialization, task- specific representation, and prediction.</p><p>Cell Initialization As stated above, the predic- tion result of t j will be conditioned on the fact representation d and the outputs of all dependent tasks y k , âˆ€t k âˆˆ D j . Hence, we have</p><formula xml:id="formula_4">Â¯ hj Â¯ cj = t i âˆˆD j W i,j hi ci + b j<label>(5)</label></formula><p>Here, h i and c i are the hidden state and memory cell of t i . Â¯ h j and Â¯ c j are the initial hidden state and memory cell of t j . W i,j and b j are transformation matrices and bias vectors specific to t i and t j .</p><p>Task-Specific Representation Taking the fact representation d, the initial hidden state Â¯ h j , and the initial memory cell Â¯ c j as inputs, we process them with an LSTM cell <ref type="bibr" target="#b10">(Hochreiter and Schmidhuber, 1997</ref>).</p><p>We regard the final hidden state h j as the task- specific representation of task t j . The last cell state c j is used to compose the initial hidden state for the downstream tasks by Eq. 5</p><p>Prediction With the representation h j , we ap- ply an affine transformation followed by softmax and obtain the final prediction asË†yj</p><formula xml:id="formula_5">asË† asË†yj = softmax W p j hj + b p j .<label>(6)</label></formula><p>Here, W p j and b p j are parameters specific to task t j .</p><p>With the prediction resultË†yresultË† resultË†y j , we minimize the cross-entropy betweenË†ybetweenË† betweenË†y j and y j as follows:</p><formula xml:id="formula_6">Lj(Ë† yj, yj) = âˆ’ |Y j | k=1 y j,k log(Ë† y j,k ).<label>(7)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Training</head><p>We use cross-entropy loss for each subtask and sum up losses to train TOPJUDGE:</p><formula xml:id="formula_7">L = |T | j=1 Î»jLj(Ë† yj, yj),<label>(8)</label></formula><p>where Î» j is the weight factor for each subtask t j . The DAG dependencies of subtasks ensure that our model is differentiable and can be trained in an end-to-end fashion. In practice, we set all weights Î» j to 1, and employ Adam (Kingma and Ba, 2015) for optimization. We also apply dropout (Srivas- tava et al., 2014) on the fact representation to pre- vent overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>To evaluate the proposed TOPJUDGE framework, we conduct a series of experiments on LJP over three large-scale datasets of criminal cases in China. We select three representative judgment prediction subtasks for comparison, including law articles, charges, and the terms of penalty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset Construction</head><p>As   <ref type="bibr">3</ref> . The details of CAIL can be found in <ref type="bibr" target="#b37">Xiao et al. (2018)</ref>. For all datasets we mentioned above, as the doc- uments are well-structured and human-annotated, we can easily extract fact descriptions, applica- ble law articles, charges and the terms of penalty from each document using regular expressions. We have manually checked a randomly sampled set of cases, and extraction errors are negligible.</p><p>In real-world scenarios, there are some cases with multiple defendants and multiple charges, which will increase the complexity of judgment prediction. As our model aims to explore the ef- fectiveness of considering topological dependen- cies between various subtasks, we filter out these cases and leave them as our future work.</p><p>Meanwhile, there are also some infrequent charges and law articles, such as money launder- ing, smuggling of nuclear materials and tax dodge. We filter out these infrequent charges and law arti- cles and only keep those with frequencies greater than 100. For the term of penalty, we divide the terms into non-overlapping intervals. We list de- tailed statistics of these datasets in <ref type="table" target="#tab_2">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baselines</head><p>For comparison, we employ the following text classification models and judgment prediction methods as baselines:</p><p>TFIDF+SVM: We employ term-frequency in- verse document frequency (TFIDF) <ref type="bibr" target="#b29">(Salton and Buckley, 1988)</ref> to extract word features and uti- lize SVM <ref type="bibr" target="#b34">(Suykens and Vandewalle, 1999</ref>) for text classification.</p><p>CNN: We employ CNN with multiple filter widths <ref type="bibr" target="#b14">(Kim, 2014</ref>) for fact encoding and classi- fication.</p><p>Hierarchical LSTM (HLSTM):   sification. Based on this work, we employ an LSTM for sentence representations and another one to obtain the representation of complete fact descriptions. Pipeline Model (PM): To demonstrate the advantage of TOPJUDGE on modeling subtasks jointly, we also implement a pipelined method for comparison. Here, we train 3 separate CNN classi- fiers for law articles, charges, and term of penalty. For each subtask, the input is the concatenation of the fact representation and the embeddings for predicted labels of previous subtasks.</p><p>Besides, we compare our model with conven- tional MTL methods that do not consider the de- pendencies among subtasks as in <ref type="figure" target="#fig_4">Fig. 3 (a)</ref>. These methods are denoted as CNN-MTL and HLSTM- MTL, where we implement the fact encoder as in <ref type="figure" target="#fig_2">Fig. 2 using CNN</ref> or HLSTM respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experimental Settings</head><p>As the case documents are written in Chinese with no space between words, we employ THU- LAC ( <ref type="bibr" target="#b33">Sun et al., 2016</ref>) for word segmentation. Af- terward, we adopt the Skip-Gram model <ref type="bibr" target="#b26">(Mikolov et al., 2013</ref>) to pre-train word embeddings on these case documents, with embedding size set to 200 and frequency threshold set to 25.</p><p>For all models, we set the fact representa- tion and task-specific representation size to 256. Meanwhile, we set the maximum sentence length to 128 words and maximum document length to 32 sentences.</p><p>For training, the learning rate of Adam opti- mizer is 10 âˆ’3 , and the dropout probability is 0.5. We also set the batch size to 128 for all models. We train every model for 16 epochs, and evaluate the final model on the testing set.</p><p>We employ accuracy (Acc.), macro-precision (MP), macro-recall (MR) and macro-F 1 (F 1 ) as evaluation metrics.</p><p>Here, the macro- precision/recall/F 1 are calculated by averaging the precision/recall/F 1 of each category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results and Analysis</head><p>We evaluate the performance on three LJP sub- tasks, including law articles (denoted as t 1 ), charges (denoted as t 2 ), and the terms of penalty (denoted as t 3 ). Experimental results are shown in <ref type="table" target="#tab_4">Tables 2, 3</ref>, and 4. Note that, we implement TOP- JUDGE with the dependency relationship in <ref type="figure" target="#fig_4">Fig. 3  (c)</ref>, i.e.,  <ref type="table">Table 4</ref>: Judgment prediction results on CAIL. Note that, "-" means the model does not converge within 128 epochs.</p><formula xml:id="formula_8">D1 = Ï†, D2 = {t1}, D3 = {t1, t2}.<label>(9)</label></formula><p>This means that the prediction of charges depends on law articles, and the prediction of term of penalty depends on both law articles and charges. Such explicit dependencies conform to the judi- cial logic of human judges, which will be verified in later sections. These results show that:</p><p>(1) The proposed TOPJUDGE model outper- forms other baselines significantly on most sub- tasks and datasets. It demonstrates the effective- ness and robustness of our proposed framework.</p><p>(2) Compared with conventional single-task models, e.g., CNN and HLSTM, MTL methods take advantage of the correlation among relevant subtasks and thus achieve promising improve- ments. It indicates the importance of modeling LJP subtasks jointly.</p><p>(3) Moreover, TOPJUDGE significantly outper- forms typical MTL models, especially on the pre- diction of charges and the terms of penalty. It veri- fies the rationality and importance of modeling de- pendencies over LJP subtasks with DAG.  To further illustrate the significance of legal de- pendencies and explore how the DAG dependen- cies influence the performance, we evaluate the performance of TOPJUDGE under various DAG architectures. Using Eq. 9 as the full dependen- cies, we remove the dependency of t 3 Â¡ t 1 (law articles and term of penalty, corresponding to the sequential form in <ref type="figure" target="#fig_4">Fig. 3)</ref>, t 2 Â¡ t 1 (law articles and charges), and all dependencies respectively. Re- sults are summarized in <ref type="table" target="#tab_8">Table 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Ablation Analysis</head><p>We observe that the performance of TOPJUDGE decreases on all tasks after removing either depen- dency. More specifically, when we dropped de- pendencies t 3 Â¡ t 1 and t 2 Â¡ t 1 respectively, sig- nificant decreases are observed for t 3 and t 2 corre- spondingly. This demonstrates that incorporating dependencies is beneficial for relevant subtasks, verifying its guiding role in the civil law system.</p><p>Meanwhile, we note that there are two main differences between TOPJUDGE and traditional multi-task models, namely the Cell Initialization and the Task-Specific Representation. We can see that if we eliminate Cell Initialization from TOPJUDGE, the dependencies will not be rep- resented in the model and it will become sim- ilar to CNN-MTL. If we eliminate the Task- Specific Representation from TOPJUDGE, TOP- JUDGE will become the same as the Pipeline Model. In a word, the main improvement of our models comes from the combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Case Study</head><p>We give some intuitive examples to demonstrate the significance of TOPJUDGE on LJP subtasks.</p><p>As shown in <ref type="table">Table 6</ref>, case 1 is about negligently causing a fire. The fact description of this case states "The defendant pulled up weeds in the fields and piled them up in haphazard stacks. Afterward, he lighted them up and triggered the forest fires..." TOPJUDGE predicts all judgments correctly, while CNN-MTL fails to predict the charge and term of penalty. Moreover, CNN-MTL obtains conflicting judgments, i.e., "crime of arson" and "1-2 years", due to its neglecting of dependencies of these sub- tasks. According to the legal provisions of law ar- ticle 115, the crime of arson should be sentenced to more than 10 years.   <ref type="table">Table 6</ref>: Example cases and their prediction results.</p><p>Case 2 in <ref type="table">Table 6</ref> is another evidence of the in- sufficiency of conventional MTL on LJP. This case is about picking quarrels and provoking troubles. Both CNN-MTL and TOPJUDGE succeed to pre- dict the relevant law articles (i.e., law article 293 of the crime of affray). However, CNN-MTL is confused between "crime of affray" and "crime of intentional destruction or damage of properties", two charges similar to each other. Conversely, TOPJUDGE can utilize the prediction result of law articles and consequently prevent this confusion.</p><p>To summarize, modeling the explicit dependen- cies among various subtasks can remarkably help the LJP model address the issue of predicting con- flicting results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Error Analysis</head><p>Prediction errors induced by our proposed model can be traced down into the following causes.</p><p>Data Imbalance. For the subtasks of law articles and charges, our model achieves more than 90% on accuracy, while only about 60% for macro-F1. This issue is much more severe on the subtask of the term of penalty, which our model yields a poor performance of only 30% macro-F1. The bad performance is mainly due to the imbal- ance of category labels, e.g., there are only a few training instances where the term is "life imprison- ment or death penalty". Most judgment prediction approaches perform poorly (especially for Recall) on these labels as listed in <ref type="figure" target="#fig_7">Fig. 4</ref>. Instance weight- ing schemes can be introduced to address this is- sue in future works.</p><p>Incomplete Information. Following existing LJP works, we predict the final judgment accord- ing to the fact descriptions, which is incomplete as compared to the whole materials relevant to this case. In Chinese Law, there are certain circum- stances under which the sentence can be short- ened. For example, minors usually receive a light- ened penalty, and those guilty of misdemeanors are allowed for a secured pending trial while pay- ing a security deposit. However, such informa- tion is not included in the fact descriptions. The lack of such information also raises difficulties for judgment prediction, especially for the prediction of the term of penalty. In <ref type="figure" target="#fig_7">Fig. 4</ref>, we can see that the highest error rate comes from the cases with a short term of penalty. Our model fails to distin- guish the cases with no penalty and those with 0-6 months term of imprisonment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we focus on the task of legal judg- ment prediction (LJP) and address multiple sub- tasks of judgment predication with a topological learning framework. To be specific, we formalize the explicit dependencies over these subtasks in a DAG form, and propose a novel MTL framework, TOPJUDGE, by integrating the DAG dependen- cies. Experimental results on three LJP subtasks and three different datasets show that our TOP- JUDGE outperforms all single-task baselines and conventional MTL models consistently and signif- icantly.</p><p>In the future, we will seek to explore the follow- ing directions: (1) We will explore more LJP sub- tasks and more scenarios of cases such as multiple defendants and charges to investigate the effective- ness of TOPJUDGE. (2) We will explore how to incorporate into LJP the temporal factors, which are not considered in this work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>On the early morning of July 24, 2017 , the defendant XX stole cash 8500 yuan and T-shirts, jackets, pants, shoes, hats (identified a total value of 574. 2 yuan) in Beijing Lining storeâ€¦ Law Article 264: [The crime of theft] Whoever steals a relatively large amount of public or private property or commits theft repeatedly fixed-term imprisonment of not more than three years, criminal detention or public surveillance.</head><label>20172</label><figDesc>Figure 1: An illustration of the judicial logic of human judges in civil law system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>For example, Duong et al. (2015) employ L2 distance for regularization, while Yang and Hospedales (2017) use the trace norm. Liu et al. (2016) introduce gates among task-specific RNN layers to control the information flow. Ruder et al. (2017) introduce a model which can de- cide the amount of sharing between different NLP tasks. There are also some works focusing on in- creasing tasks (Hashimoto et al., 2017) or handing unlabeled data (Augenstein et al., 2018).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The framework of TOPJUDGE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Fig 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Three typical forms of DAG dependencies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Fact-Law Attention Model: Luo et al. (2017) proposes a neural charge prediction model by cap- turing the interaction between fact descriptions and applicable laws with attention mechanism.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Methods</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The confusion matrix in the subtask of predicting the term of penalty on the PKU dataset. The rows denote the ground truth while the columns denote the prediction results.</figDesc><graphic url="image-2.png" coords="8,342.84,82.63,176.42,176.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>The statistics of different datasets. 

(Chinese AI and Law Challenge) is another crim-
inal case dataset for competition released by the 
Supreme People's Court of China </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head></head><label></label><figDesc>Tang et al. (2015) employs hierarchical neural networks to learn document representations in sentiment clas-</figDesc><table>Tasks 
Law Articles 
Charges 
The Term of Penalty 

Metrics 
Acc. MP 
MR 
F1 
Acc. MP 
MR 
F1 
Acc. MP 
MR 
F1 

Single 

TFIDF+SVM 
82.4 45.5 26.7 30.2 82.2 47.4 27.9 31.3 48.5 36.0 16.7 16.5 
CNN 
92.5 46.9 38.4 40.0 92.3 41.2 32.3 33.7 57.4 35.6 22.2 22.7 
HLSTM 
91.4 38.6 37.3 36.9 91.8 37.8 36.0 35.2 56.1 22.5 25.0 23.3 

Multi 

Fact-Law Att. 
93.5 50.9 45.6 45.9 93.4 47.2 41.4 41.5 56.3 31.3 26.4 26.7 
PM 
93.7 51.9 44.1 44.9 93.6 45.5 39.1 39.3 58.2 38.2 24.9 26.8 
CNN-MTL 
94.3 53.0 46.0 46.9 94.1 48.5 41.7 42.5 58.7 39.9 28.8 29.4 
HLSTM-MTL 92.4 45.5 41.4 41.0 92.3 41.9 36.6 35.9 54.9 30.6 26.6 26.4 

Ours 
TOPJUDGE 
94.4 53.9 47.3 48.2 94.9 53.9 48.2 49.1 58.8 40.2 32.9 32.8 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 2 : Judgment prediction results on CJO.</head><label>2</label><figDesc></figDesc><table>Tasks 
Law Articles 
Charges 
The Term of Penalty 

Metrics 
Acc. MP 
MR 
F1 
Acc. MP 
MR 
F1 
Acc. MP 
MR 
F1 

Single 

TFIDF+SVM 
80.9 51.3 32.6 36.4 81.0 53.4 35.4 38.7 45.3 30.4 17.4 17.2 
CNN 
93.1 64.3 52.6 54.3 93.3 61.9 49.3 51.1 57.6 24.1 23.1 23.3 
HLSTM 
91.7 54.4 53.4 50.9 91.9 52.5 48.9 47.3 54.3 20.6 21.7 19.0 

Multi 

Fact-Law Att. 
93.9 68.1 63.4 63.5 94.2 65.8 58.5 58.7 55.7 27.7 27.4 26.5 
PM 
94.4 69.6 61.0 62.2 94.3 65.1 56.2 57.2 58.2 36.2 26.4 27.1 
CNN-MTL 
95.0 73.8 64.9 66.0 95.0 70.7 60.6 61.7 58.4 36.0 28.7 28.9 
HLSTM-MTL 93.9 71.2 64.6 65.1 93.8 67.8 60.0 60.7 55.4 31.3 26.2 25.7 

Ours 
TOPJUDGE 
95.4 76.4 67.6 68.4 95.6 75.9 69.6 70.9 57.8 38.9 32.1 31.8 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 : Judgment prediction results on PKU.</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 5 : Ablation analysis on PKU.</head><label>5</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="3"> http://cail.cipsc.org.cn/index.html</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgements</head><p>This work is supported by the National Nat-ural Science Foundation of China (NSFC No. 61572273, 61772302) and the research fund of Powerlaw Inc. for AI+Law Technology. This work is also funded by China Association for Sci-ence and Technology (2016QNRC001). Tu is also supported by China Postdoctoral Innovative Talent Support Programme.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Predicting judicial decisions of the european court of human rights: A natural language processing perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaos</forename><surname>Aletras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Tsarapatsanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Preotiuc-Pietro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Lampos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PeerJ Computer Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multi-task learning of pairwise sequence classification tasks over disparate label spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>SÃ¸gaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A review of machine learning algorithms for text-documents classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baharum</forename><surname>Baharudin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khairullah</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Advances in Information Technology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="20" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: Deep neural networks with multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">New types of deep neural network learning for speech recognition and related applications: An overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="8599" to="8603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multi-task learning for multiple language translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daxiang</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dianhai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1723" to="1732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Low resource dependency parsing: Cross-lingual parameter sharing in a neural network parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="845" to="850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multi-way, multilingual neural machine translation with a shared attention mechanism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="866" to="875" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A joint many-task model: Growing a neural network for multiple nlp tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1923" to="1933" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jurgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Few-shot charge prediction with discriminative legal attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zikun</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cunchao</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A general approach for predicting the behavior of the supreme court of the united states</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Daniel Martin Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">I</forename><surname>Bommarito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Blackman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Plos one</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Mathematical models for legal prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Keown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer/LJ</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">829</biblScope>
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Predicting supreme court decisions mathematically: A quantitative analysis of the &quot;right to counsel&quot; cases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><surname>Kort</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Political Science Review</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="1957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The supreme court&apos;s many median justices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom S</forename><surname>Lauderdale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Political Science Review</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="847" to="866" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Exploiting machine learning models for chinese legal documents labeling, case classification, and sentencing prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung</forename><surname>Ting Kuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tung Jia</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Processdings of ROCLING</title>
		<meeting>essdings of ROCLING</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page">140</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Case instance generation and refinement for case-based criminal summary judgments in chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaolin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Cheng Tsung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><forename type="middle">How</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Informationence &amp; Engineering</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="783" to="800" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Exploring phrase-based classification of judicial documents for criminal charges in chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaolin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chwen Dar</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ISMIS</title>
		<meeting>ISMIS</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="681" to="690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Recurrent neural network for text classification with multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Representation learning using multi-task deep neural networks for semantic classification and information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye-Yi</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="912" to="921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning to predict charges for criminal cases with legal basis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingfeng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multi-task sequence to sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kaiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">What can help pedestrian detection?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayuan</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tete</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhimin</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3127" to="3136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Applying correlation analysis to case prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Stuart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Texas Law Review</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page">1006</biblScope>
			<date type="published" when="1963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Bingel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.08142</idno>
		<title level="m">Isabelle Augenstein, and Anders SÃ¸gaard. 2017. Learning what to share between loosely related tasks</title>
		<imprint/>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Termweighting approaches in automatic text retrieval. Information processing &amp; management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Buckley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="513" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Predicting supreme court cases probabilistically: The search and seizure cases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jeffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Segal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Political Science Review</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="891" to="900" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Exploring the use of text classi cation in the legal domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Octavia</forename><forename type="middle">Maria</forename><surname>Sulea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihaela</forename><surname>Vela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ASAIL workshop</title>
		<meeting>ASAIL workshop</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Thulac: An efficient lexical analyzer for chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxiong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaixu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhipeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Least squares support vector machine classifiers. Neural processing letters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Johan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joos</forename><surname>Suykens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vandewalle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="293" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Document modeling with gated recurrent neural network for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Quantitative analysis of judicial processes: Some practical and theoretical applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sidney</forename><surname>Ulmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Law and Contemporary Problems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page">164</biblScope>
			<date type="published" when="1963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Cail2018: A large-scale legal dataset for judgment prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaojun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoxi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhipeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cunchao</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.02478</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deep multi-task representation learning: A tensor factorisation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Interpretable charge predictions for criminal cases: Learning to generate court views from fact descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhunchen</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Chao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
