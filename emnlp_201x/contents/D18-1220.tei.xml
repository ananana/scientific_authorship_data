<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Knowledge Hunting Framework for Common Sense Reasoning</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018. 1949</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Emami</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">McGill University</orgName>
								<address>
									<region>Mila</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noelia</forename><surname>De</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">La</forename><surname>Cruz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">McGill University</orgName>
								<address>
									<region>Mila</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Montreal</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaheer</forename><surname>Suleman</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Montreal</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jackie</forename><surname>Chi</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kit</forename><surname>Cheung</surname></persName>
							<email>jcheung@cs.mcgill.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">McGill University</orgName>
								<address>
									<region>Mila</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Knowledge Hunting Framework for Common Sense Reasoning</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1949" to="1958"/>
							<date type="published">October 31-November 4, 2018. 2018. 1949</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We introduce an automatic system that achieves state-of-the-art results on the Wino-grad Schema Challenge (WSC), a common sense reasoning task that requires diverse, complex forms of inference and knowledge. Our method uses a knowledge hunting module to gather text from the web, which serves as evidence for candidate problem resolutions. Given an input problem, our system generates relevant queries to send to a search engine , then extracts and classifies knowledge from the returned results and weighs them to make a resolution. Our approach improves F1 performance on the full WSC by 0.21 over the previous best and represents the first system to exceed 0.5 F1. We further demonstrate that the approach is competitive on the Choice of Plausible Alternatives (COPA) task, which suggests that it is generally applicable.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The importance of common-sense reasoning in natural language processing, particularly for syn- tactic and semantic disambiguation, has long been recognized. Almost 30 years ago, <ref type="bibr" target="#b4">Dahlgren et al. (1989)</ref> proposed systems that use common sense to disambiguate parse trees, word senses, and quantifier scope. Although the resolution of cer- tain ambiguities depends chiefly on linguistic pat- terns (e.g., the number and gender of an antecedent for pronoun disambiguation), many cases de- pend on world knowledge, shared points of refer- ence, and an understanding of what is plausible- concepts often grouped under the term "common sense."</p><p>Various tasks have been devised to test common-sense reasoning in automatic systems. Two of the most popular are the Winograd Schema Challenge (WSC) ( <ref type="bibr" target="#b15">Levesque et al., 2011</ref>) and the Choice of Plausible Alternatives (COPA) <ref type="bibr" target="#b26">(Roemmele et al., 2011</ref>). Both require a system to assess the relative plausibility of two scenarios.</p><p>WSC problems are short passages containing a target pronoun that must be correctly resolved to one of two possible antecedents. They come in pairs which differ slightly and result in adverse correct resolutions. As an example:</p><p>(1) a. Jim yelled at Kevin because he was so upset. (Answer: Jim) b. Jim comforted Kevin because he was so upset. (Answer: Kevin)</p><p>WSC problem pairs ("twins," using the termi- nology of <ref type="bibr" target="#b8">Hirst (1988)</ref>) are carefully controlled such that heuristics involving syntactic salience, the number and gender of the antecedent, or other simple syntactic and semantic cues are ineffec- tive. This distinguishes the task from the standard coreference resolution problem. Performant sys- tems must make common sense inferences; i.e., that someone who yells is likely to be upset, and that someone who is upset tends to be comforted. Additional examples are shown in <ref type="table">Table 1</ref>. WSC problems are simple for people to solve (human participants in one study performed at 92% accuracy <ref type="bibr" target="#b2">(Bender, 2015)</ref>) but difficult for au- tomatic systems. This is because common sense reasoning encompasses many types of reasoning (causal, spatio-temporal, etc.) and requires a wide breadth of knowledge.</p><p>COPA is a related task that tests a system's abil- ity to recognize causality <ref type="bibr" target="#b26">(Roemmele et al., 2011)</ref>. Each instance comprises a premise and two candi- date causes or effects, where the correct choice is the candidate that is more plausible.</p><p>Previous approaches to common sense reason- ing, for instance based on logical formalisms <ref type="bibr" target="#b0">(Bailey et al., 2015)</ref> or deep neural models ( <ref type="bibr" target="#b17">Liu et al., 2016)</ref>, have solved only restricted subsets of the WSC with high precision. They have been tailored 1 a) The man couldn't lift his son because he was so weak. (Answer: the man) 1 b) The man couldn't lift his son because he was so heavy. (Answer: son) 2 a) The older students were bullying the younger ones, so we punished them. (Answer: the older students) 2 b) The older students were bullying the younger ones, so we rescued them. <ref type="table">(Answer: the younger ones)</ref> 3 a)</p><p>Sam tried to paint a picture of shepherds with sheep, but they ended up looking more like golfers. <ref type="table">(Answer: shepherds)</ref> 3 b) Sam tried to paint a picture of shepherds with sheep, but they ended up looking more like dogs.</p><p>(Answer: sheep) <ref type="table">Table 1</ref>: Examples of Winograd instances.</p><p>for manually selected subsets that demand a spe- cific type of reasoning ( <ref type="bibr" target="#b28">Sharma et al., 2015;</ref><ref type="bibr" target="#b17">Liu et al., 2016</ref>). Others have developed systems for relaxed common sense datasets with looser con- straints <ref type="bibr" target="#b24">(Rahman and Ng, 2012;</ref><ref type="bibr" target="#b22">Peng et al., 2015;</ref><ref type="bibr" target="#b13">Kruengkrai et al., 2014</ref>). In parallel, more gen- eral work on common sense reasoning aims to de- velop a repository of common knowledge using semi-automatic methods (e.g., <ref type="bibr">Cyc (Lenat, 1995)</ref> and ConceptNet ( <ref type="bibr" target="#b16">Liu and Singh, 2004)</ref>). However, such knowledge bases are necessarily incomplete.</p><p>In this work, we propose a general method to resolve common sense problems like WSC and COPA. Contrary to previous work, we aim to solve all problem instances rather than a restricted sub- set. Our method is based on on-the-fly knowl- edge hunting and operates in four stages. First, it parses an input problem into a representation schema. Next it generates search queries from the populated schema. It sends these to a search en- gine, and the next stage parses and filters the re- sults. Finally, it classifies and weighs the results as evidence for respective candidate resolutions.</p><p>Our approach arises from the hypothesis that there is too much common sense to encode it all statically; e.g., within a knowledge base or a neu- ral model (using existing techniques). Even mod- ern NLP corpora composed of billions of words are unlikely to offer good coverage of common sense, or if they do, instances of specific knowl- edge are likely to be "long-tailed" and difficult for statistical systems to model effectively. Informa- tion retrieval (IR) techniques can sidestep these issues by returning targeted results and by using the entire indexed internet as a knowledge source. Scenarios that appear in natural text can offer im- plicit or explicit evidence for the plausibility of related scenarios in common sense problems. To solve (1a), the following search result contains the relevant knowledge without the original ambigu- ity:</p><p>(2) I got really upset with her and I started to yell at her because... Here, the same entity, I, is the subject of both upset and yell at, which is strong evidence for resolving the original statement. This information can be extracted from a syntactic parse of the retrieved passage with standard NLP tools.</p><p>As we will demonstrate experimentally, our knowledge hunting approach achieves an F1 score of 0.51 on the WSC, improving significantly over the previous state-of-the-art (0.3 F1). When tested on the similar COPA task, a simplified knowl- edge hunting system performs competitively with the previous best. To our knowledge, this is the first method that tackles multiple common sense tasks with strong performance on each. Thus, knowledge-hunting embodies some of the general capabilities that we desire of automatic systems for common sense reasoning. <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There is increasing interest in using IR approaches to address difficult coreference problems. For ex- ample, a recent system (Rahman and Ng, 2012) uses web query information to retrieve evidence for the coreference decision in a Winograd-like corpus. Other systems ( <ref type="bibr" target="#b11">Kobdani et al., 2011;</ref><ref type="bibr" target="#b25">Ratinov and Roth, 2012;</ref><ref type="bibr" target="#b1">Bansal and Klein, 2012;</ref><ref type="bibr" target="#b32">Zheng et al., 2013;</ref><ref type="bibr" target="#b22">Peng et al., 2015;</ref><ref type="bibr" target="#b28">Sharma et al., 2015</ref>) rely on similar techniques, i.e., us- ing search-query counts or co-occurrence statistics and word alignment methods to relate antecedents with pronouns.</p><p>Most recent approaches have tackled the Wino- grad problem by simplifying it in one of two ways. First, systems have been developed exclusively for Rahman and Ng's expanded Winograd-like cor- pus. These include Rahman and Ng (2012)'s system itself, achieving 73% accuracy, and <ref type="bibr" target="#b22">Peng et al. (2015)</ref>'s system (76%). <ref type="bibr" target="#b13">Kruengkrai et al. (2014)</ref> use sentence alignment of web query snip- pets to achieve 70% accuracy on a subset of the expanded corpus. Many instances in this corpus can be resolved using associations between candi- date antecedents and the query predicate. For ex- ample, "Lions eat zebras because they are preda- tors." Many of the above systems simply query "Lions are predators" versus "zebras are preda- tors" to make a resolution decision. This exploita- tion is often the top contributor to such systems' overall accuracy <ref type="bibr" target="#b24">(Rahman and Ng, 2012)</ref>, but fails to apply in the majority (if not all) of the origi- nal Winograd instances. <ref type="bibr">2</ref> Our work alleviates this issue by generating search queries that are based exclusively on the predicates of the Winograd in- stance, not the antecedents, and by considering the strength of the evidence.</p><p>Other systems do tackle the original, more diffi- cult Winograd instances, but only a small, author- selected subset. The selection is based often on knowledge-type constraints. <ref type="bibr" target="#b28">Sharma et al. (2015)</ref>'s knowledge-hunting module focused on a subset of 71 instances that exhibit causal rela- tionships; <ref type="bibr" target="#b17">Liu et al. (2016)</ref>'s neural association model focused on a similar causal subset of 70 instances, for which events were extracted man- ually; and finally, a recent system by Huang and Luo (2017) focused on 49 instances. While these approaches demonstrate that difficult coreference problems can be resolved when they adhere to cer- tain knowledge or structural constraints, they may fail to generalize to other settings. This factor of- ten goes unnoticed when systems are compared only in terms of precision; accordingly, we use an F1-driven comparison that does not enable preci- sion boosting at the cost of recall.</p><p>Concurrently with our work, Trinh and Le (2018) introduced a system composed of 14 en- sembled language models, pre-trained in an unsu- pervised manner, that achieves up to 63.7% accu- racy on the Winograd Schema Challenge. Com- pared to our approach, their method requires train- ing multiple language models with vast amounts of data, which is much more expensive.</p><p>Other Common-sense Tasks: There are vari- ous other Turing-test alternatives that directly or indirectly assess common-sense reasoning. These include Pronoun Disambiguation Problems (more generalized, Winograd-like passages without the twist of a special word or twin) <ref type="bibr" target="#b21">(Morgenstern et al., 2016</ref>), the Narrative cloze task <ref type="bibr" target="#b29">(Taylor, 1953)</ref>, or its more difficult counterpart, the NarrativeQA Reading Comprehension Challenge <ref type="bibr" target="#b12">(Kočisk`Kočisk`y et al., 2017)</ref>.</p><p>The COPA task was proposed by <ref type="bibr" target="#b26">Roemmele et al. (2011)</ref>, who also measured the perfor- mance of several systems. The most successful used Pointwise Mutual Information (PMI) statis- tics <ref type="bibr" target="#b3">(Church and Hanks, 1990</ref>) between words in the premise and each alternative obtained from a large text corpus (as an implicit way to estimate causal association). More recent work showed that applying the same PMI-based technique on a cor- pus of stories yields better results ). The current state-of-the-art approaches leverage co-occurrence statistics extracted using causal cues ( <ref type="bibr" target="#b19">Luo et al., 2016;</ref><ref type="bibr" target="#b27">Sasaki et al., 2017</ref>).</p><p>Extended Work: Previously, <ref type="bibr" target="#b5">Emami et al. (2018)</ref> proposed a similar knowledge hunting framework to tackle the Winograd Schema Chal- lenge. This work modifies and extends their approach. Our modifications include a query- filtering step and various other tweaks that im- prove results by 0.05 F1 for our best model. In addition, we added further experiments and an ab- lation study that explores the performance of dif- ferent model components. Finally, we adapted our method to a new dataset, COPA, on which we achieve respectable results. Accordingly, we change the general takeaway of the previous work from a method with strong performance on a sin- gle dataset to one that generalizes and performs well on various tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Semantic Representation Schema</head><p>The first step is to perform a partial parse of each instance into a shallow semantic representation; that is, a general skeleton of each of the impor- tant semantic components in the order that they appear. This is performed using rules related to the syntactic parse of the sentence determined by Stanford CoreNLP ( <ref type="bibr" target="#b20">Manning et al., 2014</ref>).</p><p>In general, Winograd instances can be separated into a context clause, which introduces the two competing antecedents, and a query clause, which contains the target pronoun to be resolved. We use the following notation to define the components in our representation schema:</p><formula xml:id="formula_0">E 1 , E 2</formula><p>the candidate antecedents P red C the context predicate + discourse connective P the target pronoun P red Q the query predicate E 1 and E 2 are noun phrases in the sentence. In the WSC, these two are specified without ambiguity. P red C is the context predicate composed of the verb phrase that relates both antecedents to some event. The context contains E 1 , E 2 , and the con- text predicate P red C . The context and the query clauses are often connected by a discourse connec- tive +. The query contains the target pronoun, P , which is also specified unambiguously. In addi- tion, preceding or succeeding P is the query pred- icate, P red Q , a verb phrase involving the target pronoun. <ref type="table" target="#tab_1">Table 2</ref> shows sentence pairs in terms of each of these components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Query Generation</head><p>Based on the parse, the system generates queries to send to a search engine. The goal is to retrieve text snippets that resemble the original instance. Queries are of the form:</p><p>+T erm C +T erm Q −"Winograd"−E 1 We assume that the search queries are composed of two components, T erm C and T erm Q , which are strings that represent the events occurring in the first (context) and second (query) clause of the sentence, respectively. By excluding search results that may contain Winograd or E 1 , we ensure that we do not cheat by retrieving some rewording of the original Winograd instance.</p><p>The next task is to construct two query sets, C and Q, whose elements are possible entries for T erm C and T erm Q , respectively. We identify the root verbs in the context and query clauses, along with any modifying adjective, using the depen- dency parse of the sentence determined by Stan- ford CoreNLP ( <ref type="bibr" target="#b20">Manning et al., 2014</ref>). We add the root verbs and adjectives into the sets C and Q along with their broader verb phrases (again iden- tified directly using the dependency tree).</p><p>Augmenting the query set with WordNet We use WordNet <ref type="bibr" target="#b10">(Kilgarriff, 2000</ref>) to construct an augmented query set that contains synonyms for the verbs and adjectives involved in a representa- tion. In particular, we include the synonyms listed for the top synset of the same part of speech as the extracted verb or adjective.</p><p>Query filtering Automated query generation sometimes yields terms that are irrelevant to the disambiguation task. This can add noise to the results. To address this, we implement a seman- tic similarity algorithm that filters root verbs and modifying adjectives from the query sets accord- ing to their relevance to other terms. We esti- mate relative relevance using Wu-Palmer ( <ref type="bibr" target="#b31">Wu and Palmer, 1994)</ref> similarity scores from WordNet and filter as follows. For each passage, the semantic filter (i) computes similarity scores for every pos- sible combination of {T erm C , T erm Q } (if both T erm C and T erm Q are single words); (ii) deter- mines the maximum similarity score s; and (iii) discards any term whose highest similarity score from step (i) is less than αs, where 0 &lt; α &lt; 1. We tune α, a hyperparameter, on Rahman and Ng's expanded corpus <ref type="bibr" target="#b24">(Rahman and Ng, 2012)</ref>.</p><p>We hypothesize that terms in the query and con- text clauses more pertinent to the task have higher mutual similarity scores than irrelevant terms. To illustrate this, consider the query sets generated for Example 2a, <ref type="table">Table 1</ref>: {"bullying", "younger", "older"} and {"punished"}. Applying the se- mantic filter yields the new sets {"bullying"} and {"punished"}, where the irrelevant terms younger and older have been removed.</p><p>Manual query construction To understand the impact of the query generation step, we also manu- ally produced representations for all Winograd in- stances. We limited the size of these sets to five to prevent a blowing-up of search space during knowledge extraction. In  Sentence: The trophy doesn't fit into the brown suitcase because it is too large.</p><p>Query Generation Method C Q Automatic {"doesn't fit into", "brown", "fit" } {"large", "is too large"} Automatic, with synonyms {"doesn't fit into", "brown", "accommo- date", "fit", "suit" } {"large", "big", "is too large" } Manual {"doesn't fit into", "fit into","doesn't fit" } {"is too large", "too large", "large" } <ref type="table" target="#tab_0">Table 3</ref>: Query generation techniques on an example Winograd sentences amples of generated queries for C and Q using the various techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Parsing the Search Results</head><p>From the search results, we obtain a set of text snippets that we filter for similarity to the original problem instance. First, T erm C and T erm Q are restricted to occur in the same snippet, but are allowed to occur in any order. We filter the passed sentences further to ensure that they contain at least two entities that corefer. These may be structured as follows:</p><formula xml:id="formula_1">E 1 P red C E 2 + E 3 P red Q E 1 P red C E 2 + P red Q E 3 E 1 P red C + E 3 P red Q E 1 P red C + P red Q E 3</formula><p>We call these evidence sentences. They ex- hibit a structure similar to the corresponding Winograd instance, but with different entities and event order. P red C and P red Q (resulting from the queries T erm C and T erm Q , resp.) should be similar if not identical to P red C and P red Q from the Winograd sentence. However, E 1 , E 2 , and E 3 may not have the same semantic type, potentially simplifying their coreference resolution. A sentence for which E 3 refers to E 1 is subsequently labelled evidence-agent, and one for which E 3 refers to E 2 , evidence-patient. The exception to this rule is when an event occurs in the passive voice (e.g., was called), which reverses the conventional order of the agent and patient. Another exception is in the case of causative alternation, where a verb can be used both transitively and intransitively. The latter case can also reverse the conventional order of the agent and patient (e.g., he opened the door versus the door opened).</p><p>As an example of coreference simplification, a valid evidence sentence is: He tried to call her but she wasn't available. Here, the sentence can be resolved on the basis of the gender of the antecedents; E 3 (the pronoun she) refers to the patient, E 2 . Accordingly, the sentence is considered an evidence-patient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Antecedent Selection</head><p>We collect and reason about the set of retrieved sentences using a selection process that (i) re- solves E 3 to either E 1 or E 2 using CoreNLP's coreference resolution module (rendering them evidence-agent or evidence-patient); and (ii) uses both the count and individual features of the evi- dence sentences to resolve the original Winograd instance. For example, the more similar evidence- agents there are for the sentence Paul tried to call George on the phone, but he wasn't successful, the more likely it is that the process would guess Paul, the agent, to be the correct referent of the target pronoun.</p><p>To map each sentence to either an evidence- agent or evidence-patient, we developed a rule- based algorithm that uses the syntactic parse of an input sentence. This algorithm outputs an ev- idence label along with a list of features. The fea- tures indicate: which two entities co-refer accord-ing to Stanford CoreNLP's resolver, and to which category of E 1 , E 2 , or E 3 each belong; the token length of the sentence's search terms, T erm C and T erm Q ; the order of the sentence's search terms; whether the sentence is in active or passive voice; and whether or not the verb is causative alternat- ing. Some of these features are straightforward to extract (like token length and order, and corefer- ring entities given by CoreNLP), while others re- quire various heuristics. To map each coreferring entity in the snippet to E 1 , E 2 , or E 3 (correspond- ing loosely to context subject, context object, and query entity, respectively), we consider their posi- tion relative to the predicates in the original Wino- grad instance. That is, E 1 precedes T erm C , E 2 succeeds T erm C , and E 3 may precede or succeed T erm Q depending on the Winograd instance. To determine the voice, we use a list of auxiliary verbs and verb phrases (e.g., was, had been, is, are being) that switch the voice from active to pas- sive (e.g., "they are being bullied" vs "they bul- lied") whenever one of these precedes T erm C or T erm Q (if they are verbs). Similarly, to identify causative alternation, we use a list of causative al- ternating verbs (e.g., break, open, shut) to identify the phenomenon whenever T erm C or T erm Q is used intransitively.</p><p>These features determine the evidence label, evidence-agent (EA) or evidence-patient (EP), ac- cording to the following rules: <ref type="formula">(5)</ref> Cases <ref type="formula">(2)</ref>, <ref type="formula">(4)</ref>, and (5) account for the passive and causative constructions, which alter the mapping from syntactic role to semantic role. In addition to determining the evidence label, the features are used in a heuristic that generates scores (called strengths) for each evidence sen- tence:</p><formula xml:id="formula_2">L(e) =                EA, if E 3 refers to E 1 , active (1) EA, if E 3 refers to E 2 , passive (2) EP, if E 3 refers to E 2 , active (3) EP, if E 3 refers to E 1 , passive (4) EP, if E 3 refers to E 1 , causative</formula><p>Str(e) = LenScore(e) + OrderScore(e)</p><formula xml:id="formula_3">LenScore(e) =      2, if len(T erm Q ) &gt; 1 2, if len(T erm C ) &gt; 1 1, otherwise OrderScore(e) = 2, if T erm C T erm Q 1, if T erm Q T erm C</formula><p>As an example of scoring for an actual snip- pet, let us consider "She tried to call for him and then search for him herself, but wasn't suc- cessful," returned for T erm C =tried to call, and T erm Q =wasn't successful.</p><p>Here, both T erm Q and T erm C are multi-word search terms, and T erm C precedes T erm Q as in the original Winograd sentence. Its overall ev- idence strength is 4, the highest possible score. On the other hand, for the retrieved snippet "Has your husband tried Sudafed and was it success- ful?" for T erm Q =tried, and T erm C =successful, the evidence strength would be 3. We designed the scoring system to capture the structural simi- larity of a snippet to its corresponding Winograd instance. We observed that a greater quantity of snippets can be retrieved for less specific search terms, but with increasing noise; we sought to ac- count for this with the features described above. Note also that our use of the word features is inten- tional. While the weights assigned for the length and order scores could be optimized, as parame- ters, we consider it inappropriate to do so on the WSC since it is widely used as a test set. We set these weights according to our best guess and val- idated our choices through experiments on the set of Winograd-like sentences provided in <ref type="bibr" target="#b24">Rahman and Ng (2012)</ref>.</p><p>We run the above four processes on all snippets retrieved for the input Winograd instance. The sum of strengths for the evidence-agents is finally compared to that of the evidence-patients to make the resolution decision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head><p>We tested several versions of our framework on the original 273 Winograd sentences (135 pairs and one triple). These vary in the method of query generation: automatic vs. automatic with syn- onyms vs. manual. We compared these systems with previous work on the basis of Precision (P), Recall (R), and F1.</p><p>We used Stanford CoreNLP's coreference re- solver ( <ref type="bibr" target="#b23">Raghunathan et al., 2010</ref>) during query generation to identify the predicates from the syn- tactic parse, as well as during antecedent selec- tion to retrieve the coreference chain of a candi-date evidence sentence. Python's Selenium pack- age was used for web-scraping and Bing-USA and Google (top two pages per result) were the search engines. The search results comprise a list of doc- ument snippets that contain the queries (for exam- ple, "yelled at" and "upset"). We extract the sen- tence/s within each snippet that contain the query terms, with the added restriction that the terms should be within 70 characters of each other to en- courage relevance.   <ref type="table" target="#tab_2">Table 4</ref> shows the precision, recall, and F1 of our framework's variants: automatically generated queries (AGQ), automatically generated queries with synonyms (AGQS), and manually gener- ated queries (MGQ). We test the automatic sys- tems with (+F) and without the semantic similar- ity filter. We compare these to the systems of <ref type="bibr" target="#b28">Sharma et al. (2015</ref> and <ref type="bibr" target="#b18">Liu et al. (2017)</ref> (L2017). The system developed by <ref type="bibr" target="#b18">Liu et al. (2017)</ref> uses elements extracted manually from the problem instances, so is most closely comparable to our MGQ method. Our best automated frame- work, AGQS+F, outperforms S2015 by 0.21 F1, achieving much higher recall (0.44 vs 0.18). Our results show that the framework with manually generated queries (MGQ) performs better than its automatic counterpart, AGQ, with an F1 of 0.50. AGQS+F slightly outperforms MGQ despite be- ing fully automatic.</p><p>The power of our approach lies in its general- ity, i.e., its improved coverage of the problem set.</p><p>It produces an answer for over 70% of instances. This surpasses previous methods, which only ad- mit specific instance types, by nearly 50%.</p><p>The random baseline on this binary task achieves a P/R/F1 of 0.5. We can artificially raise the F1 performance of all systems above 0.5 by randomly guessing an answer in cases where the system makes no decision. For AGQS+F, for ex- ample, if we take a random decision on the cases (74) with no retrieved evidence, we get an accu- racy of 57.1%. However, we think it is important that systems are compared transparently based on which instances they admit and when they are ca- pable of making a prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Error Analysis</head><p>To get a sense of the performance of our heuris- tics in classifying evidence sentences in the an- tecedent selection step, we manually labelled sen- tences retrieved by the AGQS system for 40 Wino- grad instances. The categories are evidence- agent, evidence-patient, or neither (insufficient ev- idence). This amounts to a total of 876 evidence sentences. We compared these labels to those as- signed by our system. In total, 703 of the 876 evi- dence sentences were labelled correctly (81%). Of the 173 incorrect cases, 110 were marked as in- sufficient evidence. Our system is forced to label these as agent or patient.</p><p>Evidence sentences were insufficient for a va- riety of reasons. Most frequently, they were structurally incomplete or grammatically incor- rect, despite passing as valid through CoreNLP and our initial coreference heuristics. In general, our coreference heuristics filter strongly: over all Winograd instances, they filter a total of 50,110 re- trieved sentences down to only 3,097 (0.0617 ac- ceptance rate). As for the 63 cases of sufficient evidence sentences that were labelled incorrectly, the issue was either errors in the coreference in- formation from the CoreNLP pipeline or errors in our heuristics for reasoning about the coreference information. We show examples of these various sources of error in supplementary <ref type="table">Table S1</ref>. At any rate, the corrected labels (with the 110 insufficient evidence removed and the 63 cases corrected) did not result in a shift in any of the 40 coreference decisions.</p><p>In <ref type="table">Table 5</ref>, we show a sample resolution that our system makes on a problem instance, 3 including some evidence that was retrieved and labelled au- tomatically and the evidence strengths that led to the resolution. These examples reveal that, indeed, general knowledge of what is plausible appears in natural text. Our system successfully leverages this knowledge for common sense reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>WSC Instance:</head><p>The man couldn't lift his son because he was so weak. Answer: the man (Agent) Evidence and labels: "However I was so weak that I couldn't lift" → EA (query terms in bold) "She was so weak she couldn't lift" → EA "I could not stand without falling immediately and I was so weak that I couldn't lift" → EA "It hurts to lift my leg and its kind of weak" → EP Stats and resolution: Agent evidence strength: 97 Patient evidence strength: 72 Number of scraped sentences: 109 Resolution: Agent <ref type="table">Table 5</ref>: Example Resolution for a WSC problem.</p><p>We also include an example evidence snip- pet that yields a "misleading" label. Generally, sources of misleading snippets include incomplete or imprecise query generation (e.g. in <ref type="table">Table 5</ref>, querying only "lift" instead of "couldn't lift"), er- rors in the automatic parsing of sentences (e.g., in supplementary <ref type="table">Table S1</ref>.1.b, "lift" is incorrectly labelled as a verb via the parse tree, despite being a noun), and insufficient filtering of noisy sentences that are not relevant to the problem instance or are incomplete (e.g. in supplementary <ref type="table">Table S1</ref>.2.b, the sentence is incomplete and indicates a mislead- ing resolution).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Generalization to COPA</head><p>To investigate the generality of our knowledge- hunting approach, we adapted it to the Choice of Plausible Alternatives (COPA). We evaluated our basic automatic models that did not use the seman- tic similarity filter for this check.</p><p>COPA has a slightly different form that necessi- tates some modifications. As an example, (3) The climbers reached the peak of the mountain. What happened as a result? a. They encountered an avalanche. b. They congratulated each other.</p><p>During query generation, as before, the set C con- tains terms extracted from the context sentence. Instead of a single set Q as in the WSC, we gener- ate two query sets Q 1 and Q 2 , that contain terms extracted for the first and second candidate sen- tences. Because entities in the candidate sentences can contribute to the answer (unlike in the WSC), we modified the query generation rules to extract more than just predicates. Specifically, the extrac- tion procedure uses the syntactic parse tree of the phrase to back-off from extracting the clause con- taining the subject and verb phrase, to only the verb phrase, to only the verbs or adjectives that are rooted in the verb phrase. For the running example, our system generates these three sets:</p><p>C={"The climbers reached the peak", "reached the peak", "reached"}, Q 1 ={"They encountered an avalanche", "encountered an avalanche", "en- countered"}, and Q 2 ={"They congratulated each other", "congratulated each other", "congratu- lated"}. We query the web for sentences that contain terms in (C, Q 1 ) and (C, Q 2 ), with one added re- striction: for problem instances in which the rela- tion is cause, the system only extracts sentences in which T erm C precedes T erm Q 1 or T erm Q 2 ; when the relation is result (as in our running exam- ple), T erm C succeeds T erm Q 1 or T erm Q 2 . As for the WSC, the final decision is determined from the evidence snippets according to their strengths.  We tuned the system's evidence-scoring heuris- tics on COPA's 500 validation instances. In Ta- ble 6, we compare our system's performance on the 500 test instances to previous work on the basis of precision (which in the full-coverage case equates to accuracy). Our simpler AGQ method achieves 66.2% accuracy, which is re- spectable, although not state-of-the-art. As indi- cated by the lower performance of AGQS, syn- onyms from WordNet did not improve perfor- mance on COPA. Without the semantic-similarity filtering, synonyms may add noise to the re- trieved results. It has also been shown that multi- word expressions are prevalent and important for COPA ( <ref type="bibr" target="#b27">Sasaki et al., 2017)</ref>, which we have not specifically attempted to handle with our method. We believe that this is a promising direction of im- provement for our approach in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dev</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We developed a knowledge-hunting framework to tackle the Winograd Schema Challenge, a task that requires common-sense knowledge and rea- soning. Our system involves a semantic repre- sentation schema and an antecedent selection pro- cess that acts on web-search results. We evaluated the performance of our framework on the original set of WSC instances, achieving F1-performance that significantly exceeded the previous state-of- the-art. A simple port of our approach to COPA suggests that it has the potential to generalize. In the future we will study how this common- sense reasoning technique can contribute to solv- ing "edge cases" and difficult examples in more general coreference tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 3 , we show ex-</head><label>3</label><figDesc></figDesc><table>Pair 
P redC 
E1 
E2 
P redQ 
P 
Alternating Word 
(POS) 

1 
couldn't lift the man 
his son 
was so heavy 
he 
weak/heavy (adjective) 

2 
were 
bullying 

the older 
students 

the younger 
ones 
punished 
them 
punished/rescued 
(verb) 

3 
tried to 
paint 
shepherds 
sheep 

ended up 
looking more 
like 

they 
golfers/dogs (noun) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Winograd sentence pairs from Table 1, parsed into the representation schema that we define. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Coverage and performance on the 
original Winograd Schema Challenge (273 
sentences). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Model accuracy (%) on COPA. 

</table></figure>

			<note place="foot" n="1"> Code to reproduce these results are available at https://github.com/aemami1/Wino-Knowledge-Hunter</note>

			<note place="foot" n="2"> This is why we do not evaluate our method directly on the expanded corpus.</note>

			<note place="foot" n="3"> Knowledge Hunting Framework Our framework takes as input a problem instance and processes it through four stages to make a final coreference decision. First, it fits the instance to a semantic representation schema. Second, it generates a set of queries that capture the predicates in the instance&apos;s clauses and sends these to a search engine, which retrieves text snippets that closely match the schema. The returned snippets are then parsed and filtered. Finally, the snippets are resolved to their respective antecedents and the results are mapped to a best guess for the original instance&apos;s resolution. We detail these stages below, grounding our description in Winograd instances.</note>

			<note place="foot" n="3"> We provide more examples in a supplementary file.</note>

			<note place="foot" n="4"> This precision can be inflated to 67.2 by randomly guessing on the 10 examples for which there were no search results.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported by the Natural Sciences and Engineering Research Council of Canada.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The winograd schema challenge and reasoning about correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amelia</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuliya</forename><surname>Lierler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Lifschitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Working Notes of the Symposium on Logical Formalizations of Commonsense Reasoning</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Coreference semantics from web features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="389" to="398" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Establishing a human baseline for the winograd schema challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MAICS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="39" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Word association norms, mutual information, and lexicography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">Ward</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Hanks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="29" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Knowledge representation for commonsense reasoning with text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Dahlgren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joyce</forename><surname>Mcdowell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward P</forename><surname>Stabler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="149" to="170" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A generalized knowledge hunting framework for the winograd schema challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Emami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaheer</forename><surname>Suleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jackie Chi Kit</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="25" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Utdhlt: Copacetic system for choosing plausible alternatives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Travis</forename><surname>Goodwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Rink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kirk</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanda</forename><forename type="middle">M</forename><surname>Harabagiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the First Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="461" to="466" />
		</imprint>
	</monogr>
	<note>Proceedings of the Sixth International Workshop on Semantic Evaluation</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Commonsense causal reasoning using millions of personal stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cosmin</forename><surname>Andrew S Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Adrian Bejan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sagae</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semantic interpretation and ambiguity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Hirst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="131" to="177" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Commonsense reasoning in a deeper way: By discovering relations between predicates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenguan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICAART (2)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="407" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Wordnet: An electronic lexical database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Kilgarriff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Bootstrapping coreference resolution using word associations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamidreza</forename><surname>Kobdani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schiehlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Kamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="783" to="792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomáš</forename><surname>Kočisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">`</forename><surname>Kočisk`y</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gábor</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.07040</idno>
		<title level="m">The narrativeqa reading comprehension challenge</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An example-based approach to difficult pronoun resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canasai</forename><surname>Kruengkrai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoya</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Sugiura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PACLIC</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="358" to="367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Cyc: A large-scale investment in knowledge infrastructure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Douglas B Lenat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="33" to="38" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The winograd schema challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ernest</forename><surname>Hector J Levesque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leora</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Morgenstern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page">47</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Conceptnet-a practical commonsense reasoning tool-kit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Push</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BT technology journal</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="211" to="226" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Evdokimov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.07704</idno>
		<title level="m">Probabilistic reasoning via deep learning: Neural association models</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Combing context and commonsense knowledge through neural networks for solving winograd schema problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Hu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Commonsense causal reasoning between short texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyi</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Kenny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seung-Won</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyuan</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="421" to="431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The stanford corenlp natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd annual meeting of the association for computational linguistics: system demonstrations</title>
		<meeting>52nd annual meeting of the association for computational linguistics: system demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Planning, executing, and evaluating the winograd schema challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leora</forename><surname>Morgenstern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ernest</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles L</forename><surname>Ortiz</surname><genName>Jr</genName></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="50" to="54" />
			<pubPlace>AI Magazine</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Solving hard coreference problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoruo</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">61801</biblScope>
			<pubPlace>Urbana, 51</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A multipass sieve for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heeyoung</forename><surname>Karthik Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Sudarshan Rangarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="492" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Resolving complex cases of definite pronouns: the winograd schema challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Altaf</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="777" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning-based multi-sieve co-reference resolution with knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1234" to="1244" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Choice of plausible alternatives: An evaluation of commonsense causal reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melissa</forename><surname>Roemmele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew S</forename><surname>Cosmin Adrian Bejan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="90" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Handling multiword expressions in causality estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shota</forename><surname>Sasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sho</forename><surname>Takase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoya</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoaki</forename><surname>Okazaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IWCS 2017-12th International Conference on Computational Semantics</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Short papers</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Towards addressing the winograd schema challenge-building and using a semantic parser and a knowledge hunting module</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arpit</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ha</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Somak</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitta</forename><surname>Aditya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1319" to="1325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">cloze procedure&quot;: a new tool for measuring readability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journalism Bulletin</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="415" to="433" />
			<date type="published" when="1953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">A simple method for commonsense reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Trieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Trinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.02847</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">verb semantics and lexical selection in proceedings of the 32nd annual meeting of the association for computational linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Palmer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<pubPlace>New Mexico</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Dynamic knowledge-base alignment for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaping</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jinho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth Conference on Computational Natural Language Learning</title>
		<meeting>the Seventeenth Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="153" to="162" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
