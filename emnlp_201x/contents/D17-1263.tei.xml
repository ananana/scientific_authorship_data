<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:26+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Challenge Set Approach to Evaluating Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Isabelle</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Research Council</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Research Council</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">Foster</forename><surname>Google</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Research Council</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Challenge Set Approach to Evaluating Machine Translation</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2486" to="2496"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Neural machine translation represents an exciting leap forward in translation quality. But what longstanding weaknesses does it resolve, and which remain? We address these questions with a challenge set approach to translation evaluation and error analysis. A challenge set consists of a small set of sentences, each hand-designed to probe a system&apos;s capacity to bridge a particular structural divergence between languages. To exemplify this approach, we present an English-French challenge set, and use it to analyze phrase-based and neural systems. The resulting analysis provides not only a more fine-grained picture of the strengths of neural systems, but also insight into which linguistic phenomena remain out of reach.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The advent of neural techniques in machine trans- lation (MT) <ref type="bibr" target="#b13">(Kalchbrenner and Blunsom, 2013;</ref><ref type="bibr" target="#b5">Cho et al., 2014;</ref><ref type="bibr" target="#b18">Sutskever et al., 2014</ref>) has led to profound improvements in MT quality. For "easy" language pairs such as English/French or English/Spanish in particular, neural (NMT) sys- tems are much closer to human performance than previous statistical techniques ( <ref type="bibr" target="#b21">Wu et al., 2016)</ref>. This puts pressure on automatic evaluation met- rics such as BLEU ( <ref type="bibr" target="#b15">Papineni et al., 2002</ref>), which exploit surface-matching heuristics that are rela- tively insensitive to subtle differences. As NMT continues to improve, these metrics will inevitably lose their effectiveness. Another challenge posed by NMT systems is their opacity: while it was usually clear which phenomena were ill-handled * Work performed while at NRC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Src The repeated calls from his mother</head><p>should have alerted us. Ref Les appels répétés de sa m` ere auraient dû nous alerter. Sys Les appels répétés de sa m` ere devraient nous avoir alertés. Is the subject-verb agreement correct (y/n)? Yes by previous statistical systems-and why-these questions are more difficult to answer for NMT.</p><p>We propose a new evaluation methodology cen- tered around a challenge set of difficult examples that are designed using expert linguistic knowl- edge to probe an MT system's capabilities. This methodology is complementary to the standard practice of randomly selecting a test set from "real text," which remains necessary in order to predict performance on new text. By concentrating on difficult examples, a challenge set is intended to provide a stronger signal to developers. Although we believe that the general approach is compatible with automatic metrics, we used manual evalua- tion for the work presented here. Our challenge set consists of short sentences that each focus on one particular phenomenon, which makes it easy to collect reliable manual assessments of MT out- put by asking direct yes-no questions. An example is shown in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>We generated a challenge set for English to French translation by canvassing areas of linguis- tic divergence between the two language pairs, es- pecially those where errors would be made visible by French morphology. Example choice was also partly motivated by extensive knowledge of the weaknesses of phrase-based MT (PBMT). Neither of these characteristics is essential to our method, however, which we envisage evolving as NMT progresses. We used our challenge set to evalu-ate in-house PBMT and NMT systems as well as Google's GNMT system.</p><p>In addition to proposing the novel idea of a chal- lenge set evaluation, our contribution includes our annotated English-French challenge set, which we provide in both formatted text and machine- readable formats (see supplemental materials). We also supply further evidence that NMT is system- atically better than PBMT, even when BLEU score differences are small. Finally, we give an analysis of the challenges that remain to be solved in NMT, an area that has received little attention thus far.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>A number of recent papers have evaluated NMT using broad performance metrics. <ref type="bibr">The WMT 2016</ref><ref type="bibr">News Translation Task (Bojar et al., 2016</ref>) evaluated submitted systems according to both BLEU and human judgments. NMT systems were submitted to 9 of the 12 translation direc- tions, winning 4 of these and tying for first or second in the other 5, according to the official human ranking. Since then, controlled compar- isons have used BLEU to show that NMT out- performs strong PBMT systems on 30 transla- tion directions from the United Nations Parallel Corpus ( <ref type="bibr" target="#b11">Junczys-Dowmunt et al., 2016a)</ref>, and on the IWSLT English-Arabic tasks ( <ref type="bibr" target="#b8">Durrani et al., 2016</ref>). These evaluations indicate that NMT per- forms better on average than previous technolo- gies, but they do not help us understand what as- pects of the translation have improved.</p><p>Some groups have conducted more detailed er- ror analyses. <ref type="bibr" target="#b1">Bentivogli et al. (2016)</ref> carried out a number of experiments on IWSLT 2015 English- German evaluation data, where they compare ma- chine outputs to professional post-edits in order to automatically detect a number of error categories. Compared to PBMT, NMT required less post- editing effort overall, with substantial improve- ments in lexical, morphological and word order er- rors. NMT consistently out-performed PBMT, but its performance degraded faster as sentence length increased. Later, Toral and Sánchez-Cartagena (2017) conducted a similar study, examining the outputs of competition-grade systems for the 9 WMT 2016 directions that included NMT com- petitors. They reached similar conclusions regard- ing morphological inflection and word order, but found an even greater degradation in NMT perfor- mance as sentence length increased, perhaps due to these systems' use of subword units.</p><p>Most recently, <ref type="bibr" target="#b16">Sennrich (2016)</ref> proposed an ap- proach to perform targeted evaluations of NMT through the use of contrastive translation pairs. This method introduces a particular type of er- ror automatically in reference sentences, and then checks whether the NMT system's conditional probability model prefers the original reference or the corrupted version. Using this technique, they are able to determine that a recently-proposed character-based model improves generalization on unseen words, but at the cost of introducing new grammatical errors.</p><p>Our approach differs from these studies in a number of ways. First, whereas others have ana- lyzed sentences drawn from an existing bitext, we conduct our study on sentences that are manually constructed to exhibit canonical examples of spe- cific linguistic phenomena. We focus on phenom- ena that we expect to be more difficult than av- erage, resulting in a particularly challenging MT test suite <ref type="bibr" target="#b14">(King and Falkedal, 1990</ref>). These sen- tences are designed to dive deep into linguistic phenomena of interest, and to provide a much finer-grained analysis of the strengths and weak- nesses of existing technologies, including NMT systems.</p><p>However, this strategy also necessitates that we work on fewer sentences. We leverage the small size of our challenge set to manually evaluate whether the system's actual output correctly han- dles our phenomena of interest. Manual evaluation side-steps some of the pitfalls that can come with Sennrich (2016)'s contrastive pairs, as a ranking of two contrastive sentences may not necessarily reflect whether the error in question will occur in the system's actual output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Challenge Set Evaluation</head><p>Our challenge set is meant to measure the ability of MT systems to deal with some of the more diffi- cult problems that arise in translating English into French. This particular language pair happened to be most convenient for us, but similar sets can be built for any language pair.</p><p>One aspect of MT performance excluded from our evaluation is robustness to sparse data. To con- trol for this, when crafting source and reference sentences, we chose words that occurred at least 100 times in our training corpus (section 4.1). <ref type="bibr">1</ref> The challenging aspect of the test set we are pre- senting stems from the fact that the source English sentences have been chosen so that their closest French equivalent will be structurally divergent from the source in some crucial way. Transla- tional divergences have been extensively studied in the past-see for example <ref type="bibr" target="#b20">(Vinay and Darbelnet, 1958;</ref><ref type="bibr" target="#b7">Dorr, 1994)</ref>. We expect the level of difficulty of an MT test set to correlate well with its density in divergence phenomena, which we classify into three main types: morpho-syntactic, lexico-syntactic and purely syntactic divergences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Morpho-syntactic divergences</head><p>In some languages, word morphology (e.g. inflec- tions) carries more grammatical information than in others. When translating a word towards the richer language, there is a need to recover ad- ditional grammatically-relevant information from the context of the target language word. Note that we only include in our set cases where the relevant information is available in the linguistic context. <ref type="bibr">2</ref> One particularly important case of morpho- syntactic divergence is that of subject-verb agree- ment. French verbs typically have more than 30 different inflected forms, while English verbs typ- ically have 4 or 5. As a result, English verb forms strongly underspecify their French counterparts. Much of the missing information must be filled in through forced agreement in person, number and gender with the grammatical subject of the verb. But extracting these parameters can prove diffi- cult. For example, the agreement features of a co- ordinated noun phrase are a complex function of the coordinated elements: a) the gender is femi- nine if all conjuncts are feminine, otherwise mas- culine wins; b) the conjunct with the smallest per- son (p1&lt;p2&lt;p3) wins; and c) the number is al- ways plural when the coordination is "et" ("and") but the case is more complex with "ou" ("or").</p><p>A second example of morpho-syntactic diver- gence between English and French is the more ex- plicit marking of the subjunctive mood in French part of an idiomatic phrase, and guitared (0 occurrences), which is meant to test the ability to deal with "nonce words" as discussed in section 5. <ref type="bibr">2</ref> The so-called Winograd Schema Challenges (en.wikipedia.org/wiki/Winograd Schema Challenge) often involve cases where common-sense reasoning is required to correctly choose between two potential antecedent phrases for a pronoun. Such cases become En → Fr translation challenges if the relevant English pronoun is they and its alternative antecedents happen to have different grammatical genders in French: they → ils/elles. subordinate clauses. In the following example, the verb "partiez", unlike its English counterpart, is marked as subjunctive:</p><p>He demanded that you leave immedi- ately. → Il a exigé que vous partiez immédiatement.</p><p>When translating an English verb within a subor- dinate clause, the context must be examined for possible subjunctive triggers. Typically these are specific lexical items found in a governing posi- tion with respect to the subordinate clause: verbs such as "exiger que", adjectives such as "regret- table que" or subordinate conjunctions such as "` a condition que".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Lexico-syntactic divergences</head><p>Syntactically governing words such as verbs tend to impose specific requirements on their comple- ments: they subcategorize for complements of a certain syntactic type. But a source language gov- ernor and its target language counterpart can di- verge on their respective requirements. The trans- lation of such words must then trigger adjustments in the target language complement pattern. We can only examine here a few of the types instantiated in our challenge set.</p><p>A good example is argument switching. This refers to the situation where the translation of a source verb V s as V t is correct but only provided the arguments (usually the subject and the object) are flipped around. The translation of "to miss" as "manqueràmanquer`manquerà" is such a case:</p><p>John misses Mary → Mary manquè a John.</p><p>Failing to perform the switch results in a severe case of mistranslation.</p><p>A second example of lexico-syntactic diver- gence is that of "crossing movement" verbs. Con- sider the following example:</p><p>Terry swam across the river → Terry a traversé larivì erè a la nage.</p><p>The French translation could be glossed as, "Terry crossed the river by swimming." A literal transla- tion such as "Terry a nagénagé`nagéà travers larivì ere," is ruled out.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Syntactic divergences</head><p>Some syntactic divergences are not relative to the presence of a particular lexical item but rather stem from differences in the set of available syntactic patterns. Source-language instances of structures missing from the target language must be mapped onto equivalent structures. Here are some of the types appearing in our challenge set. The position of French pronouns is a major case of divergence from English. French is basi- cally an SVO language like English but it departs from that canonical order when post-verbal com- plements are pronominalized: the pronouns must then be rendered as proclitics, that is phonetically attached to the verb on its left side.</p><p>He gave Mary a book. → Il a donné un livrè a Marie.</p><formula xml:id="formula_0">He gave i it j to her k . → Il le j lui k a donné i .</formula><p>Another example of syntactic divergence be- tween English and French is that of stranded prepositions. In both languages, an operation known as "WH-movement" will move a rela- tivized or questioned element to the front of the clause containing it. When this element hap- pens to be a prepositional phrase, English offers the option to leave the preposition in its normal place, fronting only its pronominalized object. In French, the preposition is always fronted along- side its object:</p><p>The girl whom i he was dancing with j is rich. → La fille avec j qui i il dansait est riche.</p><p>A final example of syntactic divergence is the use of the so-called middle voice. While English uses the passive voice in agentless generic state- ments, French tends to prefer the use of a special pronominal construction where the pronoun "se" has no real referent:</p><p>Caviar is eaten with bread. → Le caviar se mange avec du pain.</p><p>This completes our exemplification of morpho- syntactic, lexico-syntactic and purely syntactic di- vergences. Our actual test set includes several more subcategories of each type. The ability of MT systems to deal with each such subcategory is then tested using at least three different test sen- tences. We use short test sentences so as to keep the targeted divergence in focus. The 108 sen- tences that constitute our current challenge set can be found in Appendix 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Evaluation Methodology</head><p>Given the very small size of our challenge set, it is easy to perform a human evaluation of the respec- tive outputs of a handful of different systems. The obvious advantage is that the assessment is then absolute instead of relative to one or a few refer- ence translations.</p><p>The intent of each challenge sentence is to test one and only one system capability, namely that of coping correctly with the particular associated divergence subtype. As illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>, we provide annotators with a question that spec- ifies the divergence phenomenon currently being tested, along with a reference translation with the areas of divergence highlighted. As a result, judg- ments become straightforward: was the targeted divergence correctly bridged, yes or no? 3 There is no need to mentally average over a number of different aspects of the test sentence as one does when rating the global translation quality of a sentence, e.g. on a 5-point scale. However, we acknowledge that measuring translation per- formance on complex sentences exhibiting many different phenomena remains crucial. We see our approach as being complementary to evaluations of overall translation quality.</p><p>One consequence of our divergence-focused ap- proach is that faulty translations will be judged as successes when the faults lie outside of the tar- geted divergence zone. However, this problem is mitigated by our use of short test sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Machine Translation Systems</head><p>We trained state-of-the-art neural and phrase- based systems for English-French translation on data from the WMT 2014 evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>We used the LIUM shared-task subset of the WMT 2014 corpora, 4 retaining the provided tokenization corpus lines en words fr words train <ref type="table" target="#tab_0">12.1M  304M  348M  mono 15.9M  -- 406M  dev  6003  138k  155k  test  3003  71k  81k   Table 1</ref>: Corpus statistics. The WMT12/13 eval sets are used for dev, and the WMT14 eval set is used for test. and corpus organization, but mapping characters to lowercase. <ref type="table">Table 1</ref> gives corpus statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Phrase-based systems</head><p>To ensure a competitive PBMT baseline, we per- formed phrase extraction using both IBM4 and HMM alignments with a phrase-length limit of 7; after frequency pruning, the resulting phrase table contained 516M entries. For each extracted phrase pair, we collected statistics for the hierarchical re- ordering model of <ref type="bibr" target="#b9">Galley and Manning (2008)</ref>.</p><p>We trained an NNJM model <ref type="bibr" target="#b6">(Devlin et al., 2014</ref>) on the HMM-aligned training corpus, with input and output vocabulary sizes of 64k and 32k. Words not in the vocabulary were mapped to one of 100 mkcls classes. We trained for 60 epochs of 20k × 128 minibatches, yielding a final dev-set perplexity of 6.88.</p><p>Our set of log-linear features consisted of for- ward and backward Kneser-Ney smoothed phrase probabilities and HMM lexical probabilities (4 features); hierarchical reordering probabilities (6); the NNJM probability (1); a set of sparse features as described by <ref type="bibr" target="#b3">Cherry (2013)</ref>  <ref type="figure" target="#fig_0">(10,386)</ref>; word- count and distortion penalties (2); and 5-gram lan- guage models trained on the French half of the training corpus and the French monolingual cor- pus (2). Tuning was carried out using batch lattice MIRA <ref type="bibr" target="#b4">(Cherry and Foster, 2012)</ref>. Decoding used the cube-pruning algorithm of <ref type="bibr" target="#b10">Huang and Chiang (2007)</ref>, with a distortion limit of 7.</p><p>We include two phrase-based systems in our comparison: PBMT-1 has data conditions that ex- actly match those of the NMT system, in that it does not use the language model trained on the French monolingual corpus, while PBMT-2 uses both language models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Neural systems</head><p>To build our NMT system, we used the Nema- tus toolkit, <ref type="bibr">5</ref> which implements a single-layer neu- ral sequence-to-sequence architecture with atten- tion ( <ref type="bibr" target="#b0">Bahdanau et al., 2015)</ref> and gated recurrent units ( <ref type="bibr" target="#b5">Cho et al., 2014</ref>). We used 512-dimensional word embeddings with source and target vocabu- lary sizes of 90k, and 1024-dimensional state vec- tors. The model contains 172M parameters.</p><p>We preprocessed the data using a BPE model learned from source and target corpora . Sentences longer than 50 words were discarded. Training used the Adadelta al- gorithm <ref type="bibr" target="#b22">(Zeiler, 2012)</ref>, with a minibatch size of 100 and gradients clipped to 1.0. It ran for 5 epochs, writing a checkpoint model every 30k minibatches. Following Junczys-Dowmunt et al. (2016b), we averaged the parameters from the last 8 checkpoints. To decode, we used the AmuNMT decoder (Junczys-Dowmunt et al., 2016a) with a beam size of 4.</p><p>While our primary results will focus on the above PBMT and NMT systems, where we can describe replicable configurations, we have also evaluated Google's production system, 6 which has recently moved to NMT ( <ref type="bibr" target="#b21">Wu et al., 2016)</ref>. No- tably, the "GNMT" system uses (at least) 8 en- coder and 8 decoder layers, compared to our 1 layer for each, and it is trained on corpora that are "two to three decimal orders of magnitudes big- ger than the WMT." The evaluated outputs were downloaded in December 2016.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>The 108-sentence English-French challenge set presented in Appendix 7 was submitted to the four MT systems described in section 4: PBMT-1, PBMT-2, NMT, and GNMT. Three bilingual na- tive speakers of French rated each translated sen- tence as either a success or a failure according to the protocol described in section 3.4. For exam- ple, the 26 sentences of the subcategories S1-S5 of Appendix 7 are all about different cases of subject- verb agreement. The corresponding translations were judged successful if and only if the translated verb correctly agrees with the translated subject.</p><p>The different system outputs for each source sentence were grouped together to reduce the bur- den on the annotators. That is, in <ref type="figure" target="#fig_0">figure 1</ref>, anno-tators were asked to answer the question for each of four outputs, rather than just one as shown. The outputs were listed in random order, without iden- tification. Questions were also presented in ran- dom order to each annotator. Appendix A in the supplemental materials contains the instructions shown to the annotators. As we can see, the two PBMT systems fare very poorly on our challenge set, especially in the morpho-syntactic and purely syntactic types. Their somewhat better handling of lexico- syntactic issues probably reflects the fact that PBMT systems are naturally more attuned to lex- ical cues than to morphology or syntax. The two NMT systems are clear winners in all three cat- egories. The GNMT system is best overall with a success rate of 68%, likely due to the data and architectural factors mentioned in section 4.3. <ref type="bibr">7</ref> WMT BLEU scores correlate poorly with challenge-set performance. The large gap of 2.3 BLEU points between PBMT-1 and PBMT-2 cor- responds to only a 1% gain on the challenge set, while the small gap of 0.4 BLEU between PBMT-2 and NMT corresponds to a 21% gain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Quantitative comparison</head><p>Inter-annotator agreement (final column in ta- ble 2) is excellent overall, with all three annotators agreeing on almost 90% of system outputs. Syn- tactic divergences appear to be somewhat harder to judge than other categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Qualitative assessment of NMT</head><p>We now turn to an analysis of the strengths and weaknesses of neural MT through the microscope of our divergence categorization system, hoping that this may help focus future research on key is- sues. In this discussion we ignore the results ob- tained by PBMT-2 and compare: a) the results ob- tained by PBMT-1 to those of NMT, both systems having been trained on the same dataset; and b) the <ref type="bibr">7</ref> We cannot offer a full comparison with the pre-NMT Google system. However, in October 2016 we ran a smaller 35-sentence version of our challenge set on both the Google system and our PBMT-1 system. The Google system only got 4 of those examples right (11.4%) while our PBMT-1 got 6 right (17.1%). results of these two systems with those of Google NMT which was trained on a much larger dataset.</p><p>In the remainder of the present section we will refer to the sentences of our challenge set using the subcategory-based numbering scheme S1-S26 as assigned in Appendix 7. A summary of the category-wise performance of PBMT-1, NMT and Google NMT is provided in <ref type="table">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strengths of neural MT</head><p>Overall, both neural MT systems do much bet- ter than PBMT-1 at bridging divergences. In the case of morpho-syntactic divergences, we observe a jump from 16% to 72% in the case of our two local systems. This is mostly due to the NMT sys- tem's ability to deal with many of the more com- plex cases of subject-verb agrement:</p><p>• Distractors. The subject's head noun agree- ment features get correctly passed to the verb phrase across intervening noun phrase com- plements (sentences S1a-c).</p><p>• Coordinated verb phrases. Subject agree- ment marks are correctly distributed across the elements of such verb phrases (S3a-c).</p><p>• Coordinated subjects. Much of the logic that is at stake in determining the agreement fea- tures of coordinated noun phrases (cf. our rel- evant description in section 3.1) appears to be correctly captured in the NMT translations of S4.</p><p>• Past participles. Even though the rules governing French past participle agreement are notoriously difficult (especially after the "avoir" auxiliary), they are fairly well cap- tured in the NMT translations of (S5b-e).</p><p>The NMT systems are also better at handling lexico-syntactic divergences. For example:</p><p>• Double-object verbs. There are no such verbs in French and the NMT systems perform the required adjustments flawlessly (sentences S8a-S8c).</p><p>• Overlapping subcat frames. NMT systems manage to discriminate between an NP com- plement and a sentential complement starting with an NP: cf. to know NP versus to know NP is VP (S11b-e) • NP-to-VP complements. These English in- finitival complements often need to be ren- dered as finite clauses in French and the NMT systems are better at this task (S12a-c).</p><p>Divergence type <ref type="table" target="#tab_0">Morpho-syntactic  16%  16% 72%  65%  94%  Lexico-syntactic  42%  46% 52%  62%  94%  Syntactic  33%  33% 40%  75%  81%  Overall  31%  32% 53%  68%  89%  WMT BLEU  34.2  36.5</ref> 36.9 - - <ref type="table" target="#tab_0">Table 2</ref>: Summary performance statistics for each system under study, including challenge set success rate grouped by linguistic category (aggregating all positive judgments and dividing by total judgments), as well as BLEU scores on the WMT 2014 test set. The final column gives the proportion of system outputs on which all three annotators agreed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PBMT-1 PBMT-2 NMT Google NMT Agreement</head><p>Finally, NMT systems also turn out to better handle purely syntactic divergences. For example:</p><p>• Yes-no question syntax. The differences be- tween English and French yes-no question syntax are correctly bridged by the two NMT systems (S17a-c).</p><p>• French proclitics. NMT systems are signif- icantly better at transforming English pro- nouns into French proclitics, i.e. moving them before the main verb and case-inflecting them correctly (S23a-e).</p><p>• Finally, we note that the Google system man- ages to overcome several additional chal- lenges. It correctly translates tag ques- tions (S18a-c), constructions with stranded prepositions (S19a-f), most cases of the in- alienable possession construction (S25a-e) as well as zero relative pronouns (S26a-c).</p><p>The large gap observed between the results of the in-house and Google NMT systems indicates that current neural MT systems are extremely data hungry. But given enough data, they can success- fully tackle some challenges that are often thought of as extremely difficult. A case in point here is that of stranded prepositions (see discussion in section 3.3), in which we see the NMT model cap- ture some instances of WH-movement, the text- book example of long-distance dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Weaknesses of neural MT</head><p>In spite of its clear edge over PBMT, NMT is not without some serious shortcomings. We al- ready mentioned the degradation issue with long sentence which, by design, could not be observed with our challenge set. But an analysis of our re- sults will reveal many other problems. Globally, we note that even using a staggering quantity of data and a highly sophisticated NMT model, the Google system fails to reach the 70% mark on our challenge set. The fine-grained error catego- rization associated with the challenge set will help us single out precise areas where more research is needed. Here are some relevant observations.</p><p>Incomplete generalizations. In several cases where partial results might suggest that NMT has correctly captured some basic generalization about linguistic data, further instances reveals that this is not fully the case.</p><p>• Agreement logic.</p><p>The logic governing the agreement features of coordinated noun phrases (see section 3.1) has been mostly captured by the NMT systems (cf. the 12 sen- tences of S4), but there are some gaps. For example, the Google system runs into trouble with mixed-person subjects (sentences S4d1- 3).</p><p>• Subjunctive mood triggers. While some sub- junctive mood triggers are correctly regis- tered (e.g. "demander que" and "malheureux que"), the case of such a highly frequent sub- ordinate conjunction as provided that → ` a condition que is somehow being missed (sen- tence S6a-c).</p><p>• Noun compounds. The French translation of an English compound N 1 N 2 is usu- ally of the form N 2 Prep N 1 . For any given headnoun N 2 the correct preposi- tion Prep depends on the semantic class of N 1 . For example steel/ceramic/plastic knife → couteau en acier/céramique/plastique but butter/meat/steak knife → couteaù a beurre/viande/steak. Given that neural mod- els are known to perform some semantic gen- eralizations, we find their performance dis- appointing on our compound noun examples (S14a-i).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Category</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subcategory</head><p># PBMT-1 NMT Google NMT <ref type="table" target="#tab_0">Morpho-syntactic Agreement across distractors  3  0% 100%  100%  through control verbs  4  25%  25%  25%  with coordinated target  3  0% 100%  100%  with coordinated source  12  17%  92%  75%  of past participles  4  25%  75%</ref>   <ref type="table">Table 3</ref>: Summary of scores by fine-grained categories. "#" reports number of questions in each cat- egory, while the reported score is the percentage of questions for which the divergence was correctly bridged. For each question, the three human judgments were transformed into a single judgment by taking system outputs with two positive judgments as positive, and all others as negative.</p><p>• The so-called French "inalienable posses- sion" construction arises when an agent per- forms an action on one of her body parts, e.g. I brushed my teeth. The French translation will normally replace the possessive article with a definite one and introduce a reflexive pronoun, e.g. Je me suis brossé les dents ('I brushed myself the teeth'). In our dataset, the Google system gets this right for examples in the first and third persons (sentences S25a,b) but fails to do the same with the example in the second person (sentence S25c).</p><p>Then there are also phenomena that current NMT systems, even with massive amounts of data, appear to be completely missing:</p><p>• Common and syntactically flexible idioms.</p><p>While PBMT-1 produces an acceptable trans- lation for half of the idiomatic expressions of S15 and S16, the local NMT system misses them all and the Google system does barely better. NMT systems appear to be short on raw memorization capabilities.</p><p>• Control verbs. Two different classes of verbs can govern a subject NP, an object NP plus an infinitival complement. With verbs of the "object-control" class (e.g. "persuade"), the object of the verb is understood as the seman- tic subject of the infinitive. But with those of the "subject-control" class (e.g. "promise"), it is rather the subject of the verb which plays that semantic role. None of the sys- tems tested here appear to get a grip on sub- ject control cases, as evidenced by the lack of correct feminine agreement on the French adjectives in sentences S2b-d.</p><p>• Argument switching verbs. All systems tested here mistranslate sentences S7a-c by fail- ing to perform the required argument switch:</p><formula xml:id="formula_1">NP 1 misses NP 2 → NP 2 manquè a NP 1 .</formula><p>• Crossing movement verbs. None of the sys- tems managed to correctly restructure the regular manner-of-movement verbs e.g. swim across X → traverser X ` a la nage in sentences S10a-c. Unsurprisingly, all systems also fail on the even harder example S10d, in which the "nonce verb" guitared is a spontaneous derivation from the noun guitar being cast as an ad hoc manner-of-movement verb. 8</p><p>• Middle voice. None of the systems tested here were able to recast the English "generic passive" of S21a-c into the expected French "middle voice" pronominal construction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We have presented a radically different kind of evaluation for MT systems: the use of challenge sets designed to stress-test MT systems on "hard" linguistic material, while providing a fine-grained linguistic classification of their successes and fail- ures. This approach is not meant to replace our community's traditional evaluation tools but to supplement them. Our proposed error categorization scheme makes it possible to bring to light different strengths and weaknesses of PBMT and neural MT. With the exception of idiom processing, in all cases where a clear difference was observed it turned out to be in favor of neural MT. A key factor in NMT's superiority appears to be its abil- ity to overcome many limitations of n-gram lan- guage modeling. This is clearly at play in dealing with subject-verb agreement, double-object verbs, overlapping subcategorization frames and last but not least, the pinnacle of Chomskyan linguistics, WH-movement (in this case, stranded preposi- tions).</p><p>But our challenge set also brings to light some important shortcomings of current neural MT, re- gardless of the massive amounts of training data it may have been fed. As may have been already known or suspected, NMT systems struggle with the translation of idiomatic phrases. Perhaps more interestingly, we notice that neural MT's impres- sive generalizations still seem somewhat brittle. For example, the NMT system can appear to have <ref type="bibr">8</ref> On the concept of nonce word, see https://en.wikipedia.org/wiki/Nonce word. mastered the rules governing subject-verb agree- ment or inalienable possession in French, only to trip over a rather obvious instantiation of those rules. Probing where these boundaries are, and how they relate to the neural system's training data and architecture is an obvious next step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Future Work</head><p>It is our hope that the insights derived from our challenge set evaluation will help inspire future MT research, and call attention to the fact that even "easy" language pairs like English-French still have many linguistic issues left to be resolved. But there are also several ways to improve and ex- pand upon our challenge set approach itself.</p><p>First, though our human judgments of output sentences allowed us to precisely assess the phe- nomena of interest, this approach is not scalable to large sets, and requires access to native speak- ers in order to replicate the evaluation. It would be interesting to see whether similar scores could be achieved through automatic means. The existence of human judgments for this set provides a gold- standard by which proposed automatic judgments may be meta-evaluated.</p><p>Second, the construction of such a challenge set requires in-depth knowledge of the structural di- vergences between the two languages of interest. A method to automatically create such a challenge set for a new language pair would be extremely useful. One could imagine approaches that search for divergences, indicated by atypical output con- figurations, or perhaps by a system's inability to reproduce a reference from its own training data. Localizing a divergence within a difficult sentence pair would be another useful subtask.</p><p>Finally, we would like to explore how to train an MT system to improve its performance on these divergence phenomena. This could take the form of designing a curriculum to demonstrate a par- ticular divergence to the machine, or altering the network structure to capture such generalizations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example challenge set question.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 2 summarizes</head><label>2</label><figDesc>our results in terms of per- centage of successful translations, globally and over each main type of divergence. For com- parison with traditional metrics, we also include BLEU scores measured on the WMT 2014 test set.</figDesc><table></table></figure>

			<note place="foot" n="1"> With two exceptions: spilt (58 occurrences), which is</note>

			<note place="foot" n="3"> Sometimes the system produces a translation that circumvents the divergence issue. For example, it may dodge a divergence involving adverbs by reformulating the translation to use an adjective instead. In these rare cases, we instruct our annotators to abstain from making a judgment, regardless of whether the translation is correct or not. 4 http://www.statmt.org/wmt14/translation-task.html http://www-lium.univ-lemans.fr/∼schwenk/nnmt-sharedtask</note>

			<note place="foot" n="5"> https://github.com/rsennrich/nematus 6 https://translate.google.com</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Cyril Goutte, Eric Joa-nis and Michel Simard, who graciously spent the time required to rate the output of four different MT systems on our challenge sentences. We also thank Roland Kuhn for valuable discussions, and comments on an earlier version of the paper.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplemental Materials</head><p>The supplemental materials comprise two separate files:</p><p>• challenge-a.pdf-instructions to au- thors, and rendered version of the challenge set (with annotator scores); and</p><p>• Challenge set-v2hA.json- machine-readable version of the challenge set.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1409.0473" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Conference on Learning Representations (ICLR)</title>
		<meeting>the Third International Conference on Learning Representations (ICLR)<address><addrLine>San Diego, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural versus phrasebased machine translation quality: a case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arianna</forename><surname>Bisazza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/D16-1025" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="257" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Findings of the 2016 conference on machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajen</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><forename type="middle">Jimeno</forename><surname>Yepes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varvara</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelie</forename><surname>Neveol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariana</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Rubino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolina</forename><surname>Scarton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karin</forename><surname>Verspoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W16-2301" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Conference on Machine Translation</title>
		<meeting>the First Conference on Machine Translation<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="131" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Improved reordering for phrase-based translation using sparse features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/N13-1003" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="22" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Batch tuning strategies for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Foster</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/N12-1047" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="427" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D14-1179" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast and robust neural network joint models for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rabih</forename><surname>Zbib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lamar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P14-1129" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1370" to="1380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Machine translation divergences: a formal description and proposed solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><forename type="middle">J</forename><surname>Dorr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">QCRI machine translation systems for IWSLT 16</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadir</forename><surname>Durrani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahim</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hassan</forename><surname>Sajjad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vogel</surname></persName>
		</author>
		<ptr target="https://workshop2016.iwslt.org/downloads/qcri-machine-translation.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Spoken Language Translation (IWSLT)</title>
		<meeting>the 13th International Workshop on Spoken Language Translation (IWSLT)<address><addrLine>Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A simple and effective hierarchical phrase reordering model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D08-1089" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2008 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Honolulu, Hawaii</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="848" to="856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Forest rescoring: Faster decoding with integrated language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P07-1019" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics. Association for Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association of Computational Linguistics. Association for Computational Linguistics<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="144" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Is neural machine translation ready for deployment? a case study on 30 translation directions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Dwojak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Spoken Language Translation (IWSLT)</title>
		<meeting>the 13th International Workshop on Spoken Language Translation (IWSLT)<address><addrLine>Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The amu-uedin submission to the wmt16 news translation task: Attention-based nmt models as feature functions in phrase-based smt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Dwojak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W16-2316" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Conference on Machine Translation. Association for Computational Linguistics</title>
		<meeting>the First Conference on Machine Translation. Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="319" to="325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Recurrent continuous translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D13-1176" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1700" to="1709" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Using test suites in evaluation of machine translation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kirsten</forename><surname>Falkedal</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/C/C90/C90-2037.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1990 Conference on Computational Linguistics</title>
		<meeting>the 1990 Conference on Computational Linguistics<address><addrLine>Helsinki, Finland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="doi">10.3115/1073083.1073135</idno>
		<ptr target="https://doi.org/10.3115/1073083.1073135" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">How grammatical is characterlevel neural machine translation? assessing MT quality with contrastive translation pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<idno>CoRR abs/1612.04629</idno>
		<ptr target="http://arxiv.org/abs/1612.04629" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P16-1162" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A multifaceted evaluation of neural versus statistical machine translation for 9 language directions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Toral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Víctor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sánchez-Cartagena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the The 15th Conference of the European Chapter of the Association for Computational Linguistics (EACL)</title>
		<meeting>the The 15th Conference of the European Chapter of the Association for Computational Linguistics (EACL)<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1063" to="1073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Vinay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Darbelnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Didier</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="1958" />
		</imprint>
	</monogr>
	<note>Stylistique comparée du français et de l&apos;anglais</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Klingner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apurva</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshikiyo</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideto</forename><surname>Kazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Kurian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishant</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<idno>CoRR abs/1609.08144</idno>
		<ptr target="http://arxiv.org/abs/1609.08144" />
	</analytic>
	<monogr>
		<title level="j">Oriol Vinyals</title>
		<editor>Greg Corrado, Macduff Hughes, and Jeffrey Dean</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">ADADELTA: an adaptive learning rate method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zeiler</surname></persName>
		</author>
		<idno>CoRR abs/1212.5701</idno>
		<ptr target="http://arxiv.org/abs/1212.5701" />
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
