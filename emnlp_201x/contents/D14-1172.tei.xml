<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:31+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Assessing the Impact of Translation Errors on Machine Translation Quality with Mixed-effects Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>Via Sommarive 18</addrLine>
									<postCode>38123</postCode>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>Via Sommarive 18</addrLine>
									<postCode>38123</postCode>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>Via Sommarive 18</addrLine>
									<postCode>38123</postCode>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>Via Sommarive 18</addrLine>
									<postCode>38123</postCode>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fbk -Fondazione</forename><forename type="middle">Bruno</forename><surname>Kessler</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>Via Sommarive 18</addrLine>
									<postCode>38123</postCode>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Assessing the Impact of Translation Errors on Machine Translation Quality with Mixed-effects Models</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1643" to="1653"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Learning from errors is a crucial aspect of improving expertise. Based on this notion , we discuss a robust statistical framework for analysing the impact of different error types on machine translation (MT) output quality. Our approach is based on linear mixed-effects models, which allow the analysis of error-annotated MT output taking into account the variability inherent to the specific experimental setting from which the empirical observations are drawn. Our experiments are carried out on different language pairs involving Chi-nese, Arabic and Russian as target languages. Interesting findings are reported, concerning the impact of different error types both at the level of human perception of quality and with respect to performance results measured with automatic metrics.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The dominant statistical approach to machine translation (MT) is based on learning from large amounts of parallel data and tuning the result- ing models on reference-based metrics that can be computed automatically, such as BLEU ( <ref type="bibr" target="#b22">Papineni et al., 2001</ref>), METEOR (Banerjee and <ref type="bibr" target="#b1">Lavie, 2005</ref>), TER ( <ref type="bibr" target="#b29">Snover et al., 2006</ref>), GTM ( <ref type="bibr" target="#b32">Turian et al., 2003)</ref>. Despite the steady progress in the last two decades, especially for few well resourced translation directions having English as target lan- guage, this way to approach the problem is quickly reaching a performance plateau. One reason is that parallel data are a source of reliable informa- tion but, alone, limit systems knowledge to ob- served positive examples (i.e. how a sentence should be translated) without explicitly modelling any notion of error (i.e. how a sentence should not be translated). Another reason is that, as a development and evaluation criterion, automatic metrics provide a holistic view of systems' be- haviour without identifying the specific issues of a translation. Indeed, the global scores returned by MT evaluation metrics depend on comparisons be- tween translation hypotheses and reference trans- lations, where the causes and the nature of the dif- ferences between them are not identified.</p><p>To cope with these issues and define system improvement priorities, the focus of MT evalua- tion research is gradually shifting towards profil- ing systems' behaviour with respect to various ty- pologies of errors ( <ref type="bibr" target="#b34">Vilar et al., 2006;</ref><ref type="bibr" target="#b23">Popovi´cPopovi´c and Ney, 2011;</ref><ref type="bibr">Farrús et al., 2012, inter alia)</ref>. This shift has enriched the traditional MT evaluation framework with a new element, that is the actual errors done by a system. Until now, most of the research has focused on the relationship (i.e. the correlation) between two elements of the frame- work: humans and automatic evaluation metrics. As a new element of the framework, which be- comes a sort of "evaluation triangle", the analy- sis of error annotations opens interesting research problems related to the relationships between: i) error types and human perception of MT quality and ii) error types and the sensitivity of automatic metrics.</p><p>Besides motivating further investigation on met- rics featuring high correlation with human judge- ments (a well-established MT research sub-field, which is out of the scope of this paper), connecting the vertices of this triangle raises new challenging questions such as: (1) Which types of MT errors have the high- est impact on human perception of translation quality? Surprisingly, little prior work focused on this side of the triangle. Error annotations have been considered to highlight strengths and weaknesses of MT engines or to investigate the influence of different error types on post-editors' work. However, the direct connection between er-rors and users' preferences has been only partially understood, mainly from a descriptive standpoint and through rudimentary techniques unsuitable to draw clear-cut conclusions or reliable inferences. (2) To which types of errors are different MT evaluation metrics more sensitive? This side of the triangle has been even less explored. For in- stance, little has been done to understand which automatic metric is more suitable to assess sys- tem improvements with respect to a specific issue (e.g. word order or morphology) or to shed light on the joint impact of different error types on per- formance results calculated with different metrics.</p><p>To answer these questions, we propose a ro- bust statistical framework to analyse the im- pact of different error types, alone and in com- bination, both on human perception of quality and on MT evaluation metrics' results. Our analysis is carried out by employing linear mixed-effects models, a generalization of linear regression mod- els suited to model responses with fixed and ran- dom effects. Experiments are performed on data covering three translation directions (English to Chinese, Arabic and Russian). For each direc- tion, two automatic translations were collected for around 400 sentences and were manually evalu- ated by expert translators through absolute quality judgements and error annotation.</p><p>Building on the advantages offered by linear mixed-effects models, our main contributions in- clude:</p><p>• A rigorous method, novel to MT error anal- ysis research, to relate MT issues to human preferences and MT metrics' results;</p><p>• The application of such method to three translation directions having English as source and different languages as target;</p><p>• A number of findings, specific to each lan- guage direction, which are out of the reach of the few simpler methods proposed so far.</p><p>Overall, our study has clear practical implica- tions for MT systems' development and evalu- ation. Indeed, the proposed statistical analysis framework represents an ideal instrument to: i) identify translation issues having the highest im- pact on human perception of quality and ii) choose the most appropriate evaluation metric to measure progress towards their solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Error analysis, as a way to identify systems' weak- nesses and define priorities for their improvement, is gaining increasing interest in the MT com- munity <ref type="bibr" target="#b23">(Popovi´cPopovi´c and Ney, 2011;</ref><ref type="bibr" target="#b24">Popovic et al., 2013)</ref>. Along this direction, the initial efforts to develop error taxonomies covering different levels of granularity <ref type="bibr" target="#b9">(Flanagan, 1994;</ref><ref type="bibr" target="#b34">Vilar et al., 2006;</ref><ref type="bibr" target="#b7">Farrús Cabeceran et al., 2010;</ref><ref type="bibr" target="#b30">Stymne and Ahrenberg, 2012;</ref><ref type="bibr" target="#b25">Lommel et al., 2014</ref>) have been re- cently complemented by investigations on how to exploit error annotations for diagnostic purposes. Error annotations of sentences produced by differ- ent MT systems, in different target languages and domains, have been used to determine the qual- ity of translations according to the amount of er- rors encountered ( <ref type="bibr" target="#b24">Popovic et al., 2013)</ref>, to design new automatic metrics that take into considera- tion human annotations <ref type="bibr" target="#b26">(Popovic, 2012;</ref><ref type="bibr" target="#b4">Bojar et al., 2013)</ref>, and to train classifiers that can auto- matic identify fine-grained errors in the MT output <ref type="bibr" target="#b23">(Popovi´cPopovi´c and Ney, 2011</ref>). The impact of edit op- erations on post-editors' productivity, which im- plicitly connects the severity of different errors to human activity, has also been studied <ref type="bibr" target="#b31">(Temnikova, 2010;</ref><ref type="bibr" target="#b21">O'Brien, 2011;</ref><ref type="bibr" target="#b3">Blain et al., 2011</ref>), but few attempts have been made to explicitly model how fine-grained errors impact on human quality judgements and automatic metrics. Recently, the relation between different error types, their frequency, and human quality judge- ments has been investigated from a descriptive standpoint in ( <ref type="bibr" target="#b25">Lommel et al., 2014;</ref><ref type="bibr" target="#b25">Popovi´cPopovi´c et al., 2014</ref>). In both works, however, the underlying as- sumption that the most frequent error has also the largest impact on quality perception is not verified (in general and, least of all, across language pairs, domains, MT systems and post-editors). Another limitation of the proposed (univariate) analysis lies in the fact that it exclusively focuses on error types taken in isolation. This simplification excludes the possibility that humans, when assigning a global quality score to a translation, may be influenced not only by the error types but also by their inter- action. The implications of such possibility call for a multivariate analysis capable to model also error interactions.</p><p>In ( <ref type="bibr" target="#b15">Kirchhoff et al., 2013</ref>), a statistically- grounded approach based on conjoint analysis has been used to investigate users' reactions to dif- ferent types of translation errors. According to their results, word order is the most dispreferred error type, and the count of the errors in a sen- tence is not a good predictor of users' prefer- ences. Though more sophisticated than methods based on rough error counts, the conjoint model is bound to several constraints that limit its us- ability. In particular, the application of conjoint analysis in this context requires to: i) operate with semi-automatically created (hence artificial) data instead of real MT output, ii) manually define dif- ferent levels of severity for each error type (e.g. high/medium/low), and iii) limit the number of er- ror types considered to avoid the explosion of all possible combinations. Finally, the conjoint anal- ysis framework is not able to explicitly model vari- ance in the translated sentences, the human anno- tators, and the SMT systems used to translate the source sentences. Our claim is that avoiding any possible bias introduced by these factors should be a priority in the analysis of empirical observations in a given experimental setting.</p><p>So far, the relation between errors and auto- matic metrics has been analysed by measuring the correlation between single or total error frequen- cies and automatic scores <ref type="bibr" target="#b23">(Popovi´cPopovi´c and Ney, 2011;</ref><ref type="bibr" target="#b6">Farrús et al., 2012</ref>). Using two different error tax- onomies, both works show that the sum of the er- rors has a high correlation with BLEU and TER scores. Similar to the aforementioned works ad- dressing the impact of MT errors on human per- ception, these studies disregard error interactions, and their possible impact on automatic scores.</p><p>To overcome these issues, we propose a ro- bust statistic analysis framework based on mixed- effects models, which have been successfully ap- plied to several NLP problems such as sentiment analysis <ref type="bibr" target="#b14">(Greene and Resnik, 2009)</ref>, automatic speech recognition ( <ref type="bibr" target="#b12">Goldwater et al., 2010)</ref>, and spoken language translation <ref type="bibr" target="#b28">(Ruiz and Federico, 2014)</ref>. Despite their effectiveness, the use of mixed-effects models in the MT field is rather re- cent and limited to the analysis of human post- editions ( <ref type="bibr" target="#b13">Green et al., 2013;</ref><ref type="bibr" target="#b17">Läubli et al., 2013</ref>). In both studies, the goal was to evaluate the im- pact of post-editing on the quality and productivity of human translation assuming an ANOVA mixed model for a between-subject design, in which hu- man translators either post-edited or translated the same texts. Our scenario is rather different as we employ mixed models to measure the influence of different MT error types -expressed as continu- ous fixed effects -on quality judgements and auto- matic quality metrics. Mixed models, having the capability to absorb random variability due to the specific experimental set-up, provide a robust mul- tivariate method to efficiently analyse the impor- tance of error types.</p><p>Finally, differently from all previous works, our analysis is run on language pairs having English as source and languages distant from English (in term of morphology and word-order) as target.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Mixed-effects Models</head><p>Mixed-effects models -or simply mixed models -like any regression model, express the relation- ship between a response variable and some co- variates and/or contrast factors. They enhance conventional models by complementing fixed ef- fects with so-called random effects. Random ef- fects are introduced to absorb random variability inherent to the specific experimental setting from which the observations are drawn. In general, ran- dom effects correspond to covariates that are not - or cannot be -exhaustively observed in an experi- ment, e.g. the human annotators and the evaluated systems. Hence, mixed models permit to elegantly cope with experimental design aspects that hinder the applicability of conventional regression mod- els. These are, in particular, the use of repeated and/or clustered observations that introduce corre- lations in the response variable that clearly violate the independence and homoscedasticity assump- tions of conventional linear, ANOVA, and logis- tic regression models. Significance testing with mixed models is in general more powerful, i.e. less prone to Type II Errors, and also permits to reduce the chance of Type I Errors in within-subject de- signs, which are prone to the "fallacy of language- as-a-fixed-effect" <ref type="bibr" target="#b5">(Clark, 1973)</ref>.</p><p>Random effects can be directly associated to the regression model parameters, as random in- tercepts and random slopes, and have the same form of the generic error component of the model, i.e. normally distributed with zero mean and un- known variance. As random effects introduce hid- den variables, mixed models are trained with Ex- pectation Maximization, while significance testing is performed via likelihood-ratio (LR) tests.</p><p>In this work we employ mixed linear models to measure the influence of different MT error types, expressed as continuous fixed effects, on quality judgements or on automatic quality metrics. <ref type="bibr">1</ref> We illustrate mixed linear models ( <ref type="bibr" target="#b0">Baayen et al., 2008)</ref> by referring to our analysis, which ad- dresses the relationships between a quality metric (y) and different types of errors (e.g. A, B, and C) 2 observed at the sentence level. For the sake of simplicity, we assume to have balanced repeated observations for one single crossed effect. That is, we have i ∈ {1, . . . , I} MT systems (our groups) each of which translated the same j ∈ {1, . . . , J} test sentences. Our response variable y ij -a nu- meric quality score -is computed on each (sen- tence, system) pair, and we aim to investigate its relationship with error statistics available for each MT output, namely A ij , B ij and C ij . A (possible) linear mixed model for our study would be:</p><formula xml:id="formula_0">y ij = β 0 + β 1 A ij + β 2 B ij + β 3 C ij + (1) b 0,i + b 1,i A ij + b 2,i B ij + b 3,i C i + ij</formula><p>The model is split into two lines on purpose. The first line shows the fixed effect component, that is intercept (β 0 ) and slopes (β 1 , β 2 , β 3 ) for each error type. The second line specifies the random struc- ture of the model, which includes random inter- cept and slopes for each MT system and the resid- ual error. Borrowing the notation from ( <ref type="bibr" target="#b13">Green et al., 2013)</ref>, we conveniently rewrite (1) in the group-wise arranged matrix notation:</p><formula xml:id="formula_1">y i = x T i β + z T i b i + i<label>(2)</label></formula><p>where y i is the J × 1 vector of responses, x i is the J ×p design matrix of covariates (including the in- tercept) with fixed coefficients β ∈ R p×1 , z is the random structure matrix defined by J × q covari- ates with random coefficients b i ∈ R q×1 , and i is the vector of residuals (in our example, p = 4 and q = 4). By packing together vectors and matrices indexed over groups i, we can rewrite the model in a general form ( <ref type="bibr" target="#b0">Baayen et al., 2008</ref>), which can represent any possible crossed-effects and random structures defined over them allowing, at the same time, for a compact model specification:</p><formula xml:id="formula_2">y = X T β + Z T b + (3) ∼ N (0, σ 2 I), b ∼ N (0, σ 2 Σ), b ⊥ 1</formula><p>Although mixed ordinal models ( <ref type="bibr" target="#b33">Tutz and Hennevogl, 1996)</ref> are in principle more appropriate to target quality judgements, in our preliminary investigations mixed linear models showed a significantly higher predictive power. <ref type="bibr">2</ref> Here, A, B and C represent three generic error classes. Their actual number in a given experimental setting will de- pend on the granularity of the reference error taxonomy.</p><p>where Σ is the relative variance-covariance q × q matrix of the random effects (now q = 4I), σ 2 is the variance of the per-observation term , the symbol ⊥ denotes independence of random vari- ables, and N indicates the multivariate normal dis- tribution. While b, σ, and Σ are estimated via max- imum likelihood, the single random intercept and slope values for each group are calculated subse- quently. They are referred to as Best Linear Un- biased Predictors (BLUPS) and, formally, are not parameters of the model.</p><p>The significance of the contribution of each sin- gle parameter (e.g. single entries of Σ) to the goodness of fit can be tested via likelihood ratio. In this way, both the fixed and random effect struc- ture of the model can be investigated with respect to its actual necessity to the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Dataset</head><p>For our analysis we used a dataset that covers three translation directions, corresponding to En- glish to Chinese, Arabic, and Russian. An inter- national organization provided us a set of English sentences together with their translation produced by two anonymous MT systems. For each evalu- ation item (source sentence and two MT outputs) three experts were asked to assign quality scores to the MT outputs, and a fourth expert was asked to annotate translation errors. The four experts, who were all professional translators native in the ex- amined target languages, were carefully trained to get acquainted with the evaluation guidelines and the annotation tool specifically developed for these evaluation tasks ( <ref type="bibr" target="#b11">Girardi et al., 2014</ref>). The anno- tation process was carried out in parallel by all an- notators over one week, resulting in a final dataset composed of 312 evaluation items for the ENZH direction, 393 for ENAR, and 437 for ENRU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Quality Judgements</head><p>Quality judgements were collected by asking the three experts to rate each automatic translation according to a 1-5 Likert scale, where 1 means "incomprehensible translation" and 5 means "per- fect translation". The distribution of the collected annotations with respect to each quality score is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. As we can see, this distri- bution reflects different levels of perceived qual- ity across languages. ENZH, for instance, has the highest number of low quality scores (1 and 2), while ENRU has the highest number of high qual- ity scores (4 and 5). <ref type="table">Table 1</ref> shows the average of all the qual- ity scores assigned by each annototator as well as the average score obtained for each MT sys- tem. These values demonstrate the variability of annotators and systems. A particularly high variability among human judges is observed for the ENAR language direction (also reflected by the inter-annotator agreement scores discussed be- low), while ENZH shows the highest variability between systems. As we will see in §5.1, we suc- cessfully cope with this variability by considering systems and annotators as random effects, which allow the regression models to abstract from these differences. Inter-annotator agreement was computed using the Fleiss' kappa coefficient <ref type="bibr" target="#b10">(Fleiss, 1971)</ref>, and re- sulted in 22.70% for ENZH, 5.24% for ENAR, and 21.80% for ENRU. While for ENZH and ENRU the results fall in the range of "fair" agreement ( <ref type="bibr" target="#b16">Landis and Koch, 1977)</ref>, for ENAR only "slight" agreement is reached, reflecting the higher anno- tators' variability evidenced in <ref type="table">Table 1</ref>.</p><p>A more fine-grained agreement analysis is pre- sented in <ref type="figure" target="#fig_1">Figure 2</ref>, where the kappa values are given for each score class. In general we no- tice a lower agreement on the intermediate quality scores, while annotators tend to agree on very bad and, even more, on good translations. In partic- ular, we see that the agreement for ENAR is sys- tematically lower than the values measured for the other languages on all the score classes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Error Annotation</head><p>This evaluation task was carried out by one ex- pert for each language direction, who was asked to identify the type of errors present in the MT output and to mark their position in the text. Since the fo- cus of our work is the analysis method rather than the definition of an ideal error taxonomy, for the difficult language directions addressed we opted for the following general error classes, partially overlapping with ( <ref type="bibr" target="#b34">Vilar et al., 2006</ref>): i) reordering errors, ii) lexicon errors (including wrong lexical choices and extra words), iii) missing words, iv) morphology errors. <ref type="figure" target="#fig_2">Figure 3</ref> shows the distribution of the errors in terms of affected tokens (words) for each error type. Since token counts for Chinese are not word- based but character-based, for readability purposes the number of errors counted for Chinese trans- lations have been divided by 2.5. Note also that morphological errors annotated for ENZH involve only 13 characters and thus are not visible in the plot. The total number of errors amounts to 16,320 characters for ENZH, 4,926 words for ENAR, and 5,965 words for ENRU.</p><p>This distribution highlights some differences between languages directions. For example, trans- lations into Arabic and Russian present several morphology errors, while word reordering is the most frequent issue for translations into Chinese. As we will see in §5.1, error frequency does not give a direct indication of their impact on trasla- tion quality judgements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Automatic Metrics</head><p>In our investigation we consider three popular au- tomatic metrics: sentence-level BLEU ( <ref type="bibr" target="#b18">Lin and Och, 2004</ref>), TER ( <ref type="bibr" target="#b29">Snover et al., 2006</ref>), and GTM ( <ref type="bibr" target="#b32">Turian et al., 2003</ref>). We compute all automatic scores by relying on a single reference and by means of standard packages. In particular, auto- matic scores on Chinese are computed at the char- acter level. Moreover, as we use metrics as re- sponse variables for our regression models, we compute all metrics at the sentence level. The overall mean scores for all systems and languages are reported in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>To assess the impact of translation errors on MT quality we perform two sets of experiments. The first set ( §5.1) addresses the relation between er- rors and human quality judgements. The sec- ond set ( §5.2) focuses on the relation between er- rors and automatic metrics. In both cases, be- fore measuring the impact of different errors on the response variable (respectively quality judge- ments and metrics), we validate the effectiveness of mixed linear models by comparing their predic- tion capability with other methods.</p><p>In all experiments, error counts of each category were normalized into percentages with respect to the sentence length and mapped in a logarithmic scale. In this way, we basically assume that the impact of errors tends to saturate above a given threshold, hypothesis that also results in better fits by our models. <ref type="bibr">3</ref> Notice that while the chosen log-10 base is easy to interpret, linear models can im- plicitly adjust it. Our analysis makes use of mixed linear models incorporating, as fixed effects, the four types of errors (lex, miss, morph and reo) and their pairwise interactions (the product of the sin- gle error log counts), while their random struc- ture depends on each specific experiment. For the experiments we rely on the R language (R Core Team, 2013) implementation of linear mixed model in the lme4 library ( <ref type="bibr" target="#b2">Bates et al., 2014</ref>).</p><p>We assess the quality of our mixed linear mod- els (MLM) by comparing their prediction capabil- ity with a sequence of simpler linear models in- cluding only fixed effects. In particular, we built five univariate models and two multivariate mod- els. The univariate models use as covariates, re- spectively, the sum of all error types (baseline), and each of the four types of errors (lex, miss, morph and reo). The two multivariate models in- clude all the four error types, considering them without interactions (FLM w/o Interact.) and with interactions (FLM).</p><p>Prediction performance is computed in terms of Mean Absolute Error (MAE), <ref type="bibr">4</ref> which we estimate by averaging over 1,000 random splits of the data in 90% training and 10% test. In particular, for the human quality classes we pick the integer between 1-5 that is closest to the predicted value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Errors vs. Quality Judgements</head><p>The response variable we target in this experiment is the quality score produced by human annotators. Our measurements follow a typical within-subject design in which all the 3 annotators are exposed to the same conditions (levels of the independent variables), corresponding in our case to perfectly balanced observations from 2 MT systems and N sentences. This setting results in repeated or clus- tered observations (thus violating independence) corresponding to groups which naturally identify possible random effects, 5 namely the annotators (3 levels with 2xN observations each), the systems (2 levels and 3xN observations each), and the sen- rors follows a log-scale law: e.g. more sensitive to variations in the interval <ref type="bibr">[1]</ref><ref type="bibr">[2]</ref><ref type="bibr">[3]</ref><ref type="bibr">[4]</ref><ref type="bibr">[5]</ref><ref type="bibr">[6]</ref><ref type="bibr">[7]</ref><ref type="bibr">[8]</ref><ref type="bibr">[9]</ref><ref type="bibr">[10]</ref> that in the interval <ref type="bibr">[30]</ref><ref type="bibr">[31]</ref><ref type="bibr">[32]</ref><ref type="bibr">[33]</ref><ref type="bibr">[34]</ref><ref type="bibr">[35]</ref><ref type="bibr">[36]</ref><ref type="bibr">[37]</ref><ref type="bibr">[38]</ref><ref type="bibr">[39]</ref><ref type="bibr">[40]</ref>. <ref type="bibr">4</ref> MAE is calculated as the average of the absolute errors |fi − yi|, where fi is the prediction of the model and yi the true value for the i th instance. As it is a measure of error, lower MAE scores indicate that our predictions are closer to the true values of each test instance.  <ref type="table">Table 3</ref>: Prediction capability of human judge- ments (MAE).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ENZH ENAR ENRU</head><p>tences (N levels with 6 observations each). In prin- ciple, such random effects permit to remove sys- tematic biases of individual annotators, single sys- tems and even single sentences, which are mod- elled as random variables sampled from distinct populations. <ref type="table">Table 3</ref> shows a comparison of the prediction capability of the mixed model 6 with simpler ap- proaches. While the good performance achieved by our strong baseline cannot be outperformed by separately counting the number of errors of a single type, lower MAE results are obtained by methods based on multivariate analysis. Among them, FLM brings the first consistent improve- ments over the baseline by considering error in- teractions, while MLM leads to the lowest MAE due to the addition of random effects. The impor- tance of random effects is particularly evidenced by ENAR (12 points below the baseline). Indeed, as discussed in §4.1, for this language combina- tion human annotators show the lowest agreement score. This variability, which hides the smaller differences in systems' behaviour, demonstrates the importance of accounting for the erratic fac- tors that might influence empirical observations in a given setting. The good performance achieved by MLM, combined with their high descriptive power, <ref type="bibr">7</ref> motivates their adoption in our study.</p><p>Concerning the analysis of error impact, Ta- ble 4 shows the statistically significant coefficients for the full-fledged MLM models for each trans- lation direction. By default, all reported coeffi- cients have p-values ≤ 10 −4 , while those marked with • and • have respectively p-values ≤ 10 −3 and ≤ 10 −2 . Slope coefficients basically show <ref type="bibr">6</ref> Note that the mixed model used in prediction does not in- clude the random effect on sentences since the training sam- ples do not guarantee sufficient observations for each test sen- tence. <ref type="bibr">7</ref> Note that the strong baseline used for comparison is not capable to describe the contribution of the different error types.  <ref type="table">Table 4</ref>: Effect of translation errors on MT qual- ity perception on all judged sentences. Reported coefficients (β) are all statistically significant with p ≤ 10 −4 , except those marked with • (p ≤ 10 −3 ), and</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Error</head><note type="other">ENZH ENAR ENRU Intercept 4.</note><note type="other">lex:reo 0.50 0.21 - miss:morph - 0.35 - miss:reo 0.54 0.33 - morph:reo - 0.37 -</note><formula xml:id="formula_3">• (p ≤ 10 −2 ).</formula><p>the impact of different error types (alone and in combination) on human quality scores. Those that are not statistically significant are omitted as they do not increase the fitting capability of our model. As can be seen from the table, such impact varies across the different language combinations. While for ENZH and ENRU miss is the error having the highest impact (highest decrement with respect to the intercept), the most problematic error for ENAR is lex. It is interesting to observe that pos- itive values for error combinations indicate that their combined impact is lower that the sum of the impact of the single errors. For instance, while for ENZH a one-step increment in lex and miss errors would respectively cause a reduction in the human judgement of 1.27 and 1.76, their occurrence in the same sentence would be discounted by 1.00. This would result in a global judgement of 2.26 (4.29 -1.27 -1.76 +1.00) instead of 1.26. While for ENAR this phenomenon can be observed for all error combinations, such discount effects are not always significant for the other two language pairs. The existence of discount effects of various magnitude associated to the different error com- binations is a novel finding made possible by the adoption of mixed-effect models.</p><p>Another interesting observation is that, in con- trast with the common belief that the most fre- quent errors have the highest impact on human quality judgements, our experiments do not re- veal such strict correlation (at least for the exam- ined language pairs). For instance, for ENZH and ENRU the impact of miss errors is higher than the impact of other more frequent issues.  <ref type="table">Table 5</ref>: Prediction capability of BLEU score, TER and GTM (MAE).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Errors vs. Automatic Metrics</head><p>In this experiment, the response variable is an au- tomatic metric which is computed on a sample of MT outputs (which are again perfectly balanced over systems and sentences) and a set of reference translations. As no subjects are involved in the ex- periment, random variability is assumed to come from the involved systems, the tested sentences, and the unknown missing link between the covari- ates (error types) and the response variable which is modelled by the residual noise. Notice that, in this case, the random effect on the sentences also incorporates in some sense the randomness of the corresponding reference translations, which are themselves representatives of larger samples. The prediction capability of the mixed model, in comparison with the simpler ones, is reported in <ref type="table">Table 5</ref>. Also in this case, the low MAE achieved by the baseline is out of the reach of uni- variate methods. Again, small improvements are brought by FLM when considering error interac- tions, whereas the most visible gains are achieved by MLM due to their control of random effects. This is more evident for some language combina- tions and can be explained by the differences in systems' performance, a variability factor easily absorbed by random effects. Indeed, the largest MAE decrements over the baseline are always ob- served for ENZH (for which the overall mean re- sults reported in <ref type="table" target="#tab_1">Table 2</ref> show the largest dif- ferences) and the smallest decrements relate to language/metric combinations where systems' be- haviour is more similar (e.g. ENRU/GTM).</p><p>Concerning the analysis of error impact, <ref type="table">Table  6</ref> shows how different error types (alone and in combination) influence performance results mea- sured with automatic metrics. To ease interpre- tation of the reported figures we also show Pear- son and Spearman correlations of each set of coef- ficients (excluding intercept estimates) with their corresponding coefficients reported in <ref type="table">Table 4</ref>. In fact, our primary interest in this experiment is to see which metrics show a sensitivity to specific er- ror types similar to human perception. As we can see, the coefficients for each metric significantly vary depending on the language, for the simple reason that also the distribution and co-occurrence of errors vary significantly across the different lan- guages and MT systems. Remarkably, for some translation directions, some of the metrics show a sensitivity to errors that is very similar to that of human judges. In particular, BLEU for ENZH and ENAR, and GTM for ENZH show a very high correlation with the human sensitivity to transla- tion errors, with Pearson correlation coefficient ≥ 0.97. For ENRU, the best Pearson correlation is instead achieved by TER (-0.78).</p><p>Besides these general observations, a closer look at the reported scores brings additional find- ings. In three cases (BLEU for ENZH, GTM for ENZH and ENAR) the analysed metrics are most sensitive to the same error type that has the high- est influence on human judgements (according to <ref type="table">Table 4</ref>, these are miss for ENZH and ENRU, lex for ENAR). On the contrary, in one case (TER for ENZH) the analysed metric is insensitive to the er- ror type (miss) which has the highest impact on hu- man quality scores. From a practical point of view, these remarks provide useful indications about the appropriateness of each metric to highlight the de- ficiencies of a specific system and to measure im- provements targeting specific issues. As a rule of thumb, for instance, to measure improvements of an ENZH system with respect to missing words, it would be more advisable to use BLEU or GTM instead of TER. 8  <ref type="table">Table 6</ref>: Effect of translation errors on BLEU score, TER and GTM on all judged sentences and correla- tion with their corresponding effects on human quality scores (from <ref type="table">Table 4</ref> Similar considerations also apply to the analysis of the impact of error combinations. The same dis- count effects that we noticed when analysing the impact of errors' co-occurrence on human percep- tion ( §5.1) are evidenced, with different degrees of sensitivity, by the automatic metrics. While some of them substantially reflect human response (e.g. BLEU and GTM for ENZH), in some cases we observe either the insensitivity to specific combi- nations (mostly for ENAR), or a higher sensitivity compared to the values measured for human as- sessors (mostly for ENRU, where the impact of miss:reo combinations is discounted -hence un- derestimated -by all the metrics).</p><note type="other">BLEU score TER GTM Error ENZH ENAR ENRU ENZH ENAR ENRU ENZH ENAR ENRU</note><p>Despite such small differences, the coherence of our results with previous findings ( §5.1) suggests the reliability of the applied method. Complet- ing the picture along the side of the MT evalua- tion triangle which connects error annotations and automatic metrics, our findings contribute to shed light on the existing relationships between transla- tion errors, their interaction, and the sensitivity of widely used automatic metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We investigated the MT evaluation triangle (hav- ing as corners automatic metrics, human quality judgements and error annotations) along the two less explored sides, namely: i) the relation be- tween MT errors and human quality judgements but that TER becomes less sensitive to such errors when they co-occur with other types of errors. Overall, our experiments show that when MT outputs contain more than one error type, automatic metrics show different levels of sensitivity to each specific error type. and ii) the relation between MT errors and auto- matic metrics. To this aim we employed a ro- bust statistical analysis framework based on lin- ear mixed-effects models (the first contribution of the paper), which have a higher descriptive power than simpler methods based on the raw count of translation errors and are less artificial compared to previous statistically-grounded approaches.</p><p>Working on three translation directions having Chinese, Arabic and Russian as target (our second contribution), we analysed error-annotated trans- lations considering the impact of specific errors (alone and in combination) and accounting for the variability of the experimental set-up that origi- nated our empirical observations. This led us to interesting findings specific to each language pair (third contribution). Concerning the relation be- tween MT errors and quality judgements, we have shown that: i) the frequency of errors of a given type does not correlate with human preferences, ii) errors having the highest impact can be pre- cisely isolated and iii) the impact of error inter- actions is often subject to measurable and previ- ously unknown "discount" effects. Concerning the relation between MT errors and automatic met- rics (BLEU, TER and GTM), our analysis evi- denced significant differences in the sensitivity of each metric to different error types. Such differ- ences provide useful indications about the most appropriate metric to assess system improvements with respect to specific weaknesses. If learning from errors is a crucial aspect of improving exper- tise, our method and the resulting empirical find- ings represent a significant contribution towards a more informed approach to system development, improvement and evaluation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Distribution of quality scores.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Class specific inter-annotator agreement.</figDesc><graphic url="image-2.png" coords="5,351.78,94.06,122.38,60.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Distribution of error types.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>). Reported coefficients (β) are statistically significant with p ≤ 10 −4 , except those marked with • (p ≤ 10 −3 ), • (p ≤ 10 −2 ) and 2 (p ≤ 10 −1 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 .</head><label>2</label><figDesc>Differences in systems' performance can be observed for all language pairs; as we will observe in §5.2 such variability explains the effectiveness of considering the MT systems as a random effect. BLEU TER GTM Sys1 Sys2 Sys1 Sys2 Sy1 Sys2 ENZH 27.95 44.11 64.52 48.13 62.15 72.30 ENAR 19.63 25.25 68.83 63.99 47.20 52.33 ENRU 27.10 31.07 60.89 54.41 53.74 56.41</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Overall automatic scores per system.</figDesc><table></table></figure>

			<note place="foot" n="3"> In other words, we assume that human sensitivity to er</note>

			<note place="foot" n="5"> In all our experiments, random effects are limited to random shifts since preliminary experiments also including random slopes did not provide consistent results.</note>

			<note place="foot" n="8"> Note that this conclusion holds for our data sample, in which different types of errors co-occur and only one reference translation is available. In such conditions, our regression model shows that TER is not influenced by miss errors in a statistically significant way. This does not mean that TER is insensitive to missing words when occurring in isolation,</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work has been partially supported by the EC-funded project MateCat <ref type="bibr">(ICT-2011.4.2-287688</ref>).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mixed-effects modeling with crossed random effects for subjects and items</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harald</forename><forename type="middle">R</forename><surname>Baayen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><forename type="middle">J</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><forename type="middle">M</forename><surname>Bates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of memory and language</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="390" to="412" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">METEOR: An automatic metric for MT evaluation with improved correlation with human judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satanjeev</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</title>
		<meeting>the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005-06" />
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">lme4: Linear mixed-effects models using Eigen and S4. R package version 1</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Maechler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Bolker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Walker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Qualitative analysis of post-editing for high quality machine translation. In Asia-Pacific Association for Machine Translation (AAMT), editor, Machine Translation Summit XIII</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Blain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirko</forename><surname>Plitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johann</forename><surname>Roturier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="19" to="23" />
			<pubPlace>Xiamen (China</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<title level="m">Proceedings of the Eighth Workshop on Statistical Machine Translation</title>
		<meeting>the Eighth Workshop on Statistical Machine Translation<address><addrLine>Sofia, Bulgaria, August</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="44" />
		</imprint>
	</monogr>
	<note>Findings of the 2013 Workshop on Statistical Machine Translation</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The language-as-fixed-effect fallacy: A critique of language statistics in psychological research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Herbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of verbal learning and verbal behavior</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="335" to="359" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Study and correlation analysis of linguistic, perceptual, and automatic machine translation evaluations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mireia</forename><surname>Farrús</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><forename type="middle">R</forename><surname>Costa-Jussà</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Popovi´cpopovi´c</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Soc. Inf. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="174" to="184" />
			<date type="published" when="2012-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Linguistic-based evaluation criteria to identify statistical machine translation errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><forename type="middle">Ruiz</forename><surname>Mireia Farrús Cabeceran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José</forename><surname>Costa-Jussà</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bernardo Mariño</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José</forename><surname>Acebal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adrián Rodríguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fonollosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th</title>
		<meeting>the 14th</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Annual Conference of the European Association for Machine Translation (EAMT)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Error classification for mt evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Flanagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Technology Partnerships for Crossing the Language Barrier: Proceedings of the First Conference of the Association for Machine Translation in the Americas</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Measuring nominal scale agreement among many raters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">L</forename><surname>Fleiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mt-equal: a toolkit for human assessment of machine translation output</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Girardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Amin Farajian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: System Demonstrations</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: System Demonstrations<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-08" />
			<biblScope unit="page" from="120" to="123" />
		</imprint>
		<respStmt>
			<orgName>Dublin City University and Association for Computational Linguistics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Which words are hard to recognize? prosodic, lexical, and disfluency factors that increase speech recognition error rates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="181" to="200" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The efficacy of human post-editing for language translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spence</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="439" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">More than words: Syntactic packaging and implicit sentiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, NAACL &apos;09</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, NAACL &apos;09<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="503" to="511" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A conjoint analysis framework for evaluating user preferences in machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Kirchhoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Capurro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><forename type="middle">M</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Translation</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The measurement of observer agreement for categorical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><forename type="middle">G</forename><surname>Landis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="159" to="174" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Assessing Post-Editing Efficiency in a Realistic Translation Environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Läubli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Fishel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Massey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maureen</forename><surname>Ehrensberger-Dow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Volk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of MT Summit XIV Workshop on Post-editing Technology and Practice</title>
		<editor>Michel Simard Sharon O&apos;Brien and Lucia Specia</editor>
		<meeting>MT Summit XIV Workshop on Post-editing Technology and Practice<address><addrLine>Nice, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="83" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Orange: a method for evaluating automatic evaluation metrics for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Coling 2004</title>
		<meeting>Coling 2004<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>COLING</publisher>
			<date type="published" when="2004-08-23" />
			<biblScope unit="page" from="501" to="507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arle</forename><surname>Lommel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aljoscha</forename><surname>Burchardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Popovi´cpopovi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename><surname>Harris</surname></persName>
		</author>
		<imprint>
			<publisher>Eleftherios Avramidis, and Hans Uszkoreit</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Using a new analytic measure for the annotation and analysis of mt errors on real data</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Conference of the European Association for Machine Translation (EAMT)</title>
		<meeting>the 17th Conference of the European Association for Machine Translation (EAMT)<address><addrLine>Dubrovnik, Croatia</addrLine></address></meeting>
		<imprint>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Cognitive Explorations of Translation. Bloomsbury Studies in Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Sharon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brien</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Bloomsbury Academic</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
		<idno>RC22176</idno>
		<imprint>
			<date type="published" when="2001" />
			<pubPlace>Thomas J. Watson Research Center</pubPlace>
		</imprint>
		<respStmt>
			<orgName>IBM Research Division</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Research Report</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Towards automatic error analysis of machine translation output</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Popovi´cpopovi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="657" to="688" />
			<date type="published" when="2011-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning from human judgments of machine translation output</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Popovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleftherios</forename><surname>Avramidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aljoscha</forename><surname>Burchardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Hunsicker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><surname>Schmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cindy</forename><surname>Tscherwinka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vilar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the MT Summit XIV. Proceedings of MT Summit XIV</title>
		<meeting>the MT Summit XIV. MT Summit XIV</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Relations between different types of post-editing operations, cognitive effort and temporal effort</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Popovi´cpopovi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arle</forename><surname>Lommel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aljoscha</forename><surname>Burchardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Conference of the European Association for Machine Translation (EAMT)</title>
		<meeting>the 17th Conference of the European Association for Machine Translation (EAMT)<address><addrLine>Dubrovnik, Croatia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
		</imprint>
	</monogr>
	<note>Eleftherios Avramidis, and Hans Uszkoreit</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Class error rates for evaluation of machine translation output</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Popovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Workshop on Statistical Machine Translation</title>
		<meeting>the Seventh Workshop on Statistical Machine Translation<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012-06" />
			<biblScope unit="page" from="71" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>R Core Team</surname></persName>
		</author>
		<title level="m">R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Assessing the Impact of Speech Recognition Errors on Machine Translation Quality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th Conference of the Association for Machine Translation in the Americas (AMTA)</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A study of translation edit rate with targeted human annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linnea</forename><surname>Micciulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th Conference of the Association for Machine Translation in the Americas (AMTA)</title>
		<meeting><address><addrLine>Boston, Massachusetts</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On the practice of error analysis for machine translation evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Stymne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Ahrenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalid</forename><surname>Choukri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Declerck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bente</forename><surname>Mehmet Uur Doan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maegaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC&apos;12)</title>
		<meeting>the Eight International Conference on Language Resources and Evaluation (LREC&apos;12)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Joseph Mariani, Jan Odijk, and Stelios Piperidis. Istanbul, Turkey, may. European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Cognitive evaluation approach for a controlled language post-editing experiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Temnikova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">;</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalid</forename><surname>Choukri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bente</forename><surname>Maegaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Mariani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC&apos;10)</title>
		<meeting>the Seventh International Conference on Language Resources and Evaluation (LREC&apos;10)<address><addrLine>Odijk, Stelios Piperidis, Mike Rosner, and Daniel Tapias; Valletta, Malta, may</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-01" />
		</imprint>
	</monogr>
	<note>Nicoletta Calzolari (Conference Chair). European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Evaluation of machine translation and its evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">P</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">Dan</forename><surname>Melamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the MT Summit IX</title>
		<meeting>the MT Summit IX</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Random effects in ordinal regression models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Tutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Hennevogl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Statistics &amp; Data Analysis</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="537" to="557" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Error analysis of statistical machine translation output</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vilar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC&apos;06)</title>
		<meeting>the Fifth International Conference on Language Resources and Evaluation (LREC&apos;06)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="697" to="702" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
