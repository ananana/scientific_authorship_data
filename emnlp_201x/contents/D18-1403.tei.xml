<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Summarizing Opinions: Aspect Extraction Meets Sentiment Prediction and They Are Both Weakly Supervised</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Angelidis</surname></persName>
							<email>s.angelidis@ed.ac.uk, mlap@inf.ed.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Language, Cognition and Computation School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<addrLine>10 Crichton Street</addrLine>
									<postCode>EH8 9AB</postCode>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Language, Cognition and Computation School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<addrLine>10 Crichton Street</addrLine>
									<postCode>EH8 9AB</postCode>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Summarizing Opinions: Aspect Extraction Meets Sentiment Prediction and They Are Both Weakly Supervised</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="3675" to="3686"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>3675</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a neural framework for opinion summarization from online product reviews which is knowledge-lean and only requires light supervision (e.g., in the form of product domain labels and user-provided ratings). Our method combines two weakly supervised components to identify salient opinions and form extractive summaries from multiple reviews: an aspect extractor trained under a multi-task objective, and a sentiment predictor based on multiple instance learning. We introduce an opinion summarization dataset that includes a training set of product reviews from six diverse domains and human-annotated development and test sets with gold standard aspect annotations, salience labels, and opinion summaries. Automatic evaluation shows significant improvements over baselines, and a large-scale study indicates that our opinion summaries are preferred by human judges according to multiple criteria. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Opinion summarization, i.e., the aggregation of user opinions as expressed in online reviews, blogs, internet forums, or social media, has drawn much attention in recent years due to its potential for various information access applications. For example, consumers have to wade through many product reviews in order to make an informed de- cision. The ability to summarize these reviews succinctly would allow customers to efficiently absorb large amounts of opinionated text and man- ufacturers to keep track of what customers think about their products ( <ref type="bibr" target="#b24">Liu, 2012)</ref>.</p><p>The majority of work on opinion summarization is entity-centric, aiming to create summaries from text collections that are relevant to a particular en- tity of interest, e.g., product, person, company, and so on. A popular decomposition of the prob- lem involves three subtasks ( <ref type="bibr">Hu and Liu, 2004, 1</ref> Our code and dataset are publicly available at https: //github.com/stangelid/oposum. 2006): (1) aspect extraction which aims to find specific features pertaining to the entity of interest (e.g., battery life, sound quality, ease of use) and identify expressions that discuss them; (2) senti- ment prediction which determines the sentiment orientation (positive or negative) on the aspects found in the first step, and (3) summary genera- tion which presents the identified opinions to the user (see <ref type="figure" target="#fig_0">Figure 1</ref> for an illustration of the task).</p><p>A number of techniques have been proposed for aspect discovery using part of speech tagging ( <ref type="bibr" target="#b10">Hu and Liu, 2004</ref>), syntactic parsing ( <ref type="bibr" target="#b29">Lu et al., 2009</ref>), clustering ( <ref type="bibr" target="#b32">Mei et al., 2007;</ref><ref type="bibr" target="#b42">Titov and McDonald, 2008b</ref>), data mining ( <ref type="bibr" target="#b19">Ku et al., 2006</ref>), and in- formation extraction <ref type="bibr" target="#b38">(Popescu and Etzioni, 2005)</ref>. Various lexicon and rule-based methods ( <ref type="bibr" target="#b10">Hu and Liu, 2004;</ref><ref type="bibr" target="#b19">Ku et al., 2006;</ref><ref type="bibr" target="#b2">Blair-Goldensohn et al., 2008</ref>) have been adopted for sentiment prediction together with a few learning approaches ( <ref type="bibr" target="#b29">Lu et al., 2009;</ref><ref type="bibr" target="#b37">Pappas and Popescu-Belis, 2017;</ref><ref type="bibr" target="#b0">Angelidis and Lapata, 2018)</ref>. As for the summaries, a com- mon format involves a list of aspects and the num- ber of positive and negative opinions for each ( <ref type="bibr" target="#b10">Hu and Liu, 2004)</ref>. While this format gives an over- all idea of people's opinion, reading the actual text might be necessary to gain a better under- standing of specific details. Textual summaries are created following mostly extractive methods (but see <ref type="bibr" target="#b8">Ganesan et al. 2010</ref> for an abstractive ap- proach), and various formats ranging from lists of words ( <ref type="bibr" target="#b38">Popescu and Etzioni, 2005</ref>), to phrases ( <ref type="bibr" target="#b29">Lu et al., 2009)</ref>, and sentences ( <ref type="bibr" target="#b32">Mei et al., 2007;</ref><ref type="bibr">BlairGoldensohn et al., 2008;</ref><ref type="bibr" target="#b20">Lerman et al., 2009</ref>; <ref type="bibr" target="#b43">Wang and Ling, 2016)</ref>.</p><p>In this paper, we present a neural framework for opinion extraction from product reviews. We follow the standard architecture for aspect-based summarization, while taking advantage of the suc- cess of neural network models in learning con- tinuous features without recourse to preprocess- ing tools or linguistic annotations. Central to our system is the ability to accurately identify aspect- Opinions on image quality, sound quality, connectivity, and price of an LCD television are extracted from a set of reviews. Their polarities are then used to sort them into positive and negative, while neutral or redundant comments are discarded. specific opinions by using different sources of in- formation freely available with product reviews (product domain labels, user ratings) and mini- mal domain knowledge (essentially a few aspect- denoting keywords). We incorporate these ideas into a recently proposed aspect discovery model ( <ref type="bibr" target="#b9">He et al., 2017</ref>) which we combine with a weakly supervised sentiment predictor <ref type="bibr" target="#b0">(Angelidis and Lapata, 2018)</ref> to identify highly salient opinions. Our system outputs extractive summaries using a greedy algorithm to minimize redundancy. Our approach takes advantage of weak supervision sig- nals only, requires minimal human intervention and no gold-standard salience labels or summaries for training.</p><p>Our contributions in this work are three-fold: a novel neural framework for the identification and extraction of salient customer opinions that combines aspect and sentiment information and does not require unrealistic amounts of supervi- sion; the introduction of an opinion summariza- tion dataset which consists of Amazon reviews from six product domains, and includes develop- ment and test sets with gold standard aspect an- notations, salience labels, and multi-document ex- tractive summaries; a large-scale user study on the quality of the final summaries paired with auto- matic evaluations for each stage in the summa- rization pipeline (aspects, extraction accuracy, fi- nal summaries). Experimental results demonstrate that our approach outperforms strong baselines in terms of opinion extraction accuracy and similar- ity to gold standard summaries. Human evaluation further shows that our summaries are preferred over comparison systems across multiple criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>It is outside the scope of this paper to provide a detailed treatment of the vast literature on opinion summarization and related tasks. For a compre- hensive overview of non-neural methods we refer the interested reader to <ref type="bibr" target="#b13">Kim et al. (2011)</ref> and <ref type="bibr" target="#b25">Liu and Zhang (2012)</ref>. We are not aware of previous studies which propose a neural-based system for end-to-end opinion summarization without direct supervision, although as we discuss below, recent efforts tackle various subtasks independently.</p><p>Aspect Extraction Several neural network models have been developed for the identification of aspects (e.g., words or phrases) expressed in opinions. This is commonly viewed as a super- vised sequence labeling task; <ref type="bibr" target="#b26">Liu et al. (2015)</ref> employ recurrent neural networks, whereas <ref type="bibr" target="#b46">Yin et al. (2016)</ref> use dependency-based embeddings as features in a Conditional Random Field (CRF).  combine a recursive neural network with CRFs to jointly model aspect and sentiment terms. <ref type="bibr" target="#b9">He et al. (2017)</ref> propose an aspect-based autoencoder to discover fine-grained aspects without supervision, in a process similar to topic modeling. Their model outperforms LDA-style approaches and forms the basis of our aspect extractor.</p><p>Sentiment Prediction Fully-supervised ap- proaches based on neural networks have achieved impressive results on fine-grained sentiment classification <ref type="bibr" target="#b14">(Kim, 2014;</ref><ref type="bibr" target="#b40">Socher et al., 2013</ref>). More recently, Multiple Instance Learning (MIL) models have been proposed that use freely available review ratings to train segment-level predictors. <ref type="bibr" target="#b18">Kotzias et al. (2015)</ref> and Pappas and Popescu-Belis (2017) train sentence-level predictors under a MIL objective, while our previous work <ref type="bibr" target="#b0">(Angelidis and Lapata, 2018)</ref> introduced MILNET, a hierarchical model that is trained end-to-end on document labels and produces polarity-based opinion summaries of single reviews. Here, we use MILNET to predict the sentiment polarity of individual opinions.</p><p>Multi-document Summarization A few ex- tractive neural models have been recently applied to generic multi-document summarization. <ref type="bibr" target="#b4">Cao et al. (2015)</ref> train a recursive neural network using a ranking objective to identify salient sentences, while follow-up work <ref type="bibr" target="#b3">(Cao et al., 2017</ref>) employs a multi-task objective to improve sentence extrac- tion, an idea we adapted to our task. <ref type="bibr" target="#b45">Yasunaga et al. (2017)</ref> propose a graph convolution network to represent sentence relations and estimate sen- tence salience. Our summarization method is tai- lored to the opinion extraction task, it identifies aspect-specific and salient units, while minimizing the redundancy of the final summary with a greedy selection algorithm <ref type="bibr" target="#b4">(Cao et al., 2015;</ref><ref type="bibr" target="#b45">Yasunaga et al., 2017)</ref>. Redundancy is also addressed in <ref type="bibr" target="#b8">Ganesan et al. (2010)</ref> who propose a graph-based framework for abstractive summarization. <ref type="bibr" target="#b43">Wang and Ling (2016)</ref> introduce an encoder-decoder neural method for extractive opinion summariza- tion. Their approach requires direct supervision via gold-standard extractive summaries for train- ing, in contrast to our weakly supervised formula- tion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Formulation</head><p>Let C denote a corpus of reviews on a set of prod- ucts E C = {e i } |E C | i=1 from a domain d C , e.g., tele- visions or keyboards. For every product e, the corpus contains a set of reviews R e = {r i } |Re| i=1</p><p>expressing customers' opinions. Each review r i is accompanied by the author's overall rating y i and is split into segments (s 1 , . . . , s m ), where each segment s j is in turn viewed as a sequence of words (w j1 , . . . , w jn ). A segment can be a sentence, a phrase, or in our case an Elemen- tary Discourse Unit (EDU; <ref type="bibr" target="#b30">Mann and Thompson 1988)</ref> obtained from a Rhetorical Structure The- ory (RST) parser <ref type="bibr" target="#b7">(Feng and Hirst, 2012)</ref>. EDUs roughly correspond to clauses and have been shown to facilitate performance in summarization ( , document-level sentiment anal- ysis ( <ref type="bibr" target="#b1">Bhatia et al., 2015)</ref>, and single-document opinion extraction <ref type="bibr" target="#b0">(Angelidis and Lapata, 2018)</ref>.</p><p>A segment may discuss zero or more as- pects, i.e., different product attributes. We use</p><formula xml:id="formula_0">A C = {a i } K i=1</formula><p>to refer to the aspects pertaining to domain d C . For example, picture quality, sound quality, and connectivity are all aspects of televi- sions. By convention, a general aspect is assigned to segments that do not discuss any specific as- pects. Let A s ⊆ A C denote the set of aspects mentioned in segment s; pol s ∈ [−1, +1] marks the polarity a segment conveys, where −1 indi- cates maximally negative and +1 maximally posi- tive sentiment. An opinion is represented by tuple o s = (s, A s , pol s ), and O e = {o s } s∈Re represents the set of all opinions expressed in R e .</p><p>For each product e, our goal is to produce a summary of the most salient opinions expressed in reviews R e , by selecting a small subset S e ⊂ O e . We expect segments that discuss specific product aspects to be better candidates for useful sum- maries. We hypothesize that general comments mostly describe customers' overall experience, which can also be inferred by their rating, whereas aspect-related comments provide specific reasons for their overall opinion. We also assume that seg- ments conveying highly positive or negative senti- ment are more likely to present informative opin- ions compared to neutral ones, a claim supported by previous work <ref type="bibr" target="#b0">(Angelidis and Lapata, 2018)</ref>.</p><p>We describe our novel approach to aspect ex- traction in Section 4 and detail how we combine aspect, sentiment, and redundancy information to produce opinion summaries in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Aspect Extraction</head><p>Our work builds on the aspect discovery model de- veloped by <ref type="bibr" target="#b9">He et al. (2017)</ref>, which we extend to facilitate the accurate extraction of aspect-specific review segments in a more realistic setting. In this section, we first describe their approach, point out its shortcomings, and then present the exten- sions and modifications introduced in our Multi- Seed Aspect Extractor (MATE) model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Aspect-Based Autoencoder</head><p>The Aspect-Based Autoencoder (ABAE; <ref type="bibr" target="#b9">He et al. 2017</ref>) is an adaptation of the Relationship Mod- eling <ref type="bibr">Network (Iyyer et al., 2016)</ref>, originally designed to identify attributes of fictional book characters and their relationships. The model learns a segment-level aspect predictor without supervision by attempting to reconstruct the in- put segment's encoding as a linear combination of aspect embeddings. ABAE starts by pairing each word w with a pre-trained word embedding v w ∈ R d , thus constructing a word embedding dictionary L ∈ R V ×d , where V is the size of the vocabulary. The model also keeps an aspect em- bedding dictionary A ∈ R K×d , where K is the number of aspects to be identified and i-th row a i ∈ R d is a point in the word embedding space. Matrix A is initialized using the centroids from a k-means clustering on the vocabulary's word em- beddings.</p><p>The autoencoder, first produces a vector v s for review segment s = (w 1 , . . . , w n ) using an atten- tion encoder that learns to attend on aspect words. A segment encoding is computed as the weighted average of word vectors:</p><formula xml:id="formula_1">v s = n i=1 c i v w i (1) c i = exp(u i ) n j=1 exp(u j ) (2) u i = v T w i · M · v s ,<label>(3)</label></formula><p>where c i is the i-th word's attention weight, v s is a simple average of the segment's word embeddings and attention matrix M ∈ R d×d is learned during training.</p><p>Vector v s is fed into a softmax classifier to pre- dict a probability distribution over K aspects:</p><formula xml:id="formula_2">p asp s = softmax(Wv s + b) ,<label>(4)</label></formula><p>where W ∈ R K×d and b ∈ R K are the classi- fier's weight and bias parameters. The segment's vector is then reconstructed as the weighted sum of aspect embeddings:</p><formula xml:id="formula_3">r s = A T p asp s .<label>(5)</label></formula><p>The model is trained by minimizing a recon- struction loss J r (θ) that uses randomly sampled segments n 1 , n 2 , . . . , n kn as negative examples: 2</p><formula xml:id="formula_4">J r (θ) = s∈C kn i=1 max(0, 1 − r s v s + r s v n i ) (6)</formula><p>ABAE is essentially a neural topic model; it discovers topics which will hopefully map to as- pects, without any preconceptions about the as- pects themselves, a feature shared with most previ- ous LDA-style aspect extraction approaches <ref type="bibr" target="#b41">(Titov and McDonald, 2008a;</ref><ref type="bibr" target="#b9">He et al., 2017;</ref><ref type="bibr" target="#b34">Mukherjee and Liu, 2012</ref>). These models will set the num- ber of topics to be discovered to a much larger number (∼ 15) than the actual aspects found in the data <ref type="bibr">(∼ 5)</ref>. This requires a many-to-one map- ping between discovered topics and genuine as- pects which is performed manually. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Multi-Seed Aspect Extractor</head><p>Dynamic aspect extraction is advantageous since it assumes nothing more than a set of relevant re- views for a product and may discover unusual and interesting aspects (e.g., whether a plasma televi- sion has protective packaging). However, it suffers from the fact that the identified aspects are fine- grained, they have to be interpreted post-hoc, and manually mapped to coarse-grained ones.</p><p>We propose a new weakly-supervised set-up for aspect extraction which requires little human in- volvement. For every aspect a i ∈ A C , we assume there exists a small set of seed words {sw j } l j=1 which are good descriptors of a i . We can think of these seeds as query terms that someone would use to search for segments discussing a i . They can be set manually by a domain expert or selected us- ing a small number of aspect-annotated reviews. <ref type="figure" target="#fig_1">Figure 2</ref> (top) depicts four television aspects (im- age, sound, connectivity and price) and three of their seeds in word embedding space. MATE replaces ABAE's aspect dictionary with multiple seed matrices {A 1 , A 2 , . . . , A K }. Every matrix A i ∈ R l×d , contains one row per seed word and holds the seeds' word embeddings, as illustrated by the set of <ref type="bibr">[3 × 2]</ref> matrices in <ref type="figure" target="#fig_1">Figure 2</ref>.</p><p>MATE still needs to produce an aspect matrix A ∈ R K×d , in order to reconstruct the input seg- ment's embedding. We accomplish this by reduc- ing each seed matrix to a single aspect embed- ding with the help of seed weight vectors z i ∈ R l ( j z ij = 1), and concatenating the results, illus-trated by the <ref type="bibr">[4 × 2]</ref> aspect matrix in <ref type="figure" target="#fig_1">Figure 2</ref>:</p><formula xml:id="formula_5">a i = A T i z i (7) A = [a T 1 ; . . . ; a T K ] .<label>(8)</label></formula><p>The segment is reconstructed as in Equation <ref type="formula" target="#formula_3">(5)</ref>. Weight vectors z i can be uniform (for manually selected seeds), fixed, learned during training, or set dynamically for each input segment, based on the cosine distance of its encoding to each seed embedding. Our experiments showed that fixed weights, selected through a technique described below, result in most stable performance across domains. We only focus on this variant due to space restrictions (but provide more details in the supplementary material).</p><p>When a small number of aspect-annotated re- views are available, seeds and their fixed seed weights can be selected automatically. To obtain a ranked list of terms that are most characteristic for each aspect, we use a variant of the clarity scoring function which was first introduced in information retrieval <ref type="bibr" target="#b5">(Cronen-Townsend et al., 2002</ref>). Clarity measures how much more likely it is to observe word w in the subset of segments that discuss as- pect a, compared to the corpus as a whole:</p><formula xml:id="formula_6">score a (w) = t a (w) log 2 t a (w) t(w) ,<label>(9)</label></formula><p>where t a (w) and t(w) are the l 1 -normalized tf-idf scores of w in the segments annotated with as- pect a and in all annotated segments, respectively.</p><p>Higher scores indicate higher term importance and truncating the ranked list of terms gives a fixed set of seed words, as well as their seed weights by normalizing the scores to add up to one. <ref type="table">Table 1</ref> shows the highest ranked terms obtained for every aspect in the televisions domain of our corpus (see Section 6 for a detailed description of our data).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Multi-Task Objective</head><p>MATE (and ABAE) relies on the attention encoder to identify and attend to each segment's aspect- signalling words. The reconstruction objective only provides a weak training signal, so we devise a multi-task extension to enhance the encoder's ef- fectiveness without additional annotations. We assume that aspect-relevant words not only provide a better basis for the model's aspect-based reconstruction, but are also good indicators of the product's domain. For example, the words colors and crisp, in the segment "The colors are perfectly crisp" should be sufficient to infer that the seg-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Aspect</head><p>Top <ref type="table">Terms  Image  picture color quality black bright  Sound  sound speaker quality bass loud  Connectivity  hdmi port computer input component  Price  price value money worth paid  Apps &amp; Interface  netflix user file hulu</ref>  <ref type="table">Table 1</ref>: Highest ranked words for the television corpus according to Equation (9). ment comes from a television review, whereas the words keys and type in the segment "The keys feel great to type on" are more representative of the keyboard domain. Additionally, all four words are characteristic of specific aspects.</p><note type="other">apps Ease of Use easy remote setup user menu Customer Service paid support service week replace Size &amp; Look size big bigger difference screen General tv bought hdtv happy problem</note><formula xml:id="formula_7">Let C all = C 1 ∪ C 2 ∪ . .</formula><p>. denote the union of multiple review corpora, where C 1 is consid- ered in-domain and the rest are considered out-of- domain. We use d s ∈ {d C 1 , d C 2 , . . . } to denote the true domain of segment s and define a classi- fier that uses the vectors from our segment encoder as inputs:</p><formula xml:id="formula_8">p dom s = softmax(W C v s + b C ) ,<label>(10)</label></formula><p>where p dom</p><formula xml:id="formula_9">s = p (d C 1 ) , p (d C 2 ) , .</formula><p>. . is a proba- bility distribution over product domains for seg- ment s and W C and b C are the classifier's weight and bias parameters. We use the negative log like- lihood of the domain prediction as the objective function, combined with the reconstruction loss of Equation <ref type="formula" target="#formula_3">(5)</ref> to obtain a multi-task objective:</p><formula xml:id="formula_10">J MT (θ) = J r (θ) − λ s∈C all log p (ds) ,<label>(11)</label></formula><p>where λ controls the influence of the classifica- tion loss. Note that the negative log-likelihood is summed over all segments in C all , whereas J r (θ) is only summed over the in-domain seg- ments s ∈ C 1 . It is important not to use the out-of-domain segments for segment reconstruc- tion, as they will confuse the aspect extractor due to the aspect mismatch between different domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Opinion Summarization</head><p>We now move on to describe our opinion summa- rization framework which is based on the aspect extraction component discussed so far, a polarity prediction model, and a segment selection policy which identifies and discards redundant opinions. Segment Salience 1. The color and definition are perfect.</p><p>[+]0.89 2. Set up was extremely easy,</p><p>[+]0.79 3. Not worth $ 300.</p><p>[-]0.75 4. The sound on this is horrendous.</p><p>[-]0.52 5. The sound is TERRIBLE.</p><p>[-]0.45 6. Nice and bright with good colors.</p><p>[+]0.44  Opinion Polarity Aside from describing a prod- uct's aspects, segments also express polarity (i.e., positive or negative sentiment). We identify segment polarity with the recently proposed Mul- tiple Instance Learning Network model (MILNET; Angelidis and Lapata 2018). Whilst trained on freely available document-level sentiment labels, i.e., customer ratings on a scale from 1 (negative) to 5 (positive), MILNET learns a segment-level sentiment predictor using a hierarchical, attention- based neural architecture. Given review r consisting of segments (s 1 , . . . , s m ), MILNET uses a CNN segment encoder to obtain segment vectors (u 1 , . . . , u m ), each used as input to a segment-level sen- timent classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>,040 (10) 42,727 (100) 602K (1,262) 30,443 B/T Headsets 1,471 (10) 80,239 (100) 1.46M (1,344) 51,263 Boots 4,723 (10) 77,593 (100) 987K (1,198) 30,364 Keyboards 983 (10) 33,713 (100) 625K (1,396) 34,095 Televisions 1,894 (10) 56,510 (100) 1.47M (1,483) 59,051 Vacuums 1,184 (10) 68,266 (100) 1.50M (1,492) 46,259</head><p>For every vector u i , the classifier produces a sentiment prediction p stm</p><formula xml:id="formula_11">i = p (1) i , . . . , p (M ) i</formula><p>, where p are probabilities assigned to the most negative and most positive sentiment class respectively. Re- sulting segment predictions (p stm 1 , . . . , p stm m ) are combined via a GRU-based attention mechanism to produce a document-level prediction p stm r and the model is trained end-to-end on the reviews' user ratings using negative log-likelihood.</p><p>The essential by-product of MILNET are segment-level sentiment predictions p stm i , which are transformed into polarities pol s i , by projecting them onto the [−1, +1] range using a uniformly spaced sentiment class weight vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Opinion Ranking Aspect predictions p asp</head><formula xml:id="formula_12">s = p (a 1 ) s , . . . , p (a K ) s</formula><p>and polarities pol s , form the opinion set O e = {(s, A s , pol s )} s∈Re for every product e ∈ E C . For simplicity, we set the pre- dicted aspect-set A s to only include the aspect with the highest probability, although it is straight- forward to allow for multiple aspects. We rank ev- ery opinion o s ∈ O e according to its salience:</p><formula xml:id="formula_13">sal (o s ) = |pol s | · (max i p (a i ) s − p (GEN) s ) , (12)</formula><p>where the quantity in parentheses is the probability difference between the most probable aspect and the general aspect. The salience score will be high for opinions that are very positive or very negative and are also likely to discuss a non-general aspect.</p><p>Opinion Selection The final step towards pro- ducing summaries is to discard potentially redun- dant opinions, something that is not taken into ac- count by our salience scoring method. <ref type="table" target="#tab_0">Table 2</ref> shows a partial ranking of the most salient opin- ions found in the reviews for an LCD television. All segments provide useful information, but it is evident that segments 1 and 6 as well as 4 and 5 are paraphrases of the same opinions.</p><p>We follow previous work on multi-document summarization <ref type="bibr" target="#b4">(Cao et al., 2015;</ref><ref type="bibr" target="#b45">Yasunaga et al., 2017)</ref> and use a greedy algorithm to eliminate re- dundancy. We start with the highest ranked opin- ion, and keep adding opinions to the final sum- mary one by one, unless the cosine similarity be- tween the candidate segment and any segment al- ready included in the summary is lower than 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">The OPOSUM Dataset</head><p>We created OPOSUM, a new dataset for the train- ing and evaluation of Opinion Summarization models which contains Amazon reviews from six product domains: Laptop Bags, Bluetooth Head- sets, Boots, Keyboards, Televisions, and Vacuums. The six training collections were created by down- sampling from the Amazon Product Dataset 3 in- troduced in <ref type="bibr" target="#b31">McAuley et al. (2015)</ref> and contain re- views and their respective ratings. The reviews were segmented into EDUs using a publicly avail- able RST parser <ref type="bibr" target="#b7">(Feng and Hirst, 2012)</ref>.</p><p>To evaluate our methods and facilitate research, we produced a human-annotated subset of the dataset. For each domain, we uniformly sampled (across ratings) 10 different products with 10 re- views each, amounting to a total of 600 reviews, to be used only for development (300) and test- ing (300). We obtained EDU-level aspect anno- tations, salience labels and gold standard opinion  Experimental results for the identification of aspect segments (top) and the retrieval of salient segments (bottom) on OPOSUM's six product domains and overall (AVG).</p><p>summaries, as described below. Statistics are pro- vided in <ref type="table" target="#tab_1">Table 3</ref> and in supplementary material.</p><p>Aspects For every domain, we pre-selected nine representative aspects, including the general as- pect. We presented the EDU-segmented reviews to three annotators and asked them to select the aspects discussed in each segment (multiple as- pects were allowed). Final labels were obtained using a majority vote among annotators. Inter- annotator agreement across domains and anno- tated segments using Cohen's Kappa coefficient was K = 0.61 (N = 8,175, k = 3).</p><p>Opinion Summaries We produced opinion summaries for the 60 products in our bench- mark using a two-stage procedure. First, all re- views for a product were shown to three annota- tors. Each annotator read the reviews one-by-one and selected the subset of segments they thought best captured the most important and useful com- ments, without taking redundancy into account. This phase produced binary salience labels against which we can judge the ability of a system to identify important opinions. Again, using the Kappa coefficient, agreement among annotators was K = 0.51 (N = 8,175, k = 3). <ref type="bibr">4</ref> In the sec- ond stage, annotators were shown the salient seg- ments they identified (for every product) and asked to create a final extractive summary by choosing opinions based on their popularity, fluency and clarity, while avoiding redundancy and staying un- der a budget of 100 words. We used ROUGE ( <ref type="bibr" target="#b22">Lin and Hovy, 2003)</ref> as a proxy to inter-annotator agreement. For every product, we treated one ref-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experiments</head><p>In this section, we discuss implementation de- tails and present our experimental setup and re- sults. We evaluate model performance on three subtasks: aspect identification, salient opinion ex- traction, and summary generation.</p><p>Implementation Details Reviews were lemma- tized and stop words were removed. We initial- ized MATE using 200-dimensional word embed- dings trained on each product domain using skip- gram ( <ref type="bibr" target="#b33">Mikolov et al., 2013</ref>) with default parame- ters. We used 30 seed words per aspect, obtained via Equation (9). Word embeddings L, seed ma- trices {A i } K i=1 and seed weight vectors</p><formula xml:id="formula_14">{z i } K i=1</formula><p>were fixed throughout training. We used the Adam optimizer ( <ref type="bibr" target="#b15">Kingma and Ba, 2014</ref>) with learning rate 10 −4 and mini-batch size 50, and trained for 10 epochs. We used 20 negative examples per in- put for the reconstruction loss and, when used, the multi-tasking coefficient λ was set to 10. Seed words and hyperparameters were selected on the development set and we report results on the test set, averaged over 5 runs.</p><p>Aspect Extraction We trained aspect models on the collections of <ref type="table" target="#tab_1">Table 3</ref> and evaluated their pre- dictions against the human-annotated portion of each corpus. Our MATE model and its multi- task counterpart (MATE+MT) were compared against a majority baseline and two ABAE vari- ants: vanilla ABAE, where aspect matrix A is initialized using k-means centroids and fine-tuned during training; and ABAE init , where rows of A are fixed to the centroids of respective seed em- beddings. This allows us to examine the benefits of our multi-seed aspect representation. <ref type="table" target="#tab_3">Table 4</ref> (top) reports the results using micro-averaged F1. Our models outperform both variants of ABAE across domains. ABAE init improves upon the vanilla model, affirming that informed aspect ini- tialization can facilitate the task. The richer multi- seed representation of MATE, however, helps our model achieve a 3.2% increase in F1. Further im- provements are gained by the multi-task model, which boosts performance by 2.7%.</p><p>Opinion Salience We are also interested in our system's ability to identify salient opinions in re- views. The first phase of our opinion extraction annotation provides us with binary salience labels, which we use as gold standard to evaluate sys- tem opinion rankings. For every product e, we score each segment s ∈ R e using Equation <ref type="formula">(12)</ref> and evaluate the obtained rankings via Mean Av- erage Precision (MAP) and Precision at the 5th retrieved segment (P@5). 5 Polarity scores were produced via MILNET; we obtained aspect proba- bilities from ABAE init , MATE, and MATE+MT. We also experimented with a variant that only uses MILNET's polarities and, additionally, with variants that ignore polarities and only use aspect probabilities. Results are shown in <ref type="table" target="#tab_3">Table 4</ref> (bottom). The combined use of polarity and aspect informa- tion improves the retrieval of salient opinions across domains, as all model variants that use our salience formula of Equation <ref type="formula">(12)</ref> outper- form the MILNET-and aspect-only baselines. When comparing between aspect-based alterna- tives, we observe that the extraction accuracy correlates with the quality of aspect prediction. In particular, ranking using MILNET+MATE+MT gives best results, with a 2.6% increase in MAP against MILNET+MATE and 4.6% against MIL- NET+ABAE init . The trend persists even when MILNET polarities are ignored, although the qual- ity of rankings is worse in this case.</p><p>Opinion Summaries We now turn to the sum- marization task itself, where we compare our best performing model (MILNET+MATE+MT), with and without a redundancy filter (RD), against the following methods: a baseline that selects seg- ments randomly; a Lead baseline that only selects the leading segments from each review; SumBasic, 5 A system's salience ranking is individually compared against labels from each annotator and we report the average.     <ref type="bibr" target="#b6">and Radev, 2004</ref>); Opinosis, a graph-based ab- stractive summarizer that is designed for opinion summarization ( <ref type="bibr" target="#b8">Ganesan et al., 2010</ref>). All ex- tractive methods operate on the EDU level with a 100-word budget. For Opinosis, we tested an aspect-agnostic variant that takes every review segment for a product as input, and a variant that uses MATE's groupings of segments to produce and concatenate aspect-specific summaries. <ref type="table" target="#tab_5">Table 5</ref> presents ROUGE-1, ROUGE-2 and ROUGE-L F1 scores, averaged across domains. Our model (MILNET+MATE+MT) significantly outperforms all comparison systems (p &lt; 0.05; paired bootstrap resampling; Koehn 2004), whilst using a redundancy filter slightly improves perfor- mance. Assisting Opinosis with aspect predictions is beneficial, however, it remains significantly in- ferior to our model (see the supplementary mate- rial for additional results).</p><p>We also performed a large-scale user study. For every product in the OPOSUM test set, participants were asked to compare summaries produced by: a (randomly selected) human annotator, our best performing model (MILNET+MATE+MT+RD), Opinosis, and the Lead baseline. The study was conducted on the Crowdflower platform using Best-Worst Scaling (BWS; Louviere and Wood- worth 1991; <ref type="bibr" target="#b27">Louviere et al. 2015</ref>), a less labour- intensive alternative to paired comparisons that has been shown to produce more reliable results than rating scales <ref type="bibr" target="#b16">(Kiritchenko and Mohammad, 2017)</ref>. We arranged every 4-tuple of competing summaries into four triplets. Every triplet was Product domain: Televisions Product name: Sony BRAVIA 46-Inch HDTV</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Human</head><p>Plenty of ports and settings. Easy hookups to audio and satellite sources. The sound is good and strong. This TV looks very good. and the price is even better. The on-screen menu/options is quite nice. and the internet apps work as expected. The picture is clear and sharp. which is TOO SLOW to stream HD video... The software and apps built into this TV. are difficult to use and setup. Their service is handled off shore making. communication a bit difficult. :( </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Opinosis</head><p>The picture and not bright at all even compared to my 6-year old sony lcd tv. It will not work with an hdmi. Connection because of a conflict with comcast's dhcp. Being generous because I usuallly like the design and attention to detail of sony products). I am very disappointed with this tv for two reasons: picture brightness and channel menu. Numbers of options available in the on-line area of the tv are numerous and extremely useful. Wow look at the color, look at the sharpness of the picture, amazing and the amazing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>This work</head><p>Plenty of ports and settings and have been extremely happy with it. The sound is good and strong. The picture is beautiful. And the internet apps work as expected. And the price is even better. Unbelieveable picture and the setup is so easy. Wow look at the color, look at the sharpness of the picture. The Yahoo! widgets do not work. And avoid the Sony apps at all costs. Communication a bit difficult. :( shown to three crowdworkers, who were asked to decide which summary was best and which one was worst according to four criteria: Infor- mativeness (How much useful information about the product does the summary provide?), Polar- ity (How well does the summary highlight posi- tive and negative opinions?), Coherence (How co- herent and easy to read is the summary?) Redun- dancy (How successfully does the summary avoid redundant opinions?).</p><p>For every criterion, a system's score is com- puted as the percentage of times it was selected as best minus the percentage of times it was se- lected as worst <ref type="bibr" target="#b36">(Orme, 2009)</ref>. The scores range from -100 (unanimously worst) to +100 (unani- mously best) and are shown in <ref type="table" target="#tab_6">Table 6</ref>. Partici- pants favored our model over comparison systems across all criteria (all differences are statistically significant at p &lt; 0.05 using post-hoc HD Tukey tests). Human summaries are generally preferred over our model, however the difference is signifi- cant only in terms of coherence (p &lt; 0.05).</p><p>Finally, <ref type="figure" target="#fig_4">Figure 3</ref> shows example summaries for a product from our televisions domain, pro- duced by one of our annotators and by 3 compar- ison systems (LexRank, Opinosis and our MIL- NET+MATE+MT+RD). The human summary is primarily focused on aspect-relevant opinions, a characteristic that is also captured to a large ex- tent by our method. There is substantial overlap between extracted segments, although our redun- dancy filter fails to identify a few highly similar opinions (e.g., those relating to the picture qual- ity). The LexRank summary is inferior as it only identifies a few useful opinions, and instead se- lects many general or non-opinionated comments. Lastly, the abstractive summary of Opinosis does a good job of capturing opinions about specific as- pects but lacks in fluency, as it produces grammat- ical errors. For additional system outputs, see sup- plementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions</head><p>We presented a weakly supervised neural frame- work for aspect-based opinion summarization. Our method combined a seeded aspect extractor that is trained under a multi-task objective without direct supervision, and a multiple instance learn- ing sentiment predictor, to identify and extract useful comments in product reviews. We eval- uated our weakly supervised models on a new opinion summarization corpus across three sub- tasks, namely aspect identification, salient opin- ion extraction, and summary generation. Our ap- proach delivered significant improvements over strong baselines in each of the subtasks, while a large-scale judgment elicitation study showed that crowdworkers favor our summarizer over compet- itive extractive and abstractive systems.</p><p>In the future, we plan to develop a more inte- grated approach where aspects and sentiment ori- entation are jointly identified, and work with addi- tional languages and domains. We would also like to develop methods for abstractive opinion sum- marization using weak supervision signals.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Aspect-based opinion summarization. Opinions on image quality, sound quality, connectivity, and price of an LCD television are extracted from a set of reviews. Their polarities are then used to sort them into positive and negative, while neutral or redundant comments are discarded.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Multi-Seed Aspect Extractor (MATE).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Summarization</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Human and system summaries for a product in the Televisions domain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Most salient opinions according to 
scores from Equation (12) for an LCD TV. 

Domain 
Products 
Reviews 
EDUs 
Vocab 
Laptop Cases 2</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>The OPOSUM corpus. Numbers in parentheses 
correspond to the human-annotated subset. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Summarization results on OPOSUM. 

Inform. Polarity Coherence Redund. 
Gold 
2.04 
8.70 
10.93 
6.11 
This work 
9.26 
3.15 
1.11 
2.96 
Opinosis 
-12.78 
-10.00 
-9.08 
-9.45 
Lead 
1.48 
-1.85 
-2.96 
0.37 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Best-Worst Scaling human evaluation. 

a generic frequency-based extractive summarizer 
(Nenkova and Vanderwende, 2005); LexRank, a 
generic graph-based extractive summarizer (Erkan 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>LexRank Get a Roku or Netflix box. I watch cable, Netflix, Hulu Plus, YouTube videos and computer movie files on it. Sound is good much better. DO NOT BUY! this SONY Bravia ' Smart ' TV... and avoid the Sony apps at all costs.</head><label></label><figDesc></figDesc><table>Because of 
these two issues, I returned the Sony TV. Also you can change the display and sound settings on each port. However, 
the streaming speed for netflix is just down right terrible. Most of the time I just quit. Since I do not own the cable 
box, So, I have the cable. 

</table></figure>

			<note place="foot" n="2"> ABAE also uses a uniqueness regularization term that is not shown here and is not used in our Multi-Seed Aspect Extractor model.</note>

			<note place="foot" n="3"> http://jmcauley.ucsd.edu/data/amazon/</note>

			<note place="foot" n="4"> While this may seem moderate, Radev et al. (2003) show that inter-annotator agreement for extractive summarization is usually lower (K &lt; 0.30). erence summary as system output and computed how it agrees with the rest. ROUGE scores are reported in Table 5 (last row).</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multiple Instance Learning Networks for Fine-Grained Sentiment Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Angelidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="17" to="31" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Better document-level sentiment analysis from RST discourse parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parminder</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2212" to="2218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Building a sentiment summarizer for local service reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasha</forename><surname>Blair-Goldensohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kerry</forename><surname>Hannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Neylon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Reis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Reynar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the WWW Workshop on NLP Challenges in the Information Explosion Era (NLPIX)</title>
		<meeting>the WWW Workshop on NLP Challenges in the Information Explosion Era (NLPIX)<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Improving multi-document summarization via text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqiang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3053" to="3059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Ranking with recursive neural networks and its application to multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqiang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Ninth AAAI Conference on Artificial Intelligence<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2153" to="2159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Predicting query performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Cronen-Townsend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;02</title>
		<meeting>the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;02<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="299" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Lexrank: Graph-based lexical centrality as salience in text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günes</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dragomir R Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="457" to="479" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Text-level discourse parsing with rich linguistic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vanessa</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hirst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="60" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Opinosis: a graph-based approach to abstractive summarization of highly redundant opinions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kavita</forename><surname>Ganesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="340" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An unsupervised neural attention model for aspect extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruidan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee</forename><forename type="middle">Tou</forename><surname>Wee Sun Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dahlmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="388" to="397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>eeding of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Opinion extraction and summarization on the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st National Conference on Artificial Intelligence</title>
		<meeting>the 21st National Conference on Artificial Intelligence<address><addrLine>Boston, Massachusettes, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1621" to="1624" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Feuding families and former friends: Unsupervised learning for dynamic fictional relationships</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anupam</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Snigdha</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1534" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Comprehensive review of opinion summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun Duk</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kavita</forename><surname>Ganesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parikshit</forename><surname>Sondhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Best-worst scaling more reliable than rating scales: A case study on sentiment intensity annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Kiritchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saif</forename><surname>Mohammad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="465" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Statistical significance tests for machine translation evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2004</title>
		<meeting>EMNLP 2004<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="388" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">From group to individual labels using deep features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Kotzias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Misha</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padhraic</forename><surname>Nando De Freitas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="597" to="606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Opinion extraction, summarization and tracking in news and blog corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lun-Wei</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Ting</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsin-Hsi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Syposium on Computational Approaches to Analysing Weblogs</title>
		<meeting><address><addrLine>Palo Alto, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="100" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sentiment summarization: Evaluating and learning user preferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasha</forename><surname>Blair-Goldensohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, EACL &apos;09</title>
		<meeting>the 12th Conference of the European Chapter of the Association for Computational Linguistics, EACL &apos;09</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="514" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The role of discourse units in near-extractive summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyi Jessy</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kapil</forename><surname>Thadani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Stent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting><address><addrLine>Los Angeles, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="137" to="147" />
		</imprint>
	</monogr>
	<note>Proceedings of the SIGDIAL 2016 Conference</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Automatic evaluation of summaries using n-gram cooccurrence statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<title level="m">Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="page" from="71" to="78" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sentiment analysis and opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis lectures on human language technologies</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="167" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">A survey of opinion mining and sentiment analysis. Mining Text Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="415" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Finegrained opinion mining with recurrent neural networks and word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1433" to="1443" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Best-worst scaling: Theory, methods and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jordan J Louviere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony Alfred John</forename><surname>Terry N Flynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Best-worst scaling: A model for the largest difference judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George G</forename><surname>Louviere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Woodworth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
		</imprint>
		<respStmt>
			<orgName>University of Alberta: Working Paper</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Rated aspect summarization of short comments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neel</forename><surname>Sundaresan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on World Wide Web</title>
		<meeting>the 18th International Conference on World Wide Web<address><addrLine>Madrid, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="131" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><forename type="middle">A</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thompson</surname></persName>
		</author>
		<title level="m">Rhetorical structure theory: Toward a functional theory of text organization. Text-Interdisciplinary Journal for the Study of Discourse</title>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="243" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Image-based recommendations on styles and substitutes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Targett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinfeng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Santiago, Chile</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Topic sentiment mixture: Modeling facets and opinions in weblogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Wondra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on World Wide Web</title>
		<meeting>the 16th International Conference on World Wide Web<address><addrLine>Banff, Alberta, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Lake Tahoe, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Modeling review comments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="320" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">The impact of frequency on summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Maxdiff analysis: Simple counting, individual-level logit, and HB. Technical report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Orme</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Explicit document modeling through weighted multiple-instance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaos</forename><surname>Pappas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Popescu-Belis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="591" to="626" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Extracting product features and opinions from reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana-Maria</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing<address><addrLine>British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Vancouver</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="339" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Evaluation challenges in large-scale document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horacio</forename><surname>Teufel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Saggion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danyu</forename><surname>Arda C ¸ Elebi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elliott</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Drabek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="375" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A joint model of text and aspect ratings for sentiment summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Columbus, Ohio, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="308" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Modeling online reviews with multi-grain topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on World Wide Web</title>
		<meeting>the 17th International Conference on World Wide Web<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="111" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Neural network-based abstract generation for opinions and arguments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="47" to="57" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Recursive neural conditional random fields for aspect-based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenya</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokui</forename><surname>Dahlmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="616" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Graph-based neural multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kshitijh</forename><surname>Meelu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayush</forename><surname>Pareek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishnan</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Conference on Computational Natural Language Learning</title>
		<meeting>the 21st Conference on Computational Natural Language Learning<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="452" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Unsupervised word and dependency path embeddings for aspect term extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichun</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaimeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Fifth International Joint Conference on Artificial Intelligence<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2979" to="2985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Hierarchical clustering algorithms for document datasets. Data Mining and Knowledge Discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Usama</forename><surname>Fayyad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="141" to="168" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
