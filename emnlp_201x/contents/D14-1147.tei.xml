<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Predicting Chinese Abbreviations with Minimum Semantic Unit and Global Constraints</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longkai</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory of Computational Linguistics (Peking University) Ministry of Education</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory of Computational Linguistics (Peking University) Ministry of Education</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory of Computational Linguistics (Peking University) Ministry of Education</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory of Computational Linguistics (Peking University) Ministry of Education</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Predicting Chinese Abbreviations with Minimum Semantic Unit and Global Constraints</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1405" to="1414"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose a new Chinese abbreviation prediction method which can incorporate rich local information while generating the abbreviation globally. Different to previous character tagging methods, we introduce the minimum semantic unit, which is more fine-grained than character but more coarse-grained than word, to capture word level information in the sequence labeling framework. To solve the &quot;character dupli-cation&quot; problem in Chinese abbreviation prediction, we also use a substring tagging strategy to generate local substring tagging candidates. We use an integer linear programming (ILP) formulation with various constraints to globally decode the final abbreviation from the generated candidates. Experiments show that our method outper-forms the state-of-the-art systems, without using any extra resource.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Abbreviation is defined as a shortened description of the original fully expanded form. For example, "NLP" is the abbreviation for the corresponding full form "Natural Language Processing". The ex- istence of abbreviations makes it difficult to iden- tify the terms conveying the same concept in the information retrieval (IR) systems and machine translation (MT) systems. Therefore, it is impor- tant to maintain a dictionary of the prevalent orig- inal full forms and the corresponding abbrevia- tions.</p><p>Previous works on Chinese abbreviation gen- eration focus on the sequence labeling method, which give each character in the full form an extra label to indicate whether it is kept in the abbre- viation. One drawback of the character tagging strategy is that Chinese characters only contain limited amount of information. Using character- based method alone is not enough for Chinese ab- breviation generation. Intuitively we can think of a word as the basic tagging unit to incorporate more information. However, if the basic tagging unit is word, we need to design lots of tags to repre- sent which characters are kept for each unit. For a word with n characters, we should design at least 2 n labels to cover all possible situations. This re- duces the generalization ability of the proposed model. Besides, the Chinese word segmentation errors may also hurt the performance. Therefore we propose the idea of "Minimum Semantic Unit" (MSU) which is the minimum semantic unit in Chinese language. Some of the MSUs are words, while others are more fine-grained than words. The task of selecting representative characters in the full form can be further broken down into se- lecting representative characters in the MSUs. We model this using the MSU-based tagging method, which can both utilize semantic information while keeping the tag set small. Meanwhile, the sequence labeling method per- forms badly when the "character duplication" phe- nomenon exists. Many Chinese long phrases con- tain duplicated characters, which we refer to as the "character duplication" phenomenon. There is no sound criterion for the character tagging mod- els to decide which of the duplicated character should be kept in the abbreviation and which one to be skipped. An example is " "(Beijing University of Aeronautics and Astro- nautics) whose abbreviation is "". The char- acter "" appears twice in the full form and only one is kept in the abbreviation. In these cases, we can break the long phase into local substrings. We can find the representative characters in the sub- strings instead of the long full form and let the de- coding phase to integrate useful information glob- ally. We utilize this sub-string based approach and obtain this local tagging information by labeling on the sub-string of the full character sequence.</p><p>Given the MSU-based and substring-based methods mentioned above, we can get a list of potential abbreviation candidates. Some of these candidates may not agree on keeping or skipping of some specific characters. To integrate their ad- vantages while considering the consistency, we further propose a global decoding strategy using Integer Linear Programming(ILP). The constraints in ILP can naturally incorporate 'non-local' infor- mation in contrast to probabilistic constraints that are estimated from training examples. We can also use linguistic constraints like "adjacent identical characters is not allowed" to decode the correct abbreviation in examples like the previous "" example.</p><p>Experiments show that our Chinese abbrevia- tion prediction system outperforms the state-of- the-art systems. In order to reduce the size of the search space, we further propose pruning con- straints that are learnt from the training corpus. Experiment shows that the average number of con- straints is reduced by about 30%, while the top-1 accuracy is not affected.</p><p>The paper is structured as follows. Section 1 gives the introduction. In section 2 we describe our method, including the MSUs, the substring- based tagging strategy and the ILP decoding pro- cess. Experiments are described in section 3. We also give a detailed analysis of the results in sec- tion 3. In section 4 related works are introduced, and the paper is concluded in the last section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Architecture</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Chinese Abbreviation Prediction</head><p>Chinese abbreviations are generated by selecting representative characters from the full forms. For example, the abbreviation of "" (Peking University) is "" which is generated by se- lecting the first and third characters, see TABLE 1. This can be tackled from the sequence labeling point of view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Full form</head><p>Status Keep Skip Keep Skip Result <ref type="table">Table 1</ref>: The abbreviation "" of the full form "" (Peking University)</p><p>From TABLE 1 we can see that Chinese abbre- viation prediction is a problem of selecting repre- sentative characters from the original full form <ref type="bibr">1</ref> . Based on this assumption, previous works mainly focus on this character tagging schema. In these methods, the basic tagging unit is the Chinese character. Each character in the full form is la- beled as 'K' or 'S', where 'K' means the current character should be kept in abbreviation and 'S' means the current character should be skipped.</p><p>However, a Chinese character can only contain limited amount of information. Using character- based method alone is not enough for Chinese abbreviation generation. We introduce an MSU- based method, which models the process of se- lecting representative characters given local MSU information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">MSU Based Tagging</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Minimum Semantic Unit</head><p>Because using the character-based method is not enough for Chinese abbreviation generation, we may think of word as the basic tagging unit to in- corporate more information intuitively. In English, the abbreviations (similar to acronyms) are usually formed by concatenating initial letters or parts of a series of words. In other words, English abbrevia- tion generation is based on words in the full form. However, in Chinese, word is not the most suit- able abbreviating unit. Firstly, there is no natural boundary between Chinese words. Errors from the Chinese word segmentation tools will accumulate to harm the performance of abbreviation predic- tion. Second, it is hard to design a reasonable tag set when the length of a possible Chinese word is very long. The second column of TABLE 2 shows different ways of selecting representative charac- ters of Chinese words with length 3. For a Chi- nese compound word with 3 characters, there are 6 possible ways to select characters. In this case we should have at least 6 kinds of tags to cover all pos- sible situations. The case is even worse for words with more complicated structures. A suitable ab- breviating unit should be smaller than word.</p><p>We propose the "Minimum Semantic Unit (MSU)" as the basic tagging unit. We define MSU as follows:</p><p>1. A word whose length is less or equal to 2 is an MSU.</p><p>Full form We collect all the MSUs from the benchmark datasets provided by the second International Chi- nese Word Segmentation Bakeoff 2 . We choose the Peking University (PKU) data because it is more fine-grained than all other corpora. Suppose we represent the segmented data as L (In our case L is the PKU word segmentation data), the MSU se- lecting algorithm is shown in TABLE 3.</p><formula xml:id="formula_0">SK Label MSUs (nursery) /K /S /S + (allowance) /S /K /S + (Credit card) /S /S /K + (Hydropower Station) /K /K /S ++ (Senate) /K /S /K ++ (Music group) /S /K /K +</formula><p>For a given full form, we first segment it us- ing a standard word segmenter to get a coarse- grained segmentation result. Here we use the Stan- ford Chinese Word Segmenter 3 . Then we use the MSU set to segment each word using the strategy of "Maximum Forward Matching" 4 to get the fine- grained MSU segmentation result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Labeling strategy</head><p>For MSU-based tagging, we use a labeling method which uses four tags, "KSFL". "K" stands for "Keep the whole unit", "S" stands for "Skip the whole unit", "F" stands for "keep the First charac- ter of the unit", and Label "L" stands for "keep the Last character of the unit". An example is shown in TABLE 4.</p><p>The "KSFL" tag set is also applicable for MSUs whose length is greater than 2 (an example is " /chocolate"). By examining the corpus we find that such MSUs are either kept of skipped in 2 http://www.sighan.org/bakeoff2005/ 3 http://nlp.stanford.edu/software/ segmenter.shtml 4 In Chinese, "Forward" means from left to right. <ref type="table">Table 4</ref>: The abbreviation "" of " " (National Linguistics Work Com- mittee) based on MSU tagging.</p><formula xml:id="formula_1">"" (The ab- breviation is "") KSFL /K /F /S /S /F /S</formula><p>the final abbreviations. Therefore, the labels of these long MSUs are either 'K' or 'S'. Empirically, this assumption holds for MSUs, but does not hold for words <ref type="bibr">5</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Feature templates</head><p>The feature templates we use are as follows. See TABLE 5.</p><formula xml:id="formula_2">1. Word X i (−2 ≤ i ≤ 2) 2. POS tag of word X i (−2 ≤ i ≤ 2)</formula><p>Init: Let M SU Set = empty set For each word w in L: If Length(w) ≤ 2 Add w to M SU Set End if End for For each word w in L:</p><p>If Length(w) &gt; 2 and no word x in M SU Set is a substring of w Add w to M SU Set End if End for Return M SU Set <ref type="table">Table 3</ref>: Algorithm for collecting MSUs from the PKU corpus</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Sequence Labeling Model</head><p>The MSU-based method gives each MSU an ex- tra indicative label. Therefore any sequence label- ing model is appropriate for the method. Previous works showed that Conditional Random Fields (CRFs) can outperform other sequence labeling models like MEMMs in abbreviation generation tasks ( <ref type="bibr" target="#b14">Sun et al., 2009;</ref><ref type="bibr" target="#b17">Tsuruoka et al., 2005</ref>). For this reason we choose CRFs model in our system.</p><p>For a given full form's MSU list, many can- didate abbreviations are generated by choosing the k-best results of the CRFs. We can use the forward-backward algorithm to calculate the prob- ability of a specified tagging result. To reduce the searching complexity in the ILP decoding process, we delete those candidate tagged sequences with low probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Substring Based Tagging</head><p>As mentioned in the introduction, the sequence labeling method, no matter character-based or MSU-based, perform badly when the "character duplication" phenomenon exists. When the full form contains duplicated characters, there is no sound criterion for the sequence tagging strategy to decide which of the duplicated character should be kept in the abbreviation and which one to be skipped. On the other hand, we can tag the sub- strings of the full form to find the local represen- tative characters in the substrings of the long full form. Therefore, we propose the sub-string based approach to given labeling results on sub-strings. These results can be integrated into a more accu- rate result using ILP constraints, which we will de- scribe in the next section.</p><p>Another reason for using the sub-string based methods is that long full forms contain more char- acters and are much easier to make mistakes dur- ing the sequence labeling phase. <ref type="bibr" target="#b20">Zhang et al. (2012)</ref> shows that if the full form contains less than 5 characters, a simple tagger can reach an ac- curacy of 70%. <ref type="bibr" target="#b20">Zhang et al. (2012)</ref> also shows that if the full form is longer than 10 characters, the average accuracy is less than 30%. The numerous potential candidates make it hard for the tagger to choose the correct one. For the long full forms, although the whole sequence is not correctly la- beled, we find that if we only consider its short substrings, we may find the correct representative characters. This information can be integrated into the decoding model to adjust the final result.</p><p>We use the MSU-based tagging method in the sub-string tagging. The labeling strategy and fea- ture templates are the same to the MSU-based tag- ging method. In practice, enumerating all sub- sequences of a given full form is infeasible if the full form is very long. For a given full form, we use the boundary MSUs to reduce the pos- sible sub-sequence set. For example, " "(Chinese Academy of Science) has 5 sub- sequences: "", "", "", " " and "".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">ILP Formulation of Decoding</head><p>Given the MSU-based and sub-sequence-based methods mentioned above as well as the preva- lent character-based methods, we can get a list of potential abbreviation candidates and abbrevi- ated substrings. We should integrate their advan- tages while keeping the consistency between each candidate. Therefore we further propose a global decoding strategy using Integer Linear Program- ming(ILP). The constraints in ILP can naturally incorporate 'non-local' information in contrast to probabilistic constraints that are estimated from training examples. We can also use linguistic con- straints like "adjacent identical characters is not allowed" to decode the correct abbreviation in ex- amples like the "" example in section 1.</p><p>Formally, given the character sequence of the full form c = c 1 ...c l , we keep Q top-ranked MSU-based tagging results T =(T 1 , ..., T Q ) and M tagged substrings S=(S 1 , ..., S M ) using the meth- ods described in previous sections. We also use N top-ranked character-based tagging results R=(R 1 , ..., R N ) based on the previous character- based works. We also define the set U = S ∪R∪T as the union of all candidate sequences. Our goal is to find an optimal binary variable vector solution v = x y z = (x 1 , ..., x M , y 1 , ..., y N , z 1 , ..., z Q ) that maximizes the object function:</p><formula xml:id="formula_3">λ 1 M i=1 score(S i ) · x i + λ 2 N i=1 score(R i ) · y i +λ 3 Q i=1 score(T i ) · z i</formula><p>subject to constrains in TABLE 6. The parame- ters λ 1 , λ 2 , λ 3 controls the preference of the three parts, and can be decided using cross-validation. Constraint 1 indicates that x i , y i , z i are all boolean variables. They are used as indicator vari- ables to show whether the corresponding tagged sequence is in accordance with the final result.</p><p>Constraint 2 is used to guarantee that at most one candidate from the character-based tagging is preserved. We relax the constraint to allow the sum to be zero in case that none of the top-ranked candidate is suitable to be the final result. If the sum equals zero, then the sub-sequence based tag- ging method will generate a more suitable result. Constrain 3 has the same utility for the MSU- based tagging.</p><p>Constraint 4, 5, 6 are inter-method constraints. We use them to guarantee that the labels of the preserved sequences of different tagging methods do not conflict with each other. Constraint 7 is used to guarantee that the labels of the preserved sub-strings do not conflict with each other.</p><p>Constraint 8 is used to solve the "character du- plicate" problem. When two identical characters are kept adjacently, only one of them will be kept. Which one will be kept depends on the global de- coding score. This is the advantage of ILP against traditional sequence labeling methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Pruning Constraints</head><p>The efficiency of solving the ILP decoding prob- lem depends on the number of candidate tagging sequences N and Q, as well as the number of sub- sequences M. Usually, N and Q is less than 10 in our experiment. Therefore, M influences the time complexity the most. Because we use the bound- ary of MSUs instead of enumerating all possible subsequences, the value of M can be largely re- duced.</p><p>Some characters are always labeled as "S" or "K" once the context is given. We can use this phenomenon to reduce the search space of decod- ing. Let c i denote the i th character relative to the current character c 0 and t i denote the tag of c i . The context templates we use are listed in   With respect to a training corpus, if a context C relative to c 0 always assigns a certain tag t to c 0 , then we can use this constraint in pruning. We judge the degree of "always" by checking whether</p><formula xml:id="formula_4">count(C∧t 0 =t) count(C)</formula><p>&gt; threshold. The threshold is a non-negative real number under 1.0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data and Evaluation Metric</head><p>We use the abbreviation corpus provided by Insti- tute of Computational Linguistics (ICL) of Peking University in our experiments. The corpus is sim- ilar to the corpus used in <ref type="bibr" target="#b15">Sun et al. (2008</ref><ref type="bibr" target="#b14">Sun et al. ( , 2009</ref>; <ref type="bibr" target="#b20">Zhang et al. (2012)</ref>. It contains 8, 015 Chinese ab- breviations, including noun phrases, organization names and some other types. Some examples are presented in TABLE 8. We use 80% abbreviations as training data and the rest as testing data. In some cases, a long phrase may contain more than one abbreviation. For these cases, the corpus just keeps their most commonly used abbreviation for each full form.</p><p>The evaluation metric used in our experiment is the top-K accuracy, which is also used by <ref type="bibr" target="#b17">Tsuruoka et al. (2005)</ref>, <ref type="bibr" target="#b14">Sun et al. (2009)</ref> and</p><formula xml:id="formula_5">1. x i ∈ {0, 1}, y i ∈ {0, 1}, z i ∈ {0, 1} 2. N i=1 y i ≤ 1 3. Q i=1 z i ≤ 1 4</formula><p>. ∀R i ∈ R, S j ∈ S, if R i and S j have a same position but the position gets different labels, then y i + x j ≤ 1 5. ∀T i ∈ T , S j ∈ S, if T i and S j have a same position but the position gets different labels, then z i + x j ≤ 1 6. ∀R i ∈ R, T j ∈ T , if R i and T j have a same position but the position gets different labels, then x i + z j ≤ 1 7. ∀S i , S j ∈ S if S i and S j have a same position but the position gets different labels, then z i + z j ≤ 1 8. ∀S i , S j ∈ S if the last character S i keeps is the same as the first character S j keeps, then z i + z j ≤ 1  In our experiment, top-10 can- didates are considered in re-ranking phrase and the measurement used is top-1 accuracy (which is the accuracy we usually refer to) because the final aim of the algorithm is to detect the exact abbreviation. CRF++ <ref type="bibr">7</ref> , an open source linear chain CRF tool, is used in the sequence labeling part. For ILP part, we use lpsolve 8 , which is also an open source tool. The parameters of these tools are tuned through cross-validation on the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>TABLE 9 shows the top-K accuracy of the character-based and MSU-based method. We can see that the MSU-based tagging method can uti- lize word information, which can get better perfor- mance than the character-based method. We can also figure out that the top-5 candidates include the reference abbreviation for most full forms. There- fore reasonable decoding by considering all possi- ble labeling of sequences may improve the perfor- mance. Although the MSU-based methods only outperforms character-based methods by 0.75% 7 http://crfpp.sourceforge.net/ 8 http://lpsolve.sourceforge.net/5.5/ for top-1 accuracy, it is much better when consid- ering top-2 to top-5 accuracy (+2.5%). We further select the top-ranked candidates for ILP decod- ing. Therefore the MSU-based method can further improve the performance in the global decoding phase.  We then use the top-5 candidates of character- based method and MSU-based method, as well as the top-2 results of sub-sequence labeling in the ILP decoding phase. Then we select the top- ranked candidate as the final abbreviation of each instance. TABLE 10 shows the results. We can see that the accuracy of our method is 61.0%, which improved by +3.89% compared to the character- based method, and +3.14% compared to the MSU- based method.</p><p>We find that the ILP decoding phase do play an important role in generating the right an-Method Top-1 Accuracy Char-based 0.5714 MSU-based 0.5789 ILP Result 0.6103 <ref type="table">Table 10</ref>: Top-1 Accuracy after ILP decoding swer. Some reference abbreviations which are not picked out by either tagging method can be found out after decoding. TABLE 11 shows the exam- ple of the organization name " " (Higher Education Admissions Office).</p><p>Neither the character-based method nor the MSU- based method finds the correct answer "", while after ILP decoding, "" becomes the final result.    <ref type="table">Table 13</ref>: Top-1 result of "" (Visual effects of sound and lights)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Improvements Considering Length</head><p>Full forms that are longer than five characters are long terms. Long terms contain more characters, which is much easier to make mistakes. <ref type="figure" target="#fig_2">Figure  1</ref> shows the top-1 accuracy respect to the term length using different tagging methods and using ILP decoding. The x-axis represents the length of the full form. The y-axis represents top-1 accu- racy. We find that our method works especially better than pure character-based or MSU-based approach when the full form is long. By decod- ing using ILP, both local and global information are incorporated. Therefore many of these errors can be eliminated. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Effect of pruning</head><p>As discussed in previous sections, if we are able to pre-determine that some characters in a certain context should be kept or skipped, then the num- ber of possible boolean variable x can be reduced.   <ref type="formula">(2012)</ref> and <ref type="bibr" target="#b13">Sun et al. (2013)</ref>, and experi- ment on our corpus. The first two are CRF+GI and DPLVM+GI in <ref type="bibr" target="#b14">Sun et al. (2009)</ref>, which are reported to outperform the methods in <ref type="bibr" target="#b17">Tsuruoka et al. (2005)</ref> and <ref type="bibr" target="#b15">Sun et al. (2008)</ref>. For DPLVM we use the same model in <ref type="bibr" target="#b14">Sun et al. (2009)</ref> and experiment on our own data. We also compare our approach with the method in <ref type="bibr" target="#b20">Zhang et al. (2012)</ref>. However, <ref type="bibr" target="#b20">Zhang et al. (2012)</ref> uses dif- ferent sources of search engine result information to re-rank the original candidates. We do not use any extra web resources. Because <ref type="bibr" target="#b20">Zhang et al. (2012)</ref> uses web information only in its second stage, we use "BIEP"(the tag set used by <ref type="bibr" target="#b20">Zhang et al. (2012)</ref>) to denote the first stage of <ref type="bibr" target="#b20">Zhang et al. (2012)</ref>, which also uses no web information.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Previous research mainly focuses on "abbrevia- tion disambiguation", and machine learning ap- proaches are commonly used <ref type="bibr" target="#b9">(Park and Byrd, 2001;</ref><ref type="bibr" target="#b4">HaCohen-Kerner et al., 2008;</ref><ref type="bibr" target="#b19">Yu et al., 2006;</ref><ref type="bibr" target="#b1">Ao and Takagi, 2005</ref>). These ways of link- ing abbreviation pairs are effective, however, they cannot solve our problem directly. In many cases the full form is definite while we don't know the corresponding abbreviation.</p><p>To solve this problem, some approaches main- tain a database of abbreviations and their corre- sponding "full form" pairs. The major problem of pure database-building approach is obvious. It is impossible to cover all abbreviations, and the building process is quit laborious. To find these pairs automatically, a powerful approach is to find the reference for a full form given the context, which is referred to as "abbreviation generation".</p><p>There is research on heuristic rules for gen- erating abbreviations <ref type="bibr" target="#b2">Barrett and Grems (1960)</ref>; <ref type="bibr" target="#b3">Bourne and Ford (1961)</ref>; <ref type="bibr" target="#b16">Taghva and Gilbreth (1999)</ref>; <ref type="bibr" target="#b9">Park and Byrd (2001)</ref>; <ref type="bibr" target="#b18">Wren et al. (2002);</ref><ref type="bibr" target="#b6">Hearst (2003)</ref>. Most of them achieved high per- formance. However, hand-crafted rules are time consuming to create, and it is not easy to transfer the knowledge of rules from one language to an- other.</p><p>Recent studies of abbreviation generation have focused on the use of machine learning tech- niques. <ref type="bibr" target="#b15">Sun et al. (2008)</ref> proposed a supervised learning approach by using SVM model. <ref type="bibr" target="#b17">Tsuruoka et al. (2005)</ref>; <ref type="bibr" target="#b14">Sun et al. (2009)</ref> formal- ized the process of abbreviation generation as a sequence labeling problem. In <ref type="bibr" target="#b17">Tsuruoka et al. (2005)</ref> each character in the full form is associated with a binary value label y, which takes the value S (Skip) if the character is not in the abbreviation, and value P (Preserve) if the character is in the ab- breviation. Then a MEMM model is used to model the generating process. <ref type="bibr" target="#b14">Sun et al. (2009)</ref> followed this schema but used DPLVM model to incor- porate both local and global information, which yields better results. <ref type="bibr" target="#b13">Sun et al. (2013)</ref> also uses machine learning based methods, but focuses on the negative full form problem, which is a little different from our work.</p><p>Besides these pure statistical approaches, there are also many approaches using Web as a corpus in machine learning approaches for generating ab- breviations. <ref type="bibr" target="#b0">Adar (2004)</ref> proposed methods to de- tect such pairs from biomedical documents. <ref type="bibr" target="#b7">Jain et al. (2007)</ref> used web search results as well as search logs to find and rank abbreviates full pairs, which show good result. The disadvantage is that search log data is only available in a search en- gine backend. The ordinary approaches do not have access to search engine internals. <ref type="bibr" target="#b20">Zhang et al. (2012)</ref> used web search engine information to re- rank the candidate abbreviations generated by sta- tistical approaches. Compared to their approaches, our method uses no extra resource, but reaches comparable results.</p><p>ILP shows good results in many NLP tasks. <ref type="bibr" target="#b10">Punyakanok et al. (2004)</ref>; <ref type="bibr" target="#b12">Roth and Yih (2005)</ref> used it in semantic role labeling (SRL). <ref type="bibr" target="#b8">Martins et al. (2009)</ref> used it in dependency parsing. <ref type="bibr" target="#b21">(Zhao and Marcus, 2012</ref>) used it in Chinese word seg- mentation. ( <ref type="bibr" target="#b11">Riedel and Clarke, 2006</ref>) used ILP in dependency parsing. However, previous works mainly focus on the constraints of avoiding bound- ary confliction. For example, in SRL, two argu- ment of cannot overlap. In CWS, two Chinese words cannot share a same character. Different to their methods, we investigate on the conflict of la- bels of character sub-sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future work</head><p>We propose a new Chinese abbreviation predic- tion method which can incorporate rich local in- formation while generating the abbreviation glob- ally. We propose the MSU, which is more coarse- grained than character but more fine-grained than word, to capture word information in the se- quence labeling framework. Besides the MSU- based method, we use a substring tagging strategy to generate local substring tagging candidates. We use an ILP formulation with various constraints to globally decode the final abbreviation from the generated candidates. Experiments show that our method outperforms the state-of-the-art systems, without using any extra resource. This method is not limited to Chinese abbreviation generation, it can also be applied to similar languages like Japanese.</p><p>The results are promising and outperform the baseline methods. The accuracy can still be im- proved. Potential future works may include using semi-supervised methods to incorporate unlabeled data and design reasonable features from large cor- pora. We are going to study on these issues in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Uni-gram Contexts c 0</head><label>0</label><figDesc>, c −1 , c 1 Bi-gram Contexts c −1 c0, c −1 c 1 , c 0 c 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Top-1 accuracy of different methods considering length</figDesc><graphic url="image-1.png" coords="7,313.31,140.31,206.21,99.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Representing characters of Chinese words with length 3 (K for keep and S for skip) and the 
corresponding MSUs 

2. A word whose length is larger than 2, but 
does not contain any MSUs with length equal 
to 2. For example, ""(Railway Sta-
tion) is not an MSU because the first two 
characters ""(Train) can form an MSU. 
By this definition, all 6 strings in TABLE 2 are 
often thought as a word, but they are not MSUs 
in our view. Their corresponding MSU forms are 
shown in TABLE 2. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>TABLE 7 .</head><label>7</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 7 : Context templates used in pruning</head><label>7</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 6 : Constraints for ILP</head><label>6</label><figDesc></figDesc><table>Type 
Full form 
Abbreviation 
Noun Phrase 
(Excellent articles) 

Organization 
(Writers' Association) 

Coordinate phrase (Injuries and deaths) 

Proper noun 
(Media) 


</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 8 : Examples of the corpus (Noun Phrase, Organization, Coordinate Phrase, Proper Noun)</head><label>8</label><figDesc></figDesc><table>Zhang et al. (2012). The top-K accuracy measures 
what percentage of the reference abbreviations are 
found if we take the top N candidate abbreviations 
from all the results. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 9 :</head><label>9</label><figDesc></figDesc><table>Top-K (K ≤ 5) results of character-based 
tagging and MSU-based tagging 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>TABLE 12 andTABLE 13 give</head><label>1213</label><figDesc></figDesc><table>two 
more examples. 

True Result 

Char-based 

MSU-based 

ILP Decoding 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 11 :</head><label>11</label><figDesc></figDesc><table>Top-1 result of " 
" (Higher Education Admissions Office) 

True Result 

Char-based 

MSU-based 

ILP Decoding 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 12 :</head><label>12</label><figDesc></figDesc><table>Top-1 result of "" (Articles 
exceed the value) 

True Result 

Char-based 

MSU-based 

ILP Decoding 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>TABLE 14 shows</head><label>14</label><figDesc></figDesc><table>the differences. To guarantee 
a high accuracy, we set the threshold to be 0.99. 
When the original full form is partially tagged by 
the pruning constraints, the number of boolean 
variables per full form is reduced from 34.4 to 
25.5. By doing this, we can improve the predic-
tion speed over taking the raw input. 
From TABLE 14 we can also see that the top-
1 accuracy is not affected by these pruning con-
straints. This is obvious, because CRF itself has 
a strong modeling ability. The pruning constraints 
cannot improve the model accuracy. But they can 
help eliminate those false candidates to make the 
ILP decoding faster. 

Accuracy Average length Time(s) 
raw 
0.6103 
34.4 
12.5 
pruned 0.6103 
25.5 
7.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 14 :</head><label>14</label><figDesc></figDesc><table>Comparison of testing time of raw input 
and pruned input 

3.5 Compare with the State-of-the-art 
Systems 

We also compare our method with previous meth-
ods, including Sun et al. (2009) and Zhang et al. 
(2012). Because we use a different corpus, we 
re-implement the system Sun et al. (2009), Zhang </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" validated="false"><head></head><label></label><figDesc>TABLE 15 shows the results of the comparisons. We can see that our method outperforms all other methods which use no extra resource. Because Zhang et al. (2012) uses extra web resource, the top-1 accuracy of Zhang et al. (2012) is slightly better than ours.</figDesc><table>Method 
Top-1 Accuracy 
CRF+GI 
0.5850 
DPLVM+GI 
0.5990 
BIEP 
0.5812 
Zhang et al. (2012) 0.6205 
Our Result 
0.6103 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" validated="false"><head>Table 15 :</head><label>15</label><figDesc></figDesc><table>Comparison with the state-of-the-art 
systems 

</table></figure>

			<note place="foot" n="1"> A small portion of Chinese abbreviations are not generated from the full form. For example, the abbreviation of &quot; &quot;(Shan Dong Province) is &quot;&quot;. However, we can use a look-up table to get this kind of abbreviations.</note>

			<note place="foot" n="3">. Word Bigrams (X i , X i+1 ) (−2 ≤ i ≤ 1) 4. Type of word X i (−2 ≤ i ≤ 2) 5. Length of word X i (−2 ≤ i ≤ 2) Table 5: Feature templates for unit tagging. X represents the MSU sequence of the full form. X i represents the ith MSU in the sequence. Templates 1, 2 and 3 express word uni-grams and bi-grams. In MSU-based tagging, we can utilize the POS information, which we get from the Stanford Chinese POS Tagger 6. In template 4, the type of word refers to whether it is a number, an English word or a Chinese word. Because the basic tagging unit is MSU, which carries word information, we can use many features that are infeasible in character-based tagging. 5 In table 2, all examples are partly kept. 6 http://nlp.stanford.edu/software/ tagger.shtml</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was partly supported by <ref type="bibr">Na</ref> </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Sarad: A simple and robust abbreviation dictionary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="527" to="533" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Alice: an algorithm to extract abbreviations from medline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Takagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="576" to="586" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Abbreviating words systematically</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grems</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="323" to="324" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A study of methods for systematically abbreviating english words and names</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bourne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM (JACM)</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="538" to="552" />
			<date type="published" when="1961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Combined one sense disambiguation of abbreviations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hacohen-Kerner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peretz</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th</title>
		<meeting>the 46th</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics on Human Language Technologies: Short Papers</title>
		<imprint>
			<biblScope unit="page" from="61" to="64" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A simple algorithm for identifying abbreviation definitions in biomedical text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Hearst</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Acronym-expansion recognition and ranking on the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cucerzan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Azzam</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Reuse and Integration</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="209" to="214" />
		</imprint>
	</monogr>
	<note>IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Concise integer linear programming formulations for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="342" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hybrid text mining for finding abbreviations and their definitions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Byrd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2001 conference on empirical methods in natural language processing</title>
		<meeting>the 2001 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="126" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Semantic role labeling via integer linear programming inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Punyakanok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-T</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zimak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on Computational Linguistics</title>
		<meeting>the 20th international conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page">1346</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Incremental integer linear programming for non-projective dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2006 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="129" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Integer linear programming inference for conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on Machine learning</title>
		<meeting>the 22nd international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="736" to="743" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Generalized abbreviation prediction with negative full forms and its application on improving chinese web search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Joint Conference on Natural Language Processing</title>
		<meeting>the Sixth International Joint Conference on Natural Language Processing<address><addrLine>Nagoya, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="641" to="647" />
		</imprint>
	</monogr>
	<note>Asian Federation of Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Robust approach to abbreviating terms: A discriminative latent variable model with global information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Okazaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="905" to="913" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Predicting chinese abbreviations from definitions: An empirical learning approach using support vector regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Science and Technology</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="602" to="611" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Recognizing acronyms and their definitions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Taghva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gilbreth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal on Document Analysis and Recognition</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="191" to="198" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A machine learning approach to acronym generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ananiadou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-ISMB Workshop on Linking Biological Literature, Ontologies and Databases: Mining Biological Semantics</title>
		<meeting>the ACL-ISMB Workshop on Linking Biological Literature, Ontologies and Databases: Mining Biological Semantics</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="25" to="31" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Heuristics for identification of acronym-definition patterns within text: towards an automated construction of comprehensive acronym-definition dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Garner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods of information in medicine</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="426" to="434" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A large scale, corpus-based approach for automatically disambiguating biomedical abbreviations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Hatzivassiloglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilbur</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="380" to="404" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Constructing Chinese abbreviation dictionary: A stacked approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The COLING 2012 Organizing Committee</title>
		<meeting><address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3055" to="3070" />
		</imprint>
	</monogr>
	<note>Proceedings of COLING 2012</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Exploring deterministic constraints: from a constrained english pos tagger to an efficient ilp solution to chinese word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marcus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th</title>
		<meeting>the 50th</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1054" to="1062" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
