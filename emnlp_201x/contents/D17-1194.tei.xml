<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:19+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Temporal dynamics of semantic relations in word embeddings: an application to predicting armed conflict participants</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Kutuzov</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Informatics</orgName>
								<orgName type="department" key="dep2">Department of Informatics</orgName>
								<orgName type="department" key="dep3">Department of Informatics</orgName>
								<orgName type="institution" key="instit1">University of Oslo</orgName>
								<orgName type="institution" key="instit2">University of Oslo</orgName>
								<orgName type="institution" key="instit3">University of Oslo</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Velldal</surname></persName>
							<email>erikve@ifi.uio.no</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Informatics</orgName>
								<orgName type="department" key="dep2">Department of Informatics</orgName>
								<orgName type="department" key="dep3">Department of Informatics</orgName>
								<orgName type="institution" key="instit1">University of Oslo</orgName>
								<orgName type="institution" key="instit2">University of Oslo</orgName>
								<orgName type="institution" key="instit3">University of Oslo</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lilja</forename><surname>Ã˜vrelid</surname></persName>
							<email>liljao@ifi.uio.no</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Informatics</orgName>
								<orgName type="department" key="dep2">Department of Informatics</orgName>
								<orgName type="department" key="dep3">Department of Informatics</orgName>
								<orgName type="institution" key="instit1">University of Oslo</orgName>
								<orgName type="institution" key="instit2">University of Oslo</orgName>
								<orgName type="institution" key="instit3">University of Oslo</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Temporal dynamics of semantic relations in word embeddings: an application to predicting armed conflict participants</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1824" to="1829"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper deals with using word embedding models to trace the temporal dynamics of semantic relations between pairs of words. The setup is similar to the well-known analogies task, but expanded with a time dimension. To this end, we apply incremental updating of the models with new training texts, including in-cremental vocabulary expansion, coupled with learned transformation matrices that let us map between members of the relation. The proposed approach is evaluated on the task of predicting insurgent armed groups based on geographical locations. The gold standard data for the time span 1994-2010 is extracted from the UCDP Armed Conflicts dataset. The results show that the method is feasible and outperforms the baselines, but also that important work still remains to be done.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction and related work</head><p>In this research, we make an attempt to model the dynamics of worldwide armed conflicts on the ba- sis of English news texts. To this end, we employ the well-known framework of Continuous Bag-of- Words modeling ( <ref type="bibr" target="#b11">Mikolov et al., 2013c</ref>) for train- ing word embeddings on the English Gigaword news text corpus <ref type="bibr" target="#b12">(Parker et al., 2011</ref>). We learn linear projections from the embeddings of geo- graphical locations where violent armed groups were active to the embeddings of these groups. These projections are then applied to the embed- dings and gold standard data from the subsequent year, thus predicting what entities act as violent groups in the next time slice. To evaluate our approach, we adapt the UCDP Armed Conflict Dataset ( <ref type="bibr" target="#b2">Gleditsch et al., 2002;</ref><ref type="bibr" target="#b0">Allansson et al., 2017</ref>) (see Section 2 for details).</p><p>Here is a simplified example of the task: given that in 2003, the Kashmir Liberation Front and ULFA were involved in armed conflicts in India, and Lord's Resistance Army in Uganda, predict en- tities playing the same role in 2004 in Iraq (the cor- rect answers are Ansar al-Islam, al-Mahdi Army and Islamic State). The nature of the task is con- ceptually similar to that of analogical reasoning, but with the added complexity of temporal change.</p><p>Attempts to detect semantic change using un- supervised methods have a long history. Signif- icant results have already been achieved in em- ploying word embeddings to study diachronic lan- guage change. Among others, <ref type="bibr" target="#b1">Eger and Mehler (2016)</ref> show that the embedding of a given word for a given time period to a large extent is a lin- ear combination of its embeddings for the pre- vious time periods. <ref type="bibr" target="#b3">Hamilton et al. (2016)</ref> pro- posed an important distinction between cultural shifts and linguistic drifts. They proved that global embedding-based measures (comparing the sim- ilarities of words to all other words in the lexi- con) are sensitive to regular processes of linguis- tic drift, while local measures (comparing nearest neighbors' lists) are a better fit for more irregular cultural shifts in word meaning.</p><p>Our focus here is on cultural shifts: it is not the dictionary meanings of the names denoting lo- cations and armed groups that change, but rather their 'image' in the analyzed texts. Our measure- ment approach can also be defined as 'local' to some extent: the linear projections that we learn are mostly based and evaluated on the nearest neighborhood data. However, this method is dif- ferent in that its scope is not single words but pairs of typed entities ('location' and 'armed group' in our case) and the semantic relations between them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Contributions</head><p>The main contributions of this paper are:</p><p>1. We show that distributional semantic models, in particular word embeddings, can be used not only to trace diachronic semantic shifts in words, but also the temporal dynamics of semantic relations between pairs of words.</p><p>2. The necessary prerequisites for achieving de- cent performance in this task are incremental updating of the models with new textual data (instead of training from scratch each time new data is added) and some way of expand- ing the vocabulary of the models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Gold standard data on armed conflicts</head><p>The UCDP/PRIO Armed Conflict Dataset main- tained by the Uppsala Conflict Data Program and the Peace Research Institute Oslo is a manually annotated geographical and temporal dataset with information on armed conflicts, in the time period from 1946 to the present ( <ref type="bibr" target="#b2">Gleditsch et al., 2002;</ref><ref type="bibr" target="#b0">Allansson et al., 2017)</ref>. It encodes conflicts, where at least one party is the government of a state. The Armed Conflict Dataset is widely used in statis- tical and macro-level conflict research; however, it was adapted and introduced to the NLP field only recently, starting with ( <ref type="bibr" target="#b7">Kutuzov et al., 2017)</ref>. Whereas that work was focused on detecting the onset/endpoint of armed conflicts, the current pa- per further extends on this by using the dataset to evaluate the detection of changes in the seman- tic relation holding between participants of armed conflicts and their locations. Two essential notions in the UCDP data are those of event and armed conflict. Events can evolve into full-scale armed conflicts, defined as contested incompatibilities that concern govern- ment and/or territory where the use of armed force between two parties, of which at least one is the government of a state, results in at least 25 battle- related deaths <ref type="bibr" target="#b15">(Sundberg and Melander, 2013)</ref>.</p><p>The subset of the data that we employ is the UCDP Conflict Termination dataset <ref type="bibr" target="#b5">(Kreutz, 2010)</ref>. It contains entries on starting and ending dates of about 2000 conflicts. We limit ourselves to the conflicts taking place between 1994 and 2010 (the Gigaword time span). Almost always, the first actor of the conflict (sideA) is the govern- ment of the corresponding location, and the sec- ond actor (sideB) is some insurgent armed group we are interested in. We omitted the conflicts where both sides were governments (about 2% of the entries) or where one of the sides was men- tioned in the Gigaword less than 100 times (about 1% of the entries). In cases when the UCDP de- scribed the conflict as featuring several groups on the sideB, we created a separate entry for each.</p><p>This resulted in a test set of 673 conflicts, with 137 unique Location-Insurgent pairs throughout the whole time span (many pairs appear sev- eral times in different years). In total, it men- tions 52 locations (with India being the most frequent) and 128 armed insurgent groups (with ULFA or United Liberation Front of Assam be- ing the most frequent). This test set is available for subsequent reuse (http://ltr.uio.no/ ~andreku/armedconflicts/).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Predicting armed conflict participants</head><p>In this section, we provide a detailed description of our approach, starting with a synchronic exam- ple in 3.1 and then moving on to a toy diachronic example on one pair of years in 3.2. In the next section 4, we conduct evaluation on the full test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Synchronic modeling</head><p>We first conducted preliminary experiments to as- sess the hypothesis that the embeddings contain semantic relationships of the type 'insurgent par- ticipant of an armed conflict in the location'. To this end, we trained a CBOW model on the full English Gigaword corpus (about 4.8 billion tokens in total), with a symmetric context window of 5 words, vector size 300, 10 negative samples and 5 iterations. Words with a frequency less than 100 were ignored during training. We used Gen- sim <ref type="bibr">( Ë‡ RehÅ¯Å™ek and Sojka, 2010)</ref> for training, and in terms of corpus pre-processing we performed lemmatization, PoS-tagging and NER using Stan- ford CoreNLP ( <ref type="bibr" target="#b8">Manning et al., 2014</ref>). Named en- tities were concatenated to one token (for example, United States became United::States_PROPN).</p><p>Then, we used the 137 Location-Insurgent pairs derived in Section 2 to learn a projection matrix from the embeddings for locations to the embed- dings for insurgents. The idea and the theory be- hind this approach are extensively described in ( <ref type="bibr" target="#b10">Mikolov et al., 2013b</ref>) and ( <ref type="bibr" target="#b6">Kutuzov et al., 2016</ref>), but essentially it involves training a linear regres- sion which minimizes the error in transforming</p><formula xml:id="formula_0">locâ†’group groupâ†’loc Î» @1 @5 @10 @1 @5 @10</formula><p>0.0 0.0 14.6 31.4 8.8 46.7 70.8 0.5 0.7 19.0 35.0 7.3 49.6 70.1 1.0 2.2 19.7 32.8 6.6 47.4 66.4 <ref type="table">Table 1</ref>: Accuracies for synchronic projections from locations to armed groups, and vice versa one set of vectors into another. Finding the op- timal transformation matrix amounts to solving i normal equations (where i is the vector size in the embedding model being used), as shown in Equa- tion 1:</p><formula xml:id="formula_1">Î² i = (X * X + Î» * L) âˆ’1 * X * y i (1)</formula><p>where X is the matrix of 137 location word vectors (input), y i is the array of the ith components of 137 corresponding insurgent word vectors (correct predictions), L is the identity matrix of the size i, with 0 at the top left cell, and Î» is a real number used to tune the influence of regularization term (if Î» = 0, there is no regularization). Î² i is the array of i optimal coefficients which transform an arbitrary location vector into the ith component of the corresponding insurgent vector. After learning such an array for each vector component, we have a linear projection matrix which can 'predict' an insurgent embedding from a location embedding.</p><p>To evaluate the resulting projections, we em- ployed leave-one-out cross-validation, i.e., mea- suring the average accuracy of predictions on each pair from the test set, after training the matrix on all the pairs except the one used for the testing. The transformation matrix was dot-multiplied by the location vector from the test pair. Then, we found n nearest neighbors in the word embedding model for this predicted vector. If the real insur- gent in the test pair was present in these n neigh- bors, the accuracy for this pair was 1, otherwise 0. In <ref type="table">Table 1</ref>, the average accuracies with different values of Î» and n are reported.</p><p>The relations of this kind are not symmetric: it is much easier to predict the location based on the insurgent than vice versa (see the right part of Ta- ble 1). Moreover, we find that the achieved re- sults are roughly consistent with the performance of the same approach on the Google Analogies test set ( <ref type="bibr" target="#b9">Mikolov et al., 2013a</ref>). We converted the semantic sections in the Analogies test set con- taining only nouns (capitals-common, capitals- world, cities in states, currency and family) to sets of unique pairs. Then, linear projections with Î» = 1.0 were learned and evaluated for each of them. The average accuracies over these sections were 13.0@1, 48.77@5 and 62.96@10.</p><p>The results on predicting armed groups are still worse than on the Google Analogies, because of 3 factors: 1) one-to-many relationships in the UCDP dataset (multiple armed groups can be active in the same location) make learning the transformation matrix more difficult; 2) the frequency of words denoting armed groups is lower than any of the words in the Google Analogies data set, thus, em- beddings for them are of lower quality; 3) training the matrix on the whole Gigaword model is sub- optimal, as the majority of armed groups were not active throughout all its time span.</p><p>All our experiments were also conducted us- ing the very similar Continuous Skipgram mod- els. However, as CBOW proved to consistently outperform Skipgram for our tasks, we only report results for CBOW, due to limited space. <ref type="bibr">1</ref> To sum up this section, many-to-one semantic relations between locations and insurgents do exist in the word embedding models. They are less ex- pressed than one-to-one relations like those in the Google Analogies test set, but still can be found using linear projections. In the next section, we trace the dynamics of these relations as the mod- els are updated with new data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Diachronic modeling</head><p>Our approach to using learned transformation ma- trices to trace armed conflict dynamics through time consists of the following. We first train a CBOW model on the subsection of Gigaword texts belonging to the year 1994. Then, we incremen- tally update (train) this same model with new texts, saving a new model after each subsequent year. The size of the yearly subcorpora is about 250- 320 million content words each. Importantly, we also use vocabulary expansion: new words are added to the vocabulary of the model if their fre- quency in the new yearly data satisfy our minimal threshold of 15. <ref type="bibr">2</ref> Each yearly training session is performed in 5 iterations, with linearly decreas- ing learning rate. Note that we do not use any model alignment method (Procrustes, etc): our Pairs (size) @1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>@5 @10</head><p>All <ref type="formula">(38)</ref> 44.7 73.7 84.2 New <ref type="formula">(7)</ref> 14.3 28.6 42.9  <ref type="bibr">2000 to 2001</ref> alone. This means we will have one model saved after sequen- tial training for the years up to 2000, and one saved after year 2001. Our aim is to find out whether the Location-Insurgent projection learned on the first model is able to reveal conflicts that appear in 2001. Thus, we extract from the UCDP dataset all the pairs related to the conflicts which took place between 1994 and 2000 (91 pairs total). The pro- jection is trained on their embeddings from the first model (actually, on 79 pairs, as 12 armed group names were not present in the 2000 model and subsequently skipped). Then, this projection is applied to the second model embeddings of the 47 locations, which are subject to armed conflicts in the year 2001 (38 after skipping pairs with out- of-vocabulary elements). <ref type="table" target="#tab_0">Table 2</ref> demonstrates the resulting performance (reflecting how close the predicted vectors are to the actual armed groups active in this or that location).</p><p>Note that out of 38 pairs from 2001, 31 were already present in the previous data set (ongoing conflicts). This explains why the evaluation on all the pairs gives high results. However, even for the new conflicts, the projection performance is en- couraging. Among others, it managed to precisely spot the 2001 insurgency of the members of the Kosovo Liberation Army in Macedonia, notwith- standing the fact that the initial set of training pairs did not mention Macedonia at all. Thus, it seems that the models at least partially 'align' new data along the existing semantic axis trained before.</p><p>In the next section, we systematically evaluate our approach on the whole set of UCDP conflicts in the Gigaword years <ref type="bibr">(1994)</ref><ref type="bibr">(1995)</ref><ref type="bibr">(1996)</ref><ref type="bibr">(1997)</ref><ref type="bibr">(1998)</ref><ref type="bibr">(1999)</ref><ref type="bibr">(2000)</ref><ref type="bibr">(2001)</ref><ref type="bibr">(2002)</ref><ref type="bibr">(2003)</ref><ref type="bibr">(2004)</ref><ref type="bibr">(2005)</ref><ref type="bibr">(2006)</ref><ref type="bibr">(2007)</ref><ref type="bibr">(2008)</ref><ref type="bibr">(2009)</ref><ref type="bibr">(2010)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation of diachronic models</head><p>To evaluate our approach on all the UCDP data, we again tested how good it is in predicting the future conflicts based on the projection matrices learned from the previous years. We did this for all the years between 1994 and 2010. The evalu- ation metrics are the same as in the Section 3: we calculated the ratio of correctly predicted armed groups names from the conflict pairs, for which the UCDP datasets stated that these conflicts were active in this particular year. As before, the mod- els employed in the experiment were incremen- tally trained on each successive year with vocabu- lary expansion. Words present in the gold standard but absent from the models under analysis were skipped. At the worst case, 25% of pairs were skipped from the test set; on average, 13% were skipped each year (but see the note below about the incr. static baseline). At test time, all the enti- ties were lowercased. We employ 3 baselines: 1) yearly models trained separately from scratch on the corpora con- taining texts from each year only (referred to as separate hereafter); 2) yearly models trained from scratch on all the texts from the particular year and the previous years (cumulative hereafter); 3) incrementally trained models without vocabulary expansion (incr. static hereafter).</p><p>Initially, the linear projections for all models were trained on all the conflict pairs from the past and present years, similar to Section 3.2 (dubbed up-to-now hereafter). However, the information about conflicts having ended several years before might not be strongly expressed in the model after it was incrementally updated with the data from all the subsequent years. For example, the 2005 model hardly contains much knowledge about the conflict relations between Mexico and the Popu- lar Revolutionary Army (EPR) which stopped its activities after 1996. Thus, we additionally con- ducted a similar experiment, but this time the pro- jections were learned only on the salient pairs (dubbed previous): that is, the pairs active in the last year up to which the model was trained. <ref type="table">Table 3</ref> presents the results for these experi- ments, as well as baselines (averaged across 15 years). For the proposed incr. dynamic approach, the performance of the previous projections is Only in-vocabulary pairs All pairs, including OOV up-to-now previous up-to-now previous  <ref type="table">Table 3</ref>: Average accuracies of predicting next-year insurgents on the basis of locations, using projections trained on the conflicts from all the preceding years (up-to-now) or the preceding year only (previous). Results for 3 baselines are shown along with the proposed incremental dynamic approach.</p><formula xml:id="formula_2">@1 @5 @10 @1 @5 @10 @1 @5 @10 @1 @5</formula><p>comparable to that of the up-to-now projections on the accuracies @5 and @10, and is even higher on the accuracy @1 (statistically significant with t-test, p &lt; 0.01). Thus, the single-year projections are somewhat more 'focused', while taking much less time to learn, because of less training pairs. The fact that our models were incrementally up- dated, not trained from scratch, is crucial. The re- sults of the separate baseline look more like ran- dom jitter. The cumulative baseline results are slightly better, probably simply because they are trained on more data. However, they still perform much worse than the models trained using incre- mental updates. This is because the former mod- els are not connected to each other, and thus are initialized with a different layout of words in the vector space. This gives rise to formally differ- ent directions of semantic relations in each yearly model (the relations themselves are still there, but they are rotated and scaled differently).</p><p>The results for the incr. static baseline, when tested only on the words present in the test model vocabulary (the left part of the table), seem bet- ter than those of the proposed incr. dynamic ap- proach. This stems from the fact that incremen- tal updating with static vocabulary means that we never add new words to the models; thus, they contain only the vocabulary learned from the 1994 texts. The result is that at test time we skip many more pairs than with the other approaches (about 62% in average). Subsequently, the projections are tested only on a minor part of the test sets.</p><p>Of course, skipping large parts of the data would be a major drawback for any realistic ap- plication, so the incr. static baseline is not really plausible. For comparison, the right part of <ref type="table">Table 3</ref> provides the accuracies for the setup in which all the pairs are evaluated (for pairs with OOV words the accuracy is always 0). Other tested approaches are not much affected by this change, but for incr. static the performance drops drastically. As a re- sult, for the all pairs scenario, incremental updat- ing with vocabulary expansion outperforms all the baselines (the differences are statistically signifi- cant with t-test, p &lt; 0.01).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have here shown how incrementally updated word embedding models with vocabulary expan- sion and linear projection matrices are able to trace the dynamics of subtle semantic relations over time. We applied this approach to the task of predicting armed groups active in particular geo- graphical locations and showed that it significantly outperforms the baselines. However, it can be used for any kind of semantic relations. We believe that studying temporal shifts of such projections can lead to interesting findings far beyond the usual example of 'king is to queen as man is to woman'.</p><p>To our best knowledge, the behavior of seman- tic relations in updated word embedding models was not explored before. Our experiments show that the models do preserve these 'directions' and that the learned projections not only hold for the word pairs known to the initial model, but can also be used to predict relations for the new words.</p><p>In terms of future work, we plan to trace how quickly incremental updates to the model 'dilute' the projections, rendering them useless with time. We observed this performance drop in our exper- iments, and it would be interesting to know more about the regularities governing this deterioration. Also, for the particular task of analyzing armed conflicts, we plan to research ways of improv- ing accuracy in predicting completely new armed groups not present in the training data, and the methods of filtering out locations not involved in armed conflicts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 2 : Projection accuracy for the isolated ex- ample experiment mapping from 2000 â†’ 2001.</head><label>2</label><figDesc>leave it for future work. The experiment involves applying a learned transformation matrix across pairs of models. While in Section 4 we evaluate the approach across the entire Gigaword time period, this sec- tion reports a preliminary example experiment for the transition from</figDesc><table>models are simply trained further with the new 
texts. A possible alternative to this can be incre-
mental training of hierarchical softmax functions 
proposed in (Peng et al., 2017) or incremental neg-
ative sampling proposed in (Kaji and Kobayashi, 
2017); we </table></figure>

			<note place="foot" n="1"> It seems CBOW is often better than Skipgram with linear projections; cf. the same claim in (Kutuzov et al., 2016). 2 We did not experiment with different thresholds. It was initially set to the value which produced a reasonable vocabulary size of several hundred thousand words.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Organized violence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><surname>Allansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Melander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lotta</forename><surname>ThemnÃ©r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Peace Research</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1989" to="2016" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On the linearity of semantic change: Investigating meaning variation via dynamic graph models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Eger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Mehler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="52" to="58" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Mikael Eriksson, Margareta Sollenberg, and HÃ¥vard Strand</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><forename type="middle">Petter</forename><surname>Gleditsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Wallensteen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Peace Research</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="615" to="637" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>Armed conflict 1946-2001: A new dataset</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cultural shift or linguistic drift? Comparing two computational measures of semantic change</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2116" to="2121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Incremental skip-gram model with negative sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nobuhiro</forename><surname>Kaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hayato</forename><surname>Kobayashi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.03956</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">How and when armed conflicts end: Introducing the UCDP conflict termination dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Kreutz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Peace Research</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="243" to="250" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Clustering comparable corpora of Russian and Ukrainian academic texts: Word embeddings and semantic fingerprints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Kutuzov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Kopotev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatyana</forename><surname>Sviridenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyubov</forename><surname>Ivanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Workshop on Building and Using Comparable Corpora</title>
		<meeting>the Ninth Workshop on Building and Using Comparable Corpora</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Tracing armed conflicts with diachronic word embedding models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Kutuzov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Velldal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lilja</forename><surname>Ã˜vrelid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Events and Stories in the News workshop</title>
		<meeting>the Events and Stories in the News workshop<address><addrLine>Vancouver, Canada. ACL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Exploiting similarities among languages for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1309.4168</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">English Gigaword Fifth Edition LDC2011T07</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuaki</forename><surname>Maeda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Linguistic Data Consortium</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Incrementally learning the hierarchical softmax function for neural language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaopeng</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence<address><addrLine>San Francisco, California USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3267" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Software Framework for Topic Modelling with Large Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>RadimÅ™ehÅ¯Å™ekradimË‡radimÅ™ehÅ¯Å™ek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sojka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks</title>
		<meeting>the LREC 2010 Workshop on New Challenges for NLP Frameworks<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="45" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Introducing the UCDP georeferenced event dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Sundberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Melander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Peace Research</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="523" to="532" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
