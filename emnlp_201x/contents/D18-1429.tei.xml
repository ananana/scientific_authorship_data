<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards a Better Metric for Evaluating Question Generation Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preksha</forename><surname>Nema</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Robert Bosch Center for Data Science and Artificial Intelligence</orgName>
								<orgName type="institution">Indian Institute of Technology Madras</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitesh</forename><forename type="middle">M</forename><surname>Khapra</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Robert Bosch Center for Data Science and Artificial Intelligence</orgName>
								<orgName type="institution">Indian Institute of Technology Madras</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Towards a Better Metric for Evaluating Question Generation Systems</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="3950" to="3959"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>3950</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>There has always been criticism for using n-gram based similarity metrics, such as BLEU, NIST, etc, for evaluating the performance of NLG systems. However, these metrics continue to remain popular and are recently being used for evaluating the performance of systems which automatically generate questions from documents, knowledge graphs, images, etc. Given the rising interest in such automatic question generation (AQG) systems, it is important to objectively examine whether these metrics are suitable for this task. In particular, it is important to verify whether such metrics used for evaluating AQG systems focus on answerability of the generated question by preferring questions which contain all relevant information such as question type (Wh-types), entities, relations, etc. In this work, we show that current automatic evaluation metrics based on n-gram similarity do not always correlate well with human judgments about answerability of a question. To alleviate this problem and as a first step towards better evaluation metrics for AQG, we introduce a scoring function to capture answerability and show that when this scoring function is integrated with existing metrics, they correlate significantly better with human judgments. The scripts and data developed as a part of this work are made publicly available. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The advent of large scale datasets for document Question Answering (QA) ( <ref type="bibr" target="#b29">Rajpurkar et al., 2016;</ref><ref type="bibr" target="#b26">Nguyen et al., 2016;</ref><ref type="bibr" target="#b14">Joshi et al., 2017;</ref><ref type="bibr" target="#b31">Saha et al., 2018a</ref>) knowledge base driven QA ( <ref type="bibr" target="#b3">Bordes et al., 2015;</ref><ref type="bibr" target="#b32">Saha et al., 2018b</ref>) and Visual QA ( <ref type="bibr" target="#b0">Antol et al., 2015;</ref><ref type="bibr" target="#b13">Johnson et al., 2017)</ref> has enabled the development of end-to-end supervised models for Document: In 1648 before the term "geno- cide" had been coined , the Peace of West- phalia was established to protect ethnic, racial and in some instances religious groups. Possible Question: In which year was the Peace of Westphalia established ? <ref type="table">Table 1</ref>: A sample question generated by a human.</p><p>QA. However, as is always the case, data-hungry neural network based solutions could benefit from even more training data, especially in specific do- mains which existing datasets do not cater to. Cre- ating newer datasets for specific domains or aug- menting existing datasets with more data is a te- dious, time-consuming and expensive process. To alleviate this problem and create even more train- ing data, there is growing interest in developing techniques that can automatically generate ques- tions from a given source, say a document ( , knowledge base ( <ref type="bibr" target="#b30">Reddy et al., 2017;</ref><ref type="bibr" target="#b20">Serban et al., 2016)</ref>, or image (  . We refer to this task as Automatic Question Generation (AQG). For ex- ample, given the document in <ref type="table">Table 1</ref>, the task is to automatically generate a question whose answer is also contained in the document.</p><p>Given the practical importance of AQG and its potential to influence research in QA, it is not sur- prising that there has been prolific work in this field in the past one year itself ( <ref type="bibr" target="#b12">Jain et al., 2017;</ref>. Before this field grows further, it is important that the community criti- cally examines the current evaluation metrics be- ing used for this task. In particular, there is a need to closely examine the utility of existing n-gram based similarity metrics such as BLEU ( <ref type="bibr" target="#b27">Papineni et al., 2002</ref>), METEOR <ref type="bibr" target="#b16">(Lavie and Denkowski, 2009</ref>), NIST <ref type="bibr" target="#b7">(Doddington, 2002)</ref>, etc. which have been adopted for this task. This work is a first step in that direction where we propose that apart from n-gram similarity, any metric for AQG should also take into account the answerability of the gener- ated questions. With the help of a few examples below, we illustrate that answerability depends on the presence of relevant information such as ques- tion type (Wh-types), entities, relations, etc, and it is possible that a generated question has a high BLEU score but is still unanswerable and hence not useful.</p><p>To begin with, consider the task of answering questions from a Knowledge Base. Let us as- sume that the intended (gold standard) question is "Who was the director of Titanic?" and two differ- ent AQG systems generate the following questions "S1: director of Titanic?" and "S2: Who was the director of?". Any n-gram based evaluation met- ric would obviously assign a higher score to S2 (BLEU3: 81.9) than S1 (BLEU3: 36.8). How- ever, as should be obvious S1 contains all the rele- vant information, and most humans would be eas- ily able to understand and answer this question. A good evaluation metric should capture this notion of answerability and give more importance to rel- evant words in the question which brings us to the question "Which words are relevant?"</p><p>The above example might give the impression that named entities are essential but other words are not. However, this is misleading and may not always be the case. For example, consider these questions over an image: "Are the cats drinking milk?" v/s "How many cats are drinking milk?". These two questions have very different meaning indicating that even words like are and how are also crucial. Similarly, consider the task of an- swering questions from a passage titled "Matt Da- mon". In this case, most humans will be able to answer the question "What is the birth date of" even though the named entity is missing given that the passage only talks about "Matt Damon". Thus, in some cases, depending on the source (docu- ment, knowledge base, image) different portions of the question may be important.</p><p>To concretize the intuitions developed with the help of the above examples, we first collect hu- man judgments. Specifically, we take questions from existing datasets for document QA, knowl- edge base QA and visual QA and add systematic noise to these questions. We show these questions to humans and ask them to assign scores to these questions based on the answerability and hence the usefulness of these questions (i.e., whether the question contains enough information for them to be able to answer it correctly). We also compute various n-gram similarity metrics (BLEU, ME- TEOR, NIST) comparing the noisy questions to the original questions and show that these metrics do not correlate well with human judgments. Sim- ilar studies <ref type="bibr" target="#b5">(Callison-Burch et al., 2006;</ref><ref type="bibr" target="#b20">Liu et al., 2016</ref>) have already shown that these metrics do not correlate well with fluency, adequacy, coher- ence but in this work, we focus on answerability.</p><p>Based on the human evaluations, we propose to modify existing metrics to focus on answer- ability in addition to n-gram similarity. The idea is to make these metrics flexible such that, if needed, the weight assigned to answerability and n-gram similarity can be adjusted depending on the task (document QA, Knowledge-Base QA, Visual QA). Further, for capturing answerability we propose additional weights for different com- ponents of the question (question type, content words, function words, and named entities) These weights can be learned from a small amount of hu- man annotated data and may differ from task to task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>We have organized our literature survey into 2 parts: (i) question generation systems (ii) studies which analyze evaluation metrics used for NLG.</p><p>Question Generation: Early work on question generation used rule-based approaches to gener- ate questions from declarative sentences <ref type="bibr" target="#b11">(Heilman and Smith, 2010;</ref><ref type="bibr" target="#b25">Mostow and Chen, 2009;</ref><ref type="bibr" target="#b19">Lindberg et al., 2013;</ref><ref type="bibr" target="#b15">Labutov et al., 2015</ref>). More recent works use attention based neural models for question generation ( ). Some models ( ) feed the generated questions to a QA system and use the performance of the QA system as an indica- tor of the quality of the questions. A few models ( ) treat question answering (QA) and question generation (QG) as complementary tasks and focus on jointly training for these two tasks. Other models focus only on the performance of the QA task ( <ref type="bibr" target="#b38">Yang et al., 2017;</ref> and not explicitly on the quality of the generated questions. Apart from generating questions from text there is also research on gen-erating questions from images ( <ref type="bibr" target="#b12">Jain et al., 2017;</ref>) and knowledge base ( <ref type="bibr" target="#b20">Serban et al., 2016;</ref><ref type="bibr" target="#b30">Reddy et al., 2017)</ref>.</p><p>Evaluation metrics for NLG: Current pop- ular metrics for NLG such as BLEU ( <ref type="bibr" target="#b27">Papineni et al., 2002</ref>), METEOR <ref type="bibr" target="#b16">(Lavie and Denkowski, 2009</ref>), ROUGE <ref type="bibr" target="#b18">(Lin, 2004</ref>) and NIST <ref type="bibr" target="#b7">(Doddington, 2002</ref>) essentially compute the n-gram similar- ity between the reference sentence and the gener- ated sentence. Though these metrics are very pop- ular and are used for a wide range of NLG tasks in- cluding AQG, there has always been criticism for using these metrics (for example, see <ref type="bibr">(CallisonBurch et al., 2006;</ref><ref type="bibr" target="#b28">R et al., 2007;</ref><ref type="bibr" target="#b4">Callison-Burch, 2009)</ref>). More recently, there has been criticism ( <ref type="bibr" target="#b20">Liu et al., 2016</ref>) for using such metrics for evalu- ating dialog systems eventually resulting in a new metric ( <ref type="bibr" target="#b22">Lowe et al., 2017)</ref>. This new metric while very important, came a bit late in the day and much after several dialog systems were proposed, evalu- ated and compared using the above n-gram based metrics. It is very important to prevent a similar situation in question generation where many sys- tems get proposed without evaluating them using the right metric. Our work is a first step in this di- rection, and we hope it will lead to more research in designing the right metrics for AQG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Current Evaluation Metrics</head><p>We give a quick overview of the metrics which are currently used for evaluating AQG systems.</p><p>BLEU: BLEU is a precision-based evaluation metric which considers exact n-gram matches. For a given value of n, the precision is computed as the fraction of n-grams in the generated hypothe- sis which match some n-gram in the reference hy- pothesis. The final BLEU score is computed as the geometric mean of the n-gram precisions obtained by varying n from 1 to N where N is typically 3 or 4. It also contains a brevity penalty to penalize hypothesis that are too short.</p><p>METEOR: As opposed to BLEU, METEOR uses both precision and recall, i.e., it computes the fraction of the hypothesis which matches the reference (precision) as well as the fraction of the reference which is contained in the hypothesis (re- call). Further, unlike BLEU which only considers exact matches, METEOR also considers matches with stemmed words, synonyms, and paraphrases. It also gives different weightage to matches cor- responding to function words and matches corre- sponding to content words. The final score is the harmonic mean of the precision and recall calcu- lated based on these four matches. Additionally, it also includes a fragmentation penalty to account for gaps and differences in word order. In effect, METEOR is a parametric metric where the dif- ferent parameters, viz., (i) fragmentation penalty, (ii) weights of different matchers (exact, stemmed, synonyms, paraphrases) and (iii) weights of func- tion and content words, are tuned to maximize cor- relation with human judgments.</p><p>NIST: NIST is a variant of the standard BLEU metric that takes into account the relative impor- tance of each n-grams in the sentence. In par- ticular, the metric gives a high weightage to n- grams which have a lower frequency in the corpus and hence are more informative as compared to very frequent n-grams which are less informative. Further, unlike BLEU which takes the geometric mean of n-gram precisions, NIST takes the arith- metic mean of these precisions. Additionally, they make a small change to the brevity penalty to min- imize the impact of minor variations in the length of the hypothesis.</p><p>ROUGE: ROUGE is a set of evaluation met- rics which were proposed in the context of au- tomatic summarization. Typically, most studies use ROUGE-L, which is F-measure based on the Longest Common Subsequence (LCS) between a candidate and target sentence. Given two se- quences, a common subsequence is the set of words which appear in both the sequences in the same order but unlike n-grams the common subse- quence does not need to be contiguous. LCS is the longest of such common subsequences. For exam- ple, given the sentences candidate:"the boy went home" and reference:"the boy will go home", "the boy home" is the longest common subsequence even though it is not contiguous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Human Judgments For Answerability</head><p>As mentioned earlier, for AQG, in addition to n- gram similarity, we also need to focus on the an- swerability of the generated questions. As illus- trated in Section 1, answerability of a question de- pends on whether it contains all relevant informa- tion, such as question type (Wh-types), named en- tities and content words (often relations). Further, depending on the task (document QA, knowledge- base QA or visual QA) the importance of these words may vary. We perform human evaluations to ascertain the importance of each of these com- ponents across different QA tasks. These evalua- tions allow us to independently analyze the impor- tance of each of these components for the 3 QA tasks. In the remainder of this section, we describe the (i) process of creating noisy questions (ii) in- structions given to the evaluators and the (iii) in- ferences drawn from human evaluations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Creating Noisy Questions</head><p>We took 1000 questions each from 3 popular QA datasets, viz., SQuAD, WikiMovies, and VQA. SQuAD ( <ref type="bibr" target="#b29">Rajpurkar et al., 2016</ref>) is a reading comprehension dataset consisting of around 100K questions based on passages from around 500 Wikipedia articles. The WikiMovies dataset con- tains around 100K questions which can be an- swered from a movie knowledge graph containing 43K entities and 9 relations (director, writer, actor, etc.). The VQA dataset is an image QA dataset containing 265, 016 images with around 5.4 ques- tions on average per image.</p><p>We then created noisy versions of these ques- tions using one of the following four methods:</p><p>Dropping function words: We refer to the list of English function words as defined in NLTK ( <ref type="bibr" target="#b21">Loper and Bird, 2002</ref>) and drop all such words from the question. Note that a noisy question with all function words dropped will have a very low BLEU score compared to the original question.</p><p>Dropping Named Entities: In our setup, iden- tifying named entities in questions was easy be- cause the questions were well formed and all named entities were capitalized. Alternately, we could have used the Stanford NER. However, on manual inspection, we found that marking the cap- italized words as named entities were sufficient. We randomly dropped at most three named entities per question. This allows us to study how humans rate the output of an AQG system which does not contain the correct named entities.</p><p>Dropping Content Words: Words other than function words and named entities are also cru- cial for answerability. For example, "Who killed Jane?" and "Who married Jane?" lead to totally different answers. The word "killed/married" is very relevant to ascertain the correct answer. These words typically capture the relation be- tween the entities involved (for example, killed (John, Jane)). We identify such important (con- tent) words as ones which are neither question types (7-Wh questions) nor named entities nor stop-words. This perturbation allows us to study how humans rate an AQG system which does not produce the correct content (relation) words.</p><p>Changing the Question type: Changing the question type can lead to a different answer alto- gether or can make the question incoherent. For example the answers to "Who killed Jane?" and "What killed Jane?" are completely different. We create a noisy question by randomly changing the type of the question (for example. replace "who" with "what"). These question types are well de- fined (7-Wh questions including "how") and hence it is easy to identify and replace them. This allows us to study the importance of correct question type in the output of an AQG system.</p><p>Note that, an alternate way of collecting human judgments would have been to take the output of existing AQG systems and ask humans to assign answerability scores to these questions based on the presence/absence of the above mentioned rel- evant information. However, when we asked hu- man evaluators to analyze 200 questions generated by an existing AQG system, they reported that the quality was poor. In particular, after having dis- cussions with annotators, we found that using this output, it would be very difficult to conduct such a systematic study to assess the importance of dif- ferent words in the question. Hence, we chose to use systematically simulated noisy questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Instructions</head><p>We asked the annotators to rate the answerability of the above noisy questions on a scale of 1-5. The annotators were clearly told whether the questions belonged to documents or knowledge bases or im- ages. In our initial evaluations, we also tried show- ing the actual source (image or document) to the annotators. However, we realized that this did not allow us to do an unbiased evaluation of the qual- ity of the questions. The annotators inferred miss- ing information from the document or image and marked the question as answerable (even though the relevant entity cat is missing in the question). For example, consider the image of a cat drinking milk and the question "What is the drinking ?" If a human is shown the image then she can easily in- fer that the missing information is "cat" and hence mark the question as answerable. This clearly bi- ases the study, and therefore we did not show the source to the evaluators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rating Description</head><p>Examples 1</p><p>All important information is missing and it is impossible to an- swer the question "What is against the sign ?", "Why is using O2 instead of CO2 less efficient?" 2</p><p>Most of the important information is missing and I can't infer the answer to the question "Which films did Lee H. Katzin direct ?", "Low doses of anti-inflammatories are sometimes used with what classes of drugs?" 3 Some important information is missing leading to multiple an- swers "What Harvard Alumni was the Palestine Prime Minister?", "What country is the teaching subject discussing?" 4</p><p>Most of the important information is present and I can infer the answer "How far from the Yard is the Quad located?","what films did Melvin Van Peebles star in?" 5</p><p>All important information is present and I can answer the question "What globally popular half marathon began in 1981?", "What kind of vehicle is parked the sidewalk?"  A total of 25 in-house annotators participated in our study, and we got each question evaluated by two annotators. The annotators were Computer Science graduates competent in English. We did an initial pilot using the instructions mentioned in <ref type="table" target="#tab_0">Table 2</ref>, but due to the subjective nature of the task, it was difficult for the annotators to agree on the notion of important information. In particular, we found that the annotators disagreed between most important information and all important informa- tion (i.e., they were confused between rating 1 v/s 2 and 4 v/s 5). We, therefore, did a small pilot with a group of 10 annotators and asked them to evalu- ate around 30 questions from each dataset and help us refine the guidelines to define the notion of im- portance clearly. Based on group discussions with the annotators we arrived at additional example based guidelines to help them distinguish between cases where "all the", "most of the" and "some of the" important information is present. The orig- inal instructions and various examples (some of which are shown in <ref type="table" target="#tab_0">Table 2</ref>) were then shared and explained to all the annotators, and they used these to provide their judgments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Human-Human Correlation</head><p>In <ref type="table" target="#tab_1">Table 3</ref>, we report the average inter-annotator agreement between the ratings using Cohen's kappa (κ) score <ref type="bibr" target="#b6">(Cohen, 1968)</ref>. Based on guide- lines in <ref type="bibr" target="#b23">(McHugh, 2012)</ref>   strong inter-annotator agreement for WikiMovies and moderate agreement for SQuAD and VQA. <ref type="figure" target="#fig_0">Figure 1</ref> indicates that there is a linear correla- tion between the two ratings for each question and hence we measured the correlation using Pearson coefficient. For completeness, we also measure the monotonic correlation using Spearman coef- ficient. The Spearman coefficient is slightly lower than the Pearson coefficient because the inter- annotator agreement is stronger at the tail of the distribution i.e., when the question is either very bad (Rating: 1) or very good (Rating: 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Correlation between human scores and existing evaluation metrics</head><p>We first compute BLEU, METEOR, NIST and ROUGE-L score for each noisy question by com- paring it to the original question. We then com- pute the correlation of each of these scores with annotator ratings. Note that to compute corre- lation, the annotator ratings are combined to ob- tain a gold score. The ratings are normalized us- ing the normalization method mentioned in ( <ref type="bibr" target="#b2">Blatz et al., 2004</ref>) and then averaged to obtain the gold score. For SQuAD and VQA, we observe that NIST which gives more weightage to informative n-grams correlates better than other metrics. For WikiMovies, METEOR which even allows non- exact word matches correlates better than other metrics. For SQuAD and WikiMovies, the cor- relation of human scores with the simple uni- gram based BLEU1 score is higher than that with other metrics. This is in line with the observation we made earlier that humans can understand and answer questions that are not well-formed, e.g., "What birth-date Damon?".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Modifying existing metrics for AQG</head><p>The above study suggests that existing metrics do not correlate well with human judgments about answerability. We propose modifications to these metrics so that in addition to n-gram similarity they also account for answerability. Based on the human evaluations, we found that answerability mainly depends on the presence of 4 types of ele- ments, viz., relevant content words, named entities and question types and function words. As out- lined in Section 4.1 it is easy to identify these ele- ments in the question. Let c(S r ), c(S n ), c(S q ) and c(S f ) be the number of relevant words, named entities, question words and function words re- spectively in the noisy question which have cor- responding matching words in the gold standard reference question. We can then compute the weighted average of the precision and recall of each of these elements as</p><formula xml:id="formula_0">P avg = i w i c(S i ) |l i | R avg = i w i c(S i ) |r i |</formula><p>where i ∈ {r, n, q, f }, i w i = 1 and |l i | , |r i | is the number of the words belonging to i th type of element in the noisy question and reference sen- tences respectively. Just to be clear r, n, q, f stand for relevant content words, named entities and question types and function words respectively. Note that w i 's are tunable weights and in Section 5.1, we explain how to tune these weights.  We can combine this answerability score with any existing metric (say, BLEU4) to derive a mod- ified metric for AQG as shown below:</p><formula xml:id="formula_1">Q-BLEU4 = δAnswerability + (1 − δ)BLEU4</formula><p>(1) such that δ ∈ {0, 1} to make sure that Q-Metric ranges between 0 to 1. Similarly, we can derive Q-NIST, Q-METEOR and so on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Tuning the weights w i 's and δ</head><p>We tuned the weights (w i 's and δ) using the hu- man annotation data. For each source (document, knowledge-base, and images), annotators evalu- ated 1000 noisy questions. The annotator scores were first scaled between 0 to 1 using the normal- ization method in ( <ref type="bibr" target="#b2">Blatz et al., 2004</ref>), and the nor- malized scores were averaged to obtain the final gold score. For each source, we used 300 of these annotations and used bagging to find the optimal weights. In particular, we drew 200 samples ran- domly from the given set of 300 samples and did a grid search to find w i 's and δ such that the Q- METRIC computed using Equation 1 had maxi- mum correlation with human scores. We repeated this process for k = 20 times and computed the optimal w i 's and δ each time. We found that for <ref type="table">Table 6</ref>: Correlation between proposed Q-Metric and human judgments. All the correlations have a p-value &lt; 0.01 and hence statistically significant.</p><formula xml:id="formula_2">Q-Metric SQuAD WikiMovies VQA Pearson Spearman Pearson Spearman Pearson Spearman Q-BLEU1 0.258 0.255 0.828 0.841 0.405 0.384 Q-BLEU2 0.244 0.243 0.825 0.835 0.390 0.360 Q-BLEU3 0.239 0.240 0.824 0.837 0.374 0.331 Q-BLEU4 0.233 0.232 0.826 0.837 0.373 0.311 Q-ROUGE-L</formula><note type="other">0.253 0.249 0.821 0.841 0.402 0.385 Q-METEOR 0.158 0.157 0.821 0.837 0.402 0.378 Q-NIST 0.246 0.248 0.824 0.845 0.384 0.346</note><p>any given weight (w i ) the standard deviation was very low across these k experiments. For each w i and δ we obtained the final value by taking an av- erage of the values learned in each of the k exper- iments. We also observed that the weights did not change much even when we used more data for tuning. Also note that we tuned these weights sep- arately for each metric (i.e., Q-BLEU4, Q-NIST, Q-METEOR and so on). For illustration, we re- port these weights for Q-BLEU1 metric in <ref type="table" target="#tab_4">Table  5</ref>. As expected, the weights depend on the source from which the question was generated. Note that for WikiMovies, named entities have the highest weight. For VQA content words are most impor- tant, as they provide information about the entity being referred to in the question. Note that for SQuAD and VQA, the original base metric also gets weightage comparable to other components, indicating that a fluent question makes it easier to understand thus making it answerable. The over- all trend for the values of w i 's was similar for other Q-METRICs also (i.e., for Q-NIST, Q-METEOR and so on).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Correlation between Human scores and different Q-METRICs</head><p>Once the weights are tuned, we fix these weights and compute the Q-METRIC for the remaining 600-700 examples and report the correlation with human judgments for the same set of examples (see <ref type="table">Table 6</ref>). For a fair comparison, the corre- lation scores reported in <ref type="table" target="#tab_3">Table 4</ref> are also on the same 600-700 examples. The correlation scores obtained for different Q-METRICs are indeed en- couraging. In particular, we observe that while the correlation of existing metrics with noisy ques- tions generated was very low <ref type="table" target="#tab_3">(Table 4)</ref>, the cor- relation of the modified metrics is much higher.</p><p>This suggests that adding the learnable component for answerability and tuning its weights indeed leads to a better-correlated metric. Note that for VQA and SQuAD the correlations are not as high as human-human correlations, but the correlations are still statistically significant. We acknowledge that there is clearly scope for further improvement and the proposed metric is perhaps only a first step towards designing an appropriate metric for AQG. Hopefully, the human evaluation data released as a part of this work will help to design even better metrics for AQG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Qualitative Analysis</head><p>We have listed some examples in <ref type="table" target="#tab_6">Table 7</ref>, which highlight some strengths and weakness of the pro- posed Q-METRIC. We categorize examples as positive/negative depending on the similarity be- tween human scores for answerability and the Q- BLEU score. For the examples marked as positive, the Q-BLEU score is very close to the answerabil- ity score given by humans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Extrinsic evaluation</head><p>So far we have shown that existing metrics do not always correlate well with human judgments and it is possible to design metrics which correlate bet- ter with human judgments by including a learnable component to focus on answerability. We would now like to propose an extrinsic way of evaluating the usefulness of the proposed metric. The mo- tivation for this extrinsic evaluation comes from the fact that one of the intended purposes of the modified metrics is to use them for training QA systems. Suppose we use a particular metric for evaluating the quality of an AQG system and sup- pose this metric suggests that the questions gener- ated by this system are poor. We would obviously     <ref type="table">Table 10</ref>: Performance obtained by training on dif- ferent types of noisy questions (VQA).</p><p>discard this system and not use the questions gen- erated by it to train a QA system. However, if the metric itself is questionable, then it is possible that the questions were good enough, but the metric was not good to evaluate their quality. To study this effect, we create a noisy version of the train- ing data of SQuAD, WikiMovies, and VQA using the same methods outlined in Section 4.1. We then train a state of the art model for each of these tasks on this noisy data and evaluate the trained model on the original test set of each of these datasets. The models that we considered were ( <ref type="bibr" target="#b33">Seo et al., 2016</ref>) for SQuAD, <ref type="bibr" target="#b24">(Miller et al., 2016</ref>) for Wiki- Movies and <ref type="bibr" target="#b1">(Ben-younes et al., 2017</ref>) for VQA.</p><p>The results of our experiments are summarized in <ref type="table" target="#tab_7">Table 8</ref> -10. The first column for each ta- ble shows the manner in which the noisy training data was created. The second column shows the BLEU4 score of the noisy questions when com- pared to the original reference questions (thus it tells us the perceived quality of these questions under the BLEU4 metric). We consider BLEU4 because of all the current metrics used for AQG it is the most popular. Similarly, the third column tells us the perceived quality of these questions under the Q-BLEU4 metric. Ideally, we would want that the performance of the model should correlate better with the perceived quality of the training questions as identified by a given met- ric. We observe that the general trend is better w.r.t. the Q-BLEU4 metric than the BLEU4 metric (i.e., in general, higher Q-BLEU4 indicates better performance and lower Q-BLEU4 indicates poor performance). In particular, notice that BLEU4 gives much importance to stop words, but these words hardly have any influence on the final per- formance. We believe that such an extrinsic eval- uation should also be used while designing better metrics and it would help us get better insights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>The main aim of this work was to objectively examine the utility of existing metrics for AQG. Specifically, we wanted to see if existing met- rics account for the answerability of the gener- ated questions. To do so, we took noisy generated questions from three different tasks, viz., docu- ment QA, knowledge base QA and visual QA, and showed that the answerability scores assigned by humans did not correlate well with existing met- rics. Based on these studies, we proposed a modi- fication for existing metrics and showed that with the proposed modification these metrics correlate better with human judgments. The proposed mod- ification involves learnable weights which can be tuned (depending on the source) using the human judgments released as a part of this work. Finally, we propose an extrinsic evaluation with the aim of assessing the end utility of these metrics in select- ing good AQG systems for creating training data for QA systems. Though the proposed metric cor- relates better with human judgments, there is still scope for improvement especially for document QA and visual QA. As future work, we would like to design better metrics for answerability and check if a non-linear combination of different el- ements in the Q-Metric leads to better correlation with human judgments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Human-Human Correlation for SQUAD, WikiMovies and VQA respectively.</figDesc><graphic url="image-1.png" coords="6,72.00,62.81,151.18,113.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Instructions along with the examples. The striked out words were removed as a part of systematic 
noise from the original question. 

Dataset 
κ 
Pearson Spearman 
SQuAD 
0.63 
0.823 
0.795 
WikiMovies 0.81 
0.934 
0.927 
VQA 
0.70 
0.842 
0.822 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Inter annotator agreement, Pearson and 
Spearman coefficients between Human Scores. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>we note that we have a</figDesc><table>Metric 
SQuAD 
WikiMovies 
VQA 
Pearson Spearman Pearson Spearman Pearson Spearman 
BLEU1 
0.167 
0.165 
0.179 
0.144 -0.025* 
-0.048* 
BLEU2 
0.100* 
0.103* 
0.072* 
0.087* -0.075* 
-0.091* 
BLEU3 
0.080* 
0.086* 
0.036* 
0.001* 
-0.126 
-0.114 
BLEU4 
0.065* 
0.067* -0.020* 
-0.011* -0.086* 
-0.127 
ROUGE-L 
0.165 
0.158 
0.091* 
0.043* -0.009* 
-0.053* 
METEOR 
0.107 
0.124 
0.198 
0.214 -0.035* 
0.009* 
NIST 
0.173 
0.158 
0.088* 
-0.033* 
0.158 
0.169 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Correlation between existing metrics and 
human judgments. Note that the values with  *  are 
not statistically significant (p-value &gt; 0.01). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Coefficients learnt for Q-BLEU1 from hu-
man judgments across different datasets. 

Answerability = 2. 
P avg R avg 
P avg + R avg 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>to schools, where else is popularly based authority effective? In addition schools, where else popularly based authority effective? 0.85 0.83</head><label></label><figDesc></figDesc><table>Dataset 
Original Question 
Modified Question 
Human 
Scores 
QBLEU 

SQuAD 

Positive 
What is another type of accountant other than a CPA? 
What is another type of accountant other than a ? 
0.10 
0.47 
In addition Negative 
When did Tesla begin working for the Continental Edison Company? 
When did begin working for the Continental Edison Company? 
0.10 
0.84 
What famous person congratulated him? 
What person congratulated him? 
0.85 
0.17 

VQA 

Positive 
What color is the monster truck? 
What color monster truck? 
0.92 
0.81 
What is in the polythene ? 
What is in the ? 
0.10 
0.14 

Negative 
Why there are no leaves on the tree? 
Why are leaves the tree? 
0.35 
0.73 
How are the carrots prepared in the plate? 
How carrots prepared plate? 
0.10 
0.68 

WikiMovies 

Positive 
what films does Ralf Harolde appear in ? 
what films Ralf Harolde appear ? 
0.97 
0.91 
what is a film directed by Eddie Murphy ? 
Which a film directed by Eddie Murphy ? 
0.91 
0.88 

Negative 
what films does Gerard Butler appear in ? 
how does Gerard Butler appear in ? 
0.15 
0.89 
John Conor Brooke appears in which movies ? 
appears in which movies ? 
0.03 
0.44 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Human (Gold) and Q-Metric scores for some of the examples from the collected human-
evaluation data. 

Type of Noise 
BLEU QBLEU Hit 1 
None 
100 
100 
76.5 
Stop Words 
25.4 
84.0 
75.6 
Question Type 
74.0 
79.3 
73.5 
Content Words 
29.4 
64.3 
54.7 
Named Entity 
41.9 
48.5 
17.97 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>Performance obtained by training on differ-
ent types of noisy questions (WikiMovies). 

Noise 
BLEU QBLEU F1 
None 
100 
100 
76.5 
Question Type 
80.1 
66.1 
69.0 
Stop Words 
24.2 
61.0 
70.4 
Content Words 
60.7 
57.1 
64.1 
Named Entity 
77.0 
56.0 
73.8 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 9 :</head><label>9</label><figDesc></figDesc><table>Performance obtained by training on differ-
ent types of noisy questions (SQuAD). 

Noise 
BLEU QBLEU Acc(%) 
None 
100 
100 
64.4 
Content Words 
49.4 
58.2 
60.21 
Question Type 
63.7 
50.9 
59.81 
Stop Words 
10.8 
37.7 
57.37 

</table></figure>

			<note place="foot" n="1"> https://github.com/PrekshaNema25/ Answerability-Metric</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Acknowledgements</head><p>We would like to thank Google for supporting Preksha Nema through their Google India Ph.D. Fellowship Program. We would also like to ex-press our gratitude to the volunteers who partici-pated in human evaluations.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">VQA: Visual Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislaw</forename><surname>Antol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Mutan: Multimodal tucker fusion for visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hedi</forename><surname>Ben-Younes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rémi</forename><surname>Cadene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Thome</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Confidence estimation for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blatz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simona</forename><surname>Gandrabur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyril</forename><surname>Goutte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Sanchis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Ueffing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on Computational Linguistics. Association for Computational Linguistics</title>
		<meeting>the 20th international conference on Computational Linguistics. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">315</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Large-scale simple question answering with memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno>CoRR abs/1506.02075</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fast, cheap, and creative: Evaluating translation quality using amazon&apos;s mechanical turk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Stroudsburg, PA, USA, EMNLP &apos;09</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="286" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Re-evaluation the role of bleu in machine translation research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miles</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL. The Association for Computer Linguistics</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Weighted kappa: nominal scale agreement with provision for scaled disagreement or partial credit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">213220</biblScope>
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automatic evaluation of machine translation quality using n-gram cooccurrence statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Doddington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Conference on Human Language Technology Research. HLT &apos;02</title>
		<meeting>the Second International Conference on Human Language Technology Research. HLT &apos;02</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="138" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Identifying where to focus in reading comprehension for neural question generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinya</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP. Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2067" to="2073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning to ask: Neural question generation for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinya</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junru</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1). Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1342" to="1352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Question generation for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP. Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="866" to="874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Good question! statistical ranking for question generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL. The Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="609" to="617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Creativity: Generating diverse questions using variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Unnat</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Schwing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR. IEEE Computer Society</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5415" to="5424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1988" to="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1601" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep questions without deep understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Labutov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1). The Association for Computer Linguistics</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="889" to="898" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The meteor metric for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Denkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Translation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="105" to="115" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Visual question generation as dual task of visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yikang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<idno>CoRR abs/1709.07192</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Rouge: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL workshop on Text Summarization Branches Out</title>
		<meeting>ACL workshop on Text Summarization Branches Out</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Generating natural language questions to support learning on-line</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lindberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><surname>Popowich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">C</forename><surname>Nesbit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">H</forename><surname>Winne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ENLG. The Association for Computer Linguistics</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="105" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP. The Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Nltk: The natural language toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<idno>ETMTNLP &apos;02</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics</title>
		<meeting>the ACL-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="63" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Towards an automatic turing test: Learning to evaluate dialogue responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Angelard-Gontier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1). Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1116" to="1126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Interrater reliability: the kappa statistic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mchugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biochemia medica: Biochemia medica</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="276" to="282" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Key-value memory networks for directly reading documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">H</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP. The Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1400" to="1409" />
		</imprint>
	</monogr>
	<note>AmirHossein Karimi, Antoine Bordes, and Jason Weston</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Generating instruction automatically for the reading strategy of selfquestioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Mostow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AIED. IOS Press</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">200</biblScope>
			<biblScope unit="page" from="465" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">MS MARCO: A human generated machine reading comprehension dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Cognitive Computation: Integrating neural and symbolic approaches 2016 co-located with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016)</title>
		<meeting>the Workshop on Cognitive Computation: Integrating neural and symbolic approaches 2016 co-located with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016)<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-12-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL. ACL</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Some issues in automatic evaluation of english-hindi mt: More blues for bleu</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ananthakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ritesh M</forename><surname>Sasikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Natural Language Processing</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Squad: 100, 000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-01" />
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Generating natural language question-answer pairs from a knowledge graph using a RNN based question generation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sathish</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinesh</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachindra</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Josh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL (1). Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="376" to="385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Duorc: Towards complex language understanding with paraphrased reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amrita</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Aralikatte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sankaranarayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1683" to="1693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Complex sequential question answering: Towards learning to converse over linked question answer pairs with a knowledge graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amrita</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vardaan</forename><surname>Pahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarath</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chandar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min Joon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno>CoRR abs/1611.01603</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Iulian Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>García-Durán</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gülçehre</surname></persName>
		</author>
		<imprint>
			<pubPlace>Sungjin Ahn, Sarath Chandar, Aaron C</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Generating factoid questions with recurrent neural networks: The 30m factoid question-answer corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>The Association for Computer Linguistics</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Question answering and question generation as dual tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<idno>CoRR abs/1706.02027</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">A joint model for question answering and question generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingdi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<idno>CoRR abs/1706.01450</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Semi-supervised QA with generative domain-adaptive nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<idno>CoRR abs/1702.02206</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Machine comprehension by text-to-text neural question generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingdi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gülçehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Rep4NLP@ACL. Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="15" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Asking the difficult questions: Goal-oriented visual question generation via intermediate rewards</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Van Den Hengel</surname></persName>
		</author>
		<idno>CoRR abs/1711.07614</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
