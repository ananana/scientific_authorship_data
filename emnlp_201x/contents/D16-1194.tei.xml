<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:56+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Non-uniform Language Detection in Technical Writing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weibo</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Dalhousie University</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abidalrahman</forename><surname>Moh&amp;apos;d</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Dalhousie University</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aminul</forename><surname>Islam</surname></persName>
							<email>aminul@louisiana.edu</email>
							<affiliation key="aff1">
								<orgName type="department">School of Computing and Informatics</orgName>
								<orgName type="institution">University of Louisiana at Lafayette</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Axel</forename><forename type="middle">J</forename><surname>Soto</surname></persName>
							<email>axel.soto@manchester.ac.uk</email>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Manchester</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evangelos</forename><forename type="middle">E</forename><surname>Milios</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">Dalhousie University</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Non-uniform Language Detection in Technical Writing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1892" to="1900"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Technical writing in professional environments , such as user manual authoring, requires the use of uniform language. Non-uniform language detection is a novel task, which aims to guarantee the consistency for technical writing by detecting sentences in a document that are intended to have the same meaning within a similar context but use different words or writing style. This paper proposes an approach that utilizes text similarity algorithms at lexical, syntactic, semantic and pragmatic levels. Different features are extracted and integrated by applying a machine learning classification method. We tested our method using smart phone user manuals, and compared its performance against the state-of-the-art methods in a related area. The experiments demonstrate that our approach achieves the upper bound performance for this task.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Technical writing, such as creating device operation manuals and user guide handbooks, is a special writ- ing task that requires accurate text to describe a cer- tain product or operation. To avoid ambiguity and bring accurate and straightforward understanding to readers, technical writing requires consistency in the use of terminology and uniform language <ref type="bibr" target="#b6">(Farkas, 1985)</ref>. There are always demands from modern in- dustries to improve the quality of technical docu- ments in cost-efficient ways.</p><p>Non-uniform Language Detection (NLD) aims to avoid inner-inconsistency and ambiguity of techni- cal content by identifying non-uniform sentences.</p><p>Such sentences are intended to have the same mean- ing or usage within a similar context but use differ- ent words or writing style. However, even though non-uniform sentences tend to have similar word- ing, similar sentence pairs do not necessarily indi- cate a non-uniform language instance. For example, here are four similar sentence pairs cited from the iPhone user manual <ref type="bibr" target="#b0">(Apple Inc., 2015)</ref>, where only two pairs are true non-uniform language instances:</p><p>(1) tap the screen to show the controls.</p><p>tap the screen to display the controls.</p><p>(2) tap the screen to show the controls. tap the screen to display the controls.</p><p>(3) if the photo hasn't been downloaded yet, tap the download notice first. if the video hasn't been downloaded yet, tap the download notice first.</p><p>(4) you can also turn blue tooth on or off in con- trol center. you can also turn wi-fi and blue tooth on or off in control center.</p><p>As we can see above, the pattern of difference within each sentence pair could be between one word and one word, or one word and multiple words, or one sentence having extra words or phrases that the other sentence does not have. Each pattern could be a true or false non-uniform language instance depending on the content and context. The word 'show' and 'display' are synonyms in Example (1). Both sentences convey the same meaning, so they are an instance of non-uniform language. In Exam- ple (2), even though 'enter' and 'write' are not syn- onyms, since the two sentences describe the same operation, they should be considered as non-uniform language as well. In Example (3), even though the only different words between the sentences, 'photo' and 'video', are both media contents, because they are different objects, they should not be regarded as non-uniform language. In Example (4), it is a false candidate because each sentence mentions dif- ferent functions. However, the two sentences are un- equal in length, thus it is hard to know what the ex- tra phrase 'wi-fi and' should be compared against. Therefore, it is challenging to distinguish true and false occurrences of non-uniform cases based on text similarity algorithms only, and finer grained analy- ses need to be applied. To address the problem of NLD, this paper proposes a methodology for detect- ing non-uniform language within a technical docu- ment at the sentence level. A schematic diagram of our approach is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. It is worth to mention that NLD is similar to Pla- giarism Detection and Paraphrase Detection (PD) as all these tasks aim to capture similar sentences with the same meaning ( <ref type="bibr" target="#b5">Das and Smith, 2009)</ref>. However, the goal of authors in plagiarism and paraphrasing is to change as many words as possible to increase the differences between texts, whereas in technical writing, the authors try to avoid such differences, but they do not always succeed and thus NLD solutions are needed. Cases of plagiarism and paraphrasing with high lexical differences will be typically clas- sified as NLD negative, and cases with low lexical differences will be typically classified as NLD pos- itive. While true positive cases for both NLD and PD can exist, there are not likely to happen in prac- tice since textual differences in PD tend to be much higher than in NLD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Start Text Content</head><p>To address the NLD task, Natural Language Pro- cessing (NLP) techniques at lexical, syntactic, se- mantic, and pragmatic levels are utilized. Our ap- proach also integrates resources such as Part-of- Speech (POS) tagger <ref type="bibr" target="#b1">(Bird et al., 2009)</ref>, Word- Net ( <ref type="bibr" target="#b16">Miller et al., 1990</ref>), Google Tri-gram Method (GTM) <ref type="bibr" target="#b10">(Islam et al., 2012;</ref><ref type="bibr">Mei et al., 2015)</ref>, and Flickr 1 . Analyses from different perspectives are applied, and the results are regarded as independent features that are finally integrated by applying a clas- sification method based on Support Vector Machine (SVM). A ground truth dataset created from three smart phone user manuals is used for evaluation, and it is made publicly available 2 . The experiments on this dataset demonstrate that the proposed solution to the NLD task is the most efficient method to date, and the final result is close to the upper bound per- formance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>NLD is closely related to PD, which aims to de- tect sentences that have essentially the same mean- ing. However, paraphrase is a restatement using different words to make it appear different from the original text. PD techniques cannot perform well on the NLD task as they focus on variations at a coarser granularity. We reviewed studies in the PD area, and found the Recursive Auto-Encoder (RAE) <ref type="bibr" target="#b17">(Socher et al., 2011)</ref>, and the Semantic Text Similarity (STS) <ref type="bibr" target="#b9">(Islam and Inkpen, 2008)</ref> to be the state-of-the-art methods using supervised and unsupervised-based PD, respectively. However, all the four examples provided in the introduction sec- tion would be recognized as paraphrases by these analyzers, even though only two of the pairs are real non-uniform language cases. Thus, state-of-the-art PD techniques are unable to make accurate judg- ments on these instances since PD do not address the necessary level of detail for the NLD task.</p><p>Another related area to NLD is near-duplicate text detection. It focuses on short text such as mobile phone short messages, or tweets, which are intended to have the same meaning but differ in terms of in-formal abbreviations, transliterations, and network languages ( <ref type="bibr" target="#b8">Gong et al., 2008)</ref>. The detection and elimination of near-duplicate text is of great im- portance for other text language processing such as clustering, opinion mining, and topic detection ( <ref type="bibr" target="#b18">Sun et al., 2013)</ref>. However, the studies in this area focus on reducing the comparison time in large scale text databases and creating informal abbreviation corpus, rather than exploring the text similarity methods. Basic similarity methods, such as Longest Common Substring (LCS) are utilized, but they are not suffi- cient to address the NLD task as LCS captures the matching words and their order between texts and using LCS alone will give high recall and low preci- sion for the NLD task. For the following NLD neg- ative example, LCS returns a high similarity score:</p><p>(5) If the photo hasn't been downloaded yet, tap the download notice first. If the music hasn't been downloaded yet, tap the download notice first.</p><p>Examples of this type are common in technical writ- ing, so other features are needed besides LCS to rec- ognize NLD positives. There is a research domain named near-duplicate document detection, which seems literally related to NLD, but also represents a different task. It focuses on documents that are identical in terms of written content but differ in a small portion of the docu- ment such as advertisements, counters and times- tamps ( <ref type="bibr" target="#b14">Manku et al., 2007)</ref>. Such documents are important to be identified for web crawling and the automatic collection of digital libraries. Since this area focuses on the variations between two docu- ments, especially the variations on metadata, rather than the written content within one document, their proposed solutions are not a good fit for the NLD tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Non-uniform Language Detection</head><p>As we have shown in <ref type="figure" target="#fig_0">Figure 1</ref>, a framework consist- ing of three stages is proposed to address the NLD task. The first stage extracts candidate sentence pairs that have high text similarity within a docu- ment. The second stage performs comprehensive analyses on each candidate sentence pair. The anal- yses are performed at lexical, syntactical, semantic, and pragmatic levels, where multiple NLP resources such as POS tagger, WordNet, GTM, and Flickr are utilized. The final stage integrates all the analysis results by applying a classification method based on SVM to classify the candidate sentence pairs as true or false cases of non-uniform language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Stage 1: Similar Sentences Detection</head><p>To extract the candidate sentence pairs, three text similarity algorithms are combined and applied at the sentence level. GTM is an unsupervised corpus- based approach for measuring semantic relatedness between texts. LCS focuses on the word order of sentences. Cosine Similarity provides bag-of-word similarity. GTM, LCS, and Cosine Similarity are used to filter out the pairs based on semantics, sen- tence structure, and word frequency, respectively.</p><p>The filtering thresholds were set by running ex- periments at the sentence level on the iPhone user manual (Apple Inc., 2015). Algorithm 1 is used to set the filtering threshold for each average sentence length <ref type="bibr">3</ref> .</p><p>We utilize a sentence detector and a tokenizer 4 to divide the text of the manual into a sentence set of n sentence pairs (Line 2). We separately run Algo- rithm 1 three times to set the threshold sets for GTM, LCS, and Cosine. The thresholds are set based on the lengths of both sentences of a sentence pair. The average length starts from 2 and is increased by one once the threshold for the current length is set. We discovered that once the sentence length goes above 10, the thresholds vary little. Therefore, we stop the algorithm when the threshold for pairs of average length equal to 10 is found (Line 6).</p><p>For each different average length, the algorithm starts by asking the user to input an initial similar- ity threshold and an increasing step value (Line 4- 5). An initial threshold range is generated based on the user setting. The lower bound of the range is T and the upper bound of the range is T+Step (Line 9-10). Then the algorithm would loop over all the sentence pairs ( <ref type="bibr">Line 11-20)</ref> and add the pairs within the current threshold range into set C (Line 14-16).  The similarity of sentence pairs above the previous threshold and below the current threshold are cap- tured and analyzed (Line 15-16). If they consist of all false non-uniform language candidates, we repeat the loop with a higher threshold to filter more false candidates. Once we discover that a true candidate is filtered by the current thresholds, we stop increasing and set the prior value as the threshold to maximize the recall ratio. The whole experiment is repeated for different sentence pair lengths. The final thresh- olds for different similarity methods are shown in <ref type="figure" target="#fig_1">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input : User Manual</head><formula xml:id="formula_0">Output: Threshold-Length_List [(T 1 , L 1 ), ...] 1 begin 2 S[n] ←− SentenceDetector(User Manual) 3 L ←− 2 /*Initial</formula><formula xml:id="formula_1">←− (S[i] + S[j])/2 14 if AvgL ∈ [L − 1, L) then 15 if (T low ≤ Sim(S[i], S[j])) and (Sim(S[i], S[j]) ≤ T up ) then 16 C add ←− (S[i], S[j]</formula><p>To filter the sentence pairs, we applied the thresh- olds of the three text similarity algorithms. For ex- ample, assume there are two sentences of nine-word length on average. The similarity scores of this pair have to be above all the GTM, LCS and Cosine thresholds (which are 0.943, 0.836, and 0.932, ac- cording to <ref type="figure" target="#fig_1">Figure 2</ref>) to make it a candidate instance.</p><p>By applying the thresholds shown in <ref type="figure" target="#fig_1">Figure 2</ref>, candidate pairs could be detected in reasonable scale in terms of the size of the corpus, and achieve good recall ratio as well. As for precision, around 40% of the candidates are true non-uniform language cases, where the remaining candidates are supposed to be filtered in the second stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Stage 2: Sentence Pair Analysis</head><p>In this stage, we aim to determine for the two sen- tences of a candidate pair whether they describe the same object or operation using different words or writing style (i.e., true non-uniform language) or they just appear similar but actually have different intended meanings, by using the following features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Part-of-Speech Tagging Analysis</head><p>POS tags are added for each candidate pair using NLTK ( <ref type="bibr" target="#b1">Bird et al., 2009</ref>) tagger to gain a grammati- cal view over the sentences.</p><p>As <ref type="table" target="#tab_3">Table 1</ref> shows, some differences in sentence content can be captured using POS tags, but some cannot. Thus, it is necessary to make further syntac- tic and semantic analysis to distinguish true candi- dates from false ones.</p><p>We categorized the different POS tags into the fol- lowing groups shown in <ref type="table" target="#tab_4">Table 2</ref>. The different POS tags are mapped to different categories, which are then used as one more feature of the sentence pair representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Character N-gram Analysis</head><p>In the character N-gram analysis, the relatedness between the different words of each candidate pair is calculated in terms of character unigram, bigram   and trigram similarity. The character N-gram fre- quencies with a window size from 1 to 3 is firstly calculated. Then, the N-gram distance based on the frequencies is calculated using the Common N-gram distance (CNG) ( <ref type="bibr" target="#b11">Kešelj and Cercone, 2004</ref>):</p><formula xml:id="formula_2">d( f 1 , f 2 ) = ∑ n∈dom( f 1 )∪dom( f 2 ) ( f 1 (n) − f 2 (n) f 1 (n)+ f 2 (n) 2 ) 2 (1)</formula><p>where dom( f i ) is the domain of function f i . In the equation above, n represents a certain N-gram unit. f i (n) represents the frequency of n in sen- tence i (i=1,2). If n does not appear in sentence i, f i (n)=0. The lower bound of the N-gram distance is 0 (when the two units to be compared are exactly the same). The higher the value of N-gram distance, the larger the difference, thus there is no upper bound. CNG was demonstrated to be a robust measure of dissimilarity for character N-grams in different do- mains (Wołkowicz and Kešelj, 2013).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">WordNet Lexical Relation Analysis</head><p>For a given candidate sentence pair, if the differ- ent wordingF are synonymous to each other, there is a high likelihood that the two sentences try to convey the same meaning but using different expressions. On the other hand, if the different parts of a candi- date pair are not related at the lexical level, then it is reasonable to assume that this pair is describing different objects/actions and thus they might not be instances of non-uniform language.</p><p>WordNet is utilized here to analyze the lexical re- lationship within each candidate pair to determine whether they are synonyms to each other. To per- form this analysis, we only used synset informa- tion from WordNet, and we only considered words as synonyms if they belong to a same synset. The rationale is that a similar sentence pair tends to be an instance of non-uniform language if the differ- ent words are synonyms, rather than having other relationships such as hypernymy, hyponymy, and antonymy. Therefore, we do not deem necessary to include these relationships into our analysis. For ex- ample, given a similar sentence pair: (6) if the photo hasn't been downloaded yet, tap the download notice first. if the video hasn't been downloaded yet, tap the download notice first.</p><p>The sentence pair above is not a non-uniform lan- guage instance. However, the relatedness score be- tween 'photo' and 'video' given by Wu-Palmer met- ric ( <ref type="bibr" target="#b21">Wu and Palmer, 1994)</ref> using WordNet is 0.6, which is fairly high compared to a random word pair. Yet we do not know how these words are re- lated, e.g., "photo is a kind of video", "photo is a part of video", or "photo and video are examples of media content". Thus, we might make wrong judg- ments based on such a similarity score. However, using synset information, we know that these words are not synonyms and thus probably not suggesting a non-uniform language instance. Therefore, we con- sidered as one more feature of our classifier whether mismatching words belong to the same synset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">GTM Word Relatedness Analysis</head><p>Besides text similarity, GTM also measures se- mantic relatedness between words. To find the re- latedness between a pair of words, GTM takes into account all the trigrams that start and end with the given pair of words and then normalizes their mean frequency using unigram frequency of each of the words as well as the most frequent unigram in the Google Web 1T N-gram corpus <ref type="bibr" target="#b2">(Brants and Franz, 2006</ref>), and extends the word relatedness method to measure document relatedness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.5">Flickr Related Concept Analysis</head><p>In some cases, word to word relatedness exists that goes beyond dictionary definitions, such as metonymy, in which a thing or concept is called not by its own name but rather by the name of some- thing associated in meaning with that thing or con- cept ( <ref type="bibr" target="#b12">Kövecses and Radden, 1998)</ref>. Metonymy de- tection is actually a task at the pragmatic level of NLP area, which can be appied for NLD in techni- cal writing.</p><p>Flickr is a popular photo sharing website that sup- ports time and location metadata and user tagging for each photo. Since the tags are added by humans and aim to describe or comment on a certain photo, the tags are somehow related from a human perspec- tive. As a result, Flickr becomes a large online re- source with the potential to find metonymy relation- ships in text.</p><p>Flickr made available statistical information about their dataset that can be used to query related concepts of a certain word or phrase online. We utilized this resource to detect whether the different parts within a candidate sentence pair are related at the pragmatic level. A boolean value that indicates metonymy relationship is obtained and regarded as another feature of our sentence pair representation for our NLD analysis. <ref type="table">Table 3</ref> gives some examples of relatedness that could be discovered in this stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Different Content Is Metonymy aeroplane, A380</head><p>True film, hollywood True apple, iPhone True audio, grayscale False <ref type="table">Table 3</ref>: Example of analysis using Flickr</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Stage 3: SVM Classification</head><p>All the metrics described above are regarded as fea- tures of our candidate sentence pairs. To make a comprehensive judgment based on these dif- ferent signals, a classification method based on SVM ( <ref type="bibr" target="#b19">Vladimir and Vapnik, 1995</ref>) is applied. We implemented the SVM classification using "e1071" package 5 in R. Using our labeled corpus, we trained an SVM model on 61.5% of the data and used the remaining for testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Evaluation</head><p>In this section, we present the dataset, experimental work and results, including results using other base- line methods for comparative purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment Data</head><p>We downloaded smart phone user manuals of iPhone (Apple Inc., 2015), LG (LG, 2009) and Sam- sung <ref type="bibr">(Samsung, 2011)</ref>, which are available online as three raw datasets. Then, we performed Stage 1 three times on the three different datasets, and iden- tified 325 candidate sentence pairs (650 sentences) as part of Stage 1, which is considered as our can- didate dataset. Before applying the sentence anal- ysis and classification stages, each candidate sen- tence pair in the dataset was labeled by three differ- ent annotators as true or false. Then the ground truth for each instance is generated by annotators' voting. The annotators worked separately to label the sen- tence pairs. Cases of disagreement were sent again to the annotators to double-check their judgement. Some statistics from the manuals are shown in <ref type="table" target="#tab_6">Table  4</ref>.  To prepare for the SVM based classification stage, we split the dataset into a training set DS train , and a testing set DS test . Considering that the data distri- bution is nearly balanced in terms of true and false instances, DS train was formed by randomly select- ing 200 instances from the dataset and the remaining 125 instances were used for DS test .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Methods and Results</head><p>The performance of each annotator against the ma- jority voting is evaluated in terms of Precision, Re- call, Accuracy, and F-measure. These results along with the number of true/ false, positive/ negative cases for each annotator are presented in <ref type="table" target="#tab_8">Table 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameters</head><p>Expert  To measure the agreement among annotators, the Fleiss' Kappa test <ref type="bibr" target="#b7">(Fleiss and Cohen, 1973</ref>) is used. Fleiss' Kappa is an extension of <ref type="bibr">Cohen's Kappa (Cohen, 1968)</ref>. Unlike Cohen's Kappa, which only measures the agreement between two annotators, Fleiss' Kappa measures the agreement among three or more annotators. In our case, we have 3 anno- tators (the annotator number n is 3), each annotator labeled 325 candidate pairs (the subject volume N is 325), each candidate pair is labeled either 0 or 1 (the value of category k is 2). The final Fleiss' Kappa Value is 0.545, which indicates a moderate agree- ment level (0.41-0.60) based on the Kappa Interpre- tation Model <ref type="bibr" target="#b7">(Fleiss and Cohen, 1973)</ref>. In other words, the performance of the annotators reveal that the NLD task is not simple, since there are many cases that are ambiguous and hard to make accurate judgments on, even for humans.</p><p>As <ref type="table" target="#tab_8">Table 5</ref> shows, the best performance of an- notators is highlighted and regarded as the upper bound performance (UB) of the NLD task on our dataset. The state-of-the-art unsupervised PD sys- tem named STS <ref type="bibr" target="#b9">(Islam and Inkpen, 2008)</ref>, as well as the state-of-the-art supervised PD system named RAE <ref type="bibr" target="#b17">(Socher et al., 2011)</ref>, are utilized to generate the baselines of the NLD task. STS uses the simi- larity score of 0.5 as the threshold to evaluate their method in the PD task. RAE applies supervised learning to classify a pair as a true or false instance of paraphrasing. These approaches are utilized on our evaluation as baselines for the NLD task.</p><p>After defining the upper bound and baseline performances, we evaluated our proposed method, which we name as Non-uniform Language Detect- ing System (NLDS), by training the SVM classifier on DS train , and then performing classification using the SVM classifier on DS test . The result is shown in <ref type="table" target="#tab_10">Table 6</ref> as the NLDS method. The first row presents the upper bound performance and the following two rows present the baseline performances.</p><p>To assess the importance of each feature utilized in the proposed framework, we performed a feature ablation study <ref type="bibr" target="#b3">(Cohen and Howe, 1988</ref>) on N-gram, POS analysis, lexical analysis (GTM and WordNet), and Flickr, separately on the DS test dataset. The re- sults are listed in <ref type="table" target="#tab_10">Table 6</ref>.</p><p>A series of cross-validation and Student's t-tests are applied after running NLDS, STS, RAE, and UB Method R(%) P (%) A(%) F1 <ref type="formula">(%</ref>  methods on the F-measure metric. The tests reveal that the performance of NLDS is significantly bet- ter than STS and RAE, no significant differences could be found between UB and NLDS. These re- sults demonstrate that NLDS would represent an ef- fective approach for NLD that is on pair with anno- tator judgement and overcomes state-of-the-art ap- proaches for related tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Discussion</head><p>As <ref type="table" target="#tab_10">Table 6</ref> shows, the PD systems STS and RAE re- gard all the test cases as true non-uniform language cases, so the recall ratio is 1 but the precision is low. It is worth noting that by using character N-gram analysis alone, it is not possible to obtain good re- sults. This is because the character N-gram analysis using a probabilistic method is unable to capture any difference or relatedness in the meaning, while the NLD task relies heavily on discovering such relat- edness. The reason we applied the N-gram analysis is to use it as a supplementary method to catch dif- ferences such as between 'shut down' (two words) and 'shutdown' (one word), or some spelling errors.</p><p>POS analysis provides a syntactic perspec- tive for the text instances.</p><p>For instances, 'then(/RB)' versus 'and(/CC)', and 'store(/NN)' versus 'stores(/NNS)', the differences can be re- flected in POS tags. Yet, POS analysis alone could not capture the difference between words such as 'writing(/VBG)' versus 'entering(/VBG)' since they share the same POS tag. These features make POS analysis outperform the character N-gram anal- ysis, but not semantic-based approaches.</p><p>Lexical analysis (GTM and WordNet) achieves the best recall ratio since it can provide semantic re- latedness, which is the most important aspect for the NLD task. Flickr is utilized as a supplementary re- source to provide pragmatic relatedness. By combining the different types of analyses above, the differences of each sentence pair are an- alyzed at different NLP levels and thus, the relat- edness and difference from structural, grammati- cal, syntactic, semantic and pragmatic perspectives can be captured and integrated by the classification method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This paper proposes NLDS to detect non-uniform language for technical writings at sentence level. Text, stream-based, and word similarity algorithms at the lexical, syntactic, semantic, and pragmatic levels are integrated through an SVM-based classi- fication method. To evaluate the proposed method, three annotators manually labeled all the candidate instances identified in Stage 1. Then we assigned the ground truth for each instance pair by annota- tors' voting. Fleiss' Kappa test is applied to reflect the difference of human judgments and thus to re- veal the difficulty of this task.</p><p>We also evaluated each annotator against the ground truth, and defined the best performance of human as the upper bound performance for this task. With the generated ground truth, a series of experi- ments using our implemented system were carried out with different smart phone user manuals data. We evaluated the results by comparing the outcome of the classifier with the results using each single feature, as well as the state-of-the-art PD methods.</p><p>Considering the different annotators' judgments as reflected by Fleiss' Kappa Value, the NLD task is fairly difficult. Yet, the performance of our system is close to human performance. The experiments re- veal that our solution is the most effective method to date and the performance is close to the upper bound that we defined. As for future work, we would apply deeper analysis on true non-uniform language pairs to indicate which sentence of the pair fits better with the style and language of the rest of the document. We would then provide a semi-automatic correction function to facilitate authors with the task of remov- ing non-uniform language occurrences.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Schematic diagram of our approach</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Candidate filtering thresholds</figDesc><graphic url="image-1.png" coords="4,313.20,57.83,234.00,184.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Candidate Sentence Pair with POS Tag</head><label></label><figDesc></figDesc><table>Ground Truth 

Link 
/NNP 
your 
/PRP 
device 
/NN 
to 
/TO 
iTunes 
/NNS 
stores 
/NNS 

True 

Link 
/NNP 
your 
/PRP 
device 
/NN 
to 
/TO 
iTunes 
/NNS 
store 
/NN 

Candidate 

go 
/VB 
to 
/TO 
settings 
/NNS 
&gt; 
/SYS 
general 
/JJ 
&gt; 
/SYS 
accessibility 
/NN 
&gt; 
/SYS 
audio 
/NN 

False 

go 
/VB 
to 
/TO 
settings 
/NNS 
&gt; 
/SYS 
general 
/JJ 
&gt; 
/SYS 
accessibility 
/NN 
&gt; 
/SYS 
video 
/NN 

Candidate 

Hold 
/VB 
the 
/DT 
power 
/NN 
button 
/NN 
for 
/IN 
two 
/NN 
seconds 
/NNS 
to 
/TO 
shutdown 
/NN 
the 
/DT 
device 
/NN 

True 

Hold 
/VB 
the 
/DT 
power 
/NN 
button 
/NN 
for 
/IN 
two 
/NN 
seconds 
/NNS 
to 
/TO 
shut 
/VBN 
down 
/RB 
the 
/DT 
device 
/NN 

Candidate 

Hold 
/VB 
the 
/DT 
power 
/NN 
button 
/NN 
for 
/IN 
two 
/NN 
seconds 
/NNS 
to 
/TO 
turn 
/VBN 
off 
/IN 
the 
/DT 
device 
/NN 

True 

Hold 
/VB 
the 
/DT 
power 
/NN 
button 
/NN 
for 
/IN 
two 
/NN 
seconds 
/NNS 
to 
/TO 
shut 
/VBN 
down 
/RB 
the 
/DT 
device 
/NN 

Candidate 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 1 : POS analysis on candidate sentence pairs</head><label>1</label><figDesc></figDesc><table>Label 
Description 
Example 
1 
Equal length, same POS tag 
/NN vs. /NN, /VB vs. /VB 
2 
Equal length, plural noun with singular noun 
/NN vs. /NNS 
3 
Equal length, different POS 
/NN vs. /VB 
4 
Unequal length, extra article 
/NN vs. /DT/NN 
5 
Unequal length, extra conjunction 
/NN vs. /CC/NN 
6 
Unequal length, extra adjective 
/NN vs. /JJ/NN 
7 
Other POS tag types. 
/NN vs. N/A 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 2 : POS tag categorizing</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 : Experiment data distribution</head><label>4</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 5 : Evaluation of annotators performance</head><label>5</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 6 : Evaluation of NLDS</head><label>6</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> Flickr: https://www.flickr.com/ 2 The resource is available at: https://goo.gl/6wRchr</note>

			<note place="foot" n="3"> See the Example (4) in Section 1, where two sentences within one sentence pair could be unequal in length, thus we compute the average length to represent the length of each candidate pair. 4 OpenNLP: https://opennlp.apache.org/ documentation/1.5.3/manual/opennlp.html</note>

			<note place="foot" n="5"> https://cran.r-project.org/web/packages/e1071/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research work was supported by Innovatia Inc. and NSERC. We are thankful to our colleagues An-drew Albert, David Crowley, and Erika Allen who proposed and defined this NLD task, and provided expertise that contributed on the preparation of this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">iPhone User Guide For iOS 8.4 Software</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apple</forename><surname>Inc</surname></persName>
		</author>
		<ptr target="https://manuals.info.apple.com/MANUALS/1000/MA1565/en_US/iphone_user_guide.pdf" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Natural language processing with Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>O&apos;Reilly Media</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Web 1T 5-gram Version 1</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Brants</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Franz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">How evaluation guides AI research: The message still counts more than the medium. AI magazine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adele</forename><forename type="middle">E</forename><surname>Paul R Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Howe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Weighted kappa: Nominal scale agreement provision for scaled disagreement or partial credit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">213</biblScope>
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Paraphrase identification as probabilistic quasi-synchronous recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="468" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The concept of consistency in writing and editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>David K Farkas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Technical Writing and Communication</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="353" to="364" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The equivalence of weighted kappa and the intraclass correlation coefficient as measures of reliability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Fleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Detecting near-duplicates in large-scale short text databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caichun</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Knowledge Discovery and Data Mining</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="877" to="883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Semantic text similarity using corpus-based word similarity and string similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aminul</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data (TKDD)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Text similarity using google tri-grams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aminul</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evangelos</forename><surname>Milios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlado</forename><surname>Kešelj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Artificial Intelligence</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="312" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">CNG method with weighted voting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlado</forename><surname>Kešelj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Cercone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint International Conference of the Association for Literary and Linguistic Computing and the Association for Computers and the Humanities</title>
		<meeting><address><addrLine>Göteborg, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>ALLC/ACH</publisher>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>Ad-hoc Authorship Attribution Competition. Proceedings</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Metonymy: Developing a cognitive linguistic view</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoltán</forename><surname>Kövecses</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günter</forename><surname>Radden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cognitive Linguistics (includes Cognitive Linguistic Bibliography)</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="37" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename></persName>
		</author>
		<ptr target="https://www.tracfone.com/images/en/phones/TFLG600G/manual.pdf" />
		<title level="m">LG600G User Guide</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Detecting near-duplicates for web crawling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gurmeet</forename><surname>Singh Manku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anish Das</forename><surname>Sarma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th international conference on World Wide Web</title>
		<meeting>the 16th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="141" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Abidalrahman Moh&apos;d, and Evangelos E. Milios. 2015. Efficient computation of co-occurrence based word relatedness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxin</forename><surname>Kou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhimin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rau-Chaplin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aminul</forename><surname>Islam</surname></persName>
		</author>
		<ptr target="http://ares.research.cs.dal.ca/gtm/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Introduction to wordnet: An on-line lexical database*</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Beckwith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Fellbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><forename type="middle">J</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
		<ptr target="http://cellphone.manualsonline.com/manuals/mfg/samsung/010505d5.html?p=53" />
	</analytic>
	<monogr>
		<title level="m">Samsung. 2011. Samsung 010505d5 cell phone user manual</title>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="235" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dynamic pooling and unfolding recursive autoencoders for paraphrase detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 24</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Near duplicate text detection using frequency-biased signatures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Web Information Systems Engineering-WISE 2013</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="277" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The nature of statistical learning theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vapnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vladimir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Evaluation of n-gram-based classification approaches on classical music corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacek</forename><surname>Wołkowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlado</forename><surname>Kešelj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematics and computation in music</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="213" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Verbs semantics and lexical selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhibiao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<ptr target="http://ws4jdemo.appspot.com/?mode=w&amp;s1=&amp;w1=photo&amp;s2=&amp;w2=video" />
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
