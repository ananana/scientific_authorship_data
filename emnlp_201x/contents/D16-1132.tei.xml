<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:08+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Intra-Sentential Subject Zero Anaphora Resolution using Multi-Column Convolutional Neural Network</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryu</forename><surname>Iida</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Institute of Information and Communications Technology Kyoto</orgName>
								<address>
									<postCode>619-0289</postCode>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Torisawa</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Institute of Information and Communications Technology Kyoto</orgName>
								<address>
									<postCode>619-0289</postCode>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong-Hoon</forename><surname>Oh</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Institute of Information and Communications Technology Kyoto</orgName>
								<address>
									<postCode>619-0289</postCode>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canasai</forename><surname>Kruengkrai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Institute of Information and Communications Technology Kyoto</orgName>
								<address>
									<postCode>619-0289</postCode>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Kloetzer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Institute of Information and Communications Technology Kyoto</orgName>
								<address>
									<postCode>619-0289</postCode>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Intra-Sentential Subject Zero Anaphora Resolution using Multi-Column Convolutional Neural Network</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1244" to="1254"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper proposes a method for intra-sentential subject zero anaphora resolution in Japanese. Our proposed method utilizes a Multi-column Convolutional Neural Network (MCNN) for predicting zero anaphoric relations. Motivated by Centering Theory and other previous works, we exploit as clues both the surface word sequence and the dependency tree of a target sentence in our MCNN. Even though the F-score of our method was lower than that of the state-of-the-art method, which achieved relatively high recall and low precision , our method achieved much higher precision (&gt;0.8) in a wide range of recall levels. We believe such high precision is crucial for real-world NLP applications and thus our method is preferable to the state-of-the-art method.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In such pro-drop languages as Japanese, Chinese and Italian, pronouns are frequently omitted in text. For example, the subject of uketa (suffered) is unre- alized in the following Japanese example (1):</p><p>(1) sono-houkokusho-wa seifu i -ga The report pointed out that the government i agreed to a treaty and (it i ) suffered economically.</p><p>The omitted argument is called a zero anaphor, which is represented using ϕ. In example (1), zero anaphor ϕ i refers to its antecedent, seifu i (govern- ment). Such a reference phenomenon is called zero anaphora. Identifying zero anaphoric relations is an essential task in developing such accurate NLP applications as information extraction and machine translation for pro-drop languages. For example, in Japanese, 60% of subjects in newspaper articles are unrealized as zero anaphors ( <ref type="bibr" target="#b14">Iida et al., 2007)</ref>.</p><p>This paper proposes a method for intra-sentential subject zero anaphora resolution, in which a zero anaphor and its antecedent appear in the same sen- tence and the zero anaphor must be a subject of a predicate, for Japanese. We target subject zero anaphors because they represent 85% of the intra- sentential zero anaphora in our data set (example (1) is such a case). Furthermore, this work focuses on intra-sentential zero anaphora because inter- sentential cases, in which a zero anaphor and its an- tecedent do not appear in the same sentence, are ex- tremely difficult. The accuracy of the state-of-the- art method for resolving inter-sentential anaphora is low ( <ref type="bibr" target="#b30">Sasano and Kurohashi, 2011</ref>), and we believe the current technologies are not mature enough to deal with inter-sentential cases.</p><p>Our method locally predicts the likelihood of a zero anaphoric relation between every possible com- bination of potential zero anaphor and potential an- tecedent without considering the other (potential) zero anaphoric relations in the same sentence. The final determination of zero anaphoric relations for each zero anaphor in a given sentence is done in a greedy way; only the most likely candidate an- tecedent for each zero anaphor is selected as its an- tecedent as far as the likelihood score exceeds a given threshold. This approach contrasts with global optimization methods <ref type="bibr" target="#b37">(Yoshikawa et al., 2011;</ref><ref type="bibr" target="#b10">Iida and Poesio, 2011;</ref><ref type="bibr" target="#b29">Ouchi et al., 2015)</ref>, which have recently become popular. These methods use the constraints among possible zero anaphoric relations, such as "if a candidate antecedent is identified as the antecedent of a subject zero anaphor of a predi- cate, the candidate cannot be referred to by the ob- ject zero anaphor of the same predicate", and deter- mine an optimal set of zero anaphoric relations in an entire sentence while satisfying such constraints, using such optimization techniques as sentence-wise global learning ( <ref type="bibr" target="#b29">Ouchi et al., 2015)</ref> and integer lin- ear programming ( <ref type="bibr" target="#b10">Iida and Poesio, 2011)</ref>.</p><p>Although the global optimization methods have outperformed the previous greedy-style methods, our contention is that greedy-style methods can still, in a certain sense, outperform the state-of-the-art global optimization methods. <ref type="bibr" target="#b29">Ouchi et al. (2015)</ref>'s global optimization method achieved the state-of- the-art F-score for Japanese intra-sentential subject zero anaphora resolution, but its performance has not yet reached a level of practical use. In our set- ting, for example, it actually obtained a precision of only 0.61, and even after attempting to obtain more reliable zero anaphoric relations by several modi- fications, we could only achieve 0.80 precision at extremely low recall levels (&lt;0.01). On the other hand, while our proposed greedy-style method ob- tained a lower F-score than Ouchi et al.'s method, it achieved much higher precision in a wide range of recall levels (e.g., around 0.8 precision at 0.25 in recall and around 0.7 precision at 0.4 in recall). We believe such high precision is crucial to real- world applications, even though the recall remains low, and thus our method is preferable to Ouchi et al.'s method in that sense.</p><p>In our proposed method, we use a Multi-column Convolutional Neural Network (MCNN) <ref type="bibr" target="#b2">(Cires¸anCires¸an et al., 2012)</ref>, which is a variant of a Convolutional Neu- ral Network (CNN) ( <ref type="bibr" target="#b22">LeCun et al., 1998</ref>). An MCNN has several independent columns, each of which has its own convolutional and pooling layers. The out- puts of all the columns are combined in the final layer to provide a final prediction. In this work, mo- tivated by Centering Theory ( <ref type="bibr" target="#b6">Grosz et al., 1995)</ref> and other previous works, we exploit as distinct columns the word sequences obtained from the surface word sequence and the dependency tree of a target sen- tence in our MCNN. Although the existing works also exploited such word sequences, they used only particular types of information from them as features based on the researchers' linguistic insights. In con- trast, we minimized such feature engineering due to using an MCNN.</p><p>The rest of this paper is organized as follows. In Section 2, we briefly overview previous work on zero anaphora resolution. In Section 3, we present the procedure of our zero anaphora resolu- tion method and explain the column sets used in our MCNN architecture. We evaluate how effectively our method recognizes intra-sentential subject zero anaphora in Section 4 and summarize this work and discuss future directions in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>The typical zero anaphora resolution algorithms pro- posed so far have exploited the information of a predicate that potentially has a zero anaphor and its candidate antecedent in a supervised manner <ref type="bibr" target="#b33">(Seki et al., 2002;</ref><ref type="bibr" target="#b11">Iida et al., 2003;</ref><ref type="bibr" target="#b17">Isozaki and Hirao, 2003;</ref><ref type="bibr" target="#b12">Iida et al., 2006;</ref><ref type="bibr" target="#b34">Taira et al., 2008;</ref><ref type="bibr" target="#b31">Sasano et al., 2008;</ref><ref type="bibr" target="#b16">Imamura et al., 2009;</ref><ref type="bibr" target="#b7">Hayashibe et al., 2011;</ref><ref type="bibr" target="#b10">Iida and Poesio, 2011;</ref><ref type="bibr" target="#b30">Sasano and Kurohashi, 2011;</ref><ref type="bibr" target="#b37">Yoshikawa et al., 2011</ref>). In addition, existing works have exploited the dependency path between a predicate and a candidate antecedent either by en- coding such paths to the set of binary features of the words that appear in the path ( <ref type="bibr" target="#b10">Iida and Poesio, 2011)</ref> or by mining from the paths the sub-trees that effec- tively discriminate zero anaphoric relations ( <ref type="bibr" target="#b12">Iida et al., 2006</ref>). However, both methods just focus on the dependency paths between a predicate and a candi- date antecedent without exploiting other structural fragments in the dependency tree representing a tar- get sentence, whereas our method uses the text frag- ments that cover the entire dependency tree.</p><p>Another important clue was derived from dis- course theories, such as Centering Theory ( <ref type="bibr" target="#b6">Grosz et al., 1995)</ref>. In this theory, (zero) anaphoric phe- nomenon is explained based on the rules and prin- ciples regarding the recency and saliency of candi- date antecedents. <ref type="bibr" target="#b28">Okumura and Tamura (1996)</ref> de- veloped a rule-based method based on the idea of Centering Theory. <ref type="bibr" target="#b11">Iida et al. (2003)</ref> and <ref type="bibr" target="#b16">Imamura et al. (2009)</ref> used as features for machine learning the results of rule-based antecedent identification based on a variant of Centering Theory <ref type="bibr" target="#b25">(Nariyama, 2002</ref>). However, we observed that actual anaphoric phe- nomena often do not obey Centering Theory. To robustly resolve zero anaphora, we need to explore additional clues that are represented in a target sen- tence (or text).</p><p>Recent work by <ref type="bibr" target="#b15">Iida et al. (2015)</ref> newly intro- duced a sub-problem of zero anaphora resolution, subject sharing recognition, which is the task that judges whether two predicates have the same sub- ject. In their method, a network of subject sharing predicates is created by their subject sharing rec- ognizer, and then zero anaphora resolution is per- formed by propagating a subject to the unrealized subject positions through the path in the network. Even though the accuracy of subject sharing recog- nition exceeds that of zero anaphora resolution, the zero anaphoric relations identified using the results of subject sharing recognition are limited to those that can be reached by subject sharing relations. The recall of this method is not high.</p><p>Although most zero anaphora resolution methods independently identify a zero anaphoric relation for each predicate, some previous works optimized the global assignment of zero anaphoric relations in an entire sentence (or an entire text) while satisfying several constraints among zero anaphoric relations. For example, <ref type="bibr" target="#b10">Iida and Poesio (2011)</ref> found the best assignment of subject zero anaphoric relations using integer linear programming. As mentioned in the In- troduction, <ref type="bibr" target="#b29">Ouchi et al. (2015)</ref> estimated the global score of all of the predicate-argument assignments in a sentence, which include the assignments of intra- sentential zero anaphoric relations, to find the best assignment using a hill-climbing technique. Their method has an advantage: it can exploit complicated relations (e.g., the combination of two potential zero anaphoric relations) as features to directly decide more than one predicate-argument relation simulta- neously. We adopted <ref type="bibr" target="#b29">Ouchi et al. (2015)</ref>'s method as a baseline in Section 4 because it achieved the state-of-the-art performance for intra-sentential zero anaphora resolution.</p><p>Collobert et al. <ref type="formula">(2011)</ref> proposed CNN architec- ture that can be applied to various NLP tasks, such as PoS tagging, chunking, named entity recognition and semantic role labeling. Following this work, CNNs have been utilized in such NLP tasks as docu- ment classification <ref type="bibr" target="#b19">(Kalchbrenner et al., 2014;</ref><ref type="bibr" target="#b20">Kim, 2014;</ref><ref type="bibr" target="#b18">Johnson and Zhang, 2015)</ref>, paraphrase ( <ref type="bibr" target="#b9">Hu et al., 2014;</ref><ref type="bibr" target="#b36">Yin and Schütze, 2015</ref>) and relation extraction ( <ref type="bibr" target="#b23">Liu et al., 2013;</ref><ref type="bibr" target="#b40">Zeng et al., 2014;</ref><ref type="bibr" target="#b5">dos Santos et al., 2015;</ref><ref type="bibr" target="#b27">Nguyen and Grishman, 2015)</ref>. MCNNs were first introduced for image classifica- tion <ref type="bibr" target="#b2">(Cires¸anCires¸an et al., 2012</ref>). In NLP tasks, they have been utilized for question-answering ( <ref type="bibr" target="#b4">Dong et al., 2015</ref>) and relation extraction ( <ref type="bibr" target="#b41">Zeng et al., 2015)</ref>. Our MCNN architecture was inspired by a Siamese architecture ( <ref type="bibr" target="#b1">Chopra et al., 2005</ref>), which we extend to a multi-column network and replace its similarity measure with a softmax function at its top.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed method</head><p>Our proposed method consists of the following four steps:</p><p>Step 1 Extract every pair of a predicate and a can- didate antecedent, ⟨pred i , cand i ⟩, that appears in a target sentence.</p><p>Step 2 Predict the probability of each pair using our MCNN.</p><p>Step 3 Rank in descending order all the pairs by their probabilities obtained in Step 2.</p><p>Step 4 Choose the top pair ⟨pred i , cand i ⟩ in the ranked list and fill the zero anaphor position of predicate pred i by cand i if the position has not already been filled by another candidate. Re- move ⟨pred i , cand i ⟩ from the list and repeat this step as long as the score of the chosen pair exceeds a given threshold.</p><p>In Step 1, we extract set of pairs ⟨pred i , cand i ⟩ in which candidate antecedent cand i is paired with predicate pred i . Note that we extracted predicate pred i , instead of a zero anaphor that is an unreal- ized subject of pred i , because the (potential) zero anaphor of pred i is omitted in the text and cannot be extracted directly.</p><p>In Step 2, our MCNN gives a probability that in- dicates the likelihood of a zero anaphoric relation to judge for each pair whether cand i fills the blank subject position of pred i through zero anaphora and ranks all of the pairs by the probabilities in Step 3.</p><formula xml:id="formula_0">((( ((( SURFSEQ !"#$#%&amp;'( )*%+*%,* ((( !"#$%&amp;% !&amp;'($)*" +,$-"#$), .&amp;'#&amp;.!$!/' 01/'*"'),1$#&amp;." #,.,),1!/'.&amp;#'!/'."</formula><p>)""*+,-</p><p>.",/"*0$+", )""*+,-</p><p>.",/"*0$+",</p><p>."*0%,12 ."*0%,13 ((( )""*+,-</p><p>.",/"*0$+", )""*+,-</p><p>.",/"*0$+",</p><p>."*0%,14 ."*0%,15 ((( Finally, in Step 4 we actually fill cand i in the blank subject positions of pred i in a greedy style in the order of the ranked list in Step 3, i.e., the zero anaphora resolution with a higher probability is done before that with a lower probability. If the sub- ject position is already occupied by another candi- date antecedent, candidate antecedents are no longer filled at that position.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Design of columns used in MCNN</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>In</head><p>Step 2 of our method, we use a Multi-column Convolutional Neural Network (MCNN). Note that zero anaphoric phenomena can be divided into two different referential phenomena: anaphoric (i.e., an antecedent precedes its zero anaphor) and cat- aphoric (i.e., a zero anaphor precedes its antecedent) cases. To capture this difference, we divided the set of training instances into two subsets by the relative occurrence positions of a predicate and a candidate antecedent and respectively trained two independent MCNNs using each set.</p><p>Our MCNN simultaneously uses four column sets, as illustrated in <ref type="figure" target="#fig_1">Figure 1</ref>. In the following ex- planation for each column set, we assume that can- didate antecedent cand i precedes predicate pred i in the surface order (for the opposite case, i.e., the cat- aphoric case, the positions of cand i and pred i are switched).</p><p>BASE The first column set consists of one col- umn, which stores the word vectors of the bunsetsu SURFSEQ The second column set consists of three columns, which store the word vectors of (a) the surface word sequence spanning from the beginning of the sentence to cand i , (b) the sequence between cand i and pred i , and (c) the remainder, i.e., from pred i to the end of the sentence. Note that cand i and pred i are not included in any column of this column set. We call this column set the SURFSEQ column set. DEPTREE The third set consists of four columns. We extracted four partial dependency trees from the entire dependency tree of a target sentence: (a) the dependency path between pred i and cand i , (b) the sub-trees that depend on pred i , (c) the sub-trees on which cand i depends and (d) the remaining sub- trees, which are illustrated in <ref type="figure" target="#fig_2">Figure 2</ref>. Note that cand i and pred i are not included in the partial trees. Each column stores the word vectors of the word se- quence in which the words in (the set of) the partial trees are ordered by their surface order. We call this set the DEPTREE column set.</p><p>PREDCONTEXT The fourth set consists of three columns, which store the word vectors of (a) the bunsetsu phrase including pred i , (b) the surface word sequence that appears before (a) (from the be- ginning of the sentence) and (c) the sequence that appears after (a) (until the end of the sentence). We call this column set the PREDCONTEXT column set.</p><p>Among the four column sets, the SURFSEQ col- umn set was designed to introduce the clues based</p><formula xml:id="formula_1">!"#$%&amp;'( ")% %*&amp;(+&amp;!"+% ,)--&amp;+ . /0&amp;+"(1$1!*"+2 '1314&amp; 315&amp;</formula><p>4"6&amp;+$3&amp;$% %+&amp;1%7 &amp;8"$"3#81997</p><p>1'6: ";&lt; ,);&lt; ,);&lt; ";&lt; ";&lt; ,);&lt;(/%"!#819#0&amp;'2 8"$&lt; <ref type="bibr">&amp;3;&amp;''&amp;'(891</ref>  <ref type="formula">(1)</ref> on Centering Theory, in which the antecedent for a given zero anaphor can basically be identified by the recency and saliency properties of a candidate antecedent. More precisely, in the set of the most salient candidate antecedents, the most recent one is preferred. For example, suppose example (2) in which the predicate increase has a subject zero anaphor and its antecedent is France:</p><p>(2) nihon-wa shoshikataisaku-ni Japan-TOP countermeasures to falling birth rate-IOBJ shippaishi-taga, furansu-wa sore-ni seikoushi</p><formula xml:id="formula_2">fail-PAST/BUT France-TOP it-IOBJ succeed (ϕ i -ga) shusseiritsu-o fuyashiteiru (it i -SUBJ) birth rate-OBJ increase</formula><p>Japan failed to develop countermeasures to its falling birth rate, but France i succeeded and (ϕ i ) increased its birth rate.</p><p>In this situation, there are two most salient candi- date antecedents, Japan and France, because they are marked with topic marker wa, which basically indicates the highest degree of candidate saliency. In this case, France is selected as the antecedent be- cause it appears more recently than Japan, and such recency can be estimated by consulting the surface word sequence between France and increase: no other salient candidates are included in the word se- quence. Also, the other two types of word sequences (i.e., the sequence that spans from the beginning of the sentence to cand i and that spans from pred i to its end) are important for confirming whether a more salient candidate than cand i appears in each word sequence. If such a more salient candidate is found, it should be a stronger candidate of the antecedent. The DEPTREE column set is introduced for cap- turing a different aspect of intra-sentential zero anaphora. In the explanation based on Centering Theory, the most salient candidate (e.g., the candi- date marked with wa (topic marker)) is selected as</p><formula xml:id="formula_3">!"#$%&amp;' ((( ((( )"*+,-./$"*! '0 '1 ((( '2$2 #34&amp;5,5&amp;6.* #.&amp;$7*.8%&amp;9!, #"*,!8:*&amp;% "# "$ "% /"4/&amp;$.4&amp;$3"4</formula><p>((( ((( ;&amp;'89""534:</p><p>/"4-"57$3"4 !8:*&amp;% "7$97$!,#*"% %&amp;'89""534:, "# "$&lt;.*,/"57%4! "7$97$!,#*"% %&amp;'89""534:, "# "$&lt;.*,/"57%4! 3497$,)"*+ !.=7.4/.</p><p>Figure 4: Column of our MCNN an antecedent, but example (1) in Section 1 cannot be interpreted based on saliency and recency. In ex- ample (1), the report is the most salient candidate in the sentence because it is marked with topic marker wa, but the less salient candidate government be- comes the antecedent of zero anaphor ϕ. Such a problem is often solved by introducing the depen- dency tree of a sentence. <ref type="figure" target="#fig_3">Figure 3</ref> represents the dependency tree of example <ref type="formula">(1)</ref> in which the an- tecedent of ϕ i appears in the embedded clause. In such a case, an antecedent probably exists among the most salient candidates in the embedded clause. To introduce such structural clues, we used the par- tial dependency trees as columns in the DEPTREE column set. Anaphoricity determination, which is the task of judging whether a candidate anaphor has an an- tecedent, was established as a subtask of coreference resolution. This problem was basically solved by exploring the possible candidate antecedents for a given anaphor candidate in its search space, and the results were used for improving the overall perfor- mance of coreference resolution, especially in En- glish <ref type="bibr" target="#b26">(Ng, 2004;</ref><ref type="bibr" target="#b35">Wiseman et al., 2015)</ref>. Inspired by such previous works, we designed the PRED- CONTEXT set to determine the anaphoricity of zero anaphors, i.e., to judge whether a zero anaphor can- didate has its antecedent in a sentence, by consulting the surface word sequences before and after pred i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">MCNN architecture</head><p>In our MCNN <ref type="figure">(Figure 4)</ref>, we represent each word in text fragment t by d-dimensional embedding vec-tor x i and t by matrix T = [x 1 , . . . , x |t| ]. <ref type="bibr">2</ref> T is then wired to a set of M feature maps where each feature map is a vector. Each element O in the feature map is computed by a filter denoted by f j (1 ≤ j ≤ M ) from the N -gram word sequences in t for a fixed integer N , as O = ReLU(W f j • x i:i+N −1 + b f j ), where • denotes element-wise mul- tiplication followed by the summation of the result- ing elements (i.e., a Frobenious inner product of W f j and x i:i+N −1 ) and ReLU(x) = max <ref type="bibr">(0, x)</ref>. In other words, we construct a feature map by convolv- ing a text fragment with a filter, which is parameter- ized by weight W f j ∈ R d×N and bias b f j ∈ R. Note that there can be several sets of feature maps where each set covers N -grams for different N . Note that the weight of the feature maps for each N -gram in each column set is shared.</p><p>As a whole, these feature maps are referred to as a convolution layer. The next layer is called a pool- ing layer. Here we use max-pooling ( <ref type="bibr" target="#b32">Scherer et al., 2010;</ref><ref type="bibr" target="#b3">Collobert et al., 2011</ref>), which simply selects the maximum value among the elements in the same feature map. Our assumption is that the maximum value indicates the existence of a strong clue, i.e., N -gram, for our final judgment. The selected maxi- mum values from all the M feature maps are simply concatenated, and the resulting M -dimensional vec- tor is given to our final layer.</p><p>The final layer has vectors coming from multiple feature maps in multiple columns. They are again simply concatenated and constitute a high dimen- sional feature vector. The final layer applies a linear softmax function to produce the class probabilities of the zero anaphoric labels: true and false. We use a mini-batch stochastic gradient descent (SGD) with the Adadelta update rule <ref type="bibr" target="#b39">(Zeiler, 2012)</ref>, apply ran- dom initialization within (-0.01, 0.01) for W f j , and initialize the remaining parameters at zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Revising annotation results</head><p>In our preliminary investigation of the intra- sentential zero anaphoric relations in the NAIST Text Corpus ( <ref type="bibr" target="#b14">Iida et al., 2007</ref>), since we found more annotation errors than we expected, we decided to revise the annotation results. In this revision, we additionally annotated the subject sharing relations, where two predicates have the same subject regard- less whether the subject is realized or omitted, be- tween pairs of predicates in our data set. Note that two predicates can have a subject sharing relation even if neither has a realized subject as far as a sub- ject exists that can naturally fill the subject position of the two predicates. We used the annotated results of subject sharing relations to efficiently detect the annotation errors of intra-sentential zero anaphoric relations, as shown below.</p><p>Twenty-six human annotators directly annotated the subject sharing relations for pairs of predicates in a sentence. For this annotation, we automatically extracted from the NAIST Text Corpus all the pairs of predicates that appear in the same sentence and obtained 227,517 predicate pairs. For making the annotation results more reliable, each subject shar- ing relation was individually judged by three anno- tators, and the final label was decided by a majority vote. After that, further revisions of the subject shar- ing relations and the zero anaphoric relations were performed by focusing on the inconsistent annota- tions between the newly annotated subject sharing relations and the original predicate-argument rela- tions in the NAIST Text Corpus. More precisely, we scrutinized the suspicious annotations such that a subject, which was determined through the anno- tated subject sharing relations, is not the same as a subject that was directly annotated in the NAIST Text Corpus. In this revision phase, both the subject sharing and zero anaphora relations for such suspi- cious instances were independently re-annotated by three annotators, and their final labels of both rela- tions were determined by a majority of the their de- cisions. <ref type="bibr">3</ref> As a result, 2,120 zero anaphoric instances were newly added to the corpus and 1,184 instances were removed from it for a total of 19,049 instances of intra-sentential subject zero anaphoric relations. <ref type="bibr">4</ref> Type #docs #sentences #zero anaphors <ref type="table">(intra-sentential)  train  1,757  23,152  11,453  dev  586  7,526  3,691  test  586  7,705  3,875   Table 1</ref>: Statistics of our data set</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental settings</head><p>The documents in the corpus were divided into five subsets, three of which were used as a training data set, one as a development data set, and one as a test- ing data set. The statistics of our data set are sum- marized in <ref type="table">Table 1</ref>. We evaluated the performance of our intra-sentential subject zero anaphora resolu- tion method and three baseline methods described below using the revised annotated results in our data set. We implemented our MCNN using Theano ( <ref type="bibr" target="#b0">Bastien et al., 2012)</ref>.</p><p>We pre-trained 300- dimensional word embedding vectors for 1,658,487 words 5 using Skip-gram with a negative-sampling algorithm (Mikolov et al., 2013) 6 on a set of all the sentences extracted from Wikipedia articles 7 (35,975,219 sentences). We removed from the train- ing data all the words that only appeared once be- fore training. In training, we treated them as un- known words and assigned them a random vector. To avoid overfitting, we applied early-stopping and dropout <ref type="bibr" target="#b8">(Hinton et al., 2012</ref>) of 0.5 to the final layer. We used an SGD with mini-batches of 100 and a learning rate decay of 0.95. We ran ten epochs through all of the training data, where each epoch consisted of many mini-batch updates. We utilized 3-, 4-and 5-grams with 100 filters each and used the F-score of positive instances as our evaluation met- ric. The total number of the nodes in the final layers of our MCNN was 3,300: 11 columns × 3 N -gram × 100 filters.</p><p>Word segmentation, PoS tagging and dependency parsing of the sentences in the NAIST Text Corpus were performed by a Japanese morphological ana- lyzer, MeCab 8 ( <ref type="bibr" target="#b21">Kudo et al., 2004</ref>), and a depen- two sets.dency parser, J.DepP 9 <ref type="bibr" target="#b38">(Yoshinaga and Kitsuregawa, 2009</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baselines</head><p>We compared our method with three baseline meth- ods. The first baseline is a single-column convolu- tional neural network in which the column includes the entire surface word sequence of a sentence. To give the positions of pred i and cand i to the network, we concatenated to each word vector an additional 2-dimensional vector, where the first element is set to one if the corresponding word is pred i , the sec- ond element is set to 1 if the corresponding word is cand i , and otherwise they are set to 0. This baseline was adopted for estimating the impact of a multi- column network compared to a single-column one.</p><p>The remaining two baselines are <ref type="bibr" target="#b29">Ouchi et al. (2015)</ref>'s global optimization method and <ref type="bibr" target="#b15">Iida et al. (2015)</ref>'s method based on subject sharing recogni- tion. Note that Ouchi's method outputs predicate- argument relations for three grammatical roles (subj, obj, iobj), but for this evaluation we used only the outputs related to intra-sentential subject zero anaphora resolution. As done in <ref type="bibr" target="#b29">Ouchi et al. (2015)</ref>, we averaged their performances across ten indepen- dent runs because the initial random assignment of the predicate-argument relations that was employed in their method changes the performance. Ouchi's method does not require any development data set, so we used both the development and training data sets for training their joint model. For training the subject sharing recognizer used in Iida's method, we used the annotated subject sharing relations in the training and development data sets. In these two baselines, we used the same morphological analyzer and dependency analyzer as for our method. <ref type="table">Table 2</ref> shows the results for each method. Their performances were evaluated by measuring recall, precision, F-score and average precision (Avg.P). To assess the effectiveness of each column set intro- duced in Section 3.1, we evaluated the performance of our method using every possible combination of column sets that includes at least the BASE column set. We also gave the precision-recall (PR)  <ref type="table">Table 2</ref>: Results of intra-sentential subject zero anaphora resolution curves of our method using the four column sets (BASE+SURFSEQ+DEPTREE+PREDCONTEXT), the single column baseline, and Ouchi's method in <ref type="figure" target="#fig_4">Figure 5</ref> to investigate the behavior of each method at a high precision level. <ref type="bibr">10</ref> The PR-curves of our method and the single-column baseline were plotted just by altering the threshold parameters in</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results</head><p>Step 4 of our method (See Section 3). In contrast, the PR-curve of Ouchi's method cannot be easily plotted because it gives a score to each sentence, not to each zero anaphoric relation. For plotting the PR-curve, we used the normalized global score of a sentence as the score of any zero anaphoric relations in the sentence. 11 Note that the recall of their PR-curve reached just 0.539, shown in <ref type="table">Table 2</ref>, because we could not estimate the scores of the zero anaphoric relations that were not outputted by their method. The PR-curves of the other methods also fail to reach 1.0 in recall. This is because the zero anaphoric relations are exclusive; a zero anaphor does not refer to more than one antecedent. If a method provides an incorrect zero anaphoric relation, a correct relation for the same zero anaphor will never be provided in its output. Also, note that the average precision of each method was calculated by averaging the precisions at the available recall <ref type="bibr">10</ref> The PR-curve of <ref type="bibr" target="#b15">Iida et al. (2015)</ref>'s method was not plotted because it does not provide the score of each zero anaphoric relation. <ref type="bibr">11</ref> The global score provided by Ouchi's method becomes greater based on the number of predicate-argument pairs in a sentence. To control this, we normalized the original global score by the sum of the frequencies of the single or double predicate-argument pairs because the feature functions were ap- plied to such pairs in their method. This achieved the best per- formance among the normalization schemes we have tried so far.  <ref type="table">Table 2</ref> show that our method using all the column sets achieved the best average pre- cision among the combination of column sets that include at least the BASE column set. This sug- gests that all of the clues introduced by our four column sets are effective for performance improve- ment. Table 2 also demonstrates that our method us- ing all the column sets obtained better average pre- cision than the strongest baseline, Ouchi's method, in spite of an unfavorable condition for it. <ref type="bibr">12</ref> The results also show that our method with all of the column sets achieved a better F-score than Iida's method and the single-column baseline. However, it achieved a lower F-score than Ouchi's method. This was caused by the choice of different recall lev- els for computing the F-score. In contrast, the PR-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Set</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Recall Precision F-score Avg. <ref type="table">P  Anaphoric  single-column CNN (w/ position</ref>   <ref type="table">Table 3</ref>: Results of instance-wise evaluation for anaphoric and cataphoric sets curves for these two methods in <ref type="figure" target="#fig_4">Figure 5</ref> show that our method obtained higher precision than Ouchi's method at all recall levels. Particularly, it got high precision in a wide range of recall levels (e.g., around 0.8 in precision at 0.25 in recall and around 0.7 in precision at 0.4 in recall), while the precision obtained by Ouchi's method at 0.25 in recall was just around 0.65. We believe this difference becomes crucial when using the outputs of each method for developing accurate real-world NLP applications.</p><p>In addition to an evaluation that used all of the test instances, we also investigated how our method performed differently for anaphoric and cataphoric cases. In this evaluation, we first divided our data set into anaphoric and cataphoric sets by the relative po- sition of the candidate antecedent and evaluated the performance by measuring the recall, precision, F- score and average precision for each set. This eval- uation was done instance-wise, where we took into account each pair of a predicate and its candidate an- tecedent as a classification target, while in the pre- vious evaluation the performance was measured for the set of zero anaphors in the test set. Thus, the figures in <ref type="table">Table 2 and Table 3</ref> are not comparable. Note that we only compared our method with the baseline using a single-column convolutional neural network because the other baselines are not able to output the score of each instance for measuring their average precision.</p><p>The results in <ref type="table">Table 3</ref> show that our MCNN-based method achieved better average precision than the single-column CNN baseline except the method that uses only the BASE column set for the cataphoric case. The results also demonstrate that each column set consistently contributes to improving the aver- age precision for both the anaphoric and cataphoric cases. However, <ref type="table">Table 3</ref> shows that the average pre- cision for the cataphoric set remains low. As one future direction for further improvement, we need to explore clues for identifying cataphoric relations more accurately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper proposed an accurate method for intra- sentential subject zero anaphora resolution us- ing a Multi-column Convolutional Neural Network (MCNN). As clues, our MCNN exploits both the surface word sequence and the dependency tree of a target sentence. Our experimental results show that the proposed method achieved better precision than the strong baselines in a wide range of recall levels.</p><p>As future work, we plan to use our MCNN archi- tecture for inter-sentential zero anaphora resolution and develop highly accurate NLP applications using our intra-sentential subject zero anaphora resolution method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>the report-TOP government i -SUBJ jouyaku-o teiketsushi (ϕ i -ga) keizaitekini treaty-OBJ make it i -SUBJ economically higai-o uke-ta koto-o shitekishi-ta damage-OBJ suffer-PAST COMP point out-PAST</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Our multi-column CNN architecture</figDesc><graphic url="image-1.png" coords="4,75.31,61.17,231.48,162.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Columns (a, b, c, d) in DEPTREE column set</figDesc><graphic url="image-2.png" coords="4,377.50,59.82,98.14,99.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Dependency tree of example (1)</figDesc><graphic url="image-3.png" coords="5,85.24,59.73,200.31,96.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: PR-curves of each method</figDesc></figure>

			<note place="foot" n="1"> A bunsetsu phrase is a Japanese base phrase that consists of at least one content word optionally followed by function words.</note>

			<note place="foot" n="2"> We use zero padding for dealing with text fragments of variable length (Kim, 2014).</note>

			<note place="foot" n="3"> We are planning to release the annotated results and information on the data separation used in our evaluation from https://alaginrc.nict.go.jp/. 4 After this revision, a small number of inconsistent annotated results have both a syntactically dependent subject and a subject zero anaphor because the revision was performed locally. There were 30 inconsistent instances in the testing set and 100 in the training and development sets. We only removed such instances from the testing set without changing the other</note>

			<note place="foot" n="5"> Words occurring less than five times in all the sentences were ignored to train the word embedding vectors. 6 We set the skip distance to 5 and the number of negative samples to 10. 7 https://archive.org/details/jawiki-20150118 8 http://taku910.github.io/mecab/</note>

			<note place="foot" n="9"> http://www.tkl.iis.u-tokyo.ac.jp/˜ynaga/jdepp/</note>

			<note place="foot" n="12"> When calculating the average precision of each method, the relatively low values in precision at high recall levels (i.e., from 0.54 to 0.67) were used in our method but not in Ouchi&apos;s method, as seen in Figure 5.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We thank Hiroki Ouchi for providing his predicate-argument analyzer that was proposed in <ref type="bibr" target="#b29">Ouchi et al. (2015)</ref>.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Arnaud Bergeron, Nicolas Bouchard, and Yoshua Bengio</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Bastien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NIPS 2012 Workshop: Deep Learning and Unsupervised Feature Learning</title>
		<meeting>the NIPS 2012 Workshop: Deep Learning and Unsupervised Feature Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Theano: new features and speed improvements</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Computer Vision and Pattern Recognition Conference</title>
		<meeting>Computer Vision and Pattern Recognition Conference</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="539" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multi-column deep neural networks for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Claudiu Cires¸ancires¸an</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ueli</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3642" to="3649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Question answering over freebase with multi-column convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="260" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Classifying relations by ranking with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Cicero Dos Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="626" to="634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Centering: A framework for modeling the local coherence of discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><forename type="middle">J</forename><surname>Grosz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Weinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="225" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Japanese predicate argument structure analysis exploiting argument position and type</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuta</forename><surname>Hayashibe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mamoru</forename><surname>Komachi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Joint Conference on Natural Language Processing</title>
		<meeting>5th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="201" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Improving neural networks by preventing co-adaptation of feature detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno>abs /1207.0580</idno>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Convolutional neural network architectures for matching natural language sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baotian</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingcai</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Processings of Advances in Neural Information Processing Systems 27 (NIPS 2014)</title>
		<meeting>essings of Advances in Neural Information essing Systems 27 (NIPS 2014)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2042" to="2050" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A cross-lingual ILP solution to zero anaphora resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryu</forename><surname>Iida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="804" to="813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Incorporating contextual cues in trainable models for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryu</forename><surname>Iida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroya</forename><surname>Takamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 EACL Workshop on The Computational Treatment of Anaphora</title>
		<meeting>the 2003 EACL Workshop on The Computational Treatment of Anaphora</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="23" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exploiting syntactic patterns as clues in zero-anaphora resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryu</forename><surname>Iida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Processings of the 21st International Conference on Computational Linguistics and 44th</title>
		<meeting>essings of the 21st International Conference on Computational Linguistics and 44th</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="page" from="625" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Annotating a Japanese text corpus with predicate-argument and coreference relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryu</forename><surname>Iida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mamoru</forename><surname>Komachi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop: &apos;Linguistic Annotation Workshop</title>
		<meeting>the ACL Workshop: &apos;Linguistic Annotation Workshop</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="132" to="139" />
		</imprint>
	</monogr>
	<note>Kentaro Inui, and Yuji Matsumoto</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Intra-sentential zero anaphora resolution using subject sharing recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryu</forename><surname>Iida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Torisawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chikara</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonghoon</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Kloetzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2179" to="2189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Discriminative approach to predicate-argument structure analysis with zero-anaphora resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Imamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuniko</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Izumi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="85" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Japanese zero pronoun resolution based on ranking rules and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Isozaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsutomu</forename><surname>Hirao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2003 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="184" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Effective use of word order for text categorization with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rie</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="103" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A convolutional neural network for modelling sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="655" to="665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Applying conditional random fields to Japanese 1253 morphological analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaoru</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2004 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="230" to="237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Convolution neural network for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbo</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference of Advanced Data Mining and Applications</title>
		<meeting>the 9th International Conference of Advanced Data Mining and Applications</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="231" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems 26 (NIPS 2013)</title>
		<meeting>Advances in Neural Information Processing Systems 26 (NIPS 2013)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Grammar for ellipsis resolution in Japanese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shigeko</forename><surname>Nariyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Theoretical and Methodological Issues in Machine Translation</title>
		<meeting>the 9th International Conference on Theoretical and Methodological Issues in Machine Translation</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="135" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning noun phrase anaphoricity to improve conference resolution: Issues in representation and optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Meeting of the Association for Computational Linguistics</title>
		<meeting>the 42nd Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="151" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Relation extraction: Perspective from convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huu</forename><surname>Thien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Vector Space Modeling for Natural Language Processing</title>
		<meeting>the 1st Workshop on Vector Space Modeling for Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Zero pronoun resolution in Japanese discourse based on centering theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manabu</forename><surname>Okumura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kouji</forename><surname>Tamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 16th International Conference on Computational Linguistics</title>
		<meeting>The 16th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="871" to="876" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Joint case argument identification for Japanese predicate argument structure analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroki</forename><surname>Ouchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroyuki</forename><surname>Shindo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="961" to="970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A discriminative approach to Japanese zero anaphora resolution with large-scale lexicalized case frames</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryohei</forename><surname>Sasano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Joint Conference on Natural Language Processing</title>
		<meeting>5th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="758" to="766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A fully-lexicalized probabilistic model for Japanese zero anaphora resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryohei</forename><surname>Sasano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="769" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Evaluation of pooling operations in convolutional architectures for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominik</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><surname>Behnke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on Artificial Neural Networks</title>
		<meeting>the 20th International Conference on Artificial Neural Networks</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="92" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A probabilistic method for analyzing Japanese anaphora integrating zero pronoun detection and resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuhiro</forename><surname>Seki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsushi</forename><surname>Fujii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuya</forename><surname>Ishikawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Processings of the 19th International Conference on Computational Linguistics</title>
		<meeting>essings of the 19th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A Japanese predicate argument structure analysis using decision lists</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hirotoshi</forename><surname>Taira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanae</forename><surname>Fujita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaaki</forename><surname>Nagata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2008 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="523" to="532" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning anaphoricity and antecedent ranking features for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Shieber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1416" to="1426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Convolutional neural network for paraphrase identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="901" to="911" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Jointly extracting Japanese predicateargument relation with Markov Logic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katsumasa</forename><surname>Yoshikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayuki</forename><surname>Asahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Joint Conference on Natural Language Processing</title>
		<meeting>5th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1125" to="1133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Polynomial to linear: Efficient classification with conjunctive features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoki</forename><surname>Yoshinaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaru</forename><surname>Kitsuregawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1542" to="1551" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">ADADELTA: An adaptive learning rate method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zeiler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1212.5701</idno>
		<imprint>
			<date type="published" when="2012-12-27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Relation classification via convolutional deep neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Computational Linguistics</title>
		<meeting>the 25th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2335" to="2344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction via piecewise convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1753" to="1762" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
