<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improving Large-Scale Fact-Checking using Decomposable Attention Models and Lexical Tagging</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nayeon</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Center (HLTC) Center for Artificial Intelligence Research (CAiRE)</orgName>
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Sheng</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Center (HLTC) Center for Artificial Intelligence Research (CAiRE)</orgName>
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascale</forename><surname>Fung</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Center (HLTC) Center for Artificial Intelligence Research (CAiRE)</orgName>
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Improving Large-Scale Fact-Checking using Decomposable Attention Models and Lexical Tagging</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1133" to="1138"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Fact-checking of textual sources needs to effectively extract relevant information from large knowledge bases. In this paper, we extend an existing pipeline approach to better tackle this problem. We propose a neural ranker using a decomposable attention model that dynamically selects sentences to achieve promising improvement in evidence retrieval F1 by 38.80%, with (×65) speedup compared to a TF-IDF method. Moreover, we incorporate lexical tagging methods into our pipeline framework to simplify the tasks and render the model more generalizable. As a result, our framework achieves promising performance on a large-scale fact extraction and verification dataset with speedup.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the rapid growth of available textual infor- mation, automatic extraction and verification, also known as fact-checking, has become important in order to identify relevant and factual information from the ever-growing information pool. The Fak- eNews Challenge (Pomerleau and Rao) addresses fact-checking as a simple stance detection prob- lem, where the article is verified by checking the stance agreement between an article's title and content. Similar to the FakeNews, ( <ref type="bibr" target="#b17">Rashkin et al., 2017;</ref><ref type="bibr" target="#b22">Vlachos and Riedel, 2014</ref>) focused on po- litical statements from Politifact.com to verify the degree of truthfulness. However, they assume that the gold standard documents containing the evi- dence are already known, which overly simplifies the task.</p><p>Question Answering (QA) is similar to fact- checking in the sense that a question and its an- swers can be considered as a claim and evidence respectively, but the answers may come from a large-scale database. Several approaches (Chen * * These two authors contributed equally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Claim</head><p>Finding Dory was written by anyone but an American.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evidence</head><p>Finding Dory: Directed by Andrew Stanton with co-direction by Angus MacLane, the screenplay was written by Stanton and Victoria Strouse Andrew Stanton: Andrew Stanton -LRB-born December 3, 1965 -RRB-is an American film director , screenwriter, producer and voice actor based at Pixar. Label REFUTE proposed QA system utilizing resources such as Wikipedia, which is more comprehensive and in- corporates wider world knowledge. However, the main focus is to identify only the "correct" an- swers that support a given question. Since the abil- ity to refute is as important as to support, it does not fully address the verification problem of fact- checking.</p><p>Recently, <ref type="bibr" target="#b21">Thorne et al. (2018)</ref> proposed a pub- lic dataset to explore the complete process of the large-scale fact-checking. It is designed not only to verify claims but also to extract sets of related evidence. Nevertheless, the pipeline solution pro- posed in that paper suffers from following prob- lems: 1) The overall performance (30.88% accu- racy) still needs further improvement to be ap- plicable to the evidence selection and classifica- tion, which also highlights the challenging na- ture of this task. 2) The evidence retrieval us- ing Term Frequency-Inverse Document Frequency (TF-IDF) is time-consuming since the TF-IDF be- tween a claim and set of candidate evidence cannot be computed in advance.</p><p>In this paper, we extend the original pipeline so- lution to achieve faster and better fact-checking re- sults. Our main contributions are: 1) Propose a neural ranker using decomposable attention (DA) model for evidence selection to speed up (×65) and outperform related works. 2) Incorporate sev- eral lexical tag information to effectively simplify  the problem and generalize the models. 3) Im- prove the overall fact extraction F1 by 38.80% and verification accuracy by 2.10% to achieve the state-of-the-art performance on the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>Our pipeline framework 1 has three main mod- ules: document retrieval (DR), evidence selection (ES), and textual entailment recognition (TER). The goal is to verify a given claim with a set of ev- idence from Wikipedia ( <ref type="table" target="#tab_0">Table 1)</ref>. The verification labels are support, refute and not enough informa- tion (NEI) to verify.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Lexical Tagging</head><p>In our framework, two lexical tags (i.e. part- of-speech (POS) and named entity recognition (NER)) are used to enhance the performance. We compute the tags for claims in advance using the Stanford CoreNLP ( ) library. Using this information is helpful in the follow- ing ways: 1) it helps keyword extraction for each claim. 2) it reduces the out-of-vocabulary (OOV) problems related to name or organization enti- ties, for better generalization. For example, a claim like "Michael Jackson and Justin Timber- lake are friends," is replaced as "PERSON-1 and PERSON-2 are friends". In this way, we encour- age our model to learn verification without dealing with the real entity values but the delexicalized in- dexed tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Document Retrieval (DR)</head><p>For document retrieval, we extend the method of DrQA (Chen et al., 2017a), which calculates co- sine similarity between query and document, us- ing binned unigram and bigram TF-IDF features.</p><p>We refer to this method as DR tf idf . Instead of directly selecting top k document us- ing TF-IDF as in DR tf idf , our document retriever DR rerank use TD-IDF to reduce the search space from 5.4M to 100 documents. Re-ranking is then applied to select the top k documents. For re-rank, we defined a score function f rank that ranks the relevance of the document by considering both the title and the content as follows:</p><formula xml:id="formula_0">r claim = POS match POS claim , r title = POS match POS title , f rank = r claim × r title × tf -idf</formula><p>To capture the relevance from the title, all the POS tags with high discriminating power (NN, NNS, NNP, NNPS, JJ, CD) of a claim are cho- sen as keywords. POS claim and POS title are the counts of such POS tags inside the claim and title respectively. POS match is the count of common POS keywords in the claim and the title; r claim is a ratio between POS match and POS claim to reward the documents with higher keyword hits; r title is the ratio between POS match and POS title to pe- nalize those documents with more candidate key- words as it is more likely to have keyword hits with more candidates. We incorporate the TF- IDF score (tf -idf ) to ensure that the content in- formation is not neglected. Our experiments show that our re-rank strategy increases the document recall compared to the single-step approach (Ta- ble 2). To decide on the optimal value for hyper- parameter k, full-pipeline performance was com- pared to evaluate the effect of k on final verifica- tion accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Evidence Selection (ES)</head><p>In this module, l sentences are extracted as pos- sible evidence for the claim. Instead of selecting the sentences by recomputing sentence-level TF- IDF features between claim and document text as in <ref type="bibr" target="#b21">Thorne et al. (2018)</ref>, we propose a neural ranker using decomposable attention (DA) model <ref type="bibr" target="#b14">(Parikh et al., 2016</ref>) to perform evidence selection. DA model does not require the input text to be parsed syntactically, nor is an ensemble, and it is faster without any recurrent structure. In general, using neural methods is better for the following reasons: 1) The TF-IDF may have limited ability to capture semantics compared to word representation learn- ing 2) Faster inference time compared to TF-IDF methods that need real-time reconstruction.</p><p>The neural ranker DA rank is trained using a fake task, which is to classify whether a given sen- tence is an evidence of a given claim or not. The  output of DA rank is considered as the evidence probability. The training samples are unbalanced since there are more unrelated sentences than ev- idence sentences. Note that the classifier's accu- racy on the fake task is not crucial because the choice of evidence is based on the relative score of relevance compared to other candidates. There- fore, it is not necessary to balance positive and negative samples using up/down-sampling, to the contrary, making it unbalanced actually improved the performance <ref type="table" target="#tab_4">(Table 3)</ref>. Unlike the k value which is fixed, the l value is selected dynamically based on the evidence score of DA rank '. It is used as a confidence measure of the given sentence being an evidence. Evidence with the score below fixed threshold value th is eliminated. Hence, each claim will have a differ- ent number of l evidence. To decide on th, we also carry out the full-pipeline evaluation. We propose the dynamic selection of l because we hypothe- size that any wrong evidence, or noise, from early module could harm the subsequent RTE module.</p><note type="other">TF-IDF DArank DArank+NER 1:1 1:4 1:9 1:1 1:4 1:9 l 2 0.</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Recognizing Textual Entailment (RTE)</head><p>Given a claim and l possible evidence, a DA rte classifier is trained to recognize the textual entail- ment to be support, refute or not enough informa- tion to verify (NEI). Same as <ref type="bibr" target="#b21">Thorne et al. (2018)</ref>, we use the decomposable attention (DA) between the claim and the evidence for RTE. DA model decomposes the RTE problem into subproblems, which can be considered as bi-direction word- level attention features. Note that the DA model is utilized over other models such as as <ref type="bibr" target="#b5">Chen et al. (2017b)</ref>; <ref type="bibr" target="#b10">Glockner et al. (2018)</ref>, because it is a simple but effective model. Our DA rte model must correctly decide whether a claim is NEI, when the evidence re- trieved is irrelevant and insufficient. However, NEI claims have no annotated evidence, thus can- not be used to train RTE. To overcome this issue, same as ( <ref type="bibr" target="#b21">Thorne et al., 2018)</ref>, the most probable NEI evidence are simulated by sampling sentences from the nearest page to the claim using the docu- ment retrieval module. MLP DA rte DA rte +NER Accuracy (%) 63. <ref type="bibr">2</ref> 78.4 79.9 <ref type="table">Table 4</ref>: Oracle RTE classification accuracy in the test set using gold evidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental setup</head><p>Dataset: FEVER dataset ( <ref type="bibr" target="#b21">Thorne et al., 2018</ref>) is a relatively large-scale dataset compared to other previous fact extraction and verification works, with around 5.4M Wikipedia documents and 185k samples. The claims are generated by altering sentences extracted from Wikipedia, with human- annotated evidence sentences and verification la- bels (e.g. <ref type="table" target="#tab_0">Table 1</ref>). The training/validation/test sets of these three datasets are split in advance by the providers. Note that the test-set was equally split into 3 classes: Supported (3333), Refuted (3333), NEI (3333).</p><p>Training: We trained our models end-to-end us- ing Adagrad optimizer <ref type="bibr" target="#b9">(Duchi et al., 2011</ref>). The embedding size is set to 200 and initialized with GloVe ( <ref type="bibr" target="#b15">Pennington et al., 2014</ref>). The dropout rate is set to 0.2. In all the datasets, we tuned the hyper-parameters with grid-search over the vali- dation set. Evaluation: For each module, we independently measure oracle performance, where we assume gold standard documents and set of evidence are provided (oracle evaluation). For the final full- pipeline, we compare to and follow the metric de- fined in <ref type="bibr" target="#b21">Thorne et al. (2018)</ref>. NoScoreEv is a sim- ple classification accuracy that only considers the correctness of the verification label. On the other hand, ScoreEv is a stricter measure that also con- siders the correctness of the retrieved evidence. Hence, it is a more meaningful measure because it considers the classification to be correct only if appropriate evidence is provided to justify the classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Oracle Performance</head><p>Document Retrieval: As shown in <ref type="table" target="#tab_2">Table 2</ref>, our count-based re-rank strategy outperforms the TF- IDF method. Take k = 1 as an example, we achieve 60.99% recall using only one document, which is ∼30% higher than TF-IDF approach. Given that the re- call upper-bound of re-rank is 0.8886 (k=100), our method manages to retrieve near the limit by just retrieving a few documents. Note that there is    a trade-off between the document recall and the noise ratio (i.e. low precision). As shown in Ta- ble 5, k = 2 with a low recall but high precision and F1 has the highest accuracy. This means DR that can effectively leverage this trade-off (there- fore, high F1) performs the best. Therefore, we select k = 2 for our full-pipeline. Evidence Selection: In <ref type="table" target="#tab_4">Table 3</ref>, the trained neu- ral ranker achieves a promising recall of 96.8%.</p><p>In the case of l = 5, our neural ranker can per- form 5% better than the TF-IDF method. Here, we use fixed l = 5 results for fair comparison with TF-IDF method. The ratios in <ref type="table" target="#tab_4">Table 3</ref> are the ra- tio of negative samples we tried to train the fake task. For example, 1:4 means that four negative sentences are sampled for each true evidence sen- tence. The results further give supports to our as- sumption that using unbalanced up-sampling actu- ally help train our neural ranker. Along with per- formance gain, we also achieve a drastic gain in inference time by around 65 times from 3.57 sec- onds to 0.055 seconds for each sample. The full-pipeline results for different values of th is shown in <ref type="table" target="#tab_7">Table 6</ref>. Similar to document re- trieval, having a high F1 score is the most im- portant factor in assuring high full-pipeline per- formance. This is because providing a succinct set of evidence makes the verification task eas- ier for the RTE module. Therefore, we choose DA rank +NER model with th = 0.6 for the full- pipeline. Recognizing Textual Entailment: The oracle classification accuracy for RTE is shown in Ta- ble 4. The MLP is a simple multi-layer percep- tron using TF and TF-IDF cosine similarity be- tween the claim and evidence as features as shown in <ref type="bibr" target="#b21">Thorne et al. (2018)</ref>. The highest accuracy achieved is 79.9% using DA rte with NER infor- mation, thus, we further evaluate the full-pipeline accuracy on this setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Full pipeline Performance</head><p>Combining each of our improved pipeline mod- ules using k = 2, th = 0.6, the full pipeline re- sults are shown in <ref type="table">Table 7</ref>. Our proposed frame- work can achieve 42.43% in ScoreEv and 52.54% in NoScoreEv, which outperforms DR tf idf +DA by 11.55% and 2.10%, respectively. The evidence retrieval F1 in our full framework is 56.3%, which is improved promisingly by 38.80%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Prior work <ref type="bibr" target="#b22">(Vlachos and Riedel, 2014;</ref><ref type="bibr">Ciampaglia et al., 2015</ref>) have proposed fact-checking through entailment from knowledge bases. Some works have investigated fact verification using PolitiFact data <ref type="bibr" target="#b23">(Wang, 2017;</ref><ref type="bibr" target="#b17">Rashkin et al., 2017)</ref> or Fak- eNews challenge (Pomerleau and Rao). Most closely related to our work, <ref type="bibr" target="#b21">Thorne et al. (2018)</ref> addresses large-scale fact extraction and verifica- tion task using a pipeline approach. In addition, question answering ( <ref type="bibr" target="#b7">Dang et al., 2007;</ref><ref type="bibr" target="#b4">Chen et al., 2017a;</ref><ref type="bibr" target="#b19">Ryu et al., 2014;</ref><ref type="bibr" target="#b0">Ahn et al., 2004</ref>) and task-oriented dialog systems ( <ref type="bibr" target="#b8">Dhingra et al., 2017</ref>   Madotto et al., 2018) also have similar aspects to these works, although aiming at a different goal. Other fields that are related to the particular in- dividual modules of our system are the following: Document and evidence retrieval for identifying text segments and documents to support a given claim <ref type="bibr" target="#b20">(Salton and Buckley, 1987;</ref><ref type="bibr" target="#b11">Le and Mikolov, 2014;</ref><ref type="bibr" target="#b3">Cartright et al., 2011;</ref><ref type="bibr" target="#b1">Bellot et al., 2013;</ref><ref type="bibr" target="#b18">Rinott et al., 2015)</ref>. Recognizing textual entail- ment that aims to determine whether a hypothesis h can justifiably be inferred from a premise ( <ref type="bibr" target="#b7">Dang et al., 2007;</ref><ref type="bibr" target="#b2">Bowman et al., 2015;</ref><ref type="bibr" target="#b14">Parikh et al., 2016;</ref><ref type="bibr" target="#b5">Chen et al., 2017b;</ref><ref type="bibr" target="#b10">Glockner et al., 2018)</ref>. In some of these work ( <ref type="bibr" target="#b18">Rinott et al., 2015;</ref><ref type="bibr" target="#b17">Rashkin et al., 2017)</ref>, the lexical and linguistic features are leveraged to further improve the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we extend the pipeline framework for fact-checking and propose a neural ranker for evidence selection. Our experiments show that the usage of lexical tagging is helpful in simplify- ing the task and improving the generalization abil- ity. Moreover, reducing noise in the input of RTE module, by de-noising the DR and SR modules, appears to be crucial for improving the overall per- formance. As a result, our ranker outperforms the TF-IDF method by 38.8% in evidence retrieval F1, with 65 times faster inference speed, achieving a promising performance in a large-scale fact ex- traction and verification dataset.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>k</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>7 :</head><label>7</label><figDesc>Full-pipeline evaluation on the test set using k = 2 and th = 0.6. The first and the second one (with *) are the baselines from Thorne et al. (2018).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Example of verified claim with evidence from 
multiple Wikipedia pages 

et al., 2017a; Ryu et al., 2014; Ahn et al., 2004) 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Oracle document retrieval macro-recall in the 
test set (SUPPORT/REFUTE). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 : Oracle evidence selection macro-recall in the test set using gold documents (SUPPORT/REFUTE).</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Effect of de-noising DR modules on RTE score 

th 

ES results 
RTE results 
Macro 
Recall 

Macro 
Precision 
F1 
Accuracy 
Evidence 
ScoreEv NoScoreEv Precision Recalll 
F1 
0.2 0.653 
0.275 
0.353 
0.405 
0.540 
0.337 
0.629 0.439 
0.4 0.607 
0.349 
0.406 
0.418 
0.542 
0.481 
0.586 0.528 
0.6 0.535 
0.368 
0.406 
0.424 
0.525 
0.618 
0.517 0.563 
0.8 0.413 
0.330 
0.348 
0.416 
0.484 
0.772 
0.400 0.527 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 : Effect of de-noising ES modules on RTE score</head><label>6</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>;</head><label></label><figDesc></figDesc><table>Model 
Label Accuracy (%) 
Label 
Evidence F1 
ScoreEv NoScoreEv Precision Recall 
F1 
DR tf idf + MLP * 
21.80 
38.75 
0.500 
0.387 0.310 
0.175 
DR tf idf + DA * 
30.88 
50.44 
0.530 
0.520 0.517 
Proposed 
42.43 
52.54 
0.533 
0.527 0.523 
0.563 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table</head><label></label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> https://github.com/HLTCHKUST/fact-checking</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Using wikipedia at the trec qa track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><surname>Jijkoun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilad</forename><surname>Mishne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karin</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Maarten De Rijke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schlobach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Buckland</surname></persName>
		</author>
		<editor>TREC. Citeseer</editor>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Overview of inex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrice</forename><surname>Bellot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shlomo</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sairam</forename><surname>Gurajada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriella</forename><surname>Kazai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marijn</forename><surname>Koolen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arunav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Véronique</forename><surname>Moriceau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josiane</forename><surname>Mothe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="269" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Samuel R Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.05326</idno>
		<title level="m">A large annotated corpus for learning natural language inference</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Evidence finding using a collection of books</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc-Allen</forename><surname>Cartright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Feild</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th ACM workshop on Online books, complementary social media and crowdsourcing</title>
		<meeting>the 4th ACM workshop on Online books, complementary social media and crowdsourcing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Reading wikipedia to answer opendomain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1870" to="1879" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Enhanced lstm for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1657" to="1668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovanni</forename><surname>Luca Ciampaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prashant</forename><surname>Shiralkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Luis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filippo</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Menczer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Flammini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">2015. tx. PloS one</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">128193</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Overview of the trec 2007 question answering track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoa</forename><forename type="middle">Trang</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Trec</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">63</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Towards end-to-end reinforcement learning of dialogue agents for information access</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiujun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faisal</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceddings of ACL</title>
		<meeting>eddings of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Breaking nli systems with sentences that require simple lexical inferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Glockner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vered</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.02266</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Mem2seq: Effectively incorporating knowledge bases into end-to-end task-oriented dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Sheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1468" to="1478" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL) System Demonstrations</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ankur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Uszkoreit</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01933</idno>
		<title level="m">A decomposable attention model for natural language inference</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Fake news challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dean</forename><surname>Pomerleau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delip</forename><surname>Rao</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Truth of varying shades: Analyzing language in fake news and political fact-checking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Hannah Rashkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><forename type="middle">Yea</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svitlana</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Volkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2931" to="2937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Show me your evidence-an automatic method for context dependent evidence detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruty</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lena</forename><surname>Dankin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><forename type="middle">Alzate</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Slonim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="440" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Open domain question answering using wikipedia-based knowledge model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pum-Mo</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myung-Gil</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun-Ki</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="683" to="692" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Term weighting approaches in automatic text retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
		<respStmt>
			<orgName>Cornell University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">FEVER: a large-scale dataset for fact extraction and verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<editor>NAACL-HLT</editor>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Christos Christodoulopoulos, and Arpit Mittal</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fact checking: Task definition and dataset construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science</title>
		<meeting>the ACL 2014 Workshop on Language Technologies and Computational Social Science</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="18" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">liar, liar pants on fire&quot;: A new benchmark dataset for fake news detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="422" to="426" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
