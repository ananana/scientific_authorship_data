<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:17+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning to Solve Arithmetic Word Problems with Verb Categorization</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Javad</forename><surname>Hosseini</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
							<email>{hosseini, hannaneh}@washington.edu, 2 OrenE@allenai.org, 3 nkushman@csail.mit.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Allen Institute for AI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Learning to Solve Arithmetic Word Problems with Verb Categorization</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="523" to="533"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper presents a novel approach to learning to solve simple arithmetic word problems. Our system, ARIS, analyzes each of the sentences in the problem statement to identify the relevant variables and their values. ARIS then maps this information into an equation that represents the problem, and enables its (trivial) solution as shown in Figure 1. The paper analyzes the arithmetic-word problems &quot;genre&quot;, identifying seven categories of verbs used in such problems. ARIS learns to categorize verbs with 81.2% accuracy, and is able to solve 77.7% of the problems in a corpus of standard primary school test questions. We report the first learning results on this task without reliance on pre-defined templates and make our data publicly available. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Designing algorithms to automatically solve math and science problems is a long-standing AI chal- lenge <ref type="bibr">(Feigenbaum and Feldman, 1963)</ref>. For NLP, mathematical word problems are particularly at- tractive because the text is concise and relatively straightforward, while the semantics reduces to simple equations.</p><p>Arithmetic word problems begin by describing a partial world state, followed by simple updates or elaborations and end with a quantitative ques- tion. For a child, the language understanding part is trivial, but the reasoning may be challenging; for our system, the opposite is true. ARIS needs to  make sense of multiple sentences, as shown in <ref type="figure" target="#fig_2">Fig- ure 2</ref>, without a priori restrictions on the syntax or vocabulary used to describe the problem. <ref type="figure" target="#fig_1">Figure  1</ref> shows an example where ARIS is asked to infer how many kittens Joan received based on facts and constraints expressed in the text, and represented by the state diagram and corresponding equation. While the equation is trivial, the text could have involved assembling toy aircraft, collecting coins, eating cookies, or just about any activity involving changes in the quantities of discrete objects. This paper investigates the task of learning to solve such problems by mapping the verbs in the problem text into categories that describe their im- pact on the world state. While the verbs category is crucial (e.g., what happens if "give" is replaced by "receive" in <ref type="figure" target="#fig_1">Figure 1</ref>?), some elements of the problem are irrelevant. For instance, the fact that three kittens have spots is immaterial to the solu- tion. Thus, ARIS has to determine what informa- tion is relevant to solving the problem.</p><p>To abstract from the problem text, ARIS maps the text to a state representation which consists of a set of entities, their containers, attributes, quan- tities, and relations. A problem text is split into fragments where each fragment corresponds to an observation or an update of the quantity of an en- tity in one or two containers. For example in <ref type="figure" target="#fig_1">Fig- ure 1</ref>, the sentence "Liz has 5 kittens left and 3 have spots" has two fragments of "Liz has 5 kit- tens left" and "3 have spots".</p><p>The verb in each sentence is associated with one or two containers, and ARIS has to classify each verb in a sentence into one of seven categories that describe the impact of the verb on the con- tainers <ref type="table" target="#tab_1">(Table 1</ref>). ARIS learns this classifier based on training data as described in section 4.2.</p><p>To evaluate ARIS, we compiled a corpus of about 400 arithmetic (addition and subtraction) word problems and utilized cross validation to both train ARIS and evaluate its performance over this corpus. We compare its performance to the template-based learning method developed independently and concurrently by <ref type="bibr" target="#b15">Kushman et al. (2014)</ref>. We find that our approach is much more robust to domain diversity between the train- ing and test sets.</p><p>Our contributions are three-fold: (a) We present ARIS, a novel, fully automated method that learns to solve arithmetic word problems; (b) We intro- duce a method to automatically categorize verbs for sentences from simple, easy-to-obtain train- ing data; our results refine verb senses in Word- Net <ref type="bibr" target="#b21">(Miller, 1995)</ref> for arithmetic word problems; (c) We introduce a corpus of arithmetic word prob- lems, and report on a series of experiments show- ing high efficacy in solving addition and subtrac- tion problems based on verb categorization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Understanding semantics of a natural language text has been the focus of many researchers in nat- ural language processing (NLP). Recent work fo- cus on learning to align text with meaning repre- sentations in specific, controlled domains. A few methods <ref type="bibr" target="#b29">(Zettlemoyer and Collins, 2005;</ref><ref type="bibr" target="#b9">Ge and Mooney, 2006</ref>) use an expensive supervision in the form of manually annotated formal representa- tions for every sentence in the training data. More recent work ( <ref type="bibr" target="#b6">Eisenstein et al., 2009;</ref><ref type="bibr" target="#b13">Kate and Mooney, 2007;</ref><ref type="bibr" target="#b23">Poon and Domingos, 2009;</ref><ref type="bibr" target="#b14">Kushman and Barzilay, 2013)</ref> reduce the amount of required supervision in mapping sentences to meaning representations while taking advantage of special properties of the domains. Our method, on the other hand, requires small, easy-to-obtain training data in the form of verb categories that are shared among many different problem types.</p><p>Our work is also closely related to the grounded language acquisition research <ref type="bibr" target="#b26">(Snyder and Barzilay, 2007;</ref><ref type="bibr" target="#b1">Branavan et al., 2009;</ref><ref type="bibr" target="#b2">Branavan et al., 2012;</ref><ref type="bibr" target="#b27">Vogel and Jurafsky, 2010;</ref><ref type="bibr" target="#b4">Chen et al., 2010;</ref><ref type="bibr" target="#b12">Hajishirzi et al., 2011;</ref><ref type="bibr" target="#b3">Chambers and Jurafsky, 2009;</ref><ref type="bibr" target="#b18">Liang et al., 2009;</ref><ref type="bibr" target="#b0">Bordes et al., 2010)</ref> where the goal is to align a text into underlying en- tities and events of an environment. These meth- ods interact with an environment to obtain super- vision from the real events and entities in the envi- ronment. Our method, on the other hand, grounds the problem into world state transitions by learn- ing to predict verb categories in sentences. In addi- tion, our method combines the representations of individual sentences into a coherent whole to form the equations. This is in contrast with the previous work that study each sentence in isolation from the other sentences.</p><p>Previous work on studying math word and logic problems uses manually aligned meaning repre- sentations or domain knowledge where the seman- tics for all the words is provided <ref type="bibr" target="#b17">(Lev, 2007;</ref><ref type="bibr" target="#b16">Lev et al., 2004</ref>). Most recently, <ref type="bibr" target="#b15">Kushman et al. (2014)</ref> introduced an algorithm that learns to align al- gebra problems to equations through the use of templates. This method applies to broad range of math problems, including multiplication, division, and simultaneous equations, while ARIS only han- dles arithmetic problems (addition and subtrac- tion). However, our empirical results show that for the problems it handles, ARIS is much more robust to diversity in the problem types between the training and test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Arithmetic Problem Representation</head><p>We address solving arithmetic word problems that include addition and subtraction. A problem text is split into fragments where each fragment is rep- resented as a transition between two world states in which the quantities of entities are updated or observed ( <ref type="figure" target="#fig_2">Figure 2</ref>). We refer to these fragments as sentences. We represent the world state as a tu- ple E, C, R consisting of entities E, containers C, and relations R among entities, containers, at- tributes, and quantities.</p><p>Entities: An entity is a mention in the text corre-N: W0-13 E: tree A: walnut Liz had 9 black kittens. She gave some of her kittens to Joan. Joan has now 11 kittens. Liz has 5 kitten left and 3 has spots. How many kittens did Joan get? <ref type="bibr">Liz</ref>  There are 42 walnut trees and 12 orange trees currently in the park. Park workers cut down 13 walnut trees that were damaged. How many walnut trees will be in the park when the workers are finished?</p><p>There are 42 walnut trees and 12 orange trees currently in the park. sponding to an object whose quantity is observed or is changing throughout the problem. For in- stance, kitten and tree are entities in <ref type="figure">Fig- ure</ref> 2. In addition, every entity has attributes that modify the entity. For instance, black is an at- tribute of kittens, and walnut is an attribute of tree (more details on attributes in section 4.1).</p><p>Relations describing attributes are invariant to the state changes. For instance kittens stay black throughout the problem of <ref type="figure" target="#fig_1">Figure 1</ref>.</p><p>Containers: A container is a mention in the text representing a set of entities. For instance, Liz, Joan, park, and workers are containers in <ref type="figure" target="#fig_2">Figure 2</ref>. Containers usually correspond to the person possessing entities or a location contain- ing entities. For example, in the sentence "There are 43 blue marbles in the basket. John found 32 marbles.", basket and John are containers of marbles.</p><p>Quantities: Containers include entities with their corresponding quantities in a particular world state. Quantities can be known numbers (e.g. 9), unknown variables (e.g. L 1 ), or numerical expres- sions over unknown quantities and numbers (e.g. 9−L 1 ). For instance, in state 2 of <ref type="figure" target="#fig_2">Figure 2</ref>, the nu- merical expression corresponding to Liz is 9−L 1 and corresponding to Joan is J 0 + L 1 , where J 0 is a variable representing the number of kittens that Joan has started with.</p><p>Hereinafter, we will refer to a generic entity as e, container as c, number as num, attribute as a. We represent the relation between a container, an entity, and a number in the form of a quantity ex-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Category</head><p>Example Observation There were 28 bales of hay in the barn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Positive</head><p>Joan went to 4 football games this year. Negative</p><p>John lost 3 of the violet balloons. Positive Transfer</p><p>Mike's dad borrowed 7 nickels from Mike.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Negative Transfer</head><p>Jason placed 131 erasers in the drawer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Construct</head><p>Karen added 1/4 of a cup of walnuts to a batch of trail mix. Destroy</p><p>The rabbits ate 4 of Dan's potatoes. pression N(c,e). <ref type="figure" target="#fig_2">Figure 2</ref> shows the quantity relations in different world states.</p><p>State transitions: Sentences depict progression of the world state ( <ref type="figure" target="#fig_2">Figure 2</ref>) in the form of ob- servations of updates of quantities. We assume that every sentence w consists of a verb v, an en- tity e, a quantity num (might be unknown), one or two containers c 1 , c 2 , and attributes a. The presence of the second container, c 2 , will be dic- tated by the category of the verb, as we discuss below. Sentences abstract transitions (s t → s t+1 ) between states in the form of an algebraic opera- tion of addition or subtraction. For every sentence, we model the state transition according to the verb category and containers in the sentence. There are three verb categories for sentences with one con- tainer: Observation: the quantity is initialized in the container, Positive: the quantity is increased in the container, and Negative: the quantity is de- creased in the container. Moreover, there are four categories for sentences with two containers: Pos-itive transfer: the quantity is transferred from the second container to the first one, Negative trans- fer: the quantity is transferred from the first con- tainer to the second one, Construct: the quantity is increased for both containers, and Destroy: the quantity is decreased for both containers. <ref type="figure" target="#fig_2">Figure 2</ref> shows how the state transitions are determined by the verb categories. The sen- tence "Liz has 9 black kittens" initializes the quantity of kittens in the container Liz to 9.</p><p>In addition, the sentence "She gave some of her kittens to Joan."</p><p>shows the negative transfer of L 1 kittens from Liz to Joan represented as N(Liz,kitten)=9-L 1 and N(Joan,kitten)=J 0 + L 1 .</p><p>Given a math word problem, ARIS grounds the world state into entities (e.g., kitten), contain- ers (e.g., Liz), attributes (e.g., black), and quan- tities (e.g., 9) (Section 4.1). In addition, ARIS learns state transitions by classifying verb cate- gories in sentences (Section 4.2). Finally, from the world state and transitions, it generates an arith- metic equation which can be solved to generate the numeric answer to the word problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Our Method</head><p>In this section we describe how ARIS maps an arithmetic word problem into an equation <ref type="figure" target="#fig_2">(Fig- ure 2</ref>). ARIS consists of three main steps (Fig- ure 3): (1) grounding the problem into entities and containers, (2) training a model to classify verb categories in sentences, and (3) solving the prob- lem by updating the world states with the learned verb categories and forming equations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Grounding into Entities and Containers</head><p>ARIS automatically identifies entities, attributes, containers, and quantities corresponding to every sentence fragment (details in <ref type="figure" target="#fig_1">Figure 3 step 1)</ref>. For every problem, this module returns a sequence of sentence fragments w 1 , . . . , w T , w x where every w t consists of a verb v t , an entity e t , its quantity num t , its attributes a t , and up to two containers c t 1 , c t 2 . w x corresponds to the question sentence inquiring about an unknown entity. ARIS applies the Stanford dependency parser, named entity rec- ognizer and coreference resolution system to the problem text <ref type="bibr" target="#b5">(de Marneffe et al., 2006;</ref><ref type="bibr" target="#b8">Finkel et al., 2005;</ref><ref type="bibr" target="#b24">Raghunathan et al., 2010)</ref>. It uses the predicted coreference relationships to replace pro- nouns (including possessive pronouns) with their coreferenent links. The named entity recognition output is used to identify numbers and people.</p><p>Entities: Entities are references to some object whose quantity is observed or changing through- out the problem. So to determine the set of entities, we define h as the set of noun types which have a dependent number (in the depen- dency parse) somewhere in the problem text. The set of entities is then defined as all noun phrases which are headed by a noun type in h. For in- stance kitten in the first sentence of <ref type="figure" target="#fig_1">Figure 1</ref> is an entity because it is modified by the number 9, while kitten in the second sentence of <ref type="figure" target="#fig_1">Fig- ure 1</ref> is an entity because kitten was modified by a number in the first sentence. Every number in the text is associated with one entity. Num- bers which are dependents of a noun are associ- ated with its entity. Bare numbers (not dependent on a noun) are associated with the previous entity in the text. The entity in the last sentence is identi- fied as the question entity e x . Finally, ARIS splits the problem text into T + 1 sentence fragments w 1 , . . . w T , w x such that each fragment contains a single entity and it's containers. For simplicity we refer to these fragments as a sentences.</p><p>Containers: Each entity is associated with one or two container noun phrases using the algorithm described in in <ref type="figure" target="#fig_4">Figure 3</ref> step 1c. As we saw earlier with numbers, arithmetic problems often include sentences with missing information. For example in <ref type="figure" target="#fig_2">Figure 2</ref>, the second container in the the sen- tence "Park workers had to cut down 13 walnut trees that were damaged." is not explicitly men- tioned. To handle this missing information, we use the circumscription assumption <ref type="bibr" target="#b20">(McCarthy, 1980)</ref>. The circumscription assumption formal- izes the commonsense assumption that things are as expected unless otherwise specified. In this set- ting, we assume that the set of containers are fixed in a problem. Thus if the container(s) for a given entity cannot be identified they are set to the con- tainer(s) for the previous entity with the same head word. For example in <ref type="figure" target="#fig_2">Figure 2</ref> we know from the previous sentence that trees were in the park. Therefore, we assume that the unmentioned con- tainer is the park.</p><p>Attributes: ARIS selects attributes A as modifiers for every entity from the dependency parser (de- tails in <ref type="figure" target="#fig_1">Figure 3 step 1a)</ref>. For example black is an attribute of the entity kitten and is an ad- jective modifier in the parser. These attributes are <ref type="bibr">1</ref>. Grounding into entities and containers: for every problem p in dataset (Section 4.1) (a) e1, . . . , eT , exp ← extract all entities and the question entity i. Extract all numbers and noun phrases (NP). ii. h ← all noun types which appear with a number as a dependant (in the dependency parse tree) somewhere in the problem text. iii. et ← all NPs which are headed by a noun type in h. iv. numt ← the dependant number of et if one exists. Bare numbers (not directly dependant on any noun phrase) are associated with the previous entity in the text. All other numt are set to unknown. v. ex ← the last identified entity. vi. at ← adjective and noun modifiers of et. Update implicit attributes using the previously observed attributes. vii. vt ← the verb with the shortest path to et in the dependency parse tree. (b) w1, . . . , wT , wxp ← split the problem text into fragments based on the entities and verbs (c) ct 1 , ct 2 , . . . , cT 1 , cT 2 , cx p ← the list of containers for each entity i. ct 1 ← the subject of wt.</p><p>If wt contains There is/are, ct 1 is the first adverb of place to the verb. ii. ct 2 ← An NP that is direct object of the verb. If not found, ct 2 is the object of the first adverbial phrase of the verb. iii. Circumscription assumption: When ct 1 or ct 2 are not found, they are set to the previous containers.</p><p>2. Training for sentence categorization (Section 4.2) (a) instances1, instances2 ← ∅ (b) for every sentence wt ∈ w1, . . . , wT , wxp in the training set: i. f eaturest ← extract features (similarity based, WordNet based, structural) (Section 4.2.1) ii. lt 1 , lt 2 ← determine labels for containers ct 1 and ct 2 based on the verb category of wt. iii. append f eaturest, lt,1, f eaturest, lt,2 to instances1, instances2. (c) M1, M2 ← train two SVMs for instances1, instances2</p><p>3. Solving: for every problem p in the test set (Section 4.3) (a) Identifying verb categories in sentences i. for every sentence wt ∈ w1, . . . , wT , wxp: A. f eaturest ← extract features (similarity based, WordNet based, structural). B. lt 1 , lt 2 ← classify wt for both containers ct 1 and ct 2 using models M1, M2.  used to prune the irrelevant information in pro- gressing world states.</p><p>Arithmetic problems usually include sentences with no attributes for the entities. For example, the attribute black has not been explicitly men- tioned for the kitten in the second sentence. In particular, ARIS updates an implicit attribute using the previously observed attribute. For example, in "Joan went to 4 football games this year. She went to 9 games last year.", ARIS assigns football as an attribute of the game in both sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training for Verb Categories</head><p>This step involves training a model to identify verb categories for sentences. This entails predicting one label (increasing, decreasing) for each (verb, container) pair in the sentence. Each possible set- ting of these binary labels corresponds to one of the seven verb categories discussed earlier. For ex- ample, if c 1 is increasing and c 2 is decreasing this is a positive transfer verb.</p><p>Our dataset includes word problems from dif- ferent domains (more details in Section 5.2). Each verb in our dataset is labeled with one of the 7 cat-egories from <ref type="table" target="#tab_1">Table 1.</ref> For training, we compile a list of sentences from all the problems in the dataset and split sentences into training and test sets in two settings. In the first setting no instance from the same domain appears in the training and test sets in order to study the robustness of our method to new prob- lem types. In the second setting no verb is re- peated in the training and test sets in order to study how well our method predicts categories of unseen verbs.</p><p>For every sentence w t in the problems, we build two data instances, (w t , c 1 ) and (w t , c 2 ), where c 1 and c 2 are containers extracted from the sentence. For every instance in the training data, we assign training labels using the verb categories of the sen- tences instead of labeling every sentence individu- ally. The verb can be increasing or decreasing cor- responding to every container in the sentence. For positive (negative) and construction (destruction) verbs, both instances are labeled positive (nega- tive). For transfer positive (negative) verbs, the first instance is labeled positive (negative) and the second instance is labeled negative (positive). For observation verbs, both instances are labeled pos- itive. We assume that the observation verbs are known (total of 5 verbs). Finally, we train Support Vector Machines given the extracted features and training labels explained above <ref type="figure" target="#fig_2">(Figure 3 step 2)</ref>. In the following, we describe the features used for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Features</head><p>There are three sets of features: similarity based, Wordnet-based, and structural features. The first two sets of features focus on the verb and the third set focuses on the dependency structure of the sen- tence. All of our features are unlexicalized. This allows ARIS to handle verbs in the test questions which are completely different from those seen in the training data.</p><p>Similarity-based Features: For every instance (w, c), the feature vector includes similarity be- tween the verb of the sentence w and a list of seed verbs. The list of seed verbs is automatically se- lected from a set V containing the 2000 most com- mon English verbs using 1 regularized feature se- lection technique. We select a small set of seed verbs to avoid dominating the other feature types (structural and WordNet-based features).</p><p>The goal is to automatically select verbs from V that are most discriminative for each of the 7 verb categories in <ref type="table" target="#tab_1">Table 1</ref>. We define 7 classifi- cation tasks: "Is a verb a member of each cate- gory?" Then, we select the three most represen- tative verbs for each category. To do so, we ran- domly select a set of 65 verbs V l , from all the verbs in our dataset (118 in total) and manually anno- tate the verb categories. For every classification task, the feature vector X includes the similarity scores (Equation 1) between the verb v and all the verbs in the V. We train an 1 regularized regres- sion model <ref type="bibr" target="#b22">(Park and Hastie, 2007</ref>) over the fea- ture vector X to learn each category individually. The number of original (similarity based) features in X is relatively large, but 1 regularization pro- vides a sparse weight vector. ARIS then selects the three most common verbs (without replacement) among the features (verbs) with non-zero weights. This accounts for 21 total seed verbs to be used for the main classification task. We find that in prac- tice using this selection technique leads to better performance than using either all the verbs in V or using just the 65 randomly selected verbs. Our method computes the similarity between two verbs v 1 and v 2 from the similarity between all the senses (from WordNet) of these verbs (Equa- tion 1). We compute the similarity between two senses using linear similarity <ref type="bibr" target="#b19">(Lin, 1998</ref>). The similarity between two synsets sv 1 and sv 2 are pe- nalized according to the order of each sense for the corresponding verb. Intuitively, if a synset appears earlier in the set of synsets of a verb, it is more likely to be considered as the correct meaning. Therefore, later occurrences of a synset should re- sult in reduced similarity scores. The similarity between two verbs v 1 and v 2 is the maximum sim- ilarity between two synsets of the verbs:</p><formula xml:id="formula_0">sim(v 1 , v 2 ) = max sv:synsets(v) lin-sim(sv 1 , sv 2 ) log(p 1 + p 2 )<label>(1)</label></formula><p>where sv 1 , sv 2 are two synsets, p 1 , p 2 are the posi- tion of each synset match, and lin-sim is the linear similarity. Our experiments show better perfor- mance using linear similarity compared to other common similarity metrics (e.g., WordNet path similarity and Resnik similarity <ref type="bibr" target="#b25">(Resnik, 1995)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>WordNet-based Features:</head><p>We use WordNet verb categories in the feature vector. For each part of speech in WordNet, the synsets are or- ganized into different categories. There are 15 categories for verbs. Some examples in-clude "verb.communication", "verb.possession", and "verb.creation". In addition, WordNet in- cludes the frequency measure f csv indicating how often the sense sv has appeared in a reference cor- pus. For each category i, we define the feature f i as the ratio of the frequency of the sense sv i over the total frequency of the verb i.e., f i = f csv i /f cv .</p><p>Structural Features: For structural features, we use the dependency relations between the verb and the sentence elements since they can be a good proxy of the sentence structure. ARIS uses a bi- nary vector including 35 dependency relations be- tween the verb and other elements. For example, in the sentence "Joan picked 2 apples from the ap- ple tree", the dependency between ('picked' and 'tree') and ('picked' and 'apples') are depicted as 'prep-from' and 'dobj' relations in the dependency parser, respectively. In addition, we include the length of the path in the dependency parse from the entity to the verb.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Solving the Problem</head><p>So far, ARIS grounds every problem into entities, containers, and attributes, and learns verb cate- gories in sentences. Solving the problem consists of two main steps: (1) progressing states based on verb categories in sentences and (2) forming the equation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">State Progression with Verb Categories</head><p>This step <ref type="figure" target="#fig_4">(Figure 3 step 3b</ref>) involves forming states s 1 , . . . , s T by updating quantities in every container using learned verb categories <ref type="figure" target="#fig_4">(Figure 3  step 3a)</ref>. ARIS initializes s 0 to an empty state. It then iteratively updates the state s t by progressing the state s t−1 given the sentence w t with the verb v, entity e, number num, and containers c 1 and c 2 .</p><p>For a given sentence t, ARIS attempts to match e t and c t to entities and categories in s t−1 . An entity/category is matched if has the same head word and same set of attributes as an existing en- tity/category. If an entity or category cannot be matching to one in s t−1 , then a new one is created in s t .</p><p>The progress subroutine prunes the irrelevant sentences by checking if the entity e and its at- tributes a agree with the question entity e x and its attributes a x in the question. For example both game entities agree with the question entity in the problem "Joan went to 4 football games this year. She went to 9 games last year. How many football games did Joan go?". The first entity has an ex- plicit football attribute, and the second entity has been assigned the same attribute (Section 4.1). Even if the question asks about games without mentioning football, the two sentences will match the question. Note that the second sentence would have not been matched if there was an ex- plicit mention of the 'basketball game' in the sec- ond sentence.</p><p>For the matched entities, ARIS initializes or up- dates the values of the containers c 1 , c 2 in the state s t . ARIS uses the learned verb categories in sen- tences (Section 4.2) to update the values of con- tainers. For an observation sentence w t , the value of c 1 in the state s t is assigned to the observed quantity num. For other sentence types, if the container c does not match to a container the pre- vious state, its value is initialized with a start vari- able C 0 . For example, the container Joan is ini- tialized with J 0 at the state s 1 <ref type="figure" target="#fig_2">(Figure 2</ref>). Other- wise, the values of c 1 and c 2 are updated according to the verb category in the sentence. For instance, if the verb category in the sentence is a positive transfer then N t (c 1 , e) = N t−1 (c 1 , e) − num and N t (c 2 , e) = N t−1 (c 2 , e) + num where N t (c, e) represents the quantity of e in the container c at state s t <ref type="figure" target="#fig_2">(Figure 2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Forming Equations and Solution</head><p>The question entity e x can match either to an en- tity in the final state, or to some unknown gener- ated during the state progression. Concretely, the question sentence w x asks about the quantity x of the entity e x in a container c x at a particular state s u or a transition after the sentence w u <ref type="figure" target="#fig_4">(Figure 3  step 3c)</ref>.</p><p>To determine if e x matches to an unknown vari- able, we define a matching subroutine between the question sentence w x and every sentence w t to check entities, containers, and verbs ( <ref type="figure" target="#fig_4">Figure 3  step 3(c)i)</ref>. We consider two cases. 1) When w x contains the words "begin", or "start", the un- known variable is about the initial value of an en- tity, and it is set to the start variable of the con- tainer c x <ref type="figure" target="#fig_4">(Figure 3 step 3(c)</ref>iii). For example, in "Bob had balloons. He gave 9 to his friends. He now has 4 balloons. How many balloons did he have to start with?", the unknown variable is set to the start variable B 0 . 2) When the question verb is not one of the defined set of observation verbs, ARIS attempts to match e x with an unknown in- troduced by one of the state transitions <ref type="figure" target="#fig_4">(Figure 3 step 3(c)</ref>iii). For example, the second sentence in <ref type="figure" target="#fig_1">Figure 1</ref> introduces an unknown variable over kittens. The matching subroutine matches this entity with the question entity since the question container, i.e. Joan, matches with the second container and verb categories are complementary.</p><p>In order to solve for the unknown variable x, ARIS searches through consecutive states s t and s t+1 , where in s t , the quantity of e x for a container c is an expression over x, and in s t+1 , the quan- tity is a known number for a container matched to c. It then forms an equation by comparing the quantities for containers matched between the two states. In the previous example, the equation will be B 0 − 9 = 4 by comparing states s 2 and s 3 , where the numerical expression over balloons is B 0 −9 in the state s 2 , and the quantity is a known number in the state s 3 .</p><p>When neither of the two above cases apply, ARIS matches e x to an entity in the final state, s T and returns its quantity, <ref type="figure" target="#fig_4">(Figure 3 step 3(c)iv)</ref>. In the football example of the previous sec- tion, the equation will be x = N t (c x , e x ), where N t (c x , e x ) is the quantity in the final state.</p><p>Finally, the equation will be solved for the un- known variable x and the absolute value of the un- known variable is returned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>To experimentally evaluate our method we build a dataset of arithmetic word problems along with their correct solutions. We test our method on the accuracy of solving arithmetic word problems and identifying verb categories in sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setup</head><p>Datasets: We compiled three diverse datasets MA1, MA2, IXL <ref type="table" target="#tab_3">(Table 2)</ref> of Arithmetic word problems on addition and subtraction for third, fourth, and fifth graders. These datasets have sim- ilar problem types, but have different characteris- tics. Problem types include combinations of ad- ditions, subtractions, one unknown equations, and U.S. money word problems. Problems in MA2 in- clude more irrelevant information compared to the other two datasets, and IXL includes more infor- mation gaps. In total, they include 395 problems, 13,632 words, 118 verbs, and 1,483 sentences.   sentences. We use the percentage of correct an- swers to the problems as the evaluation metric for the first task and accuracy as the evaluation metric for the second task. We use Weka's SVM (Wit- ten et al., 1999) with default parameters for clas- sification which is trained with verb categories in sentences (as described in Section 4.2).</p><p>For the first task, we compare ARIS with KAZB ( <ref type="bibr" target="#b15">Kushman et al., 2014</ref>), majority baseline, ARIS 2 , and Gold ARIS. KAZB requires training data in the form of equation systems and numeri- cal answers to the problems. The majority base- line classifies every instance as increasing. In ARIS 2 (a variant of ARIS) the system is trained in a way that no verb is repeated in the training and test sets. Gold ARIS uses the ground-truth sen- tence categories instead of predicted ones. For the second task, we compare ARIS with a baseline that uses WordNet verb senses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>We evaluate ARIS in solving arithmetic word problems in the three datasets and then evaluate its ability in classifying verb categories in sentences. <ref type="table" target="#tab_4">Table 3</ref> shows the accuracy of ARIS in solv- ing problems in each dataset (when trained on the other two datasets). <ref type="table" target="#tab_4">Table 3</ref> shows that ARIS significantly outperforms KAZB and the major- ity baseline. As expected, ARIS shows a larger gain on the two more complex datasets MA2 and IXL; our method shows promising results in deal- ing with irrelevant information (dataset MA2) and information gaps (dataset IXL). This is because ARIS learns to classify verb categories in sen- tences and does not require observing similar pat- terns/templates in the training data. Therefore, ARIS is more robust to differences between the training and test datasets and can generalize across different dataset types. As discussed in the ex- perimental setup, the datasets have mathematically similar problems, but differ in the natural language properties such as in the sentence length and irrel- evant information <ref type="table" target="#tab_3">(Table 2)</ref>. <ref type="table" target="#tab_4">Table 3</ref> also shows that the sentence categoriza- tion is performed with high accuracy even if the problem types and also the verbs are different. In particular, there are a total of 118 verbs among which 64 verbs belong to MA datasets and 54 are new to IXL. To further study this, we train our method ARIS 2 in which no verb can be repeated in the training and test sets. ARIS 2 still signifi- cantly outperforms KAZB. In addition, we observe only a slight change in accuracy between ARIS and ARIS 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Solving Arithmetic Problems</head><p>To further understand our method, we study the effect of verb categorization in sentences in solv- ing problems. <ref type="table" target="#tab_4">Table 3</ref> shows the results of Gold ARIS in solving arithmetic word problems with gold sentence categorizations. In addition, com- paring ARIS with Gold ARIS suggests that our method is able to reliably identify verb categories in sentences.</p><p>We also perform an experiment where we pool all of the problems in the three datasets and randomly choose 3 folds for the data (instead of putting each original dataset into it's own fold). We compare our method with KAZBin this scenario. In this setting, our method's accu- racy is 79.5% while KAZB's accuracy is 81.8%. As expected, our method's performance has not changed significantly from the previous setting, while KAZB's performance significantly improves because of the reduced diversity between the train- ing and test sets in this scenario. <ref type="table" target="#tab_6">Table 4</ref> compares accuracy scores of sentence categorization for our method with different fea- tures, a baseline that uses WordNet verb senses, and the majority baseline that assigns every (verb, container) pair as increasing. Similar to ARIS 2 , we randomly split verbs into three equal folds and assign the corresponding sentences to each fold. No verb is shared between training and test sets. We then directly evaluate the accuracy of the SVM's verb categorization (explained in Sec- tion 4.2). This table shows that ARIS performs well in classifying sentence categories even with new verbs in the test set. This suggests that our method can generalize well to predict verb cate- gories for unseen verbs. <ref type="table" target="#tab_6">Table 4</ref> also details the performance of four variants of our method that ablate various features of ARIS. The table shows that similarity, contex- tual, and WordNet features are all important to the performance of ARIS in verb categorization, whereas the WordNet features are less important for solving the problems. In addition, it shows that similarity features play more important roles. We also performed another experiment to study the ef- fect of the proposed feature selection method for similarity-based features. The accuracy of ARIS in classifying sentence categories is 69.7% when we use all the verbs in V in the similarity feature vector. This shows that our feature selection algo- rithm for selecting seed verbs is important towards categorizing verbs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Sentence Categorization</head><p>Finally, <ref type="table" target="#tab_6">Table 4</ref> shows that our method signif- icantly outperforms the baseline that only uses WordNet verb sense. An interesting observation is that the majority baseline in fact outperforms WordNet verb senses in verb categorization, but is significantly worse in solving arithmetic word problems. In addition, we evaluate the accuracy of predicting only verb categories by assigning the verb label according to the majority of its labels in the sentence categories. The accuracy of verb categories is 78.2% confirming that ARIS is able to successfully categorize verbs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Error Analysis</head><p>We analyzed all 63 errors of Gold ARIS and present our findings in <ref type="table" target="#tab_7">Table 5</ref>. There are five ma- jor classes of errors. In the first category, some in- formation is not mentioned explicitly and should be entailed. For example, 'washing cars' is the source of 'making money'. Despite the improve- ments that come from ARIS, a large portion of the errors can still be attributed to irrelevant informa- tion. For example, 'short' is not a 'toy'. The third category refers to errors that require knowledge   about set completions. For example, the 'played' games can be split into 'win' and 'lost' games. Finally, parsing and coreference mistakes are an- other source of errors for ARIS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussions and Conclusion</head><p>In this paper we introduce ARIS, a method for solving arithmetic word problems. ARIS learns to predict verb categories in sentences using syn- tactic and (shallow) semantic features from small, easy-to-obtain training data. ARIS grounds the world state into entities, sets, quantities, attributes, and their relations and takes advantage of the cir- cumscription assumption and successfully fills in the information gaps. Finally, ARIS makes use of attributes and discards irrelevant information in the problems. Together these provide a new rep- resentation and a learning algorithm for solving arithmetic word problems. This paper is one step toward building a sys- tem that can solve any math and logic word problem. Our empirical evaluations show that our method outperforms a template-based learn- ing method (developed recently by <ref type="bibr" target="#b15">Kushman et al. (2014)</ref>) on solving addition and subtraction prob- lems with diversity between the training and test sets. In particular, our method generalizes bet- ter to data from different domains because ARIS only relies on learning verb categories which al- leviates the need for equation templates for arith- metic problems. In this paper, we have focused on addition and subtraction problems. However, KAZB can deal with more general types of prob- lems such as multiplication, division, and simulta- neous equations.</p><p>We have observed a complementary behavior between our method and that of Kushman et al. This suggests a hybrid approach that can bene- fit from the strengths of both methods while be- ing applicable to more general problems while ro- bust to the errors specific to each. In addition, we plan to focus on incrementally collecting domain knowledge to deal with missing information gaps. Another possible direction is to improve parsing and coreference resolution.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Arithmetic word Problem Liz had 9 black kittens. She gave some of her kittens to Joan. Joan now has 11 kittens. Liz has 5 kittens left and 3 have spots. How many kittens did Joan get? State Transition s 1 Liz N: 9 E: Kitten A: Black Liz gave some of her kittens to Joan.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example problem and solution.</figDesc><graphic url="image-3.png" coords="1,418.70,318.47,105.55,58.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A figure sketching different steps of our method-a sequence of states.</figDesc><graphic url="image-36.png" coords="3,72.44,179.59,452.42,78.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>(b)</head><label></label><figDesc>State progression: Form s0, . . . , sT (Section 4.3.1) i. s0 ← null. ii. for t ∈ 1, . . . , T : st ← progress(st−1, wt). A. if et = ex and at = ax: if wt is an observation: Nt(ct 1 , et) = numt. else: update Nt(ct 1 , et) and Nt(ct 2 , et) given verb categories lt 1 , lt 2 . B. copy Nt−1(c, e) to Nt(c, e) for all other (c, e) pairs. (c) Forming equations and solution (Section 4.3.2) i. Mark each wt that matches with wx if: a) ct 1 matches with cx and verb categories are equal or verbs are similar. b) ct 2 matches with cx and the verbs are in opposite categories. ii. x ← the unknown quantity if wx matches with a sentence introducing an unknown number iii. If the question asks about an unknown variable x or a start variable (wx contains "begin" or "start"): For some container c, find two states st (quantity expression contains x) and st+1 (quantity is a known number). Then, form an equation for x: Nt(c, ex) = Nt+1(c, ex). iv. else: form equation as x = Nt(cx, ex). v. Solve the equation and return the absolute value of x.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: ARIS: a method for solving arithmetic word problems.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Examples for different verb categories in sen-

tences. Entities are underlined; containers are italic, and 
verbs are bolded. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 2 : Properties of the datasets.</head><label>2</label><figDesc></figDesc><table>MA1 IXL 
MA2 Total 
3-fold Cross validation 

ARIS 

83.6 
75.0 
74.4 
77.7 

ARIS2 

83.9 75.4 + 69.8 + 76.5 + 

KAZB 

89.6 
51.1 
51.2 
64.0 

Majority 

45.5 
71.4 
23.7 
48.9 
Gold sentence categorization 

Gold ARIS 

94.0 
77.1 
81.0 
84.0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Accuracy of solving arithmetic word problems in 

three datasets MA1, IXL, and MA2. This table compares 
our method, ARIS, ARIS2 with the state-of-the-art KAZB. All 
methods are trained on two (out of three) datasets and tested 
on the other one. ARIS2 is trained when no verb is repeated 
in the training and test sets. Gold ARIS uses gold verb cat-
egories. The improvement of ARIS (boldfaced) and ARIS2 
(denoted by + ) are significant over KAZB and the majority 
baseline with p &lt; 0.05. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Ablation study and baseline comparisons: this ta-

ble reports the accuracy of verb categorization in sentences 
and solutions for ARIS with ablating features. It also pro-
vides comparisons to WordNet and majority baselines. The 
improvement of ARIS (boldfaced) and ablations denoted by + 
are statistically significant over the baselines (with p &lt; 0.05) 
for both tasks. 

Error type 
Example 
Entailment, 
Implicit 
Action (26%) 

Last week Tom had $74. He washed cars 
over the weekend and now has $86. How 
much money did he make washing cars? 
Irrelevant 
Information 
(19%) 

Tom bought a skateboard for $9.46, and 
spent $9.56 on marbles. Tom also spent 
$14.50 on shorts. In total, how much did 
Tom spend on toys? 
Set Comple-
tion (13%) 
Sara's school played 12 games this year. 
They won 4 games. How many games did 
they lose? 
Parsing 
Issues (21%) 
Sally had 27 Pokemon cards. Dan gave 
her 41 new Pokemon cards. How many 
Pokemon cards does Sally have now? 
Others (21%) In March it rained 0.81 inches. It rained 
0.35 inches less in April than in March. 
How much did it rain in April? 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Examples of different error categories and relative 

frequencies. The cause of error is bolded. 

</table></figure>

			<note place="foot" n="1"> Our data is available at https://www.cs. washington.edu/nlp/arithmetic.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The research was supported by the Allen Institute for AI, and grants from the NSF (IIS-1352249) and UW-RRF (65-2775). We thank Ben Hixon and the anonymous reviewers for helpful com-ments and the feedback on the work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Label ranking under ambiguous supervision for learning semantic correspondences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">Weston</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Machine Learning (ICML)</title>
		<meeting>International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Reinforcement learning for mapping instructions to actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harr</forename><surname>Srk Branavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing of the AFNLP (ACL-AFNLP)</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language essing of the AFNLP (ACL-AFNLP)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning high-level planning from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Srk Branavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised learning of narrative schemas and their participants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing of the AFNLP (ACL-AFNLP)</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language essing of the AFNLP (ACL-AFNLP)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Training a multilingual sportscaster: Using perceptual context to learn language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joohyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="page">37</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generating typed dependency parses from phrase structure parses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Language Resources and Evaluation Conference (LREC)</title>
		<meeting>Language Resources and Evaluation Conference (LREC)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Reading to learn: Constructing features from semantic abstracts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Conference on Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Computers and Thought</title>
		<editor>Edward A. Feigenbaum and Julian Feldman</editor>
		<imprint>
			<date type="published" when="1963" />
			<publisher>McGraw Hill</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Incorporating non-local information into information extraction systems by gibbs sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Discriminative reranking for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifang</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning from natural instructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Confidence driven unsupervised semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Reasoning about robocup soccer narratives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">T</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eyal</forename><surname>Amir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conference on Uncertainty in Artificial Intelligence (UAI)</title>
		<meeting>Conference on Uncertainty in Artificial Intelligence (UAI)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning language semantics from ambiguous supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rohit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Kate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conference of the Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<meeting>Conference of the Association for the Advancement of Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Using semantic unification to generate regular expressions from natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the Annual Meeting of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>eeding of the Annual Meeting of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning to automatically solve algebra word problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Solving logic puzzles: From robust processing to precise semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iddo</forename><surname>Lev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Levy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Text Meaning and Interpretation at Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Packed Computation of Exact Meaning Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iddo</forename><surname>Lev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
		<respStmt>
			<orgName>CS, Stanford University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning semantic correspondences with less supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing of the AFNLP (ACL-AFNLP)</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language essing of the AFNLP (ACL-AFNLP)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An information-theoretic definition of similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Machine Learning (ICML)</title>
		<meeting>International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Circumscription-a form of nonmonotonic reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Mccarthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">L1-regularization path algorithm for generalized linear models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mee</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology</title>
		<imprint>
			<biblScope unit="page">69</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Unsupervised semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>Conference on Empirical Methods in Natural Language essing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A multi-pass sieve for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heeyoung</forename><surname>Karthik Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Sudarshan Rangarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Conference on Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Using information content to evaluate semantic similarity in a taxonomy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International joint conference on Artificial intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Database-text alignment via structured multilabel classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning to follow navigational directions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>of the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Weka: Practical machine learning tools and techniques with java implementations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eibe</forename><surname>Ian H Witten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard</forename><forename type="middle">E</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Trigg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sally Jo</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cunningham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conference on Uncertainty in Artificial Intelligence (UAI)</title>
		<meeting>Conference on Uncertainty in Artificial Intelligence (UAI)</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
