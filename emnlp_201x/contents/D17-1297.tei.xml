<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural Sequence-Labelling Models for Grammatical Error Correction</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Yannakoudakis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The ALTA Institute Computer Laboratory University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Rei</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The ALTA Institute Computer Laboratory University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Øistein</forename><forename type="middle">E</forename><surname>Andersen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The ALTA Institute Computer Laboratory University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Yuan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The ALTA Institute Computer Laboratory University of Cambridge</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Neural Sequence-Labelling Models for Grammatical Error Correction</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2795" to="2806"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose an approach to N-best list re-ranking using neural sequence-labelling models. We train a compositional model for error detection that calculates the probability of each token in a sentence being correct or incorrect, utilising the full sentence as context. Using the error detection model, we then re-rank the N best hypotheses generated by statistical machine translation systems. Our approach achieves state-of-the-art results on error correction for three different datasets, and it has the additional advantage of only using a small set of easily computed features that require no linguistic input.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Grammatical Error Correction (GEC) in non- native text attempts to automatically detect and correct errors that are typical of those found in learner writing. High precision and good coverage of learner errors is important in the development of GEC systems. Phrase-based Statistical Machine Translation (SMT) approaches to GEC have at- tracted considerable attention in recent years as they have been shown to achieve state-of-the-art results <ref type="bibr">(Felice et al., 2014;</ref><ref type="bibr">Junczys-Dowmunt and Grundkiewicz, 2016)</ref>. Given an ungrammatical in- put sentence, the task is formulated as "translat- ing" it to its grammatical counterpart. Using a par- allel dataset of input sentences and their corrected counterparts, SMT systems are typically trained to correct all error types in text without requir- ing any further linguistic input. To further adapt SMT approaches to the task of GEC and tackle the paucity of error-annotated learner data, previ- ous work has investigated a number of extensions, ranging from the addition of further features into the decoding process <ref type="bibr">(Felice et al., 2014</ref>) via re- ranking the SMT decoder's output ) to neural-network adaptation components to SMT <ref type="bibr" target="#b3">(Chollampatt et al., 2016a)</ref>.</p><p>In this paper, we propose an approach to N -best list re-ranking using neural sequence-labelling models. N -best list re-ranking allows for fast ex- perimentation since the decoding process remains unchanged and only needs to be performed once. Crucially, it can be applied to any GEC system that can produce multiple alternative hypotheses. More specifically, we train a neural compositional model for error detection that calculates the prob- ability of each token in a sentence being correct or incorrect, utilising the full sentence as context. Using the error detection model, we then re-rank the N best hypotheses generated by the SMT sys- tem. Detection models can be more fine-tuned to finer nuances of grammaticality and acceptability, and therefore better able to distinguish between correct and incorrect versions of a sentence.</p><p>Our approach achieves state-of-the-art results on GEC for three different datasets, and it has the additional advantage of using only a small set of easily computed features that require no linguis- tic information, in contrast to previous work that has utilised a large set of features in a supervised setting <ref type="bibr">(Hoang et al., 2016;</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Previous work</head><p>The first approaches to GEC primarily treat the task as a classification problem over vectors of contextual lexical and syntactic features extracted from a fixed window around the target token. A large body of work has investigated error-type- specific models, and in particular models targeting preposition and article errors, which are among the most frequent ones in non-native English learner writing ( <ref type="bibr" target="#b2">Chodorow et al., 2007;</ref><ref type="bibr">De Felice and Pul-man, 2008;</ref><ref type="bibr">Han et al., 2010;</ref><ref type="bibr" target="#b19">Tetreault et al., 2010;</ref><ref type="bibr">Han et al., 2006;</ref><ref type="bibr" target="#b20">Tetreault and Chodorow, 2008;</ref><ref type="bibr">Gamon et al., 2008;</ref><ref type="bibr">Gamon, 2010;</ref><ref type="bibr" target="#b12">Rozovskaya and Roth, 2010;</ref><ref type="bibr" target="#b16">Rozovskaya et al., 2012;</ref><ref type="bibr">Dale and Kilgarriff, 2011;</ref><ref type="bibr">Leacock et al., 2014</ref>). Core com- ponents of one of the top systems in the CoNLL 2013 and 2014 shared tasks on GEC ( <ref type="bibr" target="#b4">Ng et al., 2013</ref><ref type="bibr" target="#b17">Ng et al., , 2014</ref>) include Averaged Perceptron clas- sifiers, native-language error correction priors in Naive Bayes models, and joint inference frame- works capturing interactions between errors (e.g., noun number and verb agreement errors) <ref type="bibr" target="#b16">(Rozovskaya et al., 2012</ref><ref type="bibr" target="#b11">(Rozovskaya et al., , 2014</ref>). The power of the classification paradigm comes from its ability to generalise well to unseen examples, without necessarily requir- ing error-annotated learner data <ref type="bibr" target="#b14">(Rozovskaya and Roth, 2016)</ref>.</p><p>One of the first approaches to GEC as an SMT task is the one by <ref type="bibr" target="#b0">Brockett et al. (2006)</ref>, who gen- erate artificial data based on hand-crafted rules to train a model that can correct countability er- rors. <ref type="bibr">Dahlmeier and Ng (2011)</ref> focus on correct- ing collocation errors based on paraphrases ex- tracted from parallel corpora, while <ref type="bibr">Dahlmeier and Ng (2012a)</ref> are the first to investigate a discrim- inatively trained beam-search decoder for full- sentence correction, focusing on five different er- ror types: spelling, articles, prepositions, punc- tuation insertion, and noun number. <ref type="bibr" target="#b22">Yoshimoto et al. (2013)</ref> utilise SMT to tackle determiner and preposition errors, while <ref type="bibr" target="#b25">Yuan and Felice (2013)</ref> use POS-factored, phrase-based SMT systems, trained on both learner and artificially generated data to tackle determiner, preposition, noun num- ber, verb form, and subject-verb agreement errors. The SMT approach has better capacity to correct complex errors, and it only requires parallel cor- rected sentences as input.</p><p>Two state-of-the-art systems in the 2014 CoNLL shared task on correction of all errors re- gardless of type use SMT systems: <ref type="bibr">Felice et al. (2014)</ref> use a hybrid approach that includes a rule-based and an SMT system augmented by a large web-based language model and combined with correction-type estimation to filter out error types with zero precision. Junczys-Dowmunt and Grundkiewicz (2016) investigate parameter tuning based on the MaxMatch (M 2 ) scorer, the shared- task evaluation metric <ref type="bibr">(Dahlmeier and Ng, 2012b;</ref><ref type="bibr" target="#b17">Ng et al., 2014)</ref>, and experiment with different op- timisers and interactions of dense and sparse fea- tures. <ref type="bibr" target="#b17">Susanto et al. (2014)</ref> and <ref type="bibr" target="#b14">Rozovskaya and Roth (2016)</ref> explore combinations of SMT systems and classifiers, the latter showing substantial improve- ments over the CoNLL state of the art. <ref type="bibr" target="#b3">Chollampatt et al. (2016a)</ref> integrate a neural net- work joint model that has been adapted using native-language-specific learner text as a feature in SMT, while <ref type="bibr">Chollampatt et al. (2016b)</ref> inte- grate a neural network global lexicon model and a neural network joint model to exploit continuous space representations of words rather than discrete ones, and learn non-linear mappings.  present a Neural Machine Transla- tion (NMT) model and propose an approach that tackles the rare-word problem in NMT.  and <ref type="bibr">Mizumoto and Matsumoto (2016)</ref> employ supervised discriminative methods to re-rank the SMT decoder's N -best list output based on language model and syntac- tic features respectively. <ref type="bibr">Hoang et al. (2016)</ref> also exploit syntactic features in a supervised frame- work, but further extend their approach to generate new hypotheses. Our approach is similar in spirit, but differs in the following aspects: inspired by the work of <ref type="bibr" target="#b10">Rei and Yannakoudakis (2016)</ref> who tackle error detection rather than correction within a neural network framework, we develop a neu- ral sequence-labelling model for error detection to calculate the probability of each token in a sen- tence as being correct or incorrect; using the error detection model, we propose a small set of features that require no linguistic processing to re-rank the N best hypotheses. We evaluate our approach on three different GEC datasets and achieve state- of-the-art results, outperforming all previous ap- proaches to GEC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Datasets</head><p>We use the First Certificate in English (FCE) dataset <ref type="bibr" target="#b21">(Yannakoudakis et al., 2011)</ref>, and the NUS Corpus of Learner English (NUCLE) <ref type="bibr">(Dahlmeier et al., 2013</ref>) that was used in the CoNLL GEC shared tasks. Both datasets are annotated with the language errors committed and suggested cor- rections from expert annotators. The former con- sists of upper-intermediate learner texts written by speakers from a number of different native lan- guage backgrounds, while the latter consists of es- says written by advanced undergraduate university students from an Asian language background. We use the public FCE train/test split, and the NUCLE train/test set used in CoNLL 2014 (the test set has been annotated by two different annotators).</p><p>We also use the publicly available Lang-8 cor- pus ( <ref type="bibr">Mizumoto et al., 2012;</ref><ref type="bibr" target="#b18">Tajiri et al., 2012)</ref> and the JHU FLuency-Extended GUG corpus (J- FLEG) ( <ref type="bibr">Napoles et al., 2017)</ref>. Lang-8 contains learner English from lang-8.com, a language- learning social networking service, which has been corrected by native speakers. JFLEG is a newly released corpus for GEC evaluation that contains fluency edits to make the text more native-like in addition to correcting grammatical errors, and contains learner data from a range of proficiency levels.</p><p>We use Lang-8 and the FCE and CoNLL train- ing sets to train our neural sequence-labelling model, and test correction performance on JFLEG, and the FCE and CoNLL test sets. For JFLEG, we use the 754 sentences on which <ref type="bibr">Napoles et al. (2017)</ref> have already benchmarked four leading GEC systems. As our development set, we use a subset of the FCE training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Neural sequence labelling</head><p>We treat error detection as a sequence labelling task and assign a label to each token in the input sentence, indicating whether it is correct or incor- rect in context. These binary gold labels can be automatically extracted from the manual error an- notation available in our data (see Section 3). Sim- ilarly to <ref type="bibr" target="#b10">Rei and Yannakoudakis (2016)</ref>, we con- struct a bidirectional recurrent neural network for detecting writing errors. The system receives a se- ries of tokens [w 1 ...w T ] as input, and predicts a probability distribution over the possible labels for each token.</p><p>Every token w t is first mapped to a token rep- resentation x t , which is also optimised during training. These embeddings are composed to- gether into context-specific representations using a bidirectional LSTM (Hochreiter and Schmidhu- ber, 1997):</p><formula xml:id="formula_0">− → h t = LSTM( x t , − − → h t−1 )<label>(1)</label></formula><formula xml:id="formula_1">← − h t = LSTM( x t , ← − − h t+1 )<label>(2)</label></formula><formula xml:id="formula_2">h t = [ − → h t ; ← − h t ]<label>(3)</label></formula><p>where x t is the token representation at position t, − → h t is the hidden state of the forward-moving LSTM, ← − h t is the hidden state of the backward- moving LSTM, and h t is the concatenation of both hidden states. A feedforward hidden layer with tanh activation is then used to map the rep- resentations from both directions into a more suit- able combined space, and allow the model to learn higher-level features:</p><formula xml:id="formula_3">d t = tanh W d h t (4)</formula><p>where W d is a weight matrix. Finally, a softmax output layer predicts the label distribution for each token, given the input sequence:</p><formula xml:id="formula_4">P (y t |w 1 ...w T ) = softmax W o d t (5)</formula><p>where W o is an output weight matrix. We also make use of the character-level archi- tecture proposed by , allowing the model to learn morphological patterns and capture out-of-vocabulary words. Each individual char- acter is mapped to a character embedding and a bidirectional LSTM is used to combine them to- gether into a character-based token representation. This vector m, constructed only from individual characters, is then combined with the regular to- ken embedding x t using an adaptive gating mech- anism:</p><formula xml:id="formula_5">z = σ ( W z 1 · tanh(W z 2 x t + W z 3 m) ) (6) x t = z · x t + (1 − z) · m (7)</formula><p>where W z 1 , W z 2 and W z 3 are weight matrices, z is a dynamically calculated gating vector, and x t is the resulting token representation at position t.</p><p>We optimise the model by minimising cross- entropy between the predicted label distributions and the annotated labels. In addition to training the error detection objective, we make use of a multi-task loss function and train specific parts of the architecture as language models. This provides the model with a more informative loss function, while also encouraging it to learn more general compositional features and acting as a regulariser <ref type="bibr" target="#b8">(Rei, 2017)</ref>. First, two extra hidden layers are con- structed: <ref type="figure">Figure 1</ref>: Error detection network architecture that is repeated for all the words in a sentence (illustra- tion for the word "cat").</p><formula xml:id="formula_6">− → m t = tanh − → W m − → h t (8)</formula><formula xml:id="formula_7">← − m t = tanh ← − W m ← − h t (9)</formula><p>where − → W m and ← − W m are direction-specific weight matrices, used for connecting a forward or back- ward LSTM hidden state to a separate layer. The surrounding tokens are then predicted based on each hidden state using a softmax output layer:</p><formula xml:id="formula_8">P (w t+1 |w 1 ...w t ) = softmax − → W q − → m t (10) P (w t−1 |w t ...w T ) = softmax ← − W q ← − m t (11)</formula><p>During training, the following cost function is minimised, which combines the error detection loss function with the two language modeling ob- jectives:</p><formula xml:id="formula_9">E = − T ∑ t=1 log P (y t |w t ...w T ) − γ T −1 ∑ t=1 log P (w t+1 |w 1 ...w t ) − γ T ∑ t=2 log P (w t−1 |w t ...w T ) (12)</formula><p>where γ is a weight that controls the importance of language modeling in relation to the error detec- tion objective. <ref type="figure">Figure 1</ref> shows the error detection network architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental settings</head><p>All digits in the text are replaced with the char- acter '0'. Tokens that occur less than 2 times in the training data share an out-of-vocabulary (OOV) token embedding, whereas the character- level component still operates over the original to- kens. The model hyperparameters are tuned based on F 0.5 on the FCE development set (Section 3) and γ is set to 0.1. <ref type="bibr">1</ref> The model is optimised us- ing Adam ( <ref type="bibr">Kingma and Ba, 2015)</ref>, and training is stopped when F 0.5 does not improve on the de- velopment set over 5 epochs. Token representa- tions have size 300 and are initialised with pre- trained word2vec embeddings trained on Google News ( <ref type="bibr">Mikolov et al., 2013</ref>). The character rep- resentations have size 50 and are initialised ran- domly. The LSTM hidden layers have size 200 for each direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Error detection performance</head><p>Rei and Yannakoudakis (2016)'s error detection framework uses token-level embeddings, bidirec- tional LSTMs for context representation, and a multi-layer architecture for learning more com- plex features. They train their model on the public FCE training set, and benchmark their re- sults on the FCE and CoNLL test sets (Baseline LSTM FCE ). We also train and test our detection model on the same data and evaluate the effec- tiveness of our approach (LSTM FCE ). In <ref type="table" target="#tab_1">Table 1</ref>, we can see that our architecture achieves a higher performance on both FCE and CoNLL, and par- ticularly for FCE (7% higher F 0.5 ) and CoNLL test annotation 2 (around 2% higher F 0.5 ). When we use a larger training set that also includes the CoNLL training data and the public Lang-8 cor- pus (see Section 3), performance improves even further (LSTM), particularly for CoNLL test an- notation 1 (at least 8% higher F 0.5 compared to LSTM FCE ). We use this model in the experiments reported in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Statistical machine translation</head><p>SMT attempts to identify the 1-best correction hy- pothesis c * of an input sentence s that maximises the following:   <ref type="bibr">et al., 2003</ref>) in that they use phrases as "trans- lation" units and therefore allow many-to-many "translation" mappings. The translation model is decomposed into a phrase-translation probability model and a phrase re-ordering probability model, and the 1-best correction hypothesis is of the fol- lowing log-linear form <ref type="bibr" target="#b6">(Och and Ney, 2002</ref>):</p><formula xml:id="formula_10">c * = arg max c p LM (c) p(s|c)<label>(13)</label></formula><formula xml:id="formula_11">c * = arg max c exp K ∑ i=1 λ i h i (c, s)<label>(14)</label></formula><p>where h represents a feature function (e.g., phrase- translation probability) and λ the feature weight.</p><p>In this work, we employ two SMT systems:   <ref type="bibr">2</ref> and Junczys-Dowmunt and <ref type="bibr">Grundkiewicz (2016)</ref>. We apply our re-ranking approach to each SMT system's N -best list us- ing features derived from the neural sequence- labelling model for error detection described in the previous section, improve each of the SMT systems, and achieve state-of-the-art results on all three GEC datasets: FCE, CoNLL and JFLEG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">N -best list re-ranking</head><p>For each SMT system, we generate the list of all the 10 best candidate hypotheses. We then use the following set of features (tuned on the FCE de- velopment set, see Section 3) to assign a score to each candidate, and determine a new ranking for each SMT model:</p><p>Sentence probability: Our error detection model outputs a probabilty indicating whether a token is likely to be correct or incorrect in context. We therefore use as a feature the overall sentence probability, calculated based on the probability of each of its tokens being correct: ∑ w log P (w)</p><p>Levenshtein distance: We first use Levenshtein distance (LD) to identify which tokens in the orig- inal/source sentence have been corrected by the candidate hypothesis. We then identify the tokens that our detection model predicts as incorrect (i.e., the probability of being incorrect is greater than 0.5). These give us two different sets of annota- tions for the source sentence: tokens in the source sentence that the candidate hypothesis identifies as incorrect; and tokens in the source sentence that the error detection model identifies as incorrect.</p><p>We then convert these annotations to binary se- quences -i.e., 1 if the token is identified as in- correct, and 0 otherwise -and use as a feature the LD between those binary representations. More specifically, we would like to select the candidate sentence that has the smallest LD from the binary sequence created by the detection model: 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LD</head><p>True and false positives: Given the binary se- quences described above, we also use as a feature the ratio of true positives (TP) to false positives (FP) by treating the error detection model as the "gold standard". Specifically, we count how many times the candidate hypothesis agrees or not with the detection model on the tokens identified as in- correct: TP</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FP</head><p>We use a linear combination of the above three scores together with the overall score (i.e., original rank) given by the SMT system (we do not include any other SMT features) to re-rank each SMT sys- tem's 10-best list in an unsupervised way. The new 1-best correction hypothesis c * is then the one that maximises:  where h represents the score assigned to candidate hypothesis c according to feature i; λ is a param- eter that controls the effect feature i has on the fi- nal ranking; and K = 4 as we have four different features (three features presented in this section, plus the original score output by the SMT system). λs are tuned on the FCE development set and are set to 1, except for the sentence probability feature which has λ = 1.5. <ref type="bibr">3</ref> </p><formula xml:id="formula_12">c * = arg max c K ∑ i=1 λ i h i (c)<label>(15)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation</head><p>We evaluate the effectiveness of our re-ranking ap- proach on three different datasets: FCE, CoNLL 2014 and JFLEG. We report F 0.5 using the shared task's M 2 scorer (Dahlmeier and Ng, 2012b), and GLEU scores ( <ref type="bibr">Napoles et al., 2015</ref>). The latter is based on a variant of BLEU ( <ref type="bibr" target="#b7">Papineni et al., 2002</ref>) that is designed to reward correct edits and penalise ungrammatical ones. As mentioned in Section 5, we re-rank the 10-best lists of two SMT systems: Yuan et al. (2016) (CAMB16 SMT ) and Junczys-Dowmunt and Grundkiewicz (2016) (AMU16 SMT ). The results are presented in <ref type="table" target="#tab_3">Table  2</ref>.</p><p>We replicate the AMU16 SMT system to obtain the 10-best output, and report results using this <ref type="bibr">3</ref> We experimented with a small set of values (from 0 to 2 with increments of .1), though not exhaustively. version (AMU16 <ref type="bibr">SMT (replicated)</ref> ). Compared to the original results on CoNLL reported in their paper (AMU16 SMT (reported) ), we obtain slightly lower performance. <ref type="bibr">4</ref> We can see that AMU16 SMT is the current state of the art on CoNLL, with an F 0.5 of 49.49. On the other hand, CAMB16 SMT generalises better on FCE and JFLEG: 52.90 and 52.44 F 0.5 respectively. The lower performance of AMU16 SMT can be attributed to the fact that it is tuned for the CoNLL shared task.</p><p>The current state of the art on FCE is a neural machine translation system, CAMB16 <ref type="bibr">NMT (Yuan and Briscoe, 2016)</ref>, which is also the best model on JFLEG in terms of GLEU. The rest of the base- lines we report are: <ref type="bibr" target="#b14">Rozovskaya and Roth (2016)</ref>  <ref type="table">Table 3</ref>: Ablation tests on the FCE test set when removing one feature of the re-ranking system at a time.</p><p>When using our LSTM detection model to re- rank the 10-best list (+ LSTM), we can see that performance improves across all three datasets for both SMT systems. F 0.5 performance of CAMB16 SMT on FCE improves from 52.90 to 54.15, on CoNLL from 37.33 to 39.53, and on JF- LEG from 52.44 to 53.50 (the latter demonstrat- ing that the detection model also helps with flu- ency edits). This improved result is also better than the state of the art CAMB16 NMT on FCE. <ref type="bibr">6</ref> When looking at AMU16 SMT , we can see that re- ranking (+ LSTM) further improves the best re- sult on CoNLL from 49.34 (replicated) to 49.66 F 0.5 , and there is a similar level of improvement for both FCE and JFLEG.</p><p>As a further experiment, we re-train our er- ror detection model on the same training data as CAMB16 SMT (+ LSTM camb ). More specifically, we use the Cambridge Learner Corpus (CLC) <ref type="bibr" target="#b5">(Nicholls, 2003)</ref>, a collection of learner texts of various proficiency levels, written in response to exam prompts and manually annotated with the errors committed (around 2M sentence pairs). In <ref type="table" target="#tab_3">Table 2</ref>, we can see that the detection model fur- ther improves performance across all datasets and SMT systems. Compared to just doing SMT with CAMB16 SMT , re-ranking improves F 0.5 from 52.90 to 55.60 on FCE (performance increases further even though CAMB16 SMT 's training set includes a large set of FCE data), from 37.33 to 42.44 on CoNLL, and from 52.44 to 54.66 on JFLEG. The largest improvement is on CoNLL (5%), which is likely because CoNLL is not in- cluded in the training set. AMU16 SMT (replicated) is specifically tuned for CoNLL; nevertheless, the detection model also improves F 0.5 on CoNLL from 49.34 to 51.08. Re-ranking using a small set of detection-based features produces state-of-the-art results on all three datasets (we note that CAMB16 SMT generalises better across all).</p><p>We next run ablation tests to investigate the extent to which each feature contributes to per- formance. Results obtained on the FCE test set after excluding each of the features of the 'CAMB16 SMT + LSTM camb ' re-ranking system are presented in <ref type="table">Table 3</ref>. Overall, all features have a positive effect on performance, though the sen- tence probability feature does have the biggest im- pact: its removal is responsible for a 1.47 and 1.11 decrease of F 0.5 and GLEU respectively. A similar pattern is observed on the other datasets too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Oracle</head><p>To calculate an upper bound per SMT system per dataset, we calculate character-level LD between each candidate hypothesis in the 10-best list and the gold corrected sentence. We then calculate an oracle score by selecting the candidate hypothe- sis that has the smallest LD. Essentially the or- acle is telling us the maximum performance that can be obtained with the given 10-best list on each dataset. For datasets for which we have more than one annotation available, we select the oracle that gives the highest F 0.5 .</p><p>In <ref type="table" target="#tab_3">Table 2</ref>, we can see that, overall, CAMB16 SMT has a higher oracle performance compared to AMU16 SMT . More specifically, the maximum attainable F 0.5 on FCE is 71.60, on CoNLL 58.13, and on JFLEG 61.92. This shows empirically that the 10-best list has great potential and should be exploited further. AMU16 SMT has a lower oracle performance overall, though again this can be attributed to the fact that it is specifically tuned for CoNLL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">N -best list size</head><p>Next, we examine performance as the N -best list varies in size, ranging from 1 to 10 <ref type="table">(Table 4)</ref>. We observe a positive effect: the larger the size, the better the model for all datasets. F 0.5 does not seem to have reached a plateau with n &lt; 10, which suggests that increasing the size of the list further can potentially lead to better results. We do, however, observe that large improvements are obtained when increasing the size from 1 to 3, sug- gesting that, most of the time, better alternatives are identified within the top 3 candidate hypothe- ses. This, however, is not the case for the ora- cle (F oracle 0.5 ), which consistently increases as n gets larger.  <ref type="table">Table 4</ref>: Re-ranking performance using LSTM camb as the N -best list varies in size from 1 to 10 for CAMB16 SMT and its oracle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Error type performance</head><p>In <ref type="table">Table 5</ref>, we can see example source sentences, together with their corrected counterparts (refer- ence), 1-best candidates by CAMB16 SMT and 1- best candidates by CAMB16 SMT + LSTM camb . Re-ranking seems to fix errors such as subject- verb agreement ("the Computer help" to "the com- puter helps") and verb form ("I recommend you to visit" to "I recommend visiting"). In this section, we perform an analysis of performance per type to get a better understanding of where the strength of the re-ranking detection model comes from.</p><p>Until recently, GEC performance per error type was only analysed in terms of recall, as sys- tem output is not annotated. Recently, however, <ref type="bibr" target="#b1">Bryant et al. (2017)</ref> proposed an approach to automatically annotating GEC output with error type information, which utilises a linguistically- enhanced alignment to automatically extract the edits between pairs of source sentences and their corrected counterparts, and a dataset-independent rule-based classifier to classify the edits into er- ror types. Human evaluation showed that the pre- dicted error types were rated as "Good" or "Ac- ceptable" 95% of the time. We use their pub- licly available code to analyse per-error-type per- formance before and after re-ranking. <ref type="table">Table 6</ref> presents the performance for a sub- set of error types that are affected the most before and after re-ranking CAMB16 SMT on the FCE test set. The error types are inter- preted as follows: Missing error; Replace er- ror; Unnecessary error. The largest improve- ment is observed in replacement errors referring to possessive nouns (R:NOUN:POSS) and verb Source I work with children an the Computer help my Jop bat affeted to CAMB16 SMT I work with children and the Computer help my Jop bat affeted to CAMB16 SMT + LSTM camb I work with children and the computer helps my Jop bat affeted to Reference I work with children and the computer helps me in my job but affects it too Source It takes 25 minutes that is convenient to us CAMB16 SMT It takes 25 minutes that is convenient for us CAMB16 SMT + LSTM camb It takes 25 minutes , which is convenient for us Reference It takes 25 minutes , which is convenient for us Source I recommend to visit CAMB16 SMT I recommend you to visit CAMB16 SMT + LSTM camb I recommend visiting Reference I recommend visiting it Source Especially youngsters misuse this kind of invention CAMB16 SMT Especially youngsters misuse this kind of invention CAMB16 SMT + LSTM camb In particular , youngsters misuse this kind of invention Reference Especially youngsters misuse this kind of invention <ref type="table">Table 5</ref>: Source sentences along with gold corrections (reference), 1-best candidates by CAMB16 SMT and by CAMB16 SMT + LSTM camb . agreement (R:VERB:SVA); and in unnecessary errors referring to adverbs (U:ADV), determin- ers (U:DET), pronouns (U:PRON), and verb tense (U:VERB:TENSE).</p><p>The LSTM architecture allows the network to learn advanced composition rules and remem- ber dependencies over longer distances (e.g., R:VERB:SVA improves from 58.38 to 69.40). The network's language modelling objectives al- low it to learn better and more general com- positional features (e.g., U:ADV improves from 13.51 to 22.73), while the character-level archi- tecture facilitates modelling of morphological pat- terns [e.g., replacement errors referring to verb form (R:VERB:FORM) improve from 53.62 to 58.06]. Between M, R, and U errors, the largest improvement is observed in U, for which there is at least 5% improvement in F 0.5 . <ref type="bibr">7</ref> Overall, re-ranking improves F 0.5 across error types; however, there is a small subset that is  <ref type="table">Table 6</ref>: Error-type performance before and af- ter re-ranking on the FCE test set (largest impact highlighted in bold; bottom part of the table dis- plays negative effects on performance).</p><p>negatively affected <ref type="table">(Table 6</ref>, bottom part); for example, performance on missing errors refer- ring to verb form (M:VERB:FORM) drops from 50.00 to 38.46, and on replace contraction errors (R:CONTR) from 50.00 to 27.78. Importantly, such an analysis allows us to examine the strengths and weaknesses of the models, which is key for the deployment of GEC systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>To the best of our knowledge, no prior work has in- vestigated the impact of detection models on cor- rection performance. We proposed an approach to N -best list re-ranking using a neural sequence- labelling model that calculates the probability of each token in a sentence being correct or incor- rect in context. Detection models can be more fine-tuned to finer nuances of grammaticality, and therefore better able to distinguish between correct and incorrect versions of a sentence. Using a lin- ear combination of a small set of features derived from the detection model output, we re-ranked the N -best list of SMT systems and achieved state-of- the-art results on GEC on three different datasets. Our approach can be applied to any GEC system that produces multiple alternative hypotheses. Our results demonstrate the benefits of integrating de- tection approaches with correction systems, and how one can complement the other. Sepp <ref type="bibr">Hochreiter and Jürgen Schmidhuber. 1997</ref>. Long short-term memory. Neural Computation, 9.</p><p>Marcin Junczys-Dowmunt and Roman Grundkiewicz. 2016. Phrase-based machine translation is state-of- the-art for automatic grammatical error correction. arXiv preprint arXiv:1605.06353. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 : Token-level error detection performance of our detection models (LSTM FCE and LSTM) on</head><label>1</label><figDesc></figDesc><table>FCE and the two CoNLL 2014 test set annotations. Baseline LSTM FCE and LSTM FCE are trained only 
on the public FCE training set. 

A Language Model (LM) is used to estimate the 
correction hypothesis probability p LM (c) from a 
corpus of correct English, and a translation model 
to estimate the conditional p(s|c) from a paral-
lel corpus of corrected learner sentences. State-
of-the-art SMT systems are phrase-based (Koehn 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>2799 FCE test set</head><label>2799</label><figDesc></figDesc><table>CoNLL test set 
JFLEG 
P 
R 
F 0.5 
GLEU P 
R 
F 0.5 
GLEU P 
R 
F 0.5 
GLEU 

Baseline 
CAMB16 SMT 
63.27 31.95 52.90 70.15 45.39 21.82 37.33 64.90 65.56 29.12 52.44 46.10 
Our work 
CAMB16 SMT + LSTM 
65.03 32.45 54.15 70.72 49.58 21.84 39.53 65.68 65.86 30.56 53.50 46.74 
CAMB16 SMT + LSTM camb 
64.25 36.13 55.60 71.76 51.09 25.30 42.44 66.42 65.41 32.97 54.66 47.72 
Oracle 
80.53 49.62 71.60 78.54 68.77 35.90 58.13 70.42 73.45 38.03 61.92 50.64 

Baseline 
AMU16 SMT (reported) 
− 
− 
− 
− 
61.27 27.98 49.49 − 
− 
− 
43.20 41.70 
AMU16 SMT (replicated) 
46.94 13.75 31.66 63.73 61.15 27.84 49.34 68.23 69.22 18.56 44.77 41.98 
Our work 
AMU16 SMT (replicated) + LSTM 
40.67 17.36 32.06 63.57 58.79 30.63 49.66 68.26 60.68 22.65 45.43 42.65 
AMU16 SMT (replicated) + LSTM camb 43.34 19.88 35.07 64.78 59.88 32.16 51.08 68.69 64.12 25.06 48.88 43.26 
Oracle 
71.54 26.69 53.54 69.52 76.47 35.97 62.41 71.18 79.10 27.47 57.49 45.00 

Other baselines 
VT16 SMT + classifiers 
− 
− 
− 
− 
60.17 25.64 47.40 − 
− 
− 
− 
− 
NUS16 SMT+NNJM 
− 
− 
− 
− 
− 
− 
44.27 − 
− 
− 
52.70 46.30 
NUS16 SMT + re-ranker 
− 
− 
− 
− 
50.35 23.84 41.19 − 
− 
− 
− 
− 
CAMB16 NMT 
− 
− 
53.49 71.16 − 
− 
39.90 65.59 − 
− 
50.80 47.20 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Using the neural sequence-labelling model for error detection ('+ LSTM' or '+ LSTM camb ') to 
re-rank the 10-best lists of two SMT systems -Yuan et al. (2016) (CAMB16 SMT ) and Junczys-Dowmunt 
and Grundkiewicz (2016) (AMU16 SMT ). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head></head><label></label><figDesc>, who explore combinations of SMT systems and classifiers (VT16 SMT + classifiers); Chollampatt et al. (2016a), who integrate a neural network joint model that has been adapted using native- language-specific learner text as a feature in SMT (NUS16 SMT+NNJM ); and Hoang et al. (2016), who perform supervised N -best list re-ranking using a large set of features, and further extend their ap- proach to generate new hypotheses (NUS16 SMT + re-ranker). 5 CAMB16 SMT + LSTM camb Ablated feature F 0.5 GLEU None 55.60 71.76 Sentence probability 54.13 70.65 Levenshtein distance 55.42 71.78 True/false positives 55.14 71.75</figDesc><table></table></figure>

			<note place="foot" n="2"> Yuan et al. (2016) propose a supervised N-best list reranking approach; however, we only use their baseline SMT system.</note>

			<note place="foot" n="4"> The differences are likely to be caused by different versions of the NLTK tokeniser and/or Moses. 5 We note that Napoles et al. (2017) use an updated version of GLEU to evaluate AMU16SMT (reported), NUS16SMT+NNJM and CAMB16NMT on JFLEG. We therefore also use this updated version throughout all GLEU evaluations on JFLEG.</note>

			<note place="foot" n="6"> We note that CAMB16NMT outperforms the re-ranking approach by Yuan et al. (2016).</note>

			<note place="foot" n="7"> U improves from 38.44 to 43.77; M from 43.43 to 45.40; R from 53.25 to 55.33.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Special thanks to Christopher Bryant, Mariano Fe-lice, and Ted Briscoe, as well as the anonymous reviewers for their valuable contributions at vari-ous stages.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Correcting ESL errors using phrasal SMT techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>William B Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Automatic annotation and evaluation of error types for grammatical error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Bryant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariano</forename><surname>Felice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Detection of grammatical errors involving prepositions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Na-Rae</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth ACLSIGSEM workshop on prepositions</title>
		<meeting>the fourth ACLSIGSEM workshop on prepositions</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="25" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adapting grammatical error correction based on the native language of writers with neural network joint models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shamil</forename><surname>Chollampatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duc</forename><forename type="middle">Tam</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1901" to="1911" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The CoNLL2013 shared task on grammatical error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hwee Tou Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><surname>Siew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanbin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Hadiwinoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tetreault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth Conference on Computational Natural Language Learning: Shared Task</title>
		<meeting>the Seventeenth Conference on Computational Natural Language Learning: Shared Task</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The Cambridge Learner Corpus-error coding and analysis for lexicography and ELT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Nicholls</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Corpus Linguistics 2003 Conference</title>
		<meeting>the Corpus Linguistics 2003 Conference</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Discriminative training and maximum entropy models for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="295" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting on association for computational linguistics</title>
		<meeting>the 40th annual meeting on association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semi-supervised multitask learning for sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Rei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Attending to characters in neural sequence labeling models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Rei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">O</forename><surname>Gamal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Crichton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pyysalo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Computational Linguistics (COLING-2016)</title>
		<meeting>the 26th International Conference on Computational Linguistics (COLING-2016)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Compositional sequence labeling models for error detection in learner writing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Rei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Yannakoudakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The IllinoisColumbia system in the CoNLL-2014 shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alla</forename><surname>Rozovskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sammons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task</title>
		<meeting>the Eighteenth Conference on Computational Natural Language Learning: Shared Task</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="34" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Generating confusion sets for context-sensitive error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alla</forename><surname>Rozovskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="961" to="970" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Algorithm selection and model adaptation for ESL correction tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alla</forename><surname>Rozovskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="924" to="933" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Grammatical error correction: Machine translation and classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alla</forename><surname>Rozovskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2205" to="2215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">University of Illinois system in HOO text correction shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alla</forename><surname>Rozovskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sammons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Gioja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th European Workshop on Natural Language Generation</title>
		<meeting>the 13th European Workshop on Natural Language Generation</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="263" to="266" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The UI system in the HOO 2012 shared task on error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alla</forename><surname>Rozovskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sammons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Workshop on Building Educational Applications Using NLP</title>
		<meeting>the Seventh Workshop on Building Educational Applications Using NLP</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="272" to="280" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">System combination for grammatical error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond Hendy</forename><surname>Susanto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Phandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="951" to="962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Tense and aspect error correction for ESL learners using global context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshikazu</forename><surname>Tajiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mamoru</forename><surname>Komachi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="198" to="202" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Using parse features for preposition selection and error detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2010 conference short papers</title>
		<meeting>the ACL 2010 conference short papers</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="353" to="358" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The ups and downs of preposition error detection in ESL writing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Joel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chodorow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="865" to="872" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A new dataset and method for automatically grading esol texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Yannakoudakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Medlock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="180" to="189" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">NAIST at 2013 CoNLL grammatical error correction shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ippei</forename><surname>Yoshimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoya</forename><surname>Kose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kensuke</forename><surname>Mitsuzawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoya</forename><surname>Mizumoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuta</forename><surname>Hayashibe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mamoru</forename><surname>Komachi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL Shared Task</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="26" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Grammatical error correction using neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="380" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Candidate re-ranking for SMT-based grammatical error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariano</forename><surname>Felice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications</title>
		<meeting>the 11th Workshop on Innovative Use of NLP for Building Educational Applications</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="256" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Constrained grammatical error correction using statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariano</forename><surname>Felice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth Conference on Computational Natural Language Learning: Shared Task</title>
		<meeting>the Seventeenth Conference on Computational Natural Language Learning: Shared Task</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="52" to="61" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
