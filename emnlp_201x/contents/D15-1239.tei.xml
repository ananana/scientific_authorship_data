<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Talking to the crowd: What do people react to in online discussions?</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Jaech</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicky</forename><surname>Zayats</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Fang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Talking to the crowd: What do people react to in online discussions?</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper addresses the question of how language use affects community reaction to comments in online discussion forums, and the relative importance of the message vs. the messenger. A new comment ranking task is proposed based on community annotated karma in Reddit discussions , which controls for topic and timing of comments. Experimental work with discussion threads from six subred-dits shows that the importance of different types of language features varies with the community of interest.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Online discussion forums are a popular platform for people to share their views about current events and learn about issues of concern to them. Discus- sion forums tend to specialize on different topics, and people participating in them form communi- ties of interest. The reaction of people within a community to comments posted provides an indi- cation of community endorsement of opinions and value of information. In most discussions, the vast majority of comments spawn little reaction. In this paper, we look at whether (and how) language use affects the reaction, compared to the relative im- portance of the author and timing of the post.</p><p>Early work on factors that appear to influence crowd-based judgments of comments in the Slash- dot forum ( <ref type="bibr" target="#b8">Lampe and Resnick, 2004</ref>) indicate that timing, starting score, length of the comment, and poster anonymity/reputation appear to play a role (where anonymity has a negative effect). Judging by differences in popularity of various discussion forums, topic is clearly important. Ev- idence that language use also matters is provided by recent work (Danescu-Niculescu-Mizil et al., <ref type="bibr">2012</ref>; <ref type="bibr" target="#b7">Lakkaraju et al., 2013;</ref><ref type="bibr" target="#b0">Althoff et al., 2014;</ref><ref type="bibr" target="#b13">Tan et al., 2014</ref>). Teasing these different factors apart, however, is a challenge. The work presented in this paper provides additional insight into this question by controlling for these factors in a dif- ferent way than previous work and by examining multiple communities of interest. Specifically, us- ing data from Reddit discussion forums, we look at the role of author reputation as measured in terms of a karma k-index, and control for topic and tim- ing by ranking comments in a constrained window within a discussion.</p><p>The primary contributions of this work include findings about the role of author reputation and variation across communities in terms of aspects of language use that matter, as well as the problem formulation, associated data collection, and devel- opment of a variety of features for characterizing informativeness, community response, relevance and mood.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>Reddit 1 is the largest public online discussion fo- rum with a wide variety of subreddits, which makes it a good data source for studying how tex- tual content in a discussion impacts the response of the crowd. On Reddit, people initiate a dis- cussion thread with a post (a question, a link to a news item, etc.), and others respond with com- ments. Registered users vote on which posts and comments are important. The total amount of up votes minus the down votes (roughly) is called karma; it provides an indication of community en- dorsement and popularity of a comment, as used in ( <ref type="bibr" target="#b7">Lakkaraju et al., 2013</ref>). Karma is valued as it impacts the order in which the posts or comments are displayed, with the high karma content rising to the top. Karma points are also accumulated by members of the discussion forum as a function of the karma associated with their comments.  The Reddit data is highly skewed. Although there are thousands of active communities, only a handful of them are large. Similarly, out of the more than a million comments made per day 2 , most of them receive little to no attention; the dis- tributions of positive comment karma and author karma are Zipfian. Slightly more than half of all comments have exactly one karma point (no votes beyond the author), and only 5% of comments have less than one karma point.</p><p>For this study, we downloaded all the posts and associated comments made to six subreddits over a few weeks, as summarized in <ref type="table">Table 1</ref>, as well as karma of participants in the discussion 3 . All avail- able comments on each post were downloaded at least 48 hours after the post was made. <ref type="bibr">4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Uptake Factors</head><p>Factors other than the language use that influence whether a comment will have uptake from the community include the topic, the timing of the message, and the messenger. These factors are all evident in the Reddit discussions. Some subred- dits are more popular and thus have higher karma comments than others, reflecting the influence of topic. Comments that are posted early in the dis- cussion are more likely to have high karma, since they have more potential responses.</p><p>Previous studies on Twitter show that the rep- utation of the author substantially increases the chances of the retweet ( <ref type="bibr" target="#b12">Suh et al., 2010;</ref><ref type="bibr" target="#b2">Cha et al., 2010)</ref>, and reputation is also raised as a fac- tor in Slashdot ( <ref type="bibr" target="#b8">Lampe and Resnick, 2004</ref>). On Reddit most users are anonymous, but it is possi- ble that members of a forum become familiar with particular usernames associated with high karma comments. In order to see how important per- 2 http://www.redditblog.com/2014/12/reddit-in-2014.html <ref type="bibr">3</ref> Our data collection is available online at https://ssli.ee.washington.edu/tial/data/reddit 4 Based on our initial look at the data, we noticed that most posts receive all of their comments within 48 hours. Some comments are deleted before we are able to download them.  sonal reputation is, we looked at how often the top karma comments are associated with the top karma participants in the discussion. Since an in- dividual's karma can be skewed by a few very pop- ular posts, we measure reputation instead using a measure we call the k-index, defined to be equal to the number of comments in each user's history that have karma ≥ k. The k-index is analgous to the h-index ( <ref type="bibr" target="#b5">Hirsch, 2005</ref>) and arguably a better indicator of extended impact than total karma. The results in <ref type="table" target="#tab_2">Table 2</ref> address the question of whether the top karma comments always come from the top karma person. The Top1 column shows the percentage of threads where the top karma comment in a discussion happens to be made by the highest k-index person participating in the discussion; the next column shows the per- centage of threads where the comment comes from any one of the top 3 k-index people. We find that, in fact, the highest karma comment in a dis- cussion is rarely from the highest k-index people. The highest percentage is in ASKSCIENCE, where expertise is more highly valued. If we consider whether any one of the multiple comments that the top k-index person made is the top karma com- ment in the discussion, then the frequency is even lower.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Tasks</head><p>Having shown that the reputation of the author of a post is not a dominating factor in predicting high karma comments, we propose to control for topic and timing by ranking a set of 10 comments that were made consecutively in a short window of time within one discussion thread according to the karma they finally received. The ranking has access to the comment history about these posts. This simulates the view of an early reader of these posts, i.e., without influence of the ratings of oth-ers, so that the language content of the post is more likely to have an impact. Very long threads are sampled, so that these do not dominate the set of lists. Approximately 75% of the comment lists are designated for training and the rest is for testing, with splits at the discussion thread level. Here, feature selection is based on mean precision of the top-ranked comment (P@1), so as to empha- size learning the rare high karma events. (Note that P@1 is equivalent to accuracy but allows for any top-ranking comment to count as correct in the case of ties.) The system performance is evaluated using both P@1 and normalized discounted cumu- lative gain (NDCG) ( <ref type="bibr" target="#b1">Burges et al., 2005</ref>), which is a standard criterion for ranking evaluation when the samples to be ranked have meaningful differ- ences in scores, as is the case for karma of the comments.</p><p>In addition, for analysis purposes, we report re- sults for three surrogate tasks that can be used in the ranking problem: i) the binary ranker trained on all comment pairs within each list, in which low karma comments dominate, ii) a positive vs. neg- ative karma classifier, and iii) a high vs. medium karma classifier. All use class-balanced data; the second two are trained and tested on a biased sam- pling of the data, where the pairs need not be from the same discussion thread.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Classifier</head><p>We use the support vector machine (SVM) rank algorithm <ref type="bibr" target="#b6">(Joachims, 2002</ref>) to predict a rank or- der for each list of comments. The SVM is trained to predict which of a pair of comments has higher karma. The error term penalty parameter is tuned to maximize P@1 on a held-out validation set (20% of the training samples).</p><p>Since much of the data includes low-karma comments, there will be a tendancy for the learn- ing to emphasize features that discriminate com- ments at the lower end of the scale. In order to learn features that improve P@1, and to under- stand the relative importance of different features, we use a greedy automatic feature selection pro- cess that incrementally adds one feature whose re- sulting feature set achives the highest P@1 on the validation set. Once all features have been used, we select the model with the subset of features that obtains the best P@1 on the validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Features</head><p>The features are designed to capture several key at- tributes that we hypothesize are predictive of com- ment karma motivated by related work. The fea- tures are categorized in groups as summarized be- low, with details in supplementary material.</p><p>• Graph and Timing (G&amp;T): A baseline that captures discourse history (response structure) and comment timing, but no text content.</p><p>• Authority and Reputation (A&amp;R): K-index, whether the commenter was the original poster, and in some subreddits "flair" (display next to a comment author's username that is subject to a cursory verification by moderators).</p><p>• Informativeness (Info.): Different indicators suggestive of informative content and novelty, including various word counts, named entity counts, urls, and unseen n-grams.</p><p>• Lexical Unigrams (Lex.): Miscellaneous word class indicators, puncutation, and part-of- speech counts • Predicted Community Response (Resp.):</p><p>Probability scores from surrogate classification tasks (reply vs. no reply, positive vs. negative sentiment) to measure the community response of a comment using bag-of-words predictors.</p><p>• Relevance (Rel.): Comment similarity to the parent, post and title in terms of topic, computed with three methods: i) a distributed vector rep- resentation of topic using a non-negative matrix factorization (NMF) model ( <ref type="bibr" target="#b15">Xu et al., 2003)</ref>, ii) the average of skip-gram word embeddings ( <ref type="bibr" target="#b10">Mikolov et al., 2013)</ref>, and iii) word set Jaccard similarity ( <ref type="bibr" target="#b11">Strehl et al., 2000</ref>).</p><p>• Mood: Mean and std. deviation of sentence sen- timent in the comment; word list indicators for politeness, argumentativeness and profanity.</p><p>• Community Style (Comm.): Posterior proba- bility of each subreddit given the comment us- ing a bag-of-words model. The various word lists are motivated by fea- ture exploration studies in surrogate tasks. For example, projecting words to a two dimensional space of positive vs. negative and likelihood of reply showed that self-oriented pronouns were more likely to have no response and second- person pronouns were more likely to have a neg- ative response. The politeness and argumentative- ness/profanity lists are generated by starting with hand-specified seed lists used to train an SVM to classify word embeddings ( <ref type="bibr" target="#b10">Mikolov et al., 2013</ref>) into these categories, and expanding the lists with 500 words farthest from the decision boundary.</p><p>Both the NMF and the skip-gram topic models use a cosine distance to determine topic similarity, with 300 as the word embedding dimension. Both are trained on approximately 2 million comments in high karma posts taken across a wide variety of subreddits. We use topic models in various mea- sures of comment relevance to the discussion, but we do not use topic of the comment on its own since topic is controlled for by ranking within a thread.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Ranking Experiments</head><p>We present three sets of experiments on comment karma ranking, all of which show very differ- ent behavior for the different subreddits. <ref type="figure" target="#fig_1">Fig. 1</ref> shows the relative gain in P@1 over the G&amp;T baseline associated with using different feature groups. The importance of the different features reflect the nature of the different communities. The authority/reputation features help most for ASKSCIENCE, consistent with our k-index study. Informativeness and relevance help all subred- dits except ASKMEN and WORLDNEWS. Lexical, mood and community style features are useful in some cases, but hurt others. The predicted proba- bility of a reply was least useful, possibly because of the low-karma training bias. <ref type="table" target="#tab_4">Tables 3 and 4</ref> summarize the results for the P@1 and NDCG criteria using the greedy selec- tion procedure (which optimizes P@1) compared to a random baseline and the G&amp;T baseline. The random baseline for P@1 is greater than 10% be- cause of ties. The G&amp;T baseline results show that the graph and timing features alone obtain 21-32%    they are so rare. Although our feature selection tunes for high rank precision, it is possible that the low-karma data dominate the learning. Alter- natively, it may be that language cues are mainly useful for identifying distinguishing the negative or mid-level karma comments, and that the very high karma comments are a matter of timing. To better understand the role of language for these different types, we trained classifiers on balanced data for positive vs. negative karma and high vs. mid levels of karma. For these models, the training pairs could come from different threads, but topic is controlled for in that all topic features are rela- tive (similarity to original post, parent, etc.). We compared the results to the binary classifier used in ranking, where all pairs are considered. In all three cases, random chance accuracy is 50%. <ref type="table" target="#tab_6">Table 5</ref> shows the pairwise accuracy of these classifiers. We find that distinguishing positive from negative classes is fairly easy, with the no- table exception of the more information-oriented subreddit ASKSCIENCE. Averaging across the dif- ferent subreddits, the high vs. mid task is slightly easier than the general ranking task, but the vari- ation across subreddits is substantial. The high vs. mid distinction for FITNESS falls below chance (likely overtraining), whereas it seems to be an easier task for the ASKWOMEN, ASKMEN, and WORLDNEWS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Interest in social media is rapidly growing in re- cent years, which includes work on predicting the popularity of posts, comments and tweets. Danescu-Niculescu- <ref type="bibr" target="#b4">Mizil et al. (2012)</ref> investigate phrase memorability in the movie quotes. <ref type="bibr" target="#b3">Cheng et al. (2014)</ref> explore prediction of information cascades on Facebook. <ref type="bibr" target="#b14">Weninger et al. (2013)</ref> analyze the hierarchy of the Reddit discussions, topic shifts, and popularity of the comment, us- ing among the others very simple language anal- ysis. <ref type="bibr" target="#b9">Lampos et al. (2014)</ref> study the problem of predicting a Twitter user impact score (determined by combining the numbers of user's followers, fol- lowees, and listings) using text-based and non- textual features, showing that performance im- proves when user participation in particular topics is included.</p><p>Most relevant to this paper are studies of the ef- fect of language in popularity predictions. <ref type="bibr" target="#b13">Tan et al. (2014)</ref> study how word choice affects the pop- ularity of Twitter messages. As in our work, they control for topic, but they also control for the pop- ularity of the message authors. On Reddit, we find that celebrity status is less important than it is on Twitter since on Reddit almost everyone is anony- mous. <ref type="bibr" target="#b7">Lakkaraju et al. (2013)</ref> study how timing and language affect the popularity of posting im- ages on Reddit. They control for content by only making comparisons between reposts of the same image. Our focus is on studying comments within a discussion instead of standalone posts, and we analyze a vast majority of language features. <ref type="bibr" target="#b0">Althoff et al. (2014)</ref> use deeper language analysis on Reddit to predict the success of receiving a pizza in the Random Acts of Pizza subreddit. To our knowledge, this is the first work on ranking com- ments in terms of community endorsement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This paper addresses the problem of how language affects the reaction of community in Reddit com- ments. We collect a new dataset of six subredit dis- cussion forums. We introduce a new task of rank- ing comments based on karma in Reddit discus- sions, which controls for topic and timing of com- ments. Our results show that using language fea- tures improve the comment ranking task in most of the subreddits. Informativeness and relevance are the most broadly useful feature categories; rep- utation matters for ASKSCIENCE, and other cate- gories could either help or hurt depending on the community. Future work involves improving the classification algorithm by using new approaches to learning about rare events.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Relative improvement in P@1 over G&amp;T for individual feature groups.</figDesc><graphic url="image-1.png" coords="4,79.09,62.81,204.09,153.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Percentage of discussions where the top 
comment is made by the top k-index person (or top 
3 people) in the discussion. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Test set precision of top one prediction 
(P@1) performance for specific subreddits. 

subreddit 
Random G&amp;T 
All 

ASKSCIENCE 

0.53 
0.60 
0.60 

FITNESS 

0.57 
0.61 
0.62 

POLITICS 

0.55 
0.61 
0.62 

ASKWOMEN 

0.56 
0.62 
0.65 

ASKMEN 

0.56 
0.66 
0.66 

WORLDNEWS 

0.54 
0.61 
0.60 

Improvement 
-
12.5% 13.2% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Test set ranking NDCG performance for 
specific subreddits. 

of top karma comments depending on subreddits. 
Adding the textual features gives an improvement 
in P@1 performance over the G&amp;T baseline for 
all subreddits except ASKMEN and WORLDNEWS. 
The trends for performance measured with NDCG 
are similar, but the benefit from textual features is 
smaller. The results in both tables show different 
ways of reporting performance of the same sys-
tem, but the system has been optimized for P@1 
in terms of feature selection. In initial exploratory 
experiments, this seems to have a small impact: 
when optimizing for NDCG in feature selection 
we obtain 0.61 vs. 0.60 with the P@1-optimized 
features. 
A major challenge with identifying high karma 
comments (and negative karma comments) is that 

subreddit 
Pos/Neg High/Mid Ranking 

ASKSCIENCE 

44.5 
63.7 
61.3 

FITNESS 

74.7 
43.9 
57.5 

POLITICS 

95.5 
59.1 
58.0 

ASKWOMEN 

82.5 
67.6 
59.7 

ASKMEN 

87.0 
66.2 
60.6 

WORLDNEWS 

93.3 
69.9 
57.3 

Average 
79.6 
61.7 
59.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Accuracy of binary classifiers trained on 
balanced data to distinguish: positive vs. nega-
tive karma (Pos/Neg), high vs. mid-level karma 
(High/Mid), and ranking between any pair (Rank-
ing). </table></figure>

			<note place="foot" n="1"> http://www.reddit.com</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">How to ask for a favor: A case study on the success of altruistic requests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Althoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICWSM</title>
		<meeting>ICWSM</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning to rank using gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Renshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Lazier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Deeds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicole</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Hullender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Measuring user influence in twitter: The million follower fallacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meeyoung</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Haddadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabricio</forename><surname>Benevenuto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P Krishna</forename><surname>Gummadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICWSM</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">30</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Can cascades be predicted?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lada</forename><surname>Adamic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Dow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><forename type="middle">Michael</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">You had me at hello: How phrasing affects memorability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An index to quantify an individual&apos;s scientific research output</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><forename type="middle">E</forename><surname>Hirsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="16569" to="16572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Optimizing search engines using clickthrough data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><forename type="middle">Joachims</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGKDD</title>
		<meeting>SIGKDD</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">What&apos;s in a name? understanding the interplay between titles, content, and communities in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himabindu</forename><surname>Lakkaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Julian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICWSM</title>
		<meeting>ICWSM</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Slash(dot) and burn: distributed moderation in a large online conversation space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cliff</forename><surname>Lampe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Resnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="543" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Predicting and characterizing user impact on Twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Lampos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaos</forename><surname>Aletras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Preotiucpietro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the European Chapter of the ACL</title>
		<meeting>the Conference of the European Chapter of the ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="405" to="413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Impact of similarity measures on web-page clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Strehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joydeep</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Artificial Intelligence for Web Search</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Want to be retweeted? Large scale analytics on factors impacting retweet in Twitter network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bongwon</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichan</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Pirolli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SocialCom</title>
		<meeting>SocialCom</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="177" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The effect of wording on message propagation: Topic-and author-controlled natural experiments on Twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenhao</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An exploration of discussion threads in social news sites: A case study of the reddit community</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Weninger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avi</forename><surname>Xihao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ASONAM</title>
		<meeting>ASONAM</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Document clustering based on non-negative matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihong</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
