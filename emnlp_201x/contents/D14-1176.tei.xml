<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dependency-Based Bilingual Language Models for Reordering in Statistical Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 25-29, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Garmash</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Informatics Institute</orgName>
								<orgName type="institution">University of Amsterdam Science</orgName>
								<address>
									<addrLine>Park 904</addrLine>
									<postCode>1098 XH</postCode>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Informatics Institute</orgName>
								<orgName type="institution">University of Amsterdam Science</orgName>
								<address>
									<addrLine>Park 904</addrLine>
									<postCode>1098 XH</postCode>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Dependency-Based Bilingual Language Models for Reordering in Statistical Machine Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1689" to="1700"/>
							<date type="published">October 25-29, 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper presents a novel approach to improve reordering in phrase-based machine translation by using richer, syntactic representations of units of bilingual language models (BiLMs). Our method to include syntactic information is simple in implementation and requires minimal changes in the decoding algorithm. The approach is evaluated in a series of Arabic-English and Chinese-English translation experiments. The best models demonstrate significant improvements in BLEU and TER over the phrase-based baseline, as well as over the lexicalized BiLM by Niehues et al. (2011). Further improvements of up to 0.45 BLEU for Arabic-English and up to 0.59 BLEU for Chinese-English are obtained by combining our dependency BiLM with a lexicalized BiLM. An improvement of 0.98 BLEU is obtained for Chinese-English in the setting of an increased distortion limit.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In statistical machine translation (SMT) reorder- ing (also called distortion) refers to the order in which source words are translated to generate the translation in the target language. Word orders can differ significantly across languages. For in- stance, Arabic declarative sentences can be verb- initial, while the corresponding English translation should realize the verb after the subject, hence re- quiring a reordering. Determining the correct re- ordering during decoding is a major challenge for SMT. This problem has received a lot of attention in the literature (see, e.g., <ref type="bibr">Tillmann (2004)</ref>, <ref type="bibr">Zens and Ney (2003)</ref>, <ref type="bibr" target="#b0">Al-Onaizan and Papineni (2006)</ref>), as choosing the correct reordering improves read- ability of the translation and can have a substan- tial impact on translation quality <ref type="bibr" target="#b1">(Birch, 2011)</ref>. In this paper, we only consider those approaches that include a reordering feature function into the log- linear interpolation used during decoding.</p><p>The simplest reordering model is linear distor- tion ( <ref type="bibr" target="#b12">Koehn et al., 2003)</ref> which scores the distance between phrases translated at steps t and t + 1 of the derivation. This model ignores any contex- tual information, as the distance between trans- lated phrases is its only parameter. Lexical dis- tortion modeling <ref type="bibr">(Tillmann, 2004</ref>) conditions re- ordering probabilities on the phrase pairs trans- lated at the current and previous steps. Unlike linear distortion, it characterizes reordering not in terms of distance but type: monotone, swap, or discontinuous.</p><p>In this paper, we base our approach to reorder- ing on bilingual language models ( <ref type="bibr" target="#b17">Marino et al., 2006;</ref><ref type="bibr" target="#b19">Niehues et al., 2011</ref>). Instead of directly characterizing reordering, they model sequences of elementary translation events as a Markov pro- cess. <ref type="bibr">1</ref> Originally, <ref type="bibr" target="#b17">Marino et al. (2006)</ref> used this kind of model as the translation model, while more recently it has been used as an additional model in PBSMT systems <ref type="bibr" target="#b19">(Niehues et al., 2011</ref>). We adopt and generalize the approach of <ref type="bibr" target="#b19">Niehues et al. (2011)</ref> to investigate several variations of bilingual language models. Our method consists of labeling elementary translation events (tokens of bilingual LMs) with their different contextual properties.</p><p>What kind of contextual information should be incorporated in a reordering model? Lexical in- formation has been used by <ref type="bibr">Tillmann (2004)</ref> but is known to suffer from data sparsity <ref type="bibr">(Galley and Manning, 2008)</ref>. Also previous contributions to bilingual language modeling ( <ref type="bibr" target="#b17">Marino et al., 2006;</ref><ref type="bibr" target="#b19">Niehues et al., 2011</ref>) have mostly used lexical information, although <ref type="bibr" target="#b8">Crego and Yvon (2010a)</ref> and <ref type="bibr" target="#b9">Crego and Yvon (2010b)</ref> label bilingual to-kens with a rich set of POS tags. But in gen- eral, reordering is considered to be a syntactic phe- nomenon and thus the relevant features are syn- tactic <ref type="bibr" target="#b11">(Fox, 2002;</ref><ref type="bibr" target="#b4">Cherry, 2008)</ref>. Syntactic in- formation is incorporated in tree-based approaches in SMT, allowing one to provide a more detailed definition of translation events and to redefine de- coding as parsing of a source string ( <ref type="bibr" target="#b16">Liu et al., 2006;</ref><ref type="bibr">Huang et al., 2006;</ref><ref type="bibr" target="#b18">Marton and Resnik, 2008)</ref>, of a target string <ref type="bibr" target="#b24">(Shen et al., 2008)</ref>, or both <ref type="bibr" target="#b5">(Chiang, 2007;</ref><ref type="bibr" target="#b6">Chiang, 2010)</ref>. Reordering is a result of a given derivation, and CYK-based decoding used in tree-based approaches is more syntax-aware than the simple PBSMT decoding algorithm. Although tree-based approaches poten- tially offer a more accurate model of translation, they are also a lot more complex and requiring more intricate optimization and estimation tech- niques <ref type="bibr">(Huang and Mi, 2010)</ref>.</p><p>Our idea is to keep the simplicity of PBSMT but move towards the expressiveness typical of tree- based models. We incrementally build up the syn- tactic representation of a translation during decod- ing by adding precomputed fragments from the source parse tree. The idea to combine the mer- its of the two SMT paradigms has been proposed before, where <ref type="bibr">Huang and Mi (2010)</ref> introduce in- cremental decoding for a tree-based model. On a very general level, our approach is similar to theirs in that it keeps track of a sequence of source syn- tactic subtrees that are being translated at consec- utive decoding steps. An important difference is that they keep track of whether the visited subtrees have been fully translated, while in our approach, once a syntactic structural unit has been added to the history, it is not updated anymore.</p><p>In this paper, we focus on source syntactic in- formation. During decoding we have full access to the source sentence, which allows us to obtain a better syntactic analysis (than for a partial sen- tence) and to precompute the units that the model operates with. We investigate the following re- search questions: How well can we capture re- ordering regularities of a language pair by incor- porating source syntactic parameters into the units of a bilingual language model? What kind of source syntactic parameters are necessary and suf- ficient?</p><p>Our contributions can be summarized as fol- lows: We argue that the contextual information used in the original bilingual models <ref type="bibr" target="#b19">(Niehues et al., 2011</ref>) is insufficient and introduce a simple model that exploits source-side syntax to improve reordering (Sections 2 and 3). We perform a thor- ough comparison between different variants of our general model and compare them to the original approach. We carry out translation experiments on multiple test sets, two language pairs (Arabic- English and Chinese-English), and with respect to two metrics (BLEU and TER). Finally, we present a preliminary analysis of the reorderings resulting from the proposed models (Section 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Motivation</head><p>In this section, we elaborate on our research ques- tions and provide background for our approach. We also discuss existing bilingual n-gram mod- els and argue that they are often not expressive enough to differentiate between alternative re- orderings. We should first note that the most com- monly used n-gram model to distinguish between reorderings is a target language model, which does not take translation correspondence into account and just models target-side fluency. <ref type="bibr" target="#b0">Al-Onaizan and Papineni (2006)</ref> show that target language models by themselves are not sufficient to cor- rectly characterize reordering. In what follows we only discuss bilingual models.</p><p>The word-aligned sentence pair in <ref type="figure" target="#fig_1">Figure 1</ref>.a 2 demonstrates a common Arabic-English reorder- ing. As stated in the introduction, bilingual lan- guage models capture reordering regularities as a sequence of elementary translation events 3 . In the given example, one could decompose the sequen- tial process of translation as follows: First trans- late the first word Alwzyr as the minister, then ArjE as attributed, then ArtfAE as the increase and so on. The sequence of elementary translation events is modeled as an n-gram model (Equation 1, where t i is a translation event). There are numerous ways in which t i can be defined. Below we first discuss how they have been defined within previous ap- proaches, and then introduce our definition.</p><formula xml:id="formula_0">p(t 1 , . . . , t m ) = m i=1 p(t i |t i−n+1 . . . t i−1 ) (1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Lexicalized bilingual LMs</head><p>By including both source and target information into the representation of translation events we ob-  tain a bilingual LM. The richer representation al- lows for a finer distinction between reorderings. For example, Arabic has a morphological marker of definiteness on both nouns and adjectives. If we first translate a definite adjective and then an indefinite noun, it will probably not be a likely se- quence according to the translation model. This kind of intuition underlies the model of Niehues et al. (2011), a bilingual LM (BiLM), which defines elementary translation events t 1 , ..., t n as follows:</p><formula xml:id="formula_1">t i = e i , {f |f ∈ A(e i )}},<label>(2)</label></formula><p>where e i is the i-th target word and A : E → P(F ) is an alignment function, E and F refer- ring to target and source sentences, and P(·) is the powerset function. In other words, the i-th trans- lation event consists of the i-th target word and all source words aligned to it. <ref type="bibr" target="#b19">Niehues et al. (2011)</ref> refer to the defined translation events t i as bilin- gual tokens and we adopt this terminology. There are alternative definitions of bilingual language models. Our choice of the above defi- nition is supported by the fact that it produces an unambiguous segmentation of a parallel sentence into tokens. Ambiguous segmentation is unde- sirable because it increases the token vocabulary, and thus the model sparsity. Another disadvan- tage comes from the fact that we want to compare permutations of the same set of elements. For ex- ample, the two different segmentations of ba into <ref type="bibr">[ba]</ref> and <ref type="bibr">[b]</ref>[a] still represent the same permuta- tion of the sequence ab. In <ref type="figure" target="#fig_1">Figure 1</ref> one can pro- duce a segmentation of (AsEAr Albtrwl, oil prices) into (Albtrwl, oil) and (AsEAr, prices) or leave it as is. If we allow for both segmentations, the learnt probability parameters may be different for the sum of (Albtrwl, oil) and (AsEAr, prices) and for the unsegmented phrase.  <ref type="formula" target="#formula_1">(2011)</ref> as the original BiLM. <ref type="bibr">4</ref> At the same time, we do not see any specific obstacles for combining our work with MTUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Suitability of lexicalized BiLM to model reordering</head><p>As mentioned in the introduction, lexical informa- tion is not very well-suited to capture reordering regularities. Consider <ref type="figure">Figure 2</ref>.a. The extracted sequence of bilingual tokens is produced by align- ing source words with respect to target words (so that they are in the same order), as demonstrated by the shaded part of the picture. If we substituted the Arabic translation of Egyptian for the Arabic translation of Israeli, the reordering should remain the same. What matters for reordering is the syn- tactic role or context of a word. By using unneces- sarily fine-grained categories we risk running into sparsity issues.   <ref type="figure">Figure 2</ref>: Arabic-English parallel sentence, automatically parsed and word-aligned, with corresponding sequences of bilingual tokens (in the shaded part). Comparison between translations produced via correct (a) and incorrect (b) reorderings. rect and incorrect reorderings, see <ref type="figure">Figure 2</ref>.b. Al- though the corresponding sequence of POS-tag- substituted bilingual tokens is different from the correct sequence ( <ref type="figure">Figure 2</ref>.b, shaded part), it still is a likely sequence. Indeed, the log-probabilities of the two sequences with respect to a 4-gram BiLM model 5 result in a higher probability of −10.25 for the incorrect reordering than for the correct one (−10.39).</p><formula xml:id="formula_2">JJ NNS TO JJ NNS VBD NNS!NNP VBD!NNS NNS!IN DTNN!DTJJ IN!DTNN ROOT!VBD (a) JJ NNS TO JJ NNS VBD NNS!NNP VBD!NNS NNS!IN DTNN!DTJJ IN!DTNN ROOT!VBD (b)</formula><p>Since fully lexicalized bilingual tokens suffer from data sparsity and POS-based bilingual tokens are insufficiently expressive, the question is which level of syntactic information strikes the right bal- ance between expressiveness and generality. <ref type="bibr">5</ref> Section 4 contains details about data and software setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">BiLM with dependency information</head><p>Dependency grammar is commonly used in NLP to formalize role-based relations between words. The intuitive notion of syntactic modification is captured by the primitive binary relation of depen- dence. Dependency relations do not change with the linear order of words ( <ref type="figure">Figure 2</ref>) and therefore can provide a characterization of a word's syntac- tic class that invariant under reordering.</p><p>If we incorporate dependency relations into the representation of bilingual tokens, the incorrect re- ordering in <ref type="figure">Figure 2</ref>.b will produce a highly un- likely sequence. For example, we can substitute each source word with its POS tag and its par- ent's POS tag <ref type="figure" target="#fig_4">(Figure 3</ref>). Again, we computed 4-gram log-probabilities for the corresponding se- quences: the correct reordering results in a sub- stantially higher probability of −10.58 than the in- correct one (−13.48). We may consider situations where more fine-grained distinctions are required. In the next section, we explore different represen- tations based on source dependency trees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dependency-based BiLM</head><p>In this section, we introduce our model which combines the BiLM from Niehues et al. <ref type="formula" target="#formula_1">(2011)</ref> with source dependency information. We fur- ther give details on how the proposed models are trained and integrated into a phrase-based decoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The general framework</head><p>In the previous section we outlined our framework as composed of two steps: First, a parallel sen- tence is tokenized according to the BiLM model <ref type="bibr" target="#b19">(Niehues et al., 2011</ref>). Next, words in the bilingual tokens are substituted with their contextual prop- erties. It is thus convenient to use the following generalized definition for a token sequence t 1 ...t n in our framework:</p><formula xml:id="formula_3">t i = ContE (e i ), {ContF (f )|f ∈ A(e i )}}, (3)</formula><p>where e i is the i-th target word, A : E → P(F ) is an alignment function, F and E are source and target sentences, and ContE and ContF are tar- get and source contextual functions, respectively. A contextual function returns a word's contextual property, based on its sentential context (source or target). See <ref type="figure">Figure 4</ref> for an example of a sequence of BiLM tokens with a ContF defined as return- ing the POS tag of the source word combined with the POS tags of its parent, grandparent and sib- lings, and ContE defined as an identity function (see Section 3.2 for a detailed explanation of the functions and notation).</p><p>In this work we focus on source contextual functions (ContF ). We also exploit some very simple target contextual functions, but do not go into an in-depth exploration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dependency-based contextual functions</head><p>In NLP approaches exploiting dependency struc- ture, two kinds of relations are of special impor- tance: the parent-child relation and the sibling re- lation. <ref type="bibr" target="#b24">Shen et al. (2008)</ref> work with two well- formed dependency structures, both of which are defined in such a way that there is one common parent and a set of siblings. <ref type="bibr" target="#b15">Li et al. (2012)</ref> charac- terize rules in hierarchical SMT by labeling them with the POS tags of the parents of the words in- side the rule. <ref type="bibr" target="#b14">Lerner and Petrov (2013)</ref> model re- ordering as a sequence of classification steps based on a dependency parse of a sentence. Their model first decides how a word is reordered with respect to its parent and then how it is reordered with re- spect to its siblings.</p><p>Based on these previous approaches, we pro- pose to characterize contextual syntactic roles of a word in terms of POS tags of the words them- selves and their relatives in a dependency tree. It is straightforward to incorporate parent informa- tion since each node has a unique parent. As for siblings information, we incorporate POS tags of the closest sibling to the left and the closest to the right. We do not include all of the siblings to avoid overfitting. In addition to these basic syntactic re- lations, we consider the grandparent relation.</p><p>The following list is a summary of the source contextual functions that we use. We describe a function with respect to the kind of contextual property of a word it returns: (i) the word itself (Lex); (ii) POS label of the word (Pos); (iii) POS label of the word's parent; (iv) POS of the word's closest sibling to the left, concatenated with the POS tag of the closest sibling to the right; (v) the POS label of the word's grandparent. We use target-side contextual functions returning: (i) an empty string, (ii) POS of the word, (iii) the word itself.</p><p>Notation. We do not use the above functions separately to define individual BiLM models, but use combinations of these functions. We use the following notation for function combinations: "•" horizontally connects source (on the left) and tar- get (on the right) contextual functions for a given model. For example, <ref type="bibr">Lex</ref>•Lex refers to the original (lexicalized) BiLM. We use arrows (→) to des- ignate parental information (the arrow goes from parent to child). Pos→Pos refers to a combination of a function returning the POS of a word and the POS of its parent (as in <ref type="figure" target="#fig_4">Figure 3</ref>). Pos→Pos→Pos is a combination of the previous with the func- tion returning the grandparent's POS. Finally, we use +sibl to indicate the use of the sibling func- tion described above: For example, Pos→Pos+sibl is a source function that returns the word's POS, its parent's POS and the POS labels of the closest siblings to left and right. <ref type="bibr">6</ref> Pos+sibl→Pos is a source function returning the word's own POS, the POS of a word's parent, and the POS tags of the par- ent's siblings (left-and right-adjacent). <ref type="figure">Figure 4</ref> represents the sentence from Figure 2 during decoding in a system with an integrated Pos→Pos→Pos+sibl•Lex feature. It shows the se- quence of produced bilingual tokens and corre- sponding labels in the introduced notation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training</head><p>Training of dependency-based BiLMs consists of a sequence of extraction steps: After having pro- duced word-alignments for a bitext (Section 4), </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Decoder integration</head><p>Dependency-based BiLMs are integrated into our phrase-based SMT decoder as follows: Before translating a sentence, we produce its dependency parse. Phrase-internal word-alignments, needed to segment the translation hypothesis into tokens, are stored in the phrase table, based on the most frequent internal alignment observed during train- ing. Likewise, we store the most likely target-side POS-labeling for each phrase pair. The decoding algorithm is augmented with one additional feature function and one additional, cor- responding feature weight. At each step of the derivation, as a new phrase pair is added to the Training set N. of lines N. of tokens Source side of Ar-En set 4,376,320 148M Target side of Ar-En set 4,376,320 146M Source side of Ch-En set 2,104,652 20M Target side of Ch-En set 2,104,652 28M <ref type="table">Table 1</ref>: Training data for Arabic-English and Chinese-English experiments.</p><p>partial translation hypothesis, this function seg- ments the new phrase into bilingual tokens (given the internal alignment information) and substitutes the words in the phrase pair with syntactic labels (given the source parse and the target POS labeling associated with the phrase). The new syntactified bilingual tokens are added to the stack of preced- ing n−1 tokens, and the feature function computes the weighted updated model probability. During decoding, the probabilities of the BiLMs are com- puted in a stream-based fashion, with bilingual tokens as string tokens, and not in a class-based fashion, with syntactic source-side representations emitting the corresponding target words (Bisazza and Monz, 2014).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setup</head><p>We conduct translation experiments with a base- line PBSMT system with additionally one of the dependency-based BiLM feature functions speci- fied in Section 3. We compare the translation per- formance to a baseline PBSMT system and to a baseline augmented with the original BiLMs from (Niehues et al., 2011). Word-alignment is produced with GIZA++ ( <ref type="bibr" target="#b21">Och and Ney, 2003)</ref>. We use an in-house imple- mentation of a PBSMT system similar to Moses ( <ref type="bibr" target="#b13">Koehn et al., 2007)</ref>. Our baseline contains all standard PBSMT features including language model, lexical weighting, and lexicalized reorder- ing. The distortion limit is set to 5. A 5-gram LM is trained on the English Gigaword corpus (1.6B tokens) using SRILM with modified Kneyser-Ney smoothing and interpolation. The BiLMs were trained as described in Section 3.3. Informa- tion about the parallel data used for training the Arabic-English <ref type="bibr">7</ref>     <ref type="table" target="#tab_3">Table 2</ref> for the notation regarding statistical significance.</p><p>shown in <ref type="table">Table 1</ref>.</p><p>The feature weights were tuned by using pair- wise ranking optimization (Hopkins and May, 2011) on the MT04 benchmark (for both language pairs). During tuning, 14 PRO parameter estima- tion runs are performed in parallel on different samples of the n-best list after each decoder itera- tion. The weights of the individual PRO runs are then averaged and passed on to the next decoding iteration. Performing weight estimation indepen- dently for a number of samples corrects for some of the instability that can be caused by individual samples. For testing, we used MT08 and MT09 for Arabic, and MT06 and MT08 for Chinese. We use approximate randomization <ref type="bibr" target="#b20">(Noreen, 1989;</ref><ref type="bibr" target="#b23">Riezler and Maxwell, 2005</ref>) to test for statistically sig- nificant differences.</p><p>In the next two subsections we discuss the gen- eral results for Arabic and Chinese, where we use case-insensitive BLEU ( <ref type="bibr" target="#b22">Papineni et al., 2002</ref>) and TER ( <ref type="bibr" target="#b25">Snover et al., 2006</ref>) as evaluation metrics. This is followed by a preliminary analysis of ob- served reorderings where we compare 4-gram pre- cision results and conduct experiments with an in- creased distortion limit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Arabic-English translation experiments</head><p>We are interested in how a translation system with an integrated dependency-based BiLM fea- and several gale corpora.</p><p>ture performs as compared to the standard PB- SMT baseline and, more importantly, to the orig- inal BiLM model. We consider two variants of BiLM discussed by <ref type="bibr" target="#b19">Niehues et al. (2011)</ref>: the stan- dard one, <ref type="bibr">Lex•Lex,</ref> and the simplest syntactic one, Pos•Pos. Results for the experiments can be found in <ref type="table" target="#tab_3">Table 2</ref>. In the discussion below we mostly fo- cus on the experimental results for the large, com- bined test set MT08+MT09. <ref type="table" target="#tab_3">Table 2</ref>.a-b compares the performance of the baseline and original BiLM systems. <ref type="bibr">Lex</ref>•Lex yields strongly significant improvements over the baseline for BLEU and weakly significant im- provements for TER. Therefore, for the rest of the experiments we are interested in obtaining further improvements over <ref type="bibr">Lex•Lex.</ref> Pos→Pos•Pos <ref type="table" target="#tab_3">(Table 2</ref>.c) demonstrates the effect of adding minimal dependency information to a BiLM. <ref type="bibr">9</ref> It results in strongly significant improve- ments over the baseline and weak improvements over <ref type="bibr">Lex</ref>•Lex in terms of BLEU. We additionally ran experiments with the different target functions <ref type="table" target="#tab_4">(Table 3</ref>).</p><p>•Pos shows the highest results, and • the lowest ones: this implies that a rather expressive source syntactic representation alone still benefits from target-side syntactic information. Below, our dependency-based systems only use •Pos.</p><p>Next, we tested the effect of adding more source <ref type="table" target="#tab_4">Configuration   MT06  MT08  MT06+MT08  BLEU  TER  BLEU  TER  BLEU  TER  a PBSMT baseline  31.</ref>    <ref type="table" target="#tab_3">(Table 2</ref>.e) shows the best results overall for BLEU, although it must be pointed out that the difference with Pos→Pos•Pos is very small. With respect to TER, Pos→Pos•Pos out- performs the grandparent variant. So far, we can conclude that source par- ent information helps improve translation perfor- mance. Increased specificity of a parent (par- ent specified by a grandparent) tends to further improve performance. Up to now, we have only used syntactic information and obtained con- siderable improvements over Pos•Pos, surpass- ing the improvement provided by <ref type="bibr">Lex•Lex.</ref> Can we gain further improvements by also adding lexical information?</p><p>To this end, we con- duct experiments combining the best performing dependency-based BiLM (Pos→Pos→Pos•Pos) and the lexicalized BiLM (Lex•Lex). We hypothesize that the two models improve different aspects of translation: Lex•Lex is biased towards improving lexical choice and Pos→Pos→Pos•Pos towards im- proving reordering. Combining these two models, we may improve both aspects. The metric results for the combined set indeed support this hypothe- sis <ref type="table" target="#tab_3">(Table 2</ref>.f).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Chinese-English translation experiments</head><p>The results of the Chinese-English experiments are shown in <ref type="table" target="#tab_6">Table 4</ref>. In the discussion below we mostly focus on the experimental results for the large, combined test set MT06+MT08. We observe the same general pattern for the Pos→Pos source function <ref type="table" target="#tab_6">(Table 4</ref>.c) as for Arabic-English: the system with the •Pos target function has the highest scores ( <ref type="table" target="#tab_7">Table 5</ref>). All of the Pos→Pos• con- figurations show statistically significant improve- ments over the PBSMT baseline. For TER, two of the three Pos→Pos• variants significantly out- perform Lex•Lex. The system with sibling in- formation ( </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Preliminary analysis of reordering in translation experiments</head><p>In general, the experimental results show that us- ing source dependency information yields consis- tent improvements for translating from Arabic and Chinese into English. On the other hand, we have pointed out some discrepancies between the two metrics employed, suggesting that different sys- tem configurations may improve different aspects    of translation. To this end, we conducted some ad- ditional evaluations to understand how reordering is affected by the proposed features.</p><note type="other">Configuration Ar-En Ch-En</note><p>We use 4-gram precision as a metric of how much of the reference set word order is preserved. <ref type="table" target="#tab_10">Table 6</ref> shows the corresponding results for both languages. Just as in the previous two sections, configurations with parental information produce the best results. For Arabic, all of the depen- dency configurations outperform Lex•Lex. But the system with two feature functions, one of which is Lex•Lex, still obtains the best results, which may suggest that the lexicalized BiLM also helps to differentiate between word orders. For Chi- nese, Pos→Pos→Pos•Pos and the system combining the latter and Lex•Lex also obtain the best results. However, other dependency-based configurations do not outperform <ref type="bibr">Lex•Lex.</ref> All the experiments so far were run with a dis- tortion limit of 5. But both of the languages, es- pecially Chinese, often require reorderings over a longer distance. We performed additional experi- ments with a distortion limit of 10 for the Lex•Lex and Pos→Pos→Pos•Pos systems <ref type="table" target="#tab_11">(Tables 7 and 8)</ref>. It is more difficult to translate with a higher distor- tion limit ( <ref type="bibr">Green et al., 2010)</ref> as the set of permu- tations grows larger thereby making it more diffi- cult to differentiate between correct and incorrect continuations of the current hypothesis. It has also been noted that higher distortion limits are more likely to result in improvements for Chinese rather than Arabic to English translation <ref type="bibr" target="#b5">(Chiang, 2007;</ref><ref type="bibr">Green et al., 2010)</ref>.</p><p>We compared performance of fixed BiLM mod- els at distortion lengths of 5 and 10. Arabic- English results did not reveal statistically signif- icant differences between the two distortion lim- its for Pos→Pos→Pos•Pos. On the other hand, for Lex•Lex BLEU decreases when using a distor- tion limit of 10 compared to a limit of 5. This implies that the dependency BiLM is more ro- bust in the more challenging reordering setting than the lexicalized BiLM. Chinese-English re- sults for Pos→Pos→Pos•Pos do show significant im- provements over the distortion limit of 5 (up to 0.49 BLEU higher than the best result in <ref type="table" target="#tab_6">Table 4</ref>). This indicates that the dependency-based BiLM is better capable to take advantage of the increased distortion limit and discriminate between correct and incorrect reordering choices.</p><p>Comparing the results for Pos→Pos→Pos•Pos and Lex•Lex at a distortion limit of 10, we obtain strongly significant improvements for all metrics. For Chinese, a larger distortion limit helps for both configurations, but more so for our dependency BiLM, yielding an improvement of 0.98 BLEU over the original, lexicalized BiLM <ref type="table" target="#tab_12">(Table 8)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper, we have introduced a simple, yet ef- fective way to include syntactic information into phrase-based SMT. Our method consists of en- riching the representation of units of a bilingual language model (BiLM). We argued that the very limited contextual information used in the original bilingual models <ref type="bibr" target="#b19">(Niehues et al., 2011</ref>) can capture reorderings only to a limited degree and proposed a method to incorporate information from a source dependency tree in bilingual units. In a series of translation experiments we performed a thor- ough comparison between various syntactically- enriched BiLMs and competing models. The re- sults demonstrated that adding syntactic informa- tion from a source dependency tree to the repre- sentations of bilingual tokens in an n-gram model can yield statistically significant improvements over the competing systems.</p><p>A number of additional evaluations provided an indication for better modeling of reordering phe- nomena. The proposed dependency-based BiLMs resulted in an increase in 4-gram precision and provided further significant improvements over all considered metrics in experiments with an in- creased distortion limit.</p><p>In this paper, we have focused on rather elemen- tary dependency relations, which we are planning to expand on in future work. Our current approach is still strictly tied to the number of target tokens. In particular, we are interested in exploring ways to better capture the notion of syntactic cohesion in translation <ref type="bibr" target="#b11">(Fox, 2002;</ref><ref type="bibr" target="#b4">Cherry, 2008)</ref> within our framework.</p><p>Michel <ref type="bibr">Galley and Christopher D. Manning. 2008</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Arabic-English parallel sentence, automatically word-aligned. The bilingual token sequences are produced according to two alternative definitions (BiLM and MTU).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Durrani et al.</head><label></label><figDesc>(2011) introduce an alternative method for unambiguous bilingual segmentation where tokens are defined as minimal phrases, called minimal translation units (MTUs). Figure 1 compares the BiLM and MTU tokenization for a specific example. Since Niehues et al. (2011) have shown their model to work successfully as an addi- tional feature in combination with commonly used standard phrase-based features, we use their ap- proach as the main point of reference and base our approach on their segmentation method. In the rest of the text we refer to Niehues et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Niehues et al. (2011) also described an alterna- tive variant of the original BiLM, where words are substituted by their POS tags (Figure 2.a, shaded part</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Sequences of bilingual tokens with source words substituted with their and their parents' POS tags: correct (a) and incorrect (b) reorderings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>). Also, however, POS information by itself may be insufficiently expressive to separate cor-</figDesc><table>Egyptian exports to 

trAjEt 
SAdrAt 
mSr 
l 
Aldwl 
AlErbyp 

VBD 
NNS 
NNP 
IN 
DTNN 
DTJJ 

JJ 
NNS 
TO 

Arabic 
countries declined … 

… 

JJ 
NNS 
VBD 

trAjEt 
SAdrAt 
mSr 
l 
Aldwl 
AlErbyp 

NNS 
NNP 
IN 
DTJJ 

… 

DTNN 
VBD 

(a) 

trAjEt 
SAdrAt 
mSr 
l 
Aldwl 
AlErbyp 

VBD 
NNS 
NNP 
IN 
DTNN 
DTJJ 

Arabic 

JJ 

AlErbyp 

DTJJ 

countries 

NNS 

Aldwl 

DTNN 

declined 

VBD 

trAjEt 

VBD 

Egyptian exports to 

JJ 
NNS 
TO 

SAdrAt 
mSr 
l 

NNS 
NNP 
IN 

(b) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>and Chinese-English systems 8 is</head><label></label><figDesc></figDesc><table>Configuration 

MT08 
MT09 
MT08+MT09 
BLEU 
TER 
BLEU 
TER 
BLEU 
TER 
a PBSMT baseline 
45.12 
47.94 
48.16 
44.30 
46.57 
46.21 
b Lex•Lex 
45.27 
47.79 
48.85 
43.96 
46.98 
45.96 
Pos•Pos 
44.80 
47.84 
48.22 
44.14 ,− 46.44 
46.07 
c Pos→Pos•Pos 
45.66 , 47.17 , 49.00 ,− 43.45 , 47.25 , 45.40 , 
d Pos→Pos−sibl•Pos 
45.46 ,− 47.45 , 48.69 ,− 43.64 , 47.00 ,− 45.64 ,− 
e Pos→Pos→Pos•Pos 
45.68 , 47.42 , 49.09 ,− 43.59 , 47.30 , 45.60 , 
f Lex•Lex + Pos→Pos→Pos•Pos 45.63 , 47.48 , 49.30 , 43.60 , 47.38 , 45.63 , 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 : BLEU and TER scores for Arabic-English experiments.</head><label>2</label><figDesc></figDesc><table>Statistically significant improvements 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Different combinations of a target contextual function with the Pos→Pos source contextual function for Arabic-English. See</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><head>Table 4 :</head><label>4</label><figDesc>BLEU and TER scores for Chinese-English PBSMT baseline and BiLM pipelines. See Table 2 for the notation regarding statistical significance.</figDesc><table>Configuration 
MT06 
MT08 
MT06+MT08 
BLEU 
TER 
BLEU 
TER 
BLEU 
TER 
Pos→Pos• 
32.43 ,− 57.42 ,− 25.84 
60.51 
29.43 ,− 58.86 ,− 
Pos→Pos•Pos 32.86 ,− 57.05 , 26.09 ,− 59.87 , 29.78 ,− 58.36 , 
Pos→Pos•Lex 32.69 ,− 57.03 , 25.72 
60.17 ,− 29.52 ,− 58.49 , 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Different combinations of a target contextual function with the Pos→Pos source contextual func-
tion for Chinese-English. See Table 2 for the notation regarding statistical significance. 

dependency information. Pos→Pos+sibl•Pos (Ta-
ble 2.d) only improves over the PBSMT baseline 
(but also shows weak improvements over Lex•Lex 
for TER). It significantly degrades the perfor-
mance with respect to the Pos→Pos•Pos system (Ta-
ble 2.c). Pos→Pos→Pos•Pos </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 4 .</head><label>4</label><figDesc>d) obtains quite low BLEU results, just as in the Arabic experiments. On the other hand, its TER results are the highest overall. The system with the Pos→Pos→Pos•Pos function (Table 4.e) achieves the best results among dependency-based BiLMs for BLEU. Fi- nally, combining Pos→Pos→Pos•Pos and Lex•Lex re- sults in the largest and significant improvements over all competing systems for BLEU.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>4-gram precision scores for Arabic-English and Chinese-English baseline and BiLM systems. 

Configuration 
MT08 
MT09 
MT08+MT09 
BLEU TER 
4gram BLEU TER 
4gram BLEU TER 
4gram 
Lex•Lex 
45.19 
47.06 26.41 
48.39 
44.11 30.23 
46.72 
45.97 28.21 
Pos→Pos→Pos•Pos 45.49 
47.31 26.66 
48.90 43.57 30.92 
47.12 45.52 28.66 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>BLEU, TER and 4-gram precision scores for Arabic-English Lex•Lex and Pos→Pos→Pos•Pos 
with a distortion limit of 10. 

Configuration 
MT06 
MT08 
MT06+MT08 
BLEU TER 
4gram BLEU TER 
4gram BLEU TER 
4gram 
Lex•Lex 
33.26 
56.81 16.06 
25.67 
60.19 11.42 
29.79 
58.38 13.96 
Pos→Pos→Pos•Pos 33.92 56.29 16.26 
27.00 59.58 12.26 
30.77 57.82 14.46 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>BLEU, TER and 4-gram precision scores for Chinese-English Lex•Lex and 
Pos→Pos→Pos•Pos with a distortion limit of 10. 

</table></figure>

			<note place="foot" n="1"> Note that the standard PBSMT translation model assumes that events of translating separate phrases in a sentence are independent.</note>

			<note place="foot" n="2"> We used Buckwalter transliteration for Arabic words. 3 By an elementary translation event we mean a translation of some substructure of a sentence.</note>

			<note place="foot" n="4"> Although, strictly speaking, it is not the original approach (see the references in Section 1).</note>

			<note place="foot" n="6"> In case there is no sibling on one of the sides, (empty word) is returned.</note>

			<note place="foot" n="7"> The following Arabic-English parallel corpora were used: LDC2006E25, LDC2004T18, several gale corpora, LDC2004T17, LDC2005E46, LDC2007T08, LDC2004E13. 8 The following Chinese-English parallel corpora were used: LDC2002E18, LDC2002L27, LDC2003E07, LDC2003E14, LDC2005T06, LDC2005T10, LDC2005T34,</note>

			<note place="foot" n="9"> Additional significance testing, which is not shown in Table 2, shows a strongly significant improvement over the original syntactic BiLM Pos•Pos.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Arianna Bisazza and the reviewers for their useful comments. This research was funded in part by the Netherlands Organization for Sci-entific Research (NWO) under project numbers 639.022.213 and 612.001.218.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Distortion models for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Al-Onaizan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006-07" />
			<biblScope unit="page" from="529" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Reordering Metrics for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>University of Edinburgh</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Classbased language modeling for translating into morphologically rich languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arianna</forename><surname>Bisazza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Computational Linguistics (COLING 2014)</title>
		<meeting>the 25th International Conference on Computational Linguistics (COLING 2014)<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-08" />
			<biblScope unit="page" from="1918" to="1927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Discriminative reordering with chinese grammatical relations features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pi-Chuan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huihsin</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Syntax and Structure in Statistical Translation</title>
		<meeting>the Third Workshop on Syntax and Structure in Statistical Translation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="51" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Cohesive phrase-based decoding for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Association for Computational Linguistics</title>
		<meeting>Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="72" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hierarchical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="201" to="228" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning to translate with source and target syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1443" to="1452" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Head-Driven Statistical Models for Natural Language Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
		<respStmt>
			<orgName>University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Factored bilingual n-gram language models for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Josep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Crego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yvon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Translation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="175" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Improving reordering with linguistically informed bilingual n-grams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Josep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Crego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yvon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="197" to="205" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A joint sequence translation model with integrated reordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadir</forename><surname>Durrani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Fraser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1045" to="1054" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Phrasal cohesion and statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heidi</forename><forename type="middle">J</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL02 conference on Empirical methods in natural language processing</title>
		<meeting>the ACL02 conference on Empirical methods in natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="304" to="3111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Statistical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</title>
		<meeting>the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="48" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics on Interactive Poster and Demonstration Sessions</title>
		<meeting>the 45th Annual Meeting of the Association for Computational Linguistics on Interactive Poster and Demonstration Sessions</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Source-side classifier preordering for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uri</forename><surname>Lerner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Empirical Methods in Natural Language Processing</title>
		<meeting>the Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Head-driven hierarchical phrasebased translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="33" to="37" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Treeto-string alignment template for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shouxun</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="609" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">N-grambased machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><forename type="middle">E</forename><surname>Marino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josep</forename><forename type="middle">M</forename><surname>Banchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adria</forename><surname>Crego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrik</forename><surname>De Gispert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><forename type="middle">R</forename><surname>Fonollosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Costa-Jussà</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="527" to="549" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Soft syntactic constraints for hierarchical phrased-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Marton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Wider context by using bilingual language models in machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Niehues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teresa</forename><surname>Herrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Waibel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="198" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Computer Intensive Methods for Testing Hypotheses. An Introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">W</forename><surname>Noreen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<publisher>WileyInterscience</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A systematic comparison of various statistical alignment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="51" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On some pitfalls in automatic evaluation and significance testing for MT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">T</forename><surname>Maxwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</title>
		<meeting>the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A new string-to-dependency machine translation algorithm with a target dependency language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><forename type="middle">M</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="577" to="585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A study of translation edit rate with targeted human annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linnea</forename><surname>Micciulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AMTA</title>
		<meeting>AMTA</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="223" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Srilm at sixteen: Update and outlook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Abrash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Automatic Speech Recognition and Understanding Workshop</title>
		<meeting>IEEE Automatic Speech Recognition and Understanding Workshop</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
