<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Question Answering with Subgraph Embeddings</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
							<email>abordes@fb.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Facebook AI Research</orgName>
								<orgName type="department" key="dep2">Facebook AI Research</orgName>
								<orgName type="department" key="dep3">Facebook AI Research</orgName>
								<address>
									<addrLine>112 avenue de Wagram</addrLine>
									<postCode>770, 770</postCode>
									<settlement>Paris, Broadway, Broadway</settlement>
									<region>New York, New York</region>
									<country>France, USA, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
							<email>spchopra@fb.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Facebook AI Research</orgName>
								<orgName type="department" key="dep2">Facebook AI Research</orgName>
								<orgName type="department" key="dep3">Facebook AI Research</orgName>
								<address>
									<addrLine>112 avenue de Wagram</addrLine>
									<postCode>770, 770</postCode>
									<settlement>Paris, Broadway, Broadway</settlement>
									<region>New York, New York</region>
									<country>France, USA, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Facebook AI Research</orgName>
								<orgName type="department" key="dep2">Facebook AI Research</orgName>
								<orgName type="department" key="dep3">Facebook AI Research</orgName>
								<address>
									<addrLine>112 avenue de Wagram</addrLine>
									<postCode>770, 770</postCode>
									<settlement>Paris, Broadway, Broadway</settlement>
									<region>New York, New York</region>
									<country>France, USA, USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Question Answering with Subgraph Embeddings</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="615" to="620"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper presents a system which learns to answer questions on a broad range of topics from a knowledge base using few hand-crafted features. Our model learns low-dimensional embeddings of words and knowledge base constituents; these representations are used to score natural language questions against candidate answers. Training our system using pairs of questions and structured representations of their answers, and pairs of question paraphrases , yields competitive results on a recent benchmark of the literature.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Teaching machines how to automatically answer questions asked in natural language on any topic or in any domain has always been a long stand- ing goal in Artificial Intelligence. With the rise of large scale structured knowledge bases (KBs), this problem, known as open-domain question an- swering (or open QA), boils down to being able to query efficiently such databases with natural language. These KBs, such as FREEBASE ( <ref type="bibr" target="#b2">Bollacker et al., 2008</ref>) encompass huge ever growing amounts of information and ease open QA by or- ganizing a great variety of answers in a structured format. However, the scale and the difficulty for machines to interpret natural language still makes this task a challenging problem.</p><p>The state-of-the-art techniques in open QA can be classified into two main classes, namely, infor- mation retrieval based and semantic parsing based. Information retrieval systems first retrieve a broad set of candidate answers by querying the search API of KBs with a transformation of the ques- tion into a valid query and then use fine-grained detection heuristics to identify the exact answer ( <ref type="bibr" target="#b7">Kolomiyets and Moens, 2011;</ref><ref type="bibr" target="#b11">Unger et al., 2012;</ref><ref type="bibr" target="#b13">Yao and Van Durme, 2014</ref>). On the other hand, semantic parsing methods focus on the correct in- terpretation of the meaning of a question by a se- mantic parsing system. A correct interpretation converts a question into the exact database query that returns the correct answer. Interestingly, re- cent works <ref type="bibr" target="#b1">(Berant et al., 2013;</ref><ref type="bibr" target="#b8">Kwiatkowski et al., 2013;</ref><ref type="bibr" target="#b0">Berant and Liang, 2014;</ref><ref type="bibr" target="#b6">Fader et al., 2014</ref>) have shown that such systems can be ef- ficiently trained under indirect and imperfect su- pervision and hence scale to large-scale regimes, while bypassing most of the annotation costs.</p><p>Yet, even if both kinds of system have shown the ability to handle large-scale KBs, they still require experts to hand-craft lexicons, grammars, and KB schema to be effective. This non-negligible hu- man intervention might not be generic enough to conveniently scale up to new databases with other schema, broader vocabularies or languages other than English. In contrast, <ref type="bibr" target="#b5">(Fader et al., 2013</ref>) pro- posed a framework for open QA requiring almost no human annotation. Despite being an interesting approach, this method is outperformed by other competing methods. ( <ref type="bibr" target="#b4">Bordes et al., 2014b</ref>) in- troduced an embedding model, which learns low- dimensional vector representations of words and symbols (such as KBs constituents) and can be trained with even less supervision than the system of (Fader et al., 2013) while being able to achieve better prediction performance. However, this ap- proach is only compared with <ref type="bibr" target="#b5">(Fader et al., 2013</ref>) which operates in a simplified setting and has not been applied in more realistic conditions nor eval- uated against the best performing methods.</p><p>In this paper, we improve the model of (Bor- des et al., 2014b) by providing the ability to an- swer more complicated questions. The main con- tributions of the paper are: (1) a more sophisti- cated inference procedure that is both efficient and can consider longer paths <ref type="bibr" target="#b4">((Bordes et al., 2014b</ref>) considered only answers directly connected to the question in the graph); and (2) a richer represen- tation of the answers which encodes the question- answer path and surrounding subgraph of the KB. Our approach is competitive with the current state- of-the-art on the recent benchmark WEBQUES- TIONS ( <ref type="bibr" target="#b1">Berant et al., 2013</ref>) without using any lex- icon, rules or additional system for part-of-speech tagging, syntactic or dependency parsing during training as most other systems do.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Definition</head><p>Our main motivation is to provide a system for open QA able to be trained as long as it has ac- cess to: (1) a training set of questions paired with answers and (2) a KB providing a structure among answers. We suppose that all potential answers are entities in the KB and that questions are sequences of words that include one identified KB entity. When this entity is not given, plain string match- ing is used to perform entity resolution. Smarter methods could be used but this is not our focus.</p><p>We use WEBQUESTIONS ( <ref type="bibr" target="#b1">Berant et al., 2013</ref>) as our evaluation bemchmark. Since it contains few training samples, it is impossible to learn on it alone, and this section describes the various data sources that were used for training. These are sim- ilar to those used in <ref type="bibr" target="#b0">(Berant and Liang, 2014)</ref>.</p><p>WebQuestions This dataset is built using FREE- BASE as the KB and contains 5,810 question- answer pairs. It was created by crawling questions through the Google Suggest API, and then obtain- ing answers using Amazon Mechanical Turk. We used the original split (3,778 examples for train- ing and 2,032 for testing), and isolated 1k ques- tions from the training set for validation. WE- BQUESTIONS is built on FREEBASE since all an- swers are defined as FREEBASE entities. In each question, we identified one FREEBASE entity us- ing string matching between words of the ques- tion and entity names in FREEBASE. When the same string matches multiple entities, only the en- tity appearing in most triples, i.e. the most popular in FREEBASE, was kept. Example questions (an- swers) in the dataset include "Where did Edgar Allan Poe died?" (baltimore) or "What degrees did Barack Obama get?" (bachelor of arts, juris doctor).</p><p>Freebase FREEBASE ( <ref type="bibr" target="#b2">Bollacker et al., 2008</ref>) is a huge and freely available database of general facts; data is organized as triplets (subject, type1.type2.predicate, object), where two entities subject and object (identi- fied by mids) are connected by the relation type type1.type2.predicate. We used a subset, cre- ated by only keeping triples where one of the entities was appearing in either the WEBQUES- TIONS training/validation set or in CLUEWEB ex- tractions. We also removed all entities appearing less than 5 times and finally obtained a FREEBASE set containing 14M triples made of 2.2M entities and 7k relation types. <ref type="bibr">1</ref> Since the format of triples does not correspond to any structure one could find in language, we decided to transform them into automatically generated questions. Hence, all triples were converted into questions "What is the predicate of the type2 subject?" (using the mid of the subject) with the answer being object. An example is "What is the nationality of the person barack obama?" (united states). More examples and details are given in a longer version of this paper ( <ref type="bibr" target="#b3">Bordes et al., 2014a</ref>).</p><p>ClueWeb Extractions FREEBASE data allows to train our model on 14M questions but these have a fixed lexicon and vocabulary, which is not real- istic. Following <ref type="bibr" target="#b1">(Berant et al., 2013)</ref>, we also cre- ated questions using CLUEWEB extractions pro- vided by <ref type="bibr" target="#b9">(Lin et al., 2012</ref>). Using string match- ing, we ended up with 2M extractions structured as (subject, "text string", object) with both subject and object linked to FREEBASE. We also converted these triples into questions by using simple patterns and FREEBASE types. An exam- ple of generated question is "Where barack obama was allegedly bear in?" (hawaii).</p><p>Paraphrases The automatically generated ques- tions that are useful to connect FREEBASE triples and natural language, do not provide a satisfac- tory modeling of natural language because of their semi-automatic wording and rigid syntax. To overcome this issue, we follow <ref type="bibr" target="#b5">(Fader et al., 2013)</ref> and supplement our training data with an indirect supervision signal made of pairs of question para- phrases collected from the WIKIANSWERS web- site. On WIKIANSWERS, users can tag pairs of questions as rephrasings of each other: <ref type="bibr" target="#b5">(Fader et al., 2013</ref>) harvested a set of 2M distinct questions from WIKIANSWERS, which were grouped into 350k paraphrase clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Embedding Questions and Answers</head><p>Inspired by <ref type="bibr" target="#b4">(Bordes et al., 2014b</ref>), our model works by learning low-dimensional vector embed- dings of words appearing in questions and of enti- ties and relation types of FREEBASE, so that repre- sentations of questions and of their corresponding answers are close to each other in the joint embed- ding space. Let q denote a question and a a can- didate answer. Learning embeddings is achieved by learning a scoring function S(q, a), so that S generates a high score if a is the correct answer to the question q, and a low score otherwise. Note that both q and a are represented as a combina- tion of the embeddings of their individual words and/or symbols; hence, learning S essentially in- volves learning these embeddings. In our model, the form of the scoring function is:</p><formula xml:id="formula_0">S(q, a) = f (q) g(a).<label>(1)</label></formula><p>Let W be a matrix of R k×N , where k is the di- mension of the embedding space which is fixed a- priori, and N is the dictionary of embeddings to be learned. Let N W denote the total number of words and N S the total number of entities and relation types. With N = N W +N S , the i-th column of W is the embedding of the i-th element (word, entity or relation type) in the dictionary. The function f (.), which maps the questions into the embed- ding space R k is defined as f (q) = Wφ(q), where φ(q) ∈ N N , is a sparse vector indicating the num- ber of times each word appears in the question q (usually 0 or 1). Likewise the function g(.) which maps the answer into the same embedding space R k as the questions, is given by g(a) = Wψ(a).</p><p>Here ψ(a) ∈ N N is a sparse vector representation of the answer a, which we now detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Representing Candidate Answers</head><p>We now describe possible feature representations for a single candidate answer. (When there are multiple correct answers, we average these rep- resentations, see Section 3.4.) We consider three different types of representation, corresponding to different subgraphs of FREEBASE around it.</p><p>(i) Single Entity. The answer is represented as a single entity from FREEBASE: ψ(a) is a 1- of-N S coded vector with 1 corresponding to the entity of the answer, and 0 elsewhere.</p><p>(ii) Path Representation.</p><p>The answer is represented as a path from the entity mentioned in the question to the answer entity. In our experiments, we consid- ered 1-or 2-hops paths (i.e. with either 1 or 2 edges to traverse): (barack obama, people.person.place of birth, honolulu) is a 1-hop path and (barack obama, people.person.place of birth, location. location.containedby, hawaii) a 2-hops path. This results in a ψ(a) which is a 3-of-N S or 4-of-N S coded vector, expressing the start and end entities of the path and the relation types (but not entities) in-between.</p><p>(iii) Subgraph Representation. We encode both the path representation from (ii), and the en- tire subgraph of entities connected to the can- didate answer entity. That is, for each entity connected to the answer we include both the relation type and the entity itself in the repre- sentation ψ(a). In order to represent the an- swer path differently to the surrounding sub- graph (so the model can differentiate them), we double the dictionary size for entities, and use one embedding representation if they are in the path and another if they are in the sub- graph. Thus we now learn a parameter matrix R k×N where N = N W + 2N S (N S is the to- tal number of entities and relation types). If there are C connected entities with D relation types to the candidate answer, its representa- tion is a 3+C +D or 4+C +D-of-N S coded vector, depending on the path length.</p><p>Our hypothesis is that including more informa- tion about the answer in its representation will lead to improved results. While it is possible that all required information could be encoded in the k di- mensional embedding of the single entity (i), it is unclear what dimension k should be to make this possible. For example the embedding of a country entity encoding all of its citizens seems unrealis- tic. Similarly, only having access to the path ig- nores all the other information we have about the answer entity, unless it is encoded in the embed- dings of either the entity of the question, the an- swer or the relations linking them, which might be quite complicated as well. We thus adopt the sub- graph approach. <ref type="figure">Figure 1</ref> illustrates our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training and Loss Function</head><p>As in <ref type="bibr" target="#b12">(Weston et al., 2010)</ref>, we train our model using a margin-based ranking loss function. Let D = {(q i , a i ) : i = 1, . . . , |D|} be the training set Embedding model</p><p>Freebase subgraph</p><p>Binary encoding of the subgraph ψ(a)</p><p>Embedding of the subgraph g(a)</p><p>Binary encoding of the ques0on Φ(q)</p><p>Embedding of the ques0on f(q)</p><p>Ques0on q</p><p>Subgraph of a candidate answer a (here K. Preston)</p><p>Score S(q,a)</p><p>How the candidate answer fits the ques0on</p><p>Dot product</p><p>Embedding matrix W <ref type="figure">Figure 1</ref>: Illustration of the subgraph embedding model scoring a candidate answer: (i) locate entity in the question; (ii) compute path from entity to answer; (iii) represent answer as path plus all connected entities to the answer (the subgraph); (iv) embed both the question and the answer subgraph separately using the learnt embedding vectors, and score the match via their dot product.</p><p>of questions q i paired with their correct answer a i . The loss function we minimize is</p><formula xml:id="formula_1">|D| i=1 ¯ a∈ ¯ A(a i ) max{0, m−S(q i , a i )+S(q i , ¯ a)}, (2)</formula><p>where m is the margin (fixed to 0.1). Minimizing Eq. (2) learns the embedding matrix W so that the score of a question paired with a correct an- swer is greater than with any incorrect answer ¯ a by at least m. ¯ a is sampled from a set of incor- rect candidates ¯ A. This is achieved by sampling 50% of the time from the set of entities connected to the entity of the question (i.e. other candidate paths), and by replacing the answer entity by a ran- dom one otherwise. Optimization is accomplished using stochastic gradient descent, multi-threaded with Hogwild! <ref type="bibr" target="#b10">(Recht et al., 2011)</ref>, with the con- straint that the columns w i of W remain within the unit-ball, i.e., ∀ i , ||w i || 2 ≤ 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Multitask Training of Embeddings</head><p>Since a large number of questions in our training datasets are synthetically generated, they do not adequately cover the range of syntax used in natu- ral language. Hence, we also multi-task the train- ing of our model with the task of paraphrase pre- diction. We do so by alternating the training of S with that of a scoring function S prp (q 1 , q 2 ) = f (q 1 ) f (q 2 ), which uses the same embedding ma- trix W and makes the embeddings of a pair of questions (q 1 , q 2 ) similar to each other if they are paraphrases (i.e. if they belong to the same para- phrase cluster), and make them different other- wise. Training S prp is similar to that of S except that negative samples are obtained by sampling a question from another paraphrase cluster.</p><p>We also multitask the training of the embed- dings with the mapping of the mids of FREEBASE entities to the actual words of their names, so that the model learns that the embedding of the mid of an entity should be similar to the embedding of the word(s) that compose its name(s).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Inference</head><p>Once W is trained, at test time, for a given ques- tion q the model predicts the answer with:</p><formula xml:id="formula_2">ˆ a = argmax a ∈A(q) S(q, a )<label>(3)</label></formula><p>where A(q) is the candidate answer set. This can- didate set could be the whole KB but this has both speed and potentially precision issues. Instead, we create a candidate set A(q) for each question.</p><p>We recall that each question contains one identi- fied FREEBASE entity. A(q) is first populated with all triples from FREEBASE involving this entity. This allows to answer simple factual questions whose answers are directly connected to them (i.e. 1-hop paths). This strategy is denoted C 1 .</p><p>Since a system able to answer only such ques- tions would be limited, we supplement A(q) with examples situated in the KB graph at 2-hops from the entity of the question. We do not add all such quadruplets since this would lead to very large candidate sets. Instead, we consider the follow- ing general approach: given that we are predicting a path, we can predict its elements in turn using   <ref type="table">Table 1</ref>: Results on the WEBQUESTIONS test set.</p><p>a beam search, and hence avoid scoring all can- didates. Specifically, our model first ranks rela- tion types using Eq. <ref type="formula" target="#formula_0">(1)</ref>, i.e. selects which rela- tion types are the most likely to be expressed in q. We keep the top 10 types (10 was selected on the validation set) and only add 2-hops candidates to A(q) when these relations appear in their path. Scores of 1-hop triples are weighted by 1.5 since they have one less element than 2-hops quadru- plets. This strategy, denoted C 2 , is used by default. A prediction a can commonly actually be a set of candidate answers, not just one an- swer, for example for questions like "Who are David Beckham's children?". This is achieved by considering a prediction to be all the en- tities that lie on the same 1-hop or 2-hops path from the entity found in the question. Hence, all answers to the above question are connected to david beckham via the same path (david beckham, people.person.children, * ). The feature representation of the prediction is then the average over each candidate entity's features (see Section 3.1), i.e. ψ all (a ) = 1 |a | a j :a ψ(a j ) where a j are the individual entities in the over- all prediction a . In the results, we compare to a baseline method that can only predict single can- didates, which understandly performs poorly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We compare our system in terms of F1 score as computed by the official evaluation script 2 (F1 (Berant)) but also with a slightly different F1 def- inition, termed F1 (Yao) which was used in (Yao and Van Durme, 2014) (the difference being the way that questions with no answers are dealt with), and precision @ 1 (p@1) of the first candidate en- tity (even when there are a set of correct answers), comparing to recently published systems. <ref type="bibr">3</ref> The upper part of <ref type="table">Table 1</ref> indicates that our approach outperforms <ref type="bibr" target="#b13">(Yao and Van Durme, 2014</ref>), <ref type="bibr" target="#b1">(Berant et al., 2013)</ref> and <ref type="bibr" target="#b4">(Bordes et al., 2014b)</ref>, and per- forms similarly as <ref type="bibr" target="#b0">(Berant and Liang, 2014)</ref>.</p><p>The lower part of <ref type="table">Table 1</ref> compares various ver- sions of our model. Our default approach uses the Subgraph representation for answers and C 2 as the candidate answers set. Replacing C 2 by C 1 induces a large drop in performance because many questions do not have answers thatare di- rectly connected to their inluded entity (not in C 1 ). However, using all 2-hops connections as a candidate set is also detrimental, because the larger number of candidates confuses (and slows a lot) our ranking based inference. Our results also verify our hypothesis of Section 3.1, that a richer representation for answers (using the local subgraph) can store more pertinent information. Finally, we demonstrate that we greatly improve upon the model of ( <ref type="bibr" target="#b4">Bordes et al., 2014b</ref>), which actually corresponds to a setting with the Path rep- resentation and C 1 as candidate set.</p><p>We also considered an ensemble of our ap- proach and that of <ref type="bibr" target="#b0">(Berant and Liang, 2014</ref>). As we only had access to their test predictions we used the following combination method. Our ap- proach gives a score S(q, a) for the answer it pre- dicts. We chose a threshold such that our approach predicts 50% of the time (when S(q, a) is above its value), and the other 50% of the time we use the prediction of <ref type="bibr" target="#b0">(Berant and Liang, 2014</ref>) instead. We aimed for a 50/50 ratio because both meth- ods perform similarly. The ensemble improves the state-of-the-art, and indicates that our models are significantly different in their design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper presented an embedding model that learns to perform open QA using training data made of questions paired with their answers and of a KB to provide a structure among answers, and can achieve promising performance on the com- petitive benchmark WEBQUESTIONS.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Method</head><label></label><figDesc></figDesc></figure>

			<note place="foot" n="1"> WEBQUESTIONS contains ∼2k entities, hence restricting FREEBASE to 2.2M entities does not ease the task for us.</note>

			<note place="foot" n="2"> Available from www-nlp.stanford.edu/software/sempre/</note>

			<note place="foot" n="3"> Results of baselines except (Bordes et al., 2014b) have been extracted from the original papers. For our experiments, all hyperparameters have been selected on the WEBQUESTIONS validation set: k was chosen among {64, 128, 256}, the learning rate on a log. scale between 10 −4 and 10 −1 and we used at most 100 paths in the subgraph representation.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semantic parsing via paraphrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL&apos;14)</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (ACL&apos;14)<address><addrLine>Baltimore, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP&apos;13)</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP&apos;13)<address><addrLine>Seattle, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGMOD international conference on Management of data</title>
		<meeting>the 2008 ACM SIGMOD international conference on Management of data<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Question answering with subgraph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno>abs/1406.3676</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Open question answering with weakly supervised embedding models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD&apos;14)</title>
		<meeting>the 7th European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD&apos;14)<address><addrLine>Nancy, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Paraphrase-driven learning for open question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL&apos;13)</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics (ACL&apos;13)<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Open question answering over curated and extracted knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 20th SIGKDD Conference on Knowledge Discovery and Data Mining (KDD&apos;14)</title>
		<meeting>20th SIGKDD Conference on Knowledge Discovery and Data Mining (KDD&apos;14)<address><addrLine>New York City, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A survey on question answering technology from an information retrieval perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Kolomiyets</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page" from="5412" to="5434" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Scaling semantic parsers with on-the-fly ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP&apos;13)</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP&apos;13)<address><addrLine>Seattle, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Entity linking at web scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction (AKBCWEKEX&apos;12)</title>
		<meeting>the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction (AKBCWEKEX&apos;12)<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Hogwild!: A lock-free approach to parallelizing stochastic gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Ré</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS 24</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Template-based question answering over RDF data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Unger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenz</forename><surname>Bühmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Axel-Cyrille Ngonga</forename><surname>Ngomo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gerber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Cimiano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st international conference on World Wide Web (WWW&apos;12)</title>
		<meeting>the 21st international conference on World Wide Web (WWW&apos;12)<address><addrLine>Lyon, France</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Large scale image annotation: learning to rank with joint word-image embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">81</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Information extraction over structured data: Question answering with freebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL&apos;14)</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (ACL&apos;14)<address><addrLine>Baltimore, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
