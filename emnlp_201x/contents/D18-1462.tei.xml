<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:08+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Skeleton-Based Model for Promoting Coherence Among Sentences in Narrative Story Generation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EECS</orgName>
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuancheng</forename><surname>Ren</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EECS</orgName>
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EECS</orgName>
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zeng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EECS</orgName>
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Cai</surname></persName>
							<email>xiaoyanc@nwpu.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EECS</orgName>
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Skeleton-Based Model for Promoting Coherence Among Sentences in Narrative Story Generation</title>
					</analytic>
					<monogr>
						<title level="j" type="main">Association for Computational Linguistics</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="volume">4306</biblScope>
							<biblScope unit="page" from="4306" to="4315"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Narrative story generation is a challenging problem because it demands the generated sentences with tight semantic connections, which has not been well studied by most existing generative models. To address this problem , we propose a skeleton-based model to promote the coherence of generated stories. Different from traditional models that generate a complete sentence at a stroke, the proposed model first generates the most critical phrases, called skeleton, and then expands the skeleton to a complete and fluent sentence. The skeleton is not manually defined, but learned by a reinforcement learning method. Compared to the state-of-the-art models, our skeleton-based model can generate significantly more coherent text according to human evaluation and automatic evaluation. The G-score is improved by 20.1% in human evaluation. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We focus on the problem of narrative story gen- eration, a special kind of story generation ( <ref type="bibr" target="#b11">Li et al., 2013)</ref>. It requires systems to generate a narrative story based on a short description of a scene or an event, as shown in <ref type="table" target="#tab_0">Table 1</ref>. In gen- eral, a narrative story is described with several inter-related scenes. Different from traditional text generation tasks, this task is more challeng- ing because it demands the generated sentences with tight semantic connections. Currently, most state-of-the-art approaches ( <ref type="bibr" target="#b10">Jain et al., 2017;</ref><ref type="bibr" target="#b14">Liu et al., 2017;</ref><ref type="bibr" target="#b5">Fan et al., 2018;</ref><ref type="bibr" target="#b16">Ma et al., 2018a;</ref>) are largely based on Sequence- to-Sequence (Seq2Seq) models <ref type="bibr" target="#b21">(Sutskever et al., 2014</ref>), which generate a sentence at a stroke in a left-to-right manner.</p><p>However, we find it hard for these approaches to model the semantic dependency among sentences,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task Description</head><p>Input: A short description of a scene or an event. Output: A relevant narrative story following the input.</p><p>Examples Input: Fans came together to celebrate the opening of a new studio for an artist. Output: The artist provided champagne in flutes for everyone. Friends toasted and cheered the artist as she opened her new studio. Input: Last week I attended a wedding for the first time.</p><p>Output: There were a lot of families there. They were all taking pictures together. Everyone was very happy. The bride and groom got to ride in a limo that they rented. which causes low-quality generated stories where the scenes are irrelevant. In fact, as shown in <ref type="figure">Figure 1</ref>, we observe that the connection among sentences is mainly reflected through key phrases, such as predicates, subjects, objects and so on. In this work, we regard the phrases that express the key meanings of a sentence as a skeleton. The other words (e.g., modifiers) not only are redun- dant for understanding semantic dependency, but also make the dependency sparse. Therefore, gen- erating all information at a stroke makes it difficult to learn the dependency of sentences. In contrast, the sentences written by humans are closely tied and the whole story is more coherent and fluent. It is mainly attributed to the way of human writing where we often first come up with a skeleton and then reorganize them into a fluent sentence.</p><p>Therefore, motivated by the way of human writ- ing, we propose a skeleton-based model to im- prove the coherence of generated text. The key idea is to first generate a skeleton and then expand the skeleton to a complete sentence. As a sim- plified sentence representation, the skeleton can help machines learn the dependency of sentences by avoiding the interference of irrelevant informa- tion. Our model contains two parts: a skeleton-The artist provided champagne in flutes for everyone Friends toasted and cheered the artist as she opened her new studio Fans came together to celebrate the opening of a new studio for an artist <ref type="figure">Figure 1</ref>: The semantic dependency among sentences in a narrative story. It can be seen that the connection among sentences is mainly reflected through key phrases (shown in red). In this work, we regard such key phrases as a skeleton.</p><p>based generative module and a skeleton extraction module.</p><p>The generative module consists of an input- to-skeleton component and a skeleton-to-sentence component. The input-to-skeleton component learns to associate inputs and skeletons, and the skeleton-to-sentence component learns to expand a skeleton to a sentence. In our model, a good skeleton that can capture key semantic informa- tion is a critical supervisory signal.</p><p>The skeleton extraction module is used to gen- erate sentence skeletons. In real-world datasets, the human-annotated skeleton is usually unavail- able. In addition, it is difficult to define the uni- fied rules of extracting skeletons, because different sentences have different focuses. To address this problem, we build a skeleton extraction module to automatically explore sentence skeletons. Consid- ering the discrete choice of skeleton words causes the loss function to be non-differentiable, we use a reinforcement learning method to build the con- nection between the skeleton extraction module and the generative module.</p><p>Our contributions are listed as follows:</p><p>â€¢ A skeleton-based model is proposed to pro- mote the coherence of generated stories.</p><p>â€¢ The proposed model contains a skeleton- based generative module and a skeleton ex- traction module. Two modules are connected by a reinforcement learning method to auto- matically explore sentence skeletons.</p><p>â€¢ The experimental results on automatic eval- uation and human evaluation show that our model can generate significantly more coher- ent text compared to the state-of-the-art mod- els.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Strictly speaking, the story generation task re- quires systems to generate a story from scratch without any external materials. However, for sim- plification, many existing story generation models rely on their given materials, such as short text de- scriptions ( <ref type="bibr" target="#b7">Harrison et al., 2017;</ref><ref type="bibr" target="#b10">Jain et al., 2017)</ref>, visual images ( <ref type="bibr" target="#b2">Charles et al., 2001;</ref><ref type="bibr" target="#b9">Huang et al., 2016)</ref>, and so on. Different from these studies, we get rid of external materials and consider the complete story generation task <ref type="bibr" target="#b19">(McIntyre and Lapata, 2009)</ref>. For this task, the widely used mod- els are based on Seq2Seq models. However, al- though they can generate a fluent sentence ( ), these models still perform badly on generating inter-related sentences, which are nec- essary for a coherent story.</p><p>To address this problem, there are several mod- els that build the mid-level sentence semantic representation to simplify the dependency among sentences. <ref type="bibr" target="#b3">Clark et al. (2018)</ref> extract the entities in sentences, and combine the entity context and text context together when generating a target sen- tence. <ref type="bibr" target="#b1">Cao et al. (2018)</ref> encode the words with specific pre-defined dependency labels to a mid- level sentence representation. <ref type="bibr" target="#b18">Martin et al. (2018)</ref> use additional knowledge bases to get a general- ized sentence representation. <ref type="bibr" target="#b17">Ma et al. (2018b)</ref> use the bag-of-words which occur in all references as a representation of the correct translation. <ref type="bibr" target="#b15">Luo et al. (2018)</ref> propose to use two auto-encoders to learn the semantic representation of utterance in dialogue. However, although these models reduce the dependency sparsity to some extent, the unified rules are non-flexible and tend to generate over- simplified representations, resulting in the loss of key information.</p><p>Different from these models, we use a rein- forcement learning method to automatically ex- tract sentence skeletons for simplifying the de- pendency of sentences, rather than manual rules. Therefore, our proposed skeleton-based model is more flexible and can adaptively determine the ap- propriate granularity of sentence representations for a balance between keeping key semantics and Testing. Bottom: Training. The "input" means the existing text, including the source input and the al- ready generated text. The "skeleton" means the skele- ton of the output. The skeleton extraction module first extracts skeletons from gold outputs. The pairs of input-skeleton and skeleton-gold are used to train the input-to-skeleton component and the skeleton-to- sentence component. In return, the generative module can be used to evaluate the quality of extracted skele- tons. Therefore, we use the feedback of the generative module to reward extracted skeletons. By cooperation, the two modules can promote each other until conver- gence.</p><p>simplifying sentence representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Skeleton-Based Model</head><p>An overview of our proposed skeleton-based model is presented in Section 3.1. The details of the skeleton-based generative module and the skeleton extraction module are shown in Sec- tion 3.2 and Section 3.3. The reinforcement learn- ing method is explained in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>As shown in <ref type="figure" target="#fig_0">Figure 2</ref>, our model consists of two parts, a skeleton-based generative module G Ï† and a skeleton extraction module E Î³ . The generative module consists of an input-to-skeleton compo- nent and a skeleton-to-sentence component.</p><p>The generative module generates a story sen- tence by sentence. When decoding a sentence, the input-to-skeleton component first generates a skeleton based on the existing text, including the source input and the already generated text, and then the skeleton-to-sentence component expands and reorganizes the skeleton into a complete sen- tence. We keep running this process until the gen- erative module generates an ending symbol.</p><p>In the training process, we first use a weakly supervised method to assign the skeleton extrac- tion module with initial extraction ability. Then, we use extracted skeletons to train the input-to- skeleton component and the skeleton-to-sentence component. In return, the generative module can be used to evaluate the quality of extracted skele- tons. Therefore, we use the feedback of the gen- erative module to reward extracted skeletons. The reward refines the skeleton extraction module. The improved skeleton extraction module further en- hances the generative module. By cooperation, the two modules can promote each other until conver- gence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Skeleton-Based Generative Module</head><p>The skeleton-based generative module G Ï† con- sists of two parts: an input-to-skeleton component Q Î± and a skeleton-to-sentence component D Î¸ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Input-to-Skeleton Component</head><p>The input-to-skeleton component Q Î± builds on a Seq2Seq structure with a hierarchical encoder ( <ref type="bibr" target="#b12">Li et al., 2015)</ref> and an attention-based decoder <ref type="bibr" target="#b0">(Bahdanau et al., 2014</ref>). It is responsible for learn- ing the dependency between inputs and skele- tons. In the encoding process, we first obtain sen- tence representations via a word-level Long Short Term Memory (LSTM) network <ref type="bibr" target="#b8">(Hochreiter and Schmidhuber, 1997)</ref>, and then generate a com- pressed vector h via a sentence-level LSTM net- work. Finally, given the compressed vector h, the attention-based decoder is responsible for imagin- ing a skeleton.</p><p>Given the training pair of input c and skeleton s = {s 1 , Â· Â· Â· , s i , Â· Â· Â· , s T }, the cross-entropy loss is computed as</p><formula xml:id="formula_0">L Î± = âˆ’ T i=1 P Q (s i |c, Î±)<label>(1)</label></formula><p>where Î± refers to the parameters of the input-to- skeleton component. The skeleton s is extracted by the skeleton extraction module. The extracting details will be introduced in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Skeleton-to-Sentence Component</head><p>The skeleton-to-sentence component D Î¸ builds on a Seq2Seq structure. Both the encoder and the de- coder are one-layer LSTM networks with the at- tention mechanism. Given a skeleton s, the en- coder first generates a compressed representation, which is then used to generate a detailed and pol- ished sentence via the decoder. Given the training pair of skeleton s and target sentence y = {y 1 , Â· Â· Â· , y i , Â· Â· Â· , y M }, the cross- entropy loss is computed as</p><formula xml:id="formula_1">L Î¸ = âˆ’ M i=1 P D (y i |s, Î¸)<label>(2)</label></formula><p>where Î¸ refers to the parameters of the skeleton- to-sentence component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Skeleton Extraction Module</head><p>Given a sentence x, the skeleton extraction mod- ule E Î³ is responsible for extracting its skeleton that only preserves the key information. Spe- cially, we use the Seq2Seq model with the atten- tion mechanism as the implementation. Both the encoder and the decoder are based on LSTM struc- tures.</p><p>Since the extracted skeletons are treated as su- pervisory signals for the generative module, the extraction ability needs to be initialized. To pre- train the skeleton extraction module, we propose a weakly supervised method. We reformulate skele- ton extraction as a sentence compression problem and use a sentence compression dataset to train this module. In sentence compression, the com- pressed sentence is required to be grammatical and convey the most important information. From the aspect of keeping important information, the sen- tence compression dataset can be used to help the training of the skeleton extraction module. How- ever, since the style of the sentence compression dataset is very different from that of the narrative story dataset, it is difficult for the pre-trained mod- ule to give narrative text accurate compression re- sults. Therefore, the supervisory signals are noisy and need to be further improved.</p><p>Given the training pair of the origi- nal text x and the compressed version s = {s 1 , Â· Â· Â· , s i , Â· Â· Â· , s T }, we use the following cross-entropy loss to pre-train E Î³ :</p><formula xml:id="formula_2">L Î³ = âˆ’ T i=1 P E (s i |x, Î³)<label>(3)</label></formula><p>where Î³ is the parameters of the skeleton extrac- tion module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Reinforcement Learning Method</head><p>We propose a reinforcement learning method to build the connection between the skeleton ex- Algorithm 1 The reinforcement learning method for training the generative module G Ï† and the skeleton extraction module E Î³ .</p><p>1: Initialize the generative module G Ï† and the skeleton ex- traction module EÎ³ with random weights Ï†, Î³ 2: Pre-train EÎ³ using MLE based on Eq. 3 3: for each iteration j = 1, 2, ..., J do 4:</p><p>Generate a skeleton sj based on EÎ³ 5:</p><p>Given sj, train G Ï† based on Eq. 1 and Eq. 2. 6:</p><p>Compute the reward Rc based on Eq. 5 7:</p><p>Compute the gradient of EÎ³ based on Eq. 4 8:</p><p>Update the model parameter Î³ 9: end for traction module and the skeleton-based generative module for exploring better skeletons. The de- tailed training process is shown in Algorithm 1.</p><p>Due to the discrete choice of words in skeletons, the loss is no longer differentiable over the skele- ton extraction module. Therefore, we use policy gradient <ref type="bibr" target="#b22">(Sutton et al., 1999</ref>) to train the skeleton extraction module.</p><p>First, we calculate a reward R c based on the feedback of the generative module. The details of calculation process will be introduced in Sec- tion 3.4.1. Then, we optimize the parameters through policy gradient by maximizing the ex- pected reward to train the skeleton extraction mod- ule. According to the policy gradient theorem, the gradient for the skeleton extraction module is</p><formula xml:id="formula_3">J(Î³) = E[R c Â· log(P E (s|x), Î³)] (4)</formula><p>where x is the original sentence, s is the skeleton generated by a sampling mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Reward</head><p>To design an appropriate rewarding function, there is a critical question that needs to be considered: what will good/bad skeletons bring to the genera- tive module.</p><p>We first define what is a good (or bad) skele- ton. A good skeleton is expected to contain all key information and ignore other information. In con- trast, the skeletons that contain too much detailed information or lack necessary information are con- sidered as bad skeletons and should be punished. For ease of analysis, we classify possible scenarios into three categories: good skeletons, incomplete skeletons, and redundant skeletons.</p><p>If a skeleton contains too little information, it will get harder for the skeleton-to-sentence com- ponent to reconstruct the original sentence based on the skeleton. Therefore, the cross-entropy loss of this example will be higher compared with other skeleton-sentence pairs.</p><p>If a skeleton contains too much redundant infor- mation, the input-skeleton relation will be sparse. Therefore, the cross-entropy loss of this example will be higher compared with other input-skeleton pairs.</p><p>For a good skeleton that contains an appropri- ate amount of information, it will benefit the two components and will get balanced losses from the two components.</p><p>Therefore, to encourage good skeletons and punish bad skeletons, we use the multiplication of the cross-entropy loss in the input-to-skeleton component and that in the skeleton-to-sentence component as the reward:</p><formula xml:id="formula_4">R c = [K âˆ’ (R 1 Ã— R 2 ) 1 2 ]<label>(5)</label></formula><p>where K is the upper bound of the reward, R 1 and R 2 are cross-entropy losses in the input-to- skeleton component and the skeleton-to-sentence component, respectively. Only if two components both output lower cross-entropy losses, the ex- tracted skeleton can be rewarded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head><p>In this section, we evaluate our model on a narra- tive story generation dataset. We first introduce the dataset, the training details, the baselines, and the evaluation metrics. Then, we compare our model with the state-of-the-art models. Finally, we show the experimental results and provide the detailed analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>We use the recently introduced visual storytelling dataset ( <ref type="bibr" target="#b9">Huang et al., 2016</ref>) in our experiments. This dataset contains the pairs of photo sequences and the associated coherent narrative of events through time written by humans. We only use the text data for our experiments. In our version of narrative story generation, the model should gen- erate a coherent story based on a given sentence. We build a new dataset for this task by splitting the data into two parts. In each story, we take the first sentence as the input text, and the following sentences as the target text. The processed dataset contains 40153, 4990, and 5054 stories for train- ing, validation, and testing, respectively. The max- imum number of sentences in each story is 6. In total, the number of training sentences is over 20K and the number of training words is over 2M. To pre-train the skeleton extraction module, we use a sentence compression dataset <ref type="bibr" target="#b6">(Filippova and Altun, 2013)</ref>. In this dataset, every compression is a subsequence of tokens from the input. The dataset contains 16999, 1000, and 1998 pairs for training, validation, and testing, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baselines</head><p>We compare our proposed model with the follow- ing the state-of-the-art models.</p><p>Entity-Enhanced Seq2Seq Model (EE- Seq2Seq) <ref type="bibr" target="#b3">(Clark et al., 2018)</ref>. It regards entities as important context needed for coherent stories. When decoding a sentence, it combines entity context and text context together to reduce dependency sparsity.</p><p>Dependency-Tree Enhanced Seq2Seq Model (DE-Seq2Seq) <ref type="bibr" target="#b1">(Cao et al., 2018)</ref>. It defines some manual rules based on dependency parsing labels to find a simplified sentence representation. Fol- lowing this work, we treat the extracted words based on the predefined rules as the skeleton.</p><p>Generalized-Template Enhanced Seq2Seq Model (GE-Seq2Seq) <ref type="bibr" target="#b18">(Martin et al., 2018)</ref>. It takes advantages of existing knowledge bases to get a generalized sentence representation. Follow- ing this work, we treat the generalized sentence representation as the skeleton.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Training Details</head><p>For narrative story generation, we set the num- ber of generated sentences to 6 with the maximum length of 40 words for each generated sentence. Based on the performance on the validation set, we set the hidden size to 128, embedding size to 50, vocabulary size to 20K, and batch size to 10 for the proposed model and the state-of-the-art mod- els. We use the Adagrad (Duchi et al., 2011) opti- mizer with the initial learning rate 0.6. All of the gradients are clipped when the norm exceeds 2. Both the generative module and skeleton extrac- tive module are pre-trained for 30 and 40 epochs before reinforcement learning. The K in Equa- tion 5 is set to 1. Due to the lack of annotated enti- ties and dependency parsing labels, we use a pop- ular natural language processing toolkit, Spacy 2 , to extract entities and dependency parsing labels in the EE-Seq2Seq and DE-Seq2Seq models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models BLEU EE-Seq2Seq</head><p>0.0029 DE-Seq2Seq 0.0027 GE-Seq2Seq 0.0022 Proposed Model 0.0042 (+44.8%) <ref type="table" target="#tab_1">Table 2</ref>: Automatic evaluations of the proposed model and the state-of-the-art models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation Metrics</head><p>We conduct two kinds of evaluations in this work, automatic evaluation and human evaluation. The details of evaluation metrics are shown as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Automatic Evaluation</head><p>Following the previous work ( <ref type="bibr" target="#b13">Li et al., 2016;</ref><ref type="bibr" target="#b18">Martin et al., 2018)</ref>, we use the BLEU score to mea- sure the quality of generated text. BLEU ( <ref type="bibr" target="#b20">Papineni et al., 2002</ref>) is originally designed to automati- cally judge the machine translation quality. The key point is to compare the similarity between the results created by the machine and the references provided by the human. Currently, it is widely used in many generation tasks, such as dialogue generation, story generation, summarization, and so on. For precise results, we remove all stop words, like "the", "a", before computing BLEU scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Human Evaluation</head><p>Although the quantitative evaluation generally in- dicates the quality of generated stories, it can not accurately evaluate the generated text. Therefore, we also perform a human evaluation on the test set. We randomly choose 100 items for human evalu- ation. Each item contains the stories generated by different models given the same source sentence. The items are distributed to the annotators who have no knowledge about which model the story is from. It is important to note that all the anno- tators have linguistic background. They are asked to score the generated stories in terms of fluency and coherence. Fluency represents whether each sentence in the generated story is correct in gram- mar. Coherence evaluates whether the generated story is coherent. The score ranges from 1 to 10 (1 is very bad and 10 is very good). To evaluate the overall performance, we use the geometric mean of fluency and coherence as an evaluation metric.  cording to BLEU. In particular, the differences between the existing state-of-the-art models are within 0.07, while the proposed model supersedes the best of them by 0.13. As we previously explained, the best evalua- tion for narrative story generation is human eval- uation. The human evaluation results are listed in <ref type="table" target="#tab_2">Table 3</ref>. <ref type="bibr">3</ref> As for fluency, the proposed model receives the score of 8.69, second to the GE-Seq2Seq model. It is expected that the generalized templates can constrain the search space in generation and the model achieves higher fluency by loss of expres- sive power. In particular, we find that only 0.48%, 1.01%, and 1.20% of the unigrams, bigrams, and trigrams are unique in the stories generated by the GE-Seq2Seq model, while the percentages are 3.16%, 15.33%, and 29.67% in the stories gen- erated by our proposed model. Nonetheless, the proposed model outperforms the other two exist- ing models by a substantial margin. In terms of coherence, the proposed model is better than all the existing models. We need to point out that the GE-Seq2Seq model is scored the lowest in coher- ence, while highest in fluency. It indicates that the GE-Seq2Seq model does not learn the dependency among sentences effectively, which results from the constraint of the templates. It also needs to be noted that the models are all scored below 6 in coherence, meaning that there is still a long way to go before the generated stories satisfy the require- ment of humans. Overall, the proposed model is arguably better than the existing models in that it achieves a balance between coherence and fluency, with a G-score improvement of 20.1%. <ref type="table" target="#tab_3">Table 4</ref> presents the examples generated by different models. Compared with the existing models, the sentences generated by our proposed model are connected more logically. For the EE- Seq2Seq model, while it connects park with plants and rocks successfully (4th ex.), it insists on telling getting married when it sees <ref type="bibr">[male]</ref> or [female] (1st and 2nd ex.). Such examples suggest that some entities (e.g. park) embody semantics more independently, while for others (e.g. male), we have to associate them in the specific context. The rest of the models try to generalize the tar- get sentences. The DE-Seq2Seq model uses the core dependency arguments as the skeleton. How- ever, the results demonstrate the generated sen- tences are quite irrelevant. The sentence may have links such as walked through to came out (1st ex.), but the objects in the generated stories are hardly related. The GE-Seq2Seq model replaces the specific words with more general concepts and generates some good examples, e.g. the second one in the table. However, there can be over- generalizations. For example, as for the third ex- ample, the GE-Seq2Seq model associates driving with car show, causing the incoherent description. In the last example, the generated story completely diverges from the input. These results prove the drawbacks of static rule-based skeletons. The pro- posed model uses a skeleton extraction module to adaptively determine the appropriate granular- ity of skeletons. The skeleton keeps the main se- mantic of a sentence, which can be a whole sen- tence, phrases, or even segments. It makes the model learn the dependency of sentences more ef- fectively so that the generated stories are much more coherent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Incremental Analysis</head><p>In this section, we conduct a series of experiments to evaluate the contributions of our key compo- nents. The results are listed in <ref type="table" target="#tab_4">Table 5</ref>. The Seq2Seq model is scored the lowest according to BLEU. With the skeleton extraction module, the BLEU score is slightly improved, which sug- gests that the model starts to learn the connection of longer segments. Finally, with reinforcement learning, the BLEU score significantly overpasses the Seq2Seq model by 40%. <ref type="table">Table 6</ref> shows the human evaluation results. The slight improvement with the skeleton extrac- tion module in BLEU reflects as the decreases in both fluency and coherence. It suggests the ne- cessity of human evaluation. The decreased re- sults can be explained by the fact that the style of the dataset for pre-training the skeleton extraction module is very different from the narrative story Input 1: <ref type="bibr">[Female]</ref> and her friend had a night out on the town. EE-Seq2Seq: They were very happy to see us. <ref type="bibr">[Male]</ref> and <ref type="bibr">[female]</ref> were getting married today. DE-Seq2Seq: We walked through the streets of the city and found a place to sit. The whole family came out to support their families. GE-Seq2Seq: My friends and I went to a bar last night. <ref type="bibr">[Female]</ref> was so happy to be there. Proposed Model: They went to the bar. They had a great time. Input 2: <ref type="bibr">[Male]</ref> and <ref type="bibr">[male]</ref> are talented artists. EE-Seq2Seq: They were very happy to see us. <ref type="bibr">[Male]</ref> and <ref type="bibr">[female]</ref> were getting married today. DE-Seq2Seq:The kids get to play with the kids. We had a great time. GE-Seq2Seq:The art was very subjective. The artist had a keen eye. Proposed Model: They are discussing the importance of the lecture. Input 3: The bride was driving to the wedding. EE-Seq2Seq: The family was so happy to be there. They were very happy to see us. DE-Seq2Seq: The view from the top was amazing. There were a lot of people there. GE-Seq2Seq: I went to the car show last weekend. People are getting ready to go. Proposed Model: The groom and groomsmen watched the bride. They kissed and shared their pictures. Input 4: The park was filled with beauty. EE-Seq2Seq: The plants were so beautiful. The rocks were very pretty. DE-Seq2Seq: The family was so happy to be there. GE-Seq2Seq: There were a lot of people there. We had a great time. Proposed Model: The trees were very sparse. There were also some flowers.  dataset. While it may help extract some useful skeletons, it is likely that many of them are not suitable for learning the dependency of sentences. Finally, when the skeleton extraction module is trained on the target domain using reinforcement learning, the human evaluation is improved signif- icantly by 14% on G-score. <ref type="table">Table 7</ref> further shows the results of the skele- ton extraction module. As we can see, the mod- ule keeps only the essential parts of the sen- tence. Most of the adjectival phrases and adverbial phrases are removed. Furthermore, we can find that for longer sentences that contain too detailed information, it only extracts the key information. For shorter sentences where all information is nec-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>Fluency Coherence G-Score Seq2Seq</p><p>7.54 4.98 6.13 +Skeleton Extraction Module 7.26 4.32 5.60 +Reinforcement Learning 8.69 5.62 6.99 <ref type="table">Table 6</ref>: Human evaluations of the key components.</p><p>1) There was a small power station on the side of the building.</p><p>2) The lady wearing the pink shirt decided to stop play- ing the video and chatted with other guests.</p><p>3) At the end of the night, guests taking pictures before saying goodbye to each other. 4) Afterwards, we celebrated with some drinks and watched the rest of the parade. 5) A few miles away was a lake that we really enjoyed watching. 6) Some of the guests partied harder than others.</p><p>7) The bride was driving to the wedding. <ref type="table">Table 7</ref>: Analysis of the skeleton extraction module. Given a whole sentence as input, the words in red are the extracted skeleton.</p><p>essary, it choose to keep all words. It proves that the skeleton extraction module is effective and is expert in only removing detailed information that is not needed. Furthermore, it is not quite surprising to see that on our dataset, the Seq2Seq model beats the existing state-of-the-art models (DE-Seq2Seq and GE-Seq2Seq) in human evaluation and automatic evaluation. It is mainly attributed to the over- simplification of sentences. For narrative sen- tences, the key information is usually expressed in a complicated way. It can be a segment, a phrase, or a whole sentence. The simple rules lead to the excessive loss of key information while our pro- posed model can adaptively determine the appro- priate granularity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Error Analysis</head><p>Although the proposed model outperforms the state-of-the-art models, it needs to be noted that the highest coherence score, 5.62, is a moderate result in human evaluation, indicating that there is still a long way to go before the generated stories reach the human level. Therefore, in this subsec- tion, we give a detailed error analysis to explore what factors affect the performance.</p><p>First, we classify the generated stories with scores below 6 that are considered less coherent. We conclude 4 types of errors from these outputs and the distribution of error types are shown in <ref type="figure">Figure 3</ref>. It is expected that the irrelevant scenes make up most of the errors. In addition, there are several examples that are hard to be understood due to chaotic syntax. For the type of chaotic time- line, the model neglects the time order of scenes and the generated stories goes backward in time. The repeated scenes mean that the generated sto- ries just describe the input again. The above errors show that there are many dimensions in coherence, including scene-specific relevance, temporal con- nection, and non-recurrence. Modeling such di- mensions is still a hard problem.</p><p>Furthermore, we explore how the performance is affected by the length of input and the unseen ratio of input. The results are shown in <ref type="figure" target="#fig_1">Figure 4</ref>. "Unseen ratio" is the percentage of the phrases that are not seen in the training data. We use the gap between 1 and the BLEU score with the train- ing data as the reference to compute it. When the input is short and the model often sees the input, the generated story tends to have high coherence. However, when the length of input increases and the model is not familiar with the input, the co- herence goes down. Since our model extracts the key semantics better, the dependency of sentences can be easier to learned, which brings the smaller decrease in coherence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this work, we propose a new skeleton-based model for generating coherent narrative stories.</p><p>Different from traditional models, the proposed model first generates a skeleton that contains the key information of a sentence, and then expands the skeleton to a complete sentence. Experimental results show that our model significantly improves the quality of generated stories, especially in co- herence. However, even with the best human eval- uation results, the error analysis shows that there are still many challenges in narrative story genera- tion, which we would like to explore in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An illustration of the proposed model. Top: Testing. Bottom: Training. The "input" means the existing text, including the source input and the already generated text. The "skeleton" means the skeleton of the output. The skeleton extraction module first extracts skeletons from gold outputs. The pairs of input-skeleton and skeleton-gold are used to train the input-to-skeleton component and the skeleton-tosentence component. In return, the generative module can be used to evaluate the quality of extracted skeletons. Therefore, we use the feedback of the generative module to reward extracted skeletons. By cooperation, the two modules can promote each other until convergence.</figDesc><graphic url="image-2.png" coords="3,117.87,136.62,124.94,62.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 3: The distribution of error types.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc>An illustration of narrative story generation.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 shows the results of automatic evalua- tion. The proposed model performs the best ac-</head><label>2</label><figDesc></figDesc><table>Models 
Fluency Coherence 
G-Score 
EE-Seq2Seq 
6.28 
5.14 
5.68 
DE-Seq2Seq 
8.48 
3.54 
5.48 
GE-Seq2Seq 
9.48 
3.58 
5.82 
Proposed Model 8.69 
5.62 
6.99 (+20.1%) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 : Human evaluations of the proposed model and the state-of-the-art models.</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 : Examples generated by the proposed model and the state-of-the-art models.</head><label>4</label><figDesc></figDesc><table>Models 
BLEU 
Seq2Seq 
0.0028 
+Skeleton Extraction Module 0.0029 
+Reinforcement Learning 
0.0042 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 : Automatic evaluations of key components.</head><label>5</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> The code is available at https://github.com/ lancopku/Skeleton-Based-Generation-Model</note>

			<note place="foot" n="2"> https://spacy.io/</note>

			<note place="foot" n="3"> The inter-annotator agreement is satisfactory considering the difficulty in the human evaluation. The Pearson&apos;s correlation coefficient is 0.37 on coherence and 0.26 on fluency, with p &lt; 0.0001.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported in part by National Natu-ral Science Foundation of China (No. 61673028). We thank all the reviewers for providing the con-structive suggestions. Xu Sun is the corresponding author of this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>abs/1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Faithful to the original: Fact aware neural abstractive summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqiang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ThirtySecond AAAI Conference on Artificial Intelligence</title>
		<meeting>the ThirtySecond AAAI Conference on Artificial Intelligence<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-02-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Character-driven story generation in interactive storytelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Mead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cavazza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. Seventh International Conference on</title>
		<meeting>Seventh International Conference on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="609" to="615" />
		</imprint>
	</monogr>
	<note>Virtual Systems and Multimedia</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Neural text generation in stories using entity representations as context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>NAACL HLT 2018</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Hierarchical neural story generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<idno>abs/1805.04833</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Overcoming the lack of parallel data in sentence compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Filippova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasemin</forename><surname>Altun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="1481" to="1491" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Toward automated story generation with markov chain monte carlo methods and deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brent</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Purdy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Workshop on Intelligent Narrative Technologies</title>
		<meeting>the 2017 Workshop on Intelligent Narrative Technologies</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">JÃ¼rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Visual storytelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ting-Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasrin</forename><surname>Ferraro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">15th Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Story generation from sequence of independent short descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parag</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priyanka</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhijit</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohak</forename><surname>Sukhwani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirban</forename><surname>Laha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<idno>abs/1707.05501</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Story generation with crowdsourced plot graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lee-Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the TwentySeventh AAAI Conference on Artificial Intelligence</title>
		<meeting>the TwentySeventh AAAI Conference on Artificial Intelligence<address><addrLine>Bellevue, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-07-14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A hierarchical neural autoencoder for paragraphs and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015-07-26" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1106" to="1115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-01" />
			<biblScope unit="page" from="1192" to="1202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Table-to-text generation by structure-aware seq2seq learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kexiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
		<idno>abs/1711.09724</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An auto-encoder matching model for learning utterance-level semantic dependency in dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangchen</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Autoencoder as assistant supervisor: Improving text representation for chinese social media text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuming</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
		<idno>abs/1805.04869</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Bag-of-words as target for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuming</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyang</forename><surname>Lin</surname></persName>
		</author>
		<idno>abs/1805.04871</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Event representations for automated story generation with deep neural nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lara</forename><forename type="middle">J</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prithviraj</forename><surname>Ammanabrolu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Hancock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shruti</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brent</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">O</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-02-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning to tell tales: A data-driven approach to story generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Neil Duncan Mcintyre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL 2009, Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-02-07" />
			<biblScope unit="page" from="217" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Philadelphia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Usa</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002-07-06" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-12-813" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Policy gradient methods for reinforcement learning with function approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Satinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yishay</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Denver, Colorado, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-11-29" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1057" to="1063" />
		</imprint>
	</monogr>
	<note>NIPS Conference</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Diversity-promoting gan: A crossentropy based generative adversarial network for diversified text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuancheng</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Unpaired sentiment-to-sentiment translation: A cycled reinforcement learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuancheng</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
