<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:20+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Using Content-level Structures for Summarizing Microblog Repost Trees *</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
									<region>N.T</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">MoE Key Laboratory of High Confidence Software Technologies</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Gao</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Qatar Computing Research Institute</orgName>
								<orgName type="institution" key="instit2">Hamad Bin Khalifa University</orgName>
								<address>
									<settlement>Doha</settlement>
									<country key="QA">Qatar</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyu</forename><surname>Wei</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">The University of Texas at Dallas</orgName>
								<address>
									<settlement>Richardson</settlement>
									<region>Texas</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baolin</forename><surname>Peng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
									<region>N.T</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">MoE Key Laboratory of High Confidence Software Technologies</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kam-Fai</forename><surname>Wong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
									<region>N.T</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">MoE Key Laboratory of High Confidence Software Technologies</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Using Content-level Structures for Summarizing Microblog Repost Trees *</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>A microblog repost tree provides strong clues on how an event described therein develops. To help social media users capture the main clues of events on mi-croblogging sites, we propose a novel re-post tree summarization framework by effectively differentiating two kinds of messages on repost trees called leaders and followers, which are derived from content-level structure information, i.e., contents of messages and the reposting relations. To this end, Conditional Random Fields (CRF) model is used to detect leaders across repost tree paths. We then present a variant of random-walk-based summariza-tion model to rank and select salient messages based on the result of leader detection. To reduce the error propagation cascaded from leader detection, we improve the framework by enhancing the random walk with adjustment steps for sampling from leader probabilities given all the re-posting messages. For evaluation, we construct two annotated corpora, one for leader detection, and the other for repost tree summarization. Experimental results confirm the effectiveness of our method.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Microblogging platforms have become the center for reporting, discussing, and disseminating real- life issues, on which users usually repost to share microblog messages with their following users. Also, users can repost with commentary for not only further broadcasting but also extending the * This work is partially supported by General Research Fund of Hong Kong (417112), RGC Direct Grant (417613), and Huawei Noah's Ark Lab, Hong Kong. We would like to thank anonymous reviewers for the useful comments.</p><p>original microblog post content. Because an in- dividual post is generally too short to cover the main clues of an event, microblogging users can- not easily capture the key information from re- ceived posts due to the lack of context. And re- posting messages, namely reposts, can provide valuable context information to the previous posts including their background, development, public opinions and so on. However, a popular post usu- ally attracts a large number of reposts. It is imprac- tical for users to read them all and fully understand their contents.</p><p>The task of microblog context summarization aims to produce succinct summaries to help users better understand the main clues by extracting salient information among massive reposts of the original posts. An intuitive approach is to directly apply existing extractive summarizers based on the unstructured, plain microblog contents. But such short and informal reposts render the lack of structures in each individual message, and it is difficult for conventional extractive summarizersto identify salient messages. <ref type="bibr" target="#b2">Chang et al. (2013)</ref> pro- posed to summarize Twitter context trees by fo- cusing on modeling user influence. However, the reposts of influential users might not be salient summary candidates necessarily. For instance, celebrities might simply repost with nothing im- portant. Also, modeling user influence accurately needs tremendous historical user interaction data external to the tree being summarized while such kind of information cannot be utilized directly for summarizing the messages on the tree.</p><p>In this paper, we propose a novel mi- croblog context summarization framework based on content-level structures, i.e., message contents and reposting relations, rather than user-level in- fluence signals. The reposting relations connect the reposting messages and form a cohesive body as a tree structure named repost tree. The root rep- resents the original post and the edges denote re-posting relations. Our idea is to exploit the struc- ture of repost tree together with content of mes- sages to help distinguish two different messages on repost tree, i.e., leaders and followers. Specif- ically, leader is referred to as a message on re- post tree covering salient new information, which can lead further comments or discussions in its de- scendant reposts; follower is referred to as a mes- sage that contains no comment, simply repeats or naively responds to its ancestor leader message, thus providing no important information. The ex- ample below illustrates a repost tree path, where we use <ref type="bibr">[O]</ref> and <ref type="bibr">[R i</ref> ] to indicate the original post and the i-th repost, respectively:</p><p>[O] @MAS: Malaysia Airlines has lost contact of MH17 from Amsterdam. The last known position was over Ukrainian airspace.</p><p>[R1] @Hanna: OMG... Poor on MH17... Preying...</p><p>[R2] @Victoria: OMG that's horrible!!! I'm sorry to hear that. God will bless u poor guys. Wish world can be peaceful. And no one will get hurt.</p><p>[R3] @Dr.Dr: Six top HIV scientists are on MH17. Intuitively, leaders would be more important than followers from the summarization's perspec- tive since leaders are supposed to capture the main clues or aspects of event evolvement. The first step of our summarization system is to distinguish leaders and followers effectively. Leaders are de- tected across repost tree paths which provide rich context information owing to the tree structure. We utilize sequence tagging model Conditional Random Fields (CRF) to infer how likely it is each repost being a leader or follower. Then we incor- porate leader detection result into an unsupervised summarization model based on random walk. Our model uses content similarities between messages and consider their possibilities of being leaders to rank and select salient reposting messages that form summaries. Furthermore, we improve the framework by enhancing the random walk to re- duce the impact of errors cascaded from the leader detection module. Compared to the state-of-the- art baselines, the experimental results confirm the effectiveness of our proposed framework.</p><p>Our contributions are given as follows:</p><p>• We propose a novel microblog context sum- marization framework, in which given reposting messages organized as a repost tree (obtaining repost tree is trivial using public microblogging toolkit <ref type="bibr" target="#b25">(Ren et al., 2014)</ref>), we summarize the re- post trees based on content information and re- posting relations of messages.</p><p>• We identify a novel problem of leader de- tection for summarization, which aims to reduce noise on repost trees, and present a CRF-based method for effectively detecting leaders by utiliz- ing the tree structure and message contents.</p><p>• We incorporate the leader detection result into an unsupervised summarization model based on random walk and substantially enhance the model to reduce the impact of leader detection er- rors on summarization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The goal of text summarization is to automat- ically produce a succinct summary for one or more documents that preserves important infor- mation ( <ref type="bibr" target="#b22">Radev et al., 2002</ref>). Generally, text sum- marization techniques can be categorized into ex- tractive and abstractive methods <ref type="bibr" target="#b3">(Das and Martins, 2007)</ref>. Extractive approaches focus on how to identify and distill salient contents from orig- inal texts whereas abstractive approaches aim at producing grammatical summaries by text genera- tion.</p><p>Recently, the development of social media has made microblog summarization a hot topic. Most prior works are on event-level or topic-level sum- marization. Typically, the first step is to clus- ter posts into sub-events ( <ref type="bibr" target="#b1">Chakrabarti and Punera, 2011;</ref><ref type="bibr" target="#b4">Duan et al., 2012;</ref><ref type="bibr" target="#b28">Shen et al., 2013</ref>) or sub- topics ( <ref type="bibr" target="#b17">Long et al., 2011;</ref><ref type="bibr" target="#b26">Rosa et al., 2011;</ref><ref type="bibr" target="#b19">Meng et al., 2012)</ref>, and then the second step generates summary for each cluster.</p><p>Some works tried to apply conventional extractive summarization models directly, e.g., <ref type="bibr">LexRank (Erkan and Radev, 2004</ref> However, these general summarizers were found not suitable for microblog posts, which are infor- mal and noisy <ref type="bibr" target="#b2">(Chang et al., 2013)</ref>. Researchers then considered social signals like user following relations and retweet count ( <ref type="bibr" target="#b4">Duan et al., 2012;</ref>, and reported such features useful to help summarize microblog posts. Our work studies repost tree summarization by leverag- ing content-level structure to enrich context of messages, which is a different kind of signal. <ref type="bibr" target="#b2">Chang et al. (2013)</ref> proposed a task to summa- rize Twitter context trees consisting of an original tweet and all its reposts (i.e., replies and retweets). They combined user influence signals into a super- vised summarization framework. Our work is dif- ferent from theirs: 1) They simply treat a context tree as a tweets stream while we consider repost tree structures in summarization; 2) They rely on user interactions to calculate user influence for ex- tracting salient messages while we focus on how to utilize contents and repost tree structures to dif- ferentiate leader and follower messages for sum- marization; 3) Our summarization module is unsu- pervised, thus no need of ground-truth summaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Leader Detection Model</head><p>This section deals with how to differentiate leader and follower messages on a repost tree. Intu- itively, identifying leaders effectively makes one step closer to obtaining a good summary. <ref type="figure" target="#fig_1">Figure 1</ref> illustrates an example of a repost tree 1 . As shown in the figure, a leader message contains contents that brings essential information increase, such as a new clue about MH17 reported in <ref type="bibr">[R 6</ref> ], and potentially triggers a new round of informa- tion propagation by attracting follower messages to focus on the raised clue, like [R 7 ], <ref type="bibr">[R 8</ref> ] and <ref type="bibr">[R 9</ref> ]. As the repost tree grows, it also happens that some new reposts join in, following the clue raised by one of their ancestors, but further ex- tend it by mentioning something new, thus some of these messages may evolve into new leaders, such as <ref type="bibr">[R 10 ]</ref>.</p><p>A simple way to detect leaders on repost tree is to directly apply a binary classifier like SVM on each individual message. However, these mod- els assume reposts are independent without effec- tively leveraging abundant context along the re- post tree paths, such as the reposting relations among different reposts on a path. For instance, <ref type="bibr">[R 2</ref> ] covering rich content may be misclassified as a leader if not leveraging context information. But <ref type="bibr">1</ref> The example in Section 1 actually denotes the left-most path extracted from this tree</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[O] MAS: Malaysia Airlines has lost contact of MH17 from Amsterdam. The last known position was over Ukrainian airspace. More details to follow.</head><p>[R1] Hanna: OMG…Poor on #MH17…Preying…</p><p>[R2]Victoria: OMG that's horrible!!! I'm sorry to hear that. God will all bless u poor guys. Wish world can be peaceful. And no one will get hurt.</p><p>[R3] Dr.Dr: Six top HIV scientists are on MH17. They go for AIDS and would NEVER come back!!!</p><p>[R4] TomyBlack: 6 experts died?! Terrible loss to HIV research :(</p><p>[R5] JustinBieber: now i can't listen to #prey without crying</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[R6] NajibRazak: I am shocked by reports that</head><p>an MH plane crashed. We are launching an immediate investigation.</p><p>[R7]MrsBig: RT</p><p>[R8] MrBig: That can't be true. CRASHED…I really feel pity for u poor guys…</p><p>[R9] WindWolf: eh…MH17 lost and now a MH plane is found crashed. I feel terrible.</p><p>[R10] X-man: #MH17 must have crashed. MH370 has not been found, and now MH17' s lost, here's something suspicious. if we look into its context, we can find that <ref type="bibr">[R 2</ref> ] talks about similar things as</p><formula xml:id="formula_0">[R 1 ], then [R 1 ]</formula><p>clas- sified as a follower indicates the higher chance of [R 2 ] being a follower rather than a leader. There- fore, context information is important for indicat- ing the messages being leaders or followers.</p><p>We extract all root-to-leaf paths within a repost tree structure and detect leaders across each path. We formulate leader detection on repost tree paths as a sequence tagging problem by utilizing a state- of-the-art sequence learning model CRF ( <ref type="bibr" target="#b11">Lafferty et al., 2001</ref>), and taking advantage of its power in maximizing the likelihood of global label se- quences. We adopt CRF rather than other compet- itive context sensitive model like SVM hmm (Al- tun et al., 2003) due to its probabilistic nature. The probability of prediction by CRF can pro- vide critical chances for the following summariza- tion procedure to reduce the impact of errors made by leader detection model on summarization (see Section 4.2).</p><p>We map a repost tree path with n microblogs</p><formula xml:id="formula_1">(m 1 , m 2 , · · · , m n ) to a training instance (X, Y ). Let X = (x 1 , x 2 , · · · , x n ) represents observed sequence</formula><p>, where x i denotes the observed feature vector extracted from the i-th microblog m i , and Y = (y 1 , y 2 , · · · , y n ) where y i is the label indicat- ing whether m i is a leader or not. CRF defines the discriminative function as a joint distribution over Y given X as follows:</p><formula xml:id="formula_2">P (Y |X; θ) ∝ exp   i,j λj fj (yi, yi−1, X) + i,k µ k g k (yi, X)  </formula><p>where f j and g k are the fixed feature functions,   Path-specific Similarity to neighbors Cosine similarity between mi and m i+d where d ∈ {±1, ±2, ±3} Similarity to root Cosine similarity to the root microblog in repost tree path <ref type="table">Table 1</ref>: Features used for leader detection</p><formula xml:id="formula_3">θ = (λ 1 , λ 2 , ...; µ 1 , µ 2 , .</formula><p>..) are the parameters in- dicating the weights of features that can be esti- mated by maximum likelihood procedure in train- ing process. The prediction is done based on dy- namic programming. More details can be found in ( <ref type="bibr" target="#b11">Lafferty et al., 2001</ref>). <ref type="table">Table 1</ref> lists the features we use for leader detection. CRF can utilize both historical and future infor- mation for prediction so as to maximize the likeli- hood of the global label sequences. But we would encounter the problem of label conflict, i.e., the predictions for the same repost in context of dif- ferent paths might be different. For this reason, we determine a repost as a leader if its average marginal probabilities being a leader in context of different paths exceeds 50%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">LeadSum Summarization Model</head><p>Let T = (V, E) represent a repost tree to be summarized, where V is a set of nodes cor- responding to microblog messages, and E = {(u, v)|v is the repost of u} is the edge set denot- ing reposting relations. This section describes how to rank nodes in V to produce repost tree summaries. Enlightened by the general random- walk-based ranking algorithm DivRank ( <ref type="bibr" target="#b18">Mei et al., 2010)</ref>, we propose an unsupervised summa- rization model called LeadSum that aims to select true and salient leaders into summaries utilizing a variant of random walk based on content similari- ties and reposting relations of messages. We first present a basic LeadSum model, which assumes leader detection is perfect. Then, we enhance it to become a soft LeadSum model that reduces the impact of leader detection errors on the summa- rization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Basic-LeadSum Model</head><p>Due to the nature of leaders, they generally cover more important contents than follows do. Thus our first summarizer selects contents only from de- tected leaders. For the leaders detected in a re- post tree T , we build a similarity graph among leaders denoted as</p><formula xml:id="formula_4">G L = (V L , E L ), where V L = {v ∈ V |v is a detected leader} is the vertex set and E L = {(u, v)|u ∈ V L , v ∈ V L ,</formula><p>and u = v} is the edge set. The weight for any edge (u, v) rep- resents the content similarity between u and v, for which we use cosine similarity.</p><p>DivRank ( <ref type="bibr" target="#b18">Mei et al., 2010</ref>) is a generic graph ranking model that aims to balance high informa- tion coverage and low redundancy in top ranking vertices, which are also two key requirements for choosing salient summarization sentences ( <ref type="bibr" target="#b12">Li et al., 2009;</ref><ref type="bibr" target="#b16">Liu et al., 2015)</ref>. Based on that, we present a model to rank and select salient mes- sages from leader set V L to form a summary. Since this model simply assumes perfect leader detec- tion, it is therefore named Basic-LeadSum.</p><p>Similar as DivRank ( <ref type="bibr" target="#b18">Mei et al., 2010)</ref>, the tran- sition probability at the t-th iteration of random walk is given as follows:</p><formula xml:id="formula_5">pt(u → v) = (1 − µ) · p0(v) + µ · p0(u → v)Nt−1(v) Z(u)<label>(1)</label></formula><p>and Z(u) is the normalizing factor:</p><formula xml:id="formula_6">Z(u) = w∈V L p0(u → w)Nt−1(w)<label>(2)</label></formula><p>where p 0 (u → v) is the organic transition prob- ability which represents the content similarity be- tween u and v; N t−1 (v) denotes the times vertex v is visited up to the (t − 1)-th iteration; p 0 (v) = 1 |V L | denotes random jumping probability similar to that in PageRank; and µ is the damping weight set as 0.85 following most PageRank-based mod- els. The probability of traveling to leader v can accumulate as its weight increases during random walk, and leaders already having high weight can "absorb" weights from other leaders with high similarity to it, thus avoids redundancy.</p><p>For any v ∈ V L , the update function for its rank- ing score at the t-th iteration R t (v) is formulated as:</p><formula xml:id="formula_7">Rt(v) = u∈V L pt(u → v)Rt−1(u)<label>(3)</label></formula><p>It has been proved that the Markov chain is er- godic, thus can converge to a stationary distribu- tion ( <ref type="bibr" target="#b18">Mei et al., 2010)</ref>, which determines the final rankings for leaders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Soft-LeadSum Model</head><p>As a two-step summarization system, the perfor- mance of LeadSum relies on the leader detection, which might be error-prone. Followers misiden- tified as leaders participating in leader ranking brings risks to extract real followers into summary. Also, leaders misclassified as followers may leave out strong summary candidates. To reduce such error propagation, we enhance Basic-LeadSum by using an even-length random walk with adjust- ment steps that sample from leader probabilities given all the reposting messages, which is referred to as Soft-LeadSum.</p><p>Different from Basic-LeadSum, every message on repost tree T , no matter detected as a leader or a follower, participates in ranking process of Soft- LeadSum. In other words, in the random walk, visitor wanders on a complete graph G = (V, E ) whose vertex set V is identical to repost tree T , and E = {(u, v)|u ∈ V, v ∈ V, and u = v} rep- resents the edge set. Therefore, this makes it pos- sible to include true leaders misclassified as fol- lowers by leader detection module into summary.</p><p>However, allowing all messages to participate in ranking also increases the risk of selecting real followers. To avoid this problem, Soft-LeadSum is composed of two types of walks on G, namely WALK-1 and WALK-2. In WALK-1, visitor moves based on content similarities between mes- sages, which follows transition probabilities simi- lar to equation (1), but is specifically given as:</p><formula xml:id="formula_8">pt(u → v) = (1 − µ) · 1 |V | + µ · p0(u → v)Nt−1(v) Z(u)<label>(4)</label></formula><p>where u, v ∈ V , p 0 (u → v) is proportional to con- tent similarity between u and v similar to Basic- LeadSum, and Z(u) is the normalizing factor. WALK-2 attempts to avoid selecting true fol- lowers by adopting a sampling process, whose re- sult determines the next vertex on G to be visited. Suppose the current vertex being visited is u, then we sample from p L (u), i.e., the probability of u being a leader. Practically, p L (u) can be estimated with the average of u's marginal probabilities as a leader over all root-to-leaf paths passing u on T output by the leader detection module. If u is sampled to be a leader, we claim that leader detec- tion is correct and the visitor stays; otherwise, u is sampled as a follower, indicating that leader detec- tion module misclassifies u, so the visitor should go to u's leader. Here we assume that a follower u's leader is its nearest ancestor leader on T as shown by the dotted lines in <ref type="figure" target="#fig_1">Figure 1</ref>. Based on such simplification, we let the visitor trace back one by one along the path on T from u to root and sample from their leader probabilities until a node v is sampled as a leader and then we determine v as u's leader.</p><p>So for any u's ancestor v, the probability of v being u's leader is:</p><formula xml:id="formula_9">P r{v is u's leader} = pL(v)(1 − pL(u) − w∈P(v,u) P r{w is u's leader}) = pL(v) w∈P(v,u) {u} (1 − pL(w))<label>(5)</label></formula><p>where P(v, u) is the set of nodes between v and u on v-to-u path of repost tree, i.e., P(v, u) = {w ∈ V |w is v's descendant and u's ancestor on T }. In particular, we assume that p L (r) = 1 so as to stop the sampling process when the visitor arrives at root r. Therefore, WALK-2's transition probabilities can be calculated as follows:</p><formula xml:id="formula_10">q(u → v) = pL(v) if v = u; P r{v is u's leader} if v is u's ancestor; 0 otherwise (6)</formula><p>Algorithm 1 shows the ranking process of Soft- LeadSum, during which the visitor walks on G following WALK-1 and WALK-2 alternately. The fact that WALK-1 is ergodic ensures the ergodicity and convergency of the algorithm. In implemen- tation, we set max iteration N =1000 empirically which is large enough to ensure convergence, or stop random walk process in advance when the condition of convergence is met, i.e., the change of Euclidean difference of ranking scores for three consecutive iterations are all less than 1e-6.</p><p>Soft-LeadSum can reduce the impact of errors made by leader detection on summarization due to the following two reasons: 1) It allows all mes- sages to participate in ranking process, thus per- mits those leaders leaving out by leader detec- tion module to be selected into summary; 2) With</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Algorithm of Soft-LeadSum</head><p>Input: T , G, µ=0.85, max iteration N , length cut-off n Output: Summary with n microblog messages 1: For all v ∈ V , initialize R0(v) = p0(v) = 1 |V | 2: Initialize WALK-1's transition probabilities p0(u → v) with normalized cosine similarity between u and v. 3: Calculate WALK-2's transition probabilities q(u → v) by equation <ref type="formula" target="#formula_9">(5)</ref> and (6). 4: Initialize current walk="WALK-1" 5: for t = 1 to N and not converged do 6:</p><p>for all v ∈ V do 7:</p><p>if current walk=="WALK-1" then 8:</p><p>Update pt(u → v) by equation (4) 9:</p><p>Update Rt(v) as follows:</p><formula xml:id="formula_11">Rt(v) = u∈V Rt−1(u) · pt(u → v) 10:</formula><p>Set current walk="WALK-2" 11:</p><p>end if 12:</p><p>if current walk=="WALK-2" then 13:</p><p>Update Rv(v) as follows:</p><formula xml:id="formula_12">Rt(v) = u∈V Rt−1(u) · q(u → v) 14:</formula><p>Set current walk="WALK-1" 15:</p><p>end if 16:</p><p>end for 17: end for 18: Sort all v ∈ V by RN (v) in descending order 19: Pick the top-n messages as summary WALK-2 sampling from leader probabilities, it also reduces the risk of including real followers into summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Results</head><p>To evaluate the two modules in our repost tree summarization system, i.e., CRF-based model for leader detection and LeadSum model for summa- rization, we conducted two sets of experiments based on microblog posts data collected from Sina Weibo, which has a similar market penetration as Twitter (Rapoza, 2011) 2 . Microblog messages on Sina Weibo are in Chinese and we use Fu- danNLP ( <ref type="bibr" target="#b21">Qiu et al., 2013</ref>) for text preprocessing including word segmentation and POS tagging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiment for Leader Detection</head><p>In this experiment, we evaluated the performance of CRF model for leader detection task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Data Collection and Setup</head><p>We first crawled 1,300 different repost trees us- ing the public PKUVIS toolkit <ref type="bibr" target="#b25">(Ren et al., 2014)</ref>. Given an original microblog post, the toolkit can automatically crawl its complete repost tree. For each tree, we randomly selected one path and fur- ther formed a set with 1,300 repost tree paths, <ref type="bibr">Cross-validation Held-</ref>  which ensures that paths have different roots and the dataset can cover a wide variety of context in- formation.</p><p>Then three annotators were invited to label each repost as a leader or a follower in the context of its repost tree path independently. The average Cohen's Kappa of each two of the three annota- tors was 0.52, which is considered good agree- ment ( <ref type="bibr" target="#b7">Fleiss et al., 2013</ref>). Then, we used the labels agreed by at least two annotators as the ground truth. The training and test of the leader detection models were conducted on this corpus.</p><p>We compared the performance of CRF-based leader detection model with four baselines: Ran- dom Classifier (RC) as a weak baseline; two state- of-the-art point-wise supervised models Logis- tic Regression (LR) and Support Vector Machine (SVM); and an effective context sensitive model SVM hmm . We applied LibLinear toolkit <ref type="bibr" target="#b6">(Fan et al., 2008)</ref> to implement LR and SVM with linear kernel. SVM hmm was implemented by SVM struct toolkit ( <ref type="bibr" target="#b10">Joachims et al., 2009)</ref>. And CRF's im- plementation was based on CRF++ 3 . For all the baselines, we used features listed in <ref type="table">Table 1</ref>. The hyper-parameters of all leader detection models were tuned to the same extent based on 5-fold cross validation (with 1 fold as development set). The evaluation metrics were precision, recall and F1 score for the detected leaders. <ref type="table" target="#tab_3">Table 2</ref> shows the comparison result of 5-fold cross validation on 1,000 repost tree paths and held-out experiment on 300 complete fresh paths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Results</head><p>Among all baselines, SVM hmm performed the best, which indicates the effectiveness of incor- porating structure information for leader detec- tion. And among context-sensitive models, both SVM hmm and CRF were competitive. CRF out- performed SVM hmm slightly with 5.6% and 1.7% improved F1 score in cross validation and held-out experiments, respectively. In spite of their compa- rable performance, our framework applies CRF in- stead of SVM hmm for leader detection because of its probabilistic nature, which can be exploited by the sampling process in Soft-LeadSum to reduce the propagation of classification error to the sum- marization stage. Section 5.2.2 shows the relevant experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experiment for Summarization</head><p>In this experiment, we evaluated end-to-end per- formance of our basic and soft LeadSum summa- rization models by comparing them with state-of- the-art microblog summarizers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Data Collection and Evaluation Metrics</head><p>There is no public editorial repost tree dataset. Therefore, we manually selected 10 hot events tak- ing place during January 2nd -July 28th 2014, and then used the PKUVIS toolkit ( <ref type="bibr" target="#b25">Ren et al., 2014</ref>) to crawl the complete repost trees for all the events given the corresponding original posts. <ref type="table" target="#tab_4">Table 3</ref> shows the details about the repost tree corpus 4 . Note that this repost tree corpus has no overlap with the repost tree path dataset for learning leader detection models in Section 5.1.1.</p><p>After that, we invited three experienced editors to write summaries for each repost tree. To en- sure the quality of reference summaries, we first extracted a list of frequent nouns from each repost tree and generalized 7 to 10 topics based on the nouns list, which provided a high-level overview of a repost tree to editors. Then, our guideline required editors to read all repost microblogs or- dered sequentially on a repost tree. For every mes- sage, its entire repost tree path was also provided as supplementary context information. When fin- ished reading, editors wrote down one or two sen- tences to summarize each topic in the list.</p><p>We utilized ROUGE-N metric <ref type="bibr" target="#b13">(Lin, 2004</ref>) for benchmark, which is a standard for evaluating automatic summaries based on N-gram overlap- ping between a generated summary and a ref- erence. Specifically, ROUGE-1 and ROUGE-2 F1-measure were used as our evaluation metrics. <ref type="bibr" target="#b13">Lin et al. (2004)</ref> has demonstrated that ROUGE-2 correlates well with humans in summarizing for- mal texts. And ROUGE-1 is a better alternative in evaluating summaries for short and informal microblog messages <ref type="bibr" target="#b9">(Inouye and Kalita, 2011;</ref><ref type="bibr" target="#b2">Chang et al., 2013)</ref>.</p><p>In our human-generated summaries, the average inter-annotator-agreement by ROUGE-1 is 0.431, which means each pair of manual summaries have no more than 50% words overlap on average even written under topic constraints. This indicates that microblog repost tree summarization is generally a difficult task. The reason is that repost trees have complex structure, and editors could hardly reconstruct the repost trees even though they went through all the microblogs. Therefore, in eval- uation for each tree, we computed the average ROUGE F1 score between the model-generated summary and the three human-generated sum- maries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Results</head><p>In each automatic summarizer, we selected the top-10 ranked reposts to form a summary. We compared the end-to-end performance with the following baseline systems:</p><p>• RandSum: RandSum is a weak baseline that randomly selects reposts into summaries.</p><p>• RepSum: RepSum ranks and selects mes- sages simply by their reposts count, i.e., the size of their subtrees, based on reposting relations.</p><p>• UserRankSum: UserRankSum ranks and selects reposts by their authors' follower count based on user following relations.</p><p>• LeadProSum: LeadProSum ranks and se- lects reposting messages by their marginal prob- abilities as leaders determined by our CRF-based leader detection model.</p><p>• SVDSum: SVDSum adopts the Singular Value Decomposition (SVD) to discover hidden sub-topics for summarization <ref type="bibr" target="#b8">(Gong and Liu, 2001</ref>). Reposting messages are ranked accord- ing to latent semantic analysis with SVD on term- message matrix.</p><p>• DivRankSum: DivRankSum directly ap- plies DivRank ( <ref type="bibr" target="#b18">Mei et al., 2010</ref>) algorithm to rank all messages unaware of leaders and followers. A similar model is also reported in <ref type="bibr" target="#b31">Yan et al. (2011)</ref>. Following their work, we set damping weight as 0.85.</p><p>• UserInfSum: Chang et al. (2013) ranks mes- sages utilizing Gradient Boosted Decision Tree (GBDT) algorithm with text, popularity, tempo- ral and user influence signals to summarize Twit- ter context tree. In particular, without the interac- tion data with external users, we utilize users' fol-Name # of nodes # of nodes with comments <ref type="table" target="#tab_3">Height  Description  Tree (I)  21,353  15,409  16  HKU dropping out student wins the college entrance exam again.  Tree (II)  9,616  6,073  11  German boy complains hard schoolwork in Chinese High School.  Tree (III)  13,087  9,583  8  Movie Tiny Times 1.0 wins high grossing in criticism.  Tree (IV)</ref> 12,865 7,083 8 "I am A Singer" states that singer G.E.M asking for resinging conforms to rules. Tree <ref type="table" target="#tab_3">(V)  10,666  7,129  8  Crystal Huang clarified the rumor of her derailment.  Tree (VI)  21,127  15,057  11</ref> Germany routs Brazil 7:1 in World-Cup semi-final. Tree <ref type="table">(VII)</ref> 18,974 12,399 13</p><p>The pretty girl pregnant with a second baby graduated with her master degree. Tree <ref type="table" target="#tab_3">(VIII)  2,021  925  18  Girls appealed for equality between men and women in college admission  Tree (IX)  9,230  5,408  14  Violent terrorist attack in Kunming railway station.  Tree (X)</ref> 10,052 4,257 25 MH17 crash killed many top HIV researchers.   lower count to approximate user influence. GBDT implementation is based on RankLib 5 , and as a supervised method, UserInfSum is evaluated with 10-fold cross validation. In addition, we observed that SVM hmm is a competitive baseline for leader detection (see <ref type="table" target="#tab_3">Ta- ble 2</ref>). So we also study its impact on the Basic- LeadSum model. Note that SVM hmm cannot be combined with Soft-LeadSum since it is not prob- abilistic. <ref type="table" target="#tab_5">Table 4</ref> shows the result of overall comparisons. We have the following observations:</p><p>• RepSum utilized trivial structure informa- tion, i.e., the size of sub-tree, and its performance was poor, which was even worse than RandSum on ROUGE-2. This implies that messages with a lot of reposts may not be good candidates as other reasons may lead to their popularity, e.g., a good posting time or sense of humor.</p><p>• UserRankSum performed the best on ROUGE-1&amp;2 among all baseline summarizers, which confirms that user following relations can indeed be a strong signal in microblog summarization. UserRankSum is even slightly <ref type="bibr">5</ref> http://sourceforge.net/p/lemur/wiki/ RankLib/ better than Basic-LeadSum on ROUGE-2. But, it does not perform consistently well for all repost trees, evidenced as the large standard deviation on ROUGE-1&amp;2. This suggests that the user following relations cannot always effectively indicate salient candidates. It may not work for repost trees where authors have similar number of following users, or reposts of influential users contain nothing salient.</p><p>• LeadProSum achieved the second best per- formance among all unsupervised baselines, which indicates that the marginal probabilities as leaders can signal good summary candidates. This also confirms that leaders contain salient contents and should be distinguished from followers in summarization.</p><p>• Utilizing either SVM hmm or CRF as leader detection model to filter out followers, Basic- LeadSum almost doubled the ROUGE-1 and tripled the ROUGE-2 scores compared to Di- vRankSum's performance. This indicates that dif- ferentiating leaders and followers is very helpful to summarization.</p><p>• Basic-LeadSum performed better than all baselines on ROUGE-1&amp;2 except for a marginal drop compared to UserRankSum on ROUGE-2. But the differences with UserRankSum, LeadPro- Sum and UserInfSum are not statistically signif- icant. This may be ascribed to the error propa- gated from leader detection module to summariza- tion process.</p><p>• Soft-LeadSum outperformed all the baselines with a large margin on ROUGE-1&amp;2, including supervised summarizer UserInfSum. The one- tailed pairwise t-test indicates that all the improve- ments over baselines are significant at the 95% confidence level except for UserRankSum with 90% confidence level on ROUGE-2. This con- firms the effectiveness of our framework for pro- ducing high-quality repost tree summaries.</p><p>• The supervised model UserInfSum did not  <ref type="figure">Figure 2</ref>: The impact of α on the ROUGE-1 F1- measure of combined models perform quite well. The reason is that the model needs large amount of user interaction data exter- nal to the tree which are not readily available, and also it might be overfitting to the limited number of training instances.</p><p>• Basic-LeadSum with CRF and SVM hmm had very close ROUGE-1&amp;2 scores. Basic- LeadSum+SVM hmm is even slightly better than Basic-LeadSum+CRF. Though SVM hmm was marginally worse in leader detection experiment <ref type="table" target="#tab_3">(Table 2)</ref>, we can conclude that SVM hmm is a comparable alternative as the leader detection module for Basic-LeadSum.</p><p>• Among our models, Soft-LeadSum signif- icantly outperformed both Basic-LeadSum with CRF and that with SVM hmm . This implies that sampling steps in the enhanced random walk of Soft-LeadSum is effective in reducing the impact of leader detection error on summarization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Discussion</head><p>From <ref type="table" target="#tab_5">Table 4</ref>, we observed that user following re- lations used by UserRankSum is a strong signal for microblog summarization. A natural question is: "Can the user following relations commonly used for modeling user influence be complemen- tary to the content-level structure information used in our summariztaion models?"</p><p>We thus linearly combine the normalized rank- ing scores of LeadSum and UserRankSum using the formula α * u+(1−α) * l, where u and l denote the UserRankSum and LeadSum ranking scores, respectively. <ref type="figure">Figure 2</ref> demonstrates the impact of α on our basic and soft LeadSum model with CRF.</p><p>Clearly, Basic-LeadSum can benefit from user influence information by incorporating User- RankSum scores into it. From the incremental trend of summarization performance with the in- crease of α for α ∈ [0, 0.9], we can conclude that user influence is helpful to it. This is because Basic-LeadSum is not sufficiently robust to the er- rors cascaded from leader detection module, thus user-level structures can have the chance to com- pensate these errors for content-level structures.</p><p>Incorporating the same information into Soft- LeadSum cannot improve its performance regard- less of the value of α. This implies that content- level structures, i.e., message content and repost- ing relations together, are better indicative of good summary candidates. When these features are ap- propriately modeled by Soft-LeadSum, user in- fluence, a traditionally well-known strong signal, cannot provide extra benefit at all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>This work presents a study for microblog repost tree summarization, whose output can provide im- portant clues for event analysis on microblog- ging platforms. Conventional works considering only plain text streams is insufficient to summa- rize noisy repost trees. We propose a novel sum- marization system by effectively differentiating leader and follower messages on repost tree based on content-level structure information. Firstly, a leader detection model categorizes each repost on repost tree path as a leader or a follower. Then, a random-walk variant summarization model called LeadSum is proposed to rank and select salient microblog messages on the basis of leader de- tection result. To reduce errors cascaded from leader detection, we enhance LeadSum based on an even-length random walk by sampling from leader probabilities for improving summarization. Based on real-world microblog post dataset, the experimental results confirm that our proposed framework is effective for repost tree summariza- tion by the end-to-end comparison with the state- of-the-art baselines.</p><p>Constrained by the amount of annotation, we adopt this two-step framework and an unsuper- vised summarization algorithm. With the develop- ment of our corpora, we plan to explore the useful- ness of supervised structure learning approaches, such as tree-structured CRF ( <ref type="bibr" target="#b30">Tang et al., 2006;</ref><ref type="bibr" target="#b20">Mensink et al., 2013)</ref>, to integrate leader detec- tion and summarization into a unified framework, and make global inference for important leaders by capturing various non-linear dependencies.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>), MEAD (Radev et al., 2004), TF-IDF (Inouye and Kalita, 2011), Integer Linear Programming (Liu et al., 2011; Takamura et al., 2011), etc. Sharif et al. (2010) modeled the problem as optimal path finding on a phrase reinforcement graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of repost tree. [O]: the original post; [R i ]: the i-th repost; Solid arrow lines: reposting relationship; Dotted lines: hidden leader-follower relationship; Dark boxes: leaders to be detected.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Feature</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Remarks: B-LS: Basic-LeadSum model; S-LS: Soft-LeadSum model F1: F1-measure of ROUGE-1 or ROUGE-2 σ: Standard deviation of F1-measure over 10 repost trees SIG: Significance indicator of F1-measure based on one-tailed pairwise t-test: -Significantly different with B-LS+CRF: * (p &lt; 0.1); ** (p &lt; 0.05) -Significantly different with S-LS+CRF: † (p &lt; 0.1); ‡ (p &lt; 0.05)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>The performance of leader detection (%) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Description of repost tree summarization corpus consisting of 10 hot events 

ROUGE-1 
ROUGE-2 
F1 
σ 
SIG 
F1 
σ 
SIG 
RandSum 
.159 
.046 
** ‡ 
.037 
.009 
** ‡ 
RepSum 
.162 
.071 
** ‡ 
.030 
.016 
** ‡ 
UserRankSum 
.292 
.066 
 ‡ 
.087 
.028 
 † 
LeadProSum 
.270 
.119 
 ‡ 
.064 
.038 
 ‡ 
SVDSum 
.222 
.070 
** ‡ 
.048 
.032 
** ‡ 
DivRankSum 
.159 
.079 
** ‡ 
.029 
.018 
** ‡ 
UserInfSum 
.272 
.091 
 ‡ 
.071 
.028 
 ‡ 

B-LS+SVM hmm 
.301 
.031 
 ‡ 
.085 
.020 
 † 
B-LS+CRF 
.300 
.029 
 ‡ 
.082 
.016 
 ‡ 
S-LS+CRF 
.351 
.027 
NA 
.105 
.018 
NA 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 : Comparison of different summarizers</head><label>4</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="2"> The datasets are available at http://www1.se. cuhk.edu.hk/ ˜ lijing/data/repost_tree_ summ.zip</note>

			<note place="foot" n="3"> http://taku910.github.io/crfpp/</note>

			<note place="foot" n="4"> All descriptions are English translations of the root microblogs originally in Chinese.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Hidden markov support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasemin</forename><surname>Altun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Tsochantaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twentieth International Conference on Machine Learning, ICML</title>
		<meeting>the Twentieth International Conference on Machine Learning, ICML</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Event summarization using tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepayan</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunal</forename><surname>Punera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Conference on Weblogs and Social Media</title>
		<meeting>the Fifth International Conference on Weblogs and Social Media</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="66" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards twitter context summarization with user influence models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth ACM International Conference on Web Search and Data Mining, WSDM</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="527" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A survey on automatic text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Literature Survey for the Language and Statistics II course at CMU</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="192" to="195" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Twitter topic summarization by ranking tweets using social influence and content quality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajuan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhimin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heung-Yeung</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Computational Linguistics, COLING</title>
		<meeting>the 24th International Conference on Computational Linguistics, COLING</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="763" to="780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Lexrank: Graph-based lexical centrality as salience in text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günes</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res. (JAIR)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="457" to="479" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">LIBLINEAR: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Rong-En Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Statistical methods for rates and proportions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruce</forename><surname>Joseph L Fleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myunghee Cho</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Generic text summarization using relevance measure and latent semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihong</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual International ACM Conference on Research and Development in Information Retrieval, SIGIR</title>
		<meeting>the 24th Annual International ACM Conference on Research and Development in Information Retrieval, SIGIR</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="19" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Comparing twitter summarization algorithms for multiple post summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Inouye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jugal</forename><forename type="middle">K</forename><surname>Kalita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Privacy, Security, Risk and Trust (PASSAT) and 2011 IEEE Third Inernational Conference on Social Computing (SocialCom)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="298" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cutting-plane training of structural svms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Finley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunnam John</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="27" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning, ICML</title>
		<meeting>the Eighteenth International Conference on Machine Learning, ICML</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Enhancing diversity, coverage and balance for summarization through structure learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangda</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gui-Rong</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on World Wide Web</title>
		<meeting>the 18th International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>WWW</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="71" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Rouge: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-04 Workshop</title>
		<meeting>the ACL-04 Workshop</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Why is sxsw trending?: exploring multiple text sources for twitter topic summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuliang</forename><surname>Weng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Languages in Social Media</title>
		<meeting>the Workshop on Languages in Social Media</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="66" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Graph-based multi-tweet summarization using social signals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yitong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Computational Linguistics</title>
		<meeting>the 24th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1699" to="1714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-document summarization based on two-level sparse representation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongliang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hong</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth Conference on Artificial Intelligence, AAAI</title>
		<meeting>the Twenty-Ninth Conference on Artificial Intelligence, AAAI</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="196" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Towards effective event detection, tracking and summarization on microblog data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haofen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ou</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Web-Age Information Management-12th International Conference, WAIM</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="652" to="663" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Divrank: the interplay of prestige and diversity in information networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1009" to="1018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Entity-centric topic-oriented opinion summarization in twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinfan</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="379" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Tree-structured CRF models for interactive image labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><forename type="middle">J</forename><surname>Verbeek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriela</forename><surname>Csurka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="476" to="489" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Fudannlp: A toolkit for chinese natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Annual Meeting of the Association for Computational Linguistics, ACL</title>
		<meeting>Annual Meeting of the Association for Computational Linguistics, ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="49" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Introduction to the special issue on summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="399" to="408" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">MEAD-A platform for multidocument multilingual text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasha</forename><surname>Allison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blairgoldensohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanko</forename><surname>Arda C ¸ Elebi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elliott</forename><surname>Dimitrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Drábek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Hakim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danyu</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jahna</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Otterbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Conference on Language Resources and Evaluation</title>
		<editor>Horacio Saggion, Simone Teufel, Michael Topper, Adam Winkel, and Zhu Zhang</editor>
		<meeting>the Fourth International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<publisher>LREC</publisher>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">China&apos;s weibos vs us&apos;s twitter: And the winner is</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Rapoza</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Weiboevents: A crowd sourcing weibo visual analytic system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Donghao Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhuang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoru</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Pacific Visualization Symposium, PacificVis</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="330" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Anatole Gershman, and Robert Frederking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">Dela</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rushin</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGIR: SWSM</title>
		<meeting>the ACM SIGIR: SWSM</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>Topical clustering of tweets</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Automatic summarization of twitter topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beaux</forename><surname>Sharifi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark-Anthony</forename><surname>Hutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jugal</forename><surname>Kalita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">National Workshop on Design and Analysis of Algorithm</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A participant-based approach for event summarization using twitter streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuliang</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, HLT-NAACL</title>
		<meeting>Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1152" to="1162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Summarizing a document stream</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroya</forename><surname>Takamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hikaru</forename><surname>Yokono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manabu</forename><surname>Okumura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval-33rd European Conference on IR Research, ECIR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="177" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Tree-structured conditional random fields for semantic annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingcai</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan-Zi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bangyong</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Proceedings of 5th International Semantic Web Conference, ISWC</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="640" to="653" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Timeline generation through evolutionary trans-temporal summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congrui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="433" to="443" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
