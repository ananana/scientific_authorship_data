<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:29+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improving Word Alignment using Word Similarity</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theerawat</forename><surname>Songyot</surname></persName>
							<email>songyot@usc.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept of Computer Science</orgName>
								<orgName type="department" key="dep2">Dept of Computer Science and Engineering</orgName>
								<orgName type="institution" key="instit1">University of Southern California</orgName>
								<orgName type="institution" key="instit2">University of Notre Dame</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
							<email>dchiang@nd.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept of Computer Science</orgName>
								<orgName type="department" key="dep2">Dept of Computer Science and Engineering</orgName>
								<orgName type="institution" key="instit1">University of Southern California</orgName>
								<orgName type="institution" key="instit2">University of Notre Dame</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Improving Word Alignment using Word Similarity</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1840" to="1845"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We show that semantic relationships can be used to improve word alignment, in addition to the lexical and syntactic features that are typically used. In this paper, we present a method based on a neural network to automatically derive word similarity from monolingual data. We present an extension to word alignment models that exploits word similarity. Our experiments , in both large-scale and resource-limited settings, show improvements in word alignment tasks as well as translation tasks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Word alignment is an essential step for learn- ing translation rules in statistical machine trans- lation. The task is to find word-level transla- tion correspondences in parallel text. Formally, given a source sentence e consisting of words e 1 , e 2 , . . . , e l and a target sentence f consisting of words f 1 , f 2 , . . . , f m , we want to infer an alignment a, a sequence of indices a 1 , a 2 , . . . , a m which indicates, for each target word f i , the corre- sponding source word e a i or a null word. Machine translation systems, including state-of-the-art sys- tems, then use the word-aligned corpus to extract translation rules.</p><p>The most widely used methods, the IBM mod- els ( <ref type="bibr" target="#b2">Brown et al., 1993</ref>) and HMM ( <ref type="bibr" target="#b24">Vogel et al., 1996)</ref>, define a probability distribution p(f , a | e) that models how each target word f i is gener- ated from a source word e a i with respect to an alignment a. The models, however, tend to mis- align low-frequency words as they have insuffi- cient training samples. The problem can get worse in low-resource languages. Two branches of re- search have tried to alleviate the problem. The † Most of the work reported here was performed while the second author was at the University of Southern California. first branch relies solely on the parallel data; how- ever, additional assumptions about the data are re- quired. This includes, but is not limited to, ap- plying prior distributions ( <ref type="bibr" target="#b17">Mermer and Saraçlar, 2011;</ref><ref type="bibr" target="#b22">Vaswani et al., 2012</ref>) or smoothing tech- niques ( <ref type="bibr" target="#b27">Zhang and Chiang, 2014</ref>). The other branch uses information learned from monolin- gual data, which is generally easier to acquire than parallel data. Previous work in this branch mostly involves applying syntactic constraints <ref type="bibr" target="#b26">(Yamada and Knight, 2001;</ref><ref type="bibr" target="#b3">Cherry and Lin, 2006;</ref><ref type="bibr" target="#b25">Wang and Zong, 2013)</ref> and syntactic features ( <ref type="bibr" target="#b21">Toutanova et al., 2002</ref>) into the models. The use of syntac- tic relationships can, however, be limited between historically unrelated language pairs.</p><p>Our motivation lies in the fact that a meaningful sentence is not merely a grammatically structured sentence; its semantics can provide insightful in- formation for the task. For example, suppose that the models are uncertain about aligning e to f . If the models are informed that e is semantically re- lated to e , f is semantically related to f , and f is a translation of e , it should intuitively increase the probability that f is a translation of e. Our work focuses on using such a semantic relationship, in particular, word similarity, to improve word align- ments.</p><p>In this paper, we propose a method to learn sim- ilar words from monolingual data (Section 2) and an extension to word alignment models in which word similarity can be incorporated (Section 3). We demonstrate its application in word alignment and translation (Section 4) and then briefly discuss the novelty of our work in comparison to other methods (Section 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Learning word similarity</head><p>Given a word w, we want to learn a word simi- larity model p(w | w) of what words w might be used in place of w. Word similarity can be used to improve word alignment, as in this pa-per, but can potentially be useful for other nat- ural language processing tasks as well. Such a model might be obtained from a monolingual the- saurus, in which humans manually provide sub- jective evaluation for word similarity probabilities, but an automatic method would be preferable. In this section, we present a direct formulation of the word similarity model, which can automatically be trained from monolingual data, and then consider a more practical variant, which we adopt in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Model</head><p>Given an arbitrary word type w, we define a word similarity model p(w | w) for all word types w in the vocabulary V as</p><formula xml:id="formula_0">p(w | w) = c p(c | w) p(w | c)</formula><p>where c is a word context represented by a se- quence w 1 , w 2 , . . . , w 2n consisting of n word to- kens on the left and n word tokens on the right of w, excluding w. The submodel p(c | w) can be a categorical distribution. However, modeling the word context model, p(w | c), as a categori- cal distribution would cause severe overfitting, be- cause the number of all possible contexts is |V | 2n , which is exponential in the length of the context. We therefore parameterize it using a feedforward neural network as shown in <ref type="figure" target="#fig_3">Figure 1</ref>, since the structure has been shown to be effective for lan- guage modeling ( <ref type="bibr" target="#b0">Bengio et al., 2006;</ref><ref type="bibr" target="#b23">Vaswani et al., 2013)</ref>. The input to the network is a one-hot representation of each word in c, where the spe- cial symbols &lt;s&gt;, &lt;/s&gt;, &lt;unk&gt; are reserved for sentence beginning, sentence ending, and words not in the vocabulary. There is an output node for each w ∈ V , whose activation is p(w | c). Following <ref type="bibr" target="#b0">Bengio et al. (2006)</ref>, the network uses a shared linear projection matrix to the input em- bedding layer, which allows information sharing among the context words and also substantially reduces the number of parameters. The input em- bedding layer has a dimensionality of 150 for each input word. The network uses two hidden layers with 1,000 and 150 rectified linear units, respec- tively, and a softmax output layer. We arbitrarily use n = 5 throughout this paper.  . . .  can be independently trained easily by maximum likelihood estimation, while the word context model p(w | c) may be difficult to train at scale. We follow previous work <ref type="bibr" target="#b18">(Mnih and Teh, 2012;</ref><ref type="bibr" target="#b23">Vaswani et al., 2013</ref>) in adopting noise- contrastive estimation ( <ref type="bibr" target="#b10">Gutmann and Hyvärinen, 2010)</ref>, a fast and simple training algorithm that scales independently of the vocabulary size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Training</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Model variants</head><p>The above formulation of the word similarity model can be interpreted as a mixture model in which w is similar to w if any of the context prob- abilities agrees. However, to guard against false positives, we can alternatively reformulate it as a product of experts (Hinton, 1999),</p><formula xml:id="formula_1">p(w | w) = 1 Z(w) exp c p(c | w) log p(w | c)</formula><p>where Z(w) is a normalization constant. Under this model, w is similar to w if all of the context probabilities agree. Both methods produce reason- ably good word similarity; however, in practice, the latter performs better. Since most of the p(w | w) will be close to zero, for computational efficiency, we can se- lect the k most similar words and renormalize the probabilities. <ref type="table">Table 1</ref> shows some examples learned from the 402M-word Xinhua portion of the English Gigaword corpus (LDC2007T07), us- ing a vocabulary V of the 30,000 most frequent words. We set k = 5 for illustration purposes.</p><formula xml:id="formula_2">p(w | country) p(w | region)</formula><p>p(w | area) country 0.8363 region 0.8338 area 0.8551 region 0.0558 area 0.0760 region 0.0524 nation 0.0522 country 0.0524 zone 0.0338 world 0.0282 province 0.0195 city 0.0326 city 0.0273 city 0.0181 areas 0.0258 <ref type="table">Table 1</ref>: Examples of word similarity</p><p>The method can easily be applied to other related models, for example, the log-linear reparameteri- zation of Model 2 by <ref type="bibr" target="#b9">Dyer et al. (2013)</ref>. Basically, all the IBM models involve modeling lexical trans- lation probabilities p(f | e) which are parameter- ized as categorical distributions. IBM Model 1, for instance, is defined as</p><formula xml:id="formula_3">p(f , a | e) ∝ m i=1 p(f i | e a i ) = m i=1 t(f i | e a i )</formula><p>where each t(f | e) denotes the model parameters directly corresponding to p(f | e). Models 2-5 and the HMM-based model introduce additional components in order to capture word ordering and word fertility. However, they have p(f | e) in common.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model</head><p>To incorporate word similarity in word alignment models, we redefine the lexical translation proba- bilities as</p><formula xml:id="formula_4">p(f | e) = e ,f p(e | e) t(f | e ) p(f | f )</formula><p>for all f, e, including words not in the vocabulary. While the factor p(e | e) can be directly computed by the word similarity model, the factor p(f | f ) can be problematic because it vanishes for f out of vocabulary. One possible solution would be to use Bayes' rule</p><formula xml:id="formula_5">p(f | f ) = p(f | f ) p(f ) p(f )</formula><p>where p(f | f ) is computed by the word similar- ity model. However, we find that this is prone to numerical instability and other complications. In our experiments, we tried the simpler assumption that p(f | f ) ≈ p(f | f ), with the rationale that both probabilities are measures of word similarity, which is intuitively a symmetric relation. We also compared the performance of both methods. <ref type="table">Ta- ble 2</ref> shows that this simple solution works as well as the more exact method of using Bayes' rule. We describe the experiment details in Section 4.  <ref type="table">Table 2</ref>: Assuming that word similarity is sym- metric, i.e. p(f | f ) ≈ p(f | f ), works as well as computing p(f | f ) using Bayes' rule.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Re-estimating word similarity</head><p>Depending on the quality of word similarity and the distribution of words in the parallel data, ap- plying word similarity directly to the model could lead to an undesirable effect where similar but not interchangeable words rank in the top of the trans- lation probabilities. On the other hand, if we set</p><formula xml:id="formula_6">p(e | e) = 1[e = e] p(f | f ) = 1[f = f ]</formula><p>where 1 denotes the indicator function, the model reduces to the standard IBM models. To get the best of both worlds, we smooth the two models together so that we rely more on word similarity for rare words and less for frequent words˜p</p><formula xml:id="formula_7">words˜ words˜p(w | w) = count(w)1[w = w] + α p(w | w) count(w) + α</formula><p>This can be thought of as similar to Witten-Bell smoothing, or adding α pseudocounts distributed according to our p(w | w). The hyperparame- ter α controls how much influence our word sim- ilarity model has. We investigated the effect of α by varying this hyperparameter in our word align- ment experiments whose details are described in Section 4. <ref type="figure" target="#fig_4">Figure 2</ref> shows that performance of the model, as measured by F1 score, is rather insensi- tive to the choice of α. We used a value of 40 in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training</head><p>Our word alignment models can be trained in the same way as the IBM models using the Expec- tation Maximization (EM) algorithm to maximize the likelihood of the parallel data. Our extension only introduces an additional time complexity on the order of O(k 2 ) on top of the base models, where k is the number of word types used to es- timate the full-vocabulary word similarity models. The larger the value of k is, the closer to the full- vocabulary models our estimations are. In prac- tice, a small value of k seems to be effective since p(w | w) is negligibly small for most w .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Alignment experiments</head><p>We conducted word alignment experiments on 2 language pairs: Chinese-English and Arabic-English. For Chinese-English, we used 9.5M+12.3M words of parallel text from the NIST 2009 constrained task 1 and evaluated on 39.6k+50.9k words of hand-aligned data (LDC2010E63, LDC2010E37). For Arabic- English, we used 4.2M+5.4M words of parallel text from the NIST 2009 constrained task 2 and evaluated on 10.7k+15.1k words of hand- aligned data (LDC2006E86). To demonstrate performance under resource-limited settings, we additionally experimented on only the first eighth of the full data, specifically, 1.2M+1.6M words for Chinese-English and 1.0M+1.4M words for Arabic-English. We trained word similarity models on the Xinhua portions of English Gigaword (LDC2007T07), Chinese Gigaword (LDC2007T38), and Arabic Gigaword (LDC2011T1), which are 402M, 323M, and 125M words, respectively. The vocabulary V was the 30,000 most frequent words from each corpus  and the k = 10 most similar words were used. We modified GIZA++ ( <ref type="bibr" target="#b19">Och and Ney, 2003</ref>) to incorporate word similarity. For all experiments, we used the default configuration of GIZA++: 5 iterations each of IBM Model 1, 2, HMM, 3 and 4. We aligned the parallel texts in both forward and backward directions and symmetrized them using grow-diag-final-and ( <ref type="bibr" target="#b13">Koehn et al., 2005</ref>). We evaluated alignment quality using precision, recall, and F1.</p><p>The results in <ref type="table" target="#tab_3">Table 3</ref> suggest that our modeling approach produces better word alignments. We found that our models not only learned smoother translation models for low frequency words but also ranked the conditional probabilities more ac- curately with respect to the correct translations. To illustrate this, we categorized the alignment links from the Chinese-English low-resource ex- periment into bins with respect to the English source word frequency and individually evaluated them. As shown in <ref type="figure" target="#fig_5">Figure 3</ref>, the gain for low fre- quency words is particularly large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Translation experiments</head><p>We also ran end-to-end translation experiments. For both languages, we used subsets of the NIST <ref type="bibr">2004</ref>   build a hierarchical phrase-based translation sys- tem (Chiang, 2007) trained using MIRA <ref type="bibr" target="#b5">(Chiang, 2012)</ref>. Then, we evaluated the translation qual- ity using BLEU ( <ref type="bibr" target="#b20">Papineni et al., 2002</ref>) and ME- TEOR <ref type="bibr" target="#b7">(Denkowski and Lavie, 2014)</ref>, and per- formed significance testing using bootstrap resam- pling <ref type="bibr" target="#b15">(Koehn, 2004</ref>) with 1,000 samples. Under the resource-limited settings, our meth- ods consistently show 1.1-1.3 BLEU (0.8-1.2 METEOR) improvements on Chinese-English and 0.8-0.9 BLEU (0.8-0.9 METEOR) improvements on Arabic-English, as shown in <ref type="table" target="#tab_3">Table 3</ref>. These im- provements are statistically significant (p &lt; 0.01). On the full data, our method improves Chinese- English translation by 0.3-0.5 BLEU (0.3 ME- TEOR), which is unfortunately not statistically significant, and Arabic-English translation by 0.5- 0.6 BLEU (0.5 METEOR), which is statistically significant (p &lt; 0.01).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related work</head><p>Most previous work on word alignment problems uses morphosyntactic-semantic features, for ex- ample, word stems, content words, orthography <ref type="bibr" target="#b6">(De Gispert et al., 2006;</ref><ref type="bibr" target="#b11">Hermjakob, 2009)</ref>. A variety of log-linear models have been proposed to incorporate these features <ref type="bibr" target="#b8">(Dyer et al., 2011;</ref><ref type="bibr">BergKirkpatrick et al., 2010</ref>). These approaches usu- ally require numerical optimization for discrimi- native training as well as language-specific engi- neering and may limit their applications to mor- phologically rich languages.</p><p>A more semantic approach resorts to training word alignments on semantic word classes <ref type="bibr" target="#b16">(Ma et al., 2011</ref>). However, the resulting alignments are only used to supplement the word alignments learned on lexical words. To our knowledge, our work, which directly incorporates semantic rela- tionships in word alignment models, is novel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have presented methods to extract word simi- larity from monolingual data and apply it to word alignment models. Our method can learn simi- lar words and word similarity probabilities, which can be used inside any probability model and in many natural language processing tasks. We have demonstrated its effectiveness in statistical ma- chine translation. The enhanced models can sig- nificantly improve alignment quality as well as translation quality.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>We extract training data by either collecting or sampling the target words w ∈ V and their word input word</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The structure of the word context model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Alignment F1 is fairly insensitive to α over a large range of values</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: F1 scores for words binned by frequency. Our model gives the largest improvements for the lowest-frequency words.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Experimental results. Our model improves alignments and translations on both language pairs.</figDesc><table></table></figure>

			<note place="foot" n="3"> Word alignment model In this section, we present our word alignment models by extending the standard IBM models.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We express our appreciation to Ashish Vaswani for his advice and assistance. We also thank Hui Zhang, Tomer Levinboim, Qing Dou, Aliya Deri for helpful discussions and the anonymous review-ers for their insightful critiques. This research was supported in part by DOI/IBC grant D12AP00225 and a Google Research Award to Chiang.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural probabilistic language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Sébastien</forename><surname>Senécal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fréderic</forename><surname>Morin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Luc</forename><surname>Gauvain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Innovations in Machine Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="137" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Painless unsupervised learning with features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Bouchard-Côté</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Denero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT NAACL</title>
		<meeting>HLT NAACL</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="582" to="590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The mathematics of statistical machine translation: Parameter estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><forename type="middle">J Della</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">A</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="311" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Soft syntactic constraints for word alignment through discriminative training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING/ACL</title>
		<meeting>COLING/ACL</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hierarchical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="201" to="228" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hope and fear for discriminative training of statistical translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1159" to="1187" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Improving statistical word alignments with morpho-syntactic transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepa</forename><surname>Adrì A De Gispert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrik</forename><surname>Popovi´cpopovi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><forename type="middle">B</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Mariño</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Natural Language Processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="368" to="379" />
		</imprint>
	</monogr>
	<note>Hermann Ney, and Rafael Banchs</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Meteor universal: Language specific translation evaluation for any target language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EACL 2014 Workshop on Statistical Machine Translation</title>
		<meeting>the EACL 2014 Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Unsupervised word alignment with arbitrary features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL: HLT</title>
		<meeting>ACL: HLT</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="409" to="419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A simple, fast, and effective reparameterization of IBM Model 2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Chahuneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACLHLT</title>
		<meeting>NAACLHLT</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="644" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Noisecontrastive estimation: A new estimation principle for unnormalized statistical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics (AI-STATS)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="297" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Improved word alignment with statistics and linguistic heuristics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="229" to="237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Products of experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Edinburgh system description for the 2005 IWSLT speech translation evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amittai</forename><surname>Axelrod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miles</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Talbot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Spoken Language Translation (IWSLT)</title>
		<meeting>the International Workshop on Spoken Language Translation (IWSLT)</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL: Interactive Poster and Demonstration Sessions</title>
		<meeting>ACL: Interactive Poster and Demonstration Sessions</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Statistical significance tests for machine translation evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving low-resource statistical machine translation with a novel semantic word clustering algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Matsoukas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of MT Summit</title>
		<meeting>MT Summit</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Bayesian word alignment for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cos¸kuncos¸kun</forename><surname>Mermer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murat</forename><surname>Saraçlar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL: HLT</title>
		<meeting>ACL: HLT</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="182" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A fast and simple algorithm for training neural probabilistic language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A systematic comparison of various statistical alignment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="51" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Extensions to HMM-based statistical word alignment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tolga Ilhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="87" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Smaller alignment models for better translations: unsupervised word alignment with the 0norm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="311" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Decoding with large-scale neural language models improves translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinggong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><surname>Fossum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">HMM-based word alignment in statistical translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Tillmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="836" to="841" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Largescale word alignment using soft dependency cohesion constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="291" to="300" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A syntaxbased statistical translation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="523" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Kneser-Ney smoothing on expected counts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
