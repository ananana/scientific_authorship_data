<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bilingual Structured Language Models for Statistical Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Garmash</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Informatics Institute</orgName>
								<orgName type="institution">University of Amsterdam Science</orgName>
								<address>
									<addrLine>Park 904</addrLine>
									<postCode>1098 XH</postCode>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Informatics Institute</orgName>
								<orgName type="institution">University of Amsterdam Science</orgName>
								<address>
									<addrLine>Park 904</addrLine>
									<postCode>1098 XH</postCode>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bilingual Structured Language Models for Statistical Machine Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper describes a novel target-side syntactic language model for phrase-based statistical machine translation, bilingual structured language model. Our approach represents a new way to adapt structured language models (Chelba and Jelinek, 2000) to statistical machine translation, and a first attempt to adapt them to phrase-based statistical machine translation. We propose a number of variations of the bilingual structured language model and evaluate them in a series of rescoring experiments. Rescoring of 1000-best translation lists produces statistically significant improvements of up to 0.7 BLEU over a strong baseline for Chinese-English, but does not yield improvements for Arabic-English.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many model components of competitive statisti- cal machine translation (SMT) systems are based on rather simplistic definitions with little linguis- tic grounding, which includes the definitions of phrase pairs, lexicalized reordering, and n-gram language models. However, earlier work has also shown that statistical MT can benefit from ad- ditional linguistically motivated models. Most prominent among the linguistically motivated ap- proaches are syntax-based MT systems which take into account the syntactic structure of sen- tences through CKY decoding and categorial la- bels ( <ref type="bibr" target="#b38">Zollmann and Venugopal, 2006;</ref><ref type="bibr" target="#b31">Shen et al., 2008</ref>). On the other hand, the commonly used phrase-based SMT approaches can also reap some of the benefits of using syntactic information by integrating linguistic components addressing spe- cific phenomena, such as Cherry (2008), <ref type="bibr" target="#b2">Carpuat et al. (2010)</ref>, <ref type="bibr" target="#b7">Crego and Yvon (2010)</ref>, Ge (2010), <ref type="bibr" target="#b35">Xiang et al. (2011)</ref>, <ref type="bibr" target="#b20">Lerner and Petrov (2013)</ref>, <ref type="bibr" target="#b10">Garmash and Monz (2014)</ref>.</p><p>This paper is a contribution to the existing body of work on how syntactically motivated models help translation performance. We work with the phrase-based SMT (PBSMT) ( <ref type="bibr" target="#b17">Koehn et al., 2003)</ref> framework as the baseline system. Our choice is motivated by the fact that PBSMT is a conceptu- ally simple and therefore flexible framework. It is typically quite straightforward to integrate an ad- ditional model into the system. Also, PBSMT is the most widely used framework in the SMT re- search community, which ensures comparability of our results to other people's work on the topic.</p><p>There is a variety of ways syntax can be used in a PBSMT model. Typically a syntactic represen- tation of a source sentence is used to define con- straints on the order in which the decoder trans- lates it. For example, Cherry (2008) defines soft constraints based on the notion of syntactic cohe- sion (Section 2). Ge (2010) captures reordering patterns by defining soft constraints based on the currently translated word's POS tag and the words structurally related to it. On the other hand, tar- get syntax is more challenging to use in PBSMT, since a target-side syntactic model does not have access to the whole target sentence at decoding. <ref type="bibr" target="#b27">Post and Gildea (2008)</ref> is one of the few target- side syntactic approaches applicable to PBSMT, but it has been shown not to improve translation. Their approach uses a target side parser as a lan- guage model: one of the reasons why it fails is that a parser assumes its input to be grammatical and chooses the most likely parse for it. What we are interested in during translation is how gram-matical the target sentence actually is.</p><p>In addition to reordering constraints, source syntax can be used for target-side language mod- eling. A target side string can be encoded with source-syntactic building blocks and then scored as to how well-formed it is. <ref type="bibr" target="#b7">Crego and Yvon (2010)</ref>, <ref type="bibr" target="#b22">Niehues et al. (2011)</ref>, <ref type="bibr" target="#b10">Garmash and Monz (2014)</ref> model target sequences as strings of tokens built from the target POS tag and the POS tags of the source words related to it through alignment and the source parse. In this paper, we define a target-side syntactic language model that takes structural constraints from the source sentence, but uses the words from the target side (as 'building blocks'). We do it by adapting an existing mono- lingual model of <ref type="bibr" target="#b4">Chelba and Jelinek (2000)</ref>, struc- tured language models, to the bilingual setting. Our contributions can be summarized as follows:</p><p>• we propose a novel method to adapt monolin- gual structured language models <ref type="bibr" target="#b4">(Chelba and Jelinek, 2000</ref>) (Section 3) to a PBSMT sys- tem (Section 4), which does not require an external on-the-fly parser, but only uses the given source-side syntactic analysis to infer structural relations between target words;</p><p>• building on the existing literature, we pro- pose a set of deterministic rules that incre- mentally build up a parse of a target trans- lation hypothesis based on the source parse (Section 4);</p><p>• we evaluate our models in a series of rescor- ing experiments and achieve statistically sig- nificant improvements of up to 0.7 BLEU for Chinese-English (Section 5).</p><p>Before describing the models, we motivate our method with a common assumption about cross- lingual correspondence (Section 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Direct correspondence assumption and syntactic cohesion in SMT</head><p>Before we apply the syntactic model introduced in Section 3 to the bilingual setting (Section 4), we first explain two widely used assumptions about syntactic correspondence across languages. We take a dependency tree to be a syntactic rep- resentation of a sentence and reason about other syntactic assumptions and models in its terms. In this work, we choose a dependency structure over a constituency structure because the former (a)</p><formula xml:id="formula_0">0 1 2 (b) 0 1 2 3 (c) 0 1 2 3 (d)</formula><p>Figure 1: Examples of projective and non- projective parses. (a-b): projective (a) and non- projective (b) parses of the same dependency tree. (b) is non-projective because node 1 is not a de- scendant of either 0 or 2 (it is the parent of 2). (c- d): projective (c) and non-projective (d) parses of the same dependency tree. Node 2 in (d) is placed between its sibling (node 1) and the child of its sibling (node 3), neither of which is its ancestor.</p><p>is more primitive. 1 A dependency parse D is a dependency tree analysis of a sentence W , and we will think of it as a relation between words of W , such that D(w, v) if w is a parent (head) of v (v being a child/modifier). D can be gener- alized to D * which is an relation between words that are connected by a continuous path in a de- pendency tree (i.e.</p><formula xml:id="formula_1">D * (w, v) if D(w, v) or if ∃u s.t. D(w, u) ∧ D * (u, v)).</formula><p>We assume unlabeled dependency trees. Finally, we make a projectivity assumption, which is supported by empirical data in many languages ( <ref type="bibr" target="#b19">Kuhlmann and Nivre, 2006;</ref><ref type="bibr" target="#b14">Havelka, 2007)</ref>, and makes a model computation- ally less expensive. A dependency parse D of a sentence W = w 1 , . . . , w n is projective, if for ev- ery word pair w i , w j ∈ W s.t. D(w i , w j ) it holds that every w k ∈ W s.t. i &lt; k &lt; j or j &lt; k &lt; i is a descendant of w i , i.e., D * (w i , w k ); see <ref type="figure">Figure 1</ref>. Most NLP models that address the interaction of two or more languages are based (explicitly or implicitly) on the direct correspondence assump- tion (DCA) ( <ref type="bibr" target="#b16">Hwa et al., 2002</ref>). It states that close translation equivalents in different languages have the same dependency structure. This is grounded linguistically, as translation equivalence implies semantic equivalence and therefore thematic rela- tions are preserved ( <ref type="bibr" target="#b16">Hwa et al., 2002</ref>). Thus de- pendency relations are preserved, as they are de- fined based on thematic relations between words. On the other hand, there is plenty empirical evi- dence supporting the violation of DCA under cer- tain conditions ( <ref type="bibr" target="#b16">Hwa et al., 2002</ref>). For instance, even semantically very close sentences in differ- ent languages may have a different number of  words. Syntactic divergence increases if the two languages are typologically different.</p><p>Even though DCA only holds up to a certain level of precision, it is widely used in NLP. There are models of cross-lingual transfer that define syntactic structure of one language by condition- ing it on the structure of semantically equiva- lent sentences in another language ( <ref type="bibr" target="#b21">Naseem et al., 2012)</ref>. DCA has also been used in SMT. In partic- ular, syntax-based SMT is built implicitly around this assumption <ref type="bibr" target="#b34">(Wu, 1997;</ref><ref type="bibr" target="#b36">Yamada and Knight, 2001</ref>). In Quirk and Menezes (2006) DCA is explicitly implemented by defining a translation model in terms of treelet pairs where target-side treelets are produced by projecting source depen- dencies via word alignments.</p><p>Closely related to DCA is the notion of syn- tactic cohesion of translation <ref type="bibr" target="#b9">(Fox, 2002;</ref><ref type="bibr" target="#b5">Cherry, 2008)</ref>. This is a constraint that does not allow for non-projective reordering: Given a source parse D S , a translation W is cohesive if all translated target words w i , w j do not have any word w k be- tween them such that there is a source subtree sub in D S such that some parts of it are translated by w i and w j but not by w k <ref type="figure" target="#fig_2">(Figure 2</ref>). Cherry (2008) and <ref type="bibr" target="#b0">Bach et al. (2009)</ref> define a set of soft con- straints based on the syntactic cohesion assump- tion which are applicable to PBSMT decoding. They only require phrase applications, and not necessarily individual target words, to conform to the cohesion principle. For example, if we imag- ine a situation where a subtree as in <ref type="figure" target="#fig_2">Figure 2</ref>(b) is translated as a whole with one phrase applica- tion (and not word by word), then it does not vio- late the cohesion principle, although it is internally uncohesive. Both our approach and Cherry <ref type="bibr">(2008)</ref> implement the idea of conforming the target trans- lation to the source syntactic structure, but in dif- ferent ways. Approaches like Cherry (2008) de- fine principles that constrain the decoder in order to produce better translations. Our goal is to have a model that allows for a more direct way of evalu- ation of how well-formed the target translation is. In Section 5 we compare translation performance of the two approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Structured language models</head><p>As discussed in Sections 1 and 2, we would like to test how much a PBSMT can benefit from an ad- ditional syntax-based LM. In this section, we de- scribe a syntactic language model, structured LM (SLM) <ref type="bibr" target="#b4">(Chelba and Jelinek, 2000</ref>), that we extend to a bilingual setting and apply to SMT in Sec- tion 4. SLMs have been applied in SMT before <ref type="bibr" target="#b36">(Yamada and Knight, 2001;</ref><ref type="bibr" target="#b37">Yu et al., 2014</ref>), but as we show in Section 4, we provide a much sim- pler method to integrate it into the system. While a SLM is not the only syntactically defined LM, it is one of the few that models sentence genera- tion sequentially. And due to the way the decoding procedure of PBSMT is defined, it is natural and straightforward to use models whose score can be computed sequentially. Other syntactic language models define sentence generation hierarchically <ref type="bibr" target="#b31">(Shen et al., 2008;</ref><ref type="bibr" target="#b30">Sennrich, 2015)</ref>, which com- plicates their integration into a PBSMT system.</p><p>The linguistic intuition behind SLMs is that the structural children of a word do not essentially change its distributional properties but just provide additional specification. In <ref type="figure" target="#fig_3">Figure 3</ref>(a) the word president has two modifiers: the and former and it follows yesterday (an adjunct) and precedes met (a predicate). This ordering is correct in English. If instead its modifier was a or an entire relative clause, it would not make it incorrect.</p><p>To capture this observation, <ref type="bibr" target="#b4">(Chelba and Jelinek, 2000</ref>) propose a language model where each word w i of a sentence W is predicted by an or- dered subset of the words preceding w i . This con- ditioning subset is selected based on the syntactic properties of the preceding sequence W i−1 : the strong predictors are kept and the weak ones are left out. The strong predictors are the set of ex- posed heads. Given a subsequence W i−1 and its associated parse D i−1 , exposed heads are the roots of all the disconnected subtrees in D i−1 . Note that For an example, consider again <ref type="figure" target="#fig_3">Figure 3(a)</ref>. In a left-to-right scenario, when met is generated, a regular n-gram LM conditions it on yesterday the former president, while a SLM conditions it on yesterday president, since these two words are the exposed heads with respect to met <ref type="figure" target="#fig_3">(Figure 3(b)</ref>). The words the and former are modifiers of pres- ident and they get filtered out. Thus we obtain a less specific conditioning history, which may lead to the resulting model being less sparse. Another potential benefit is that SLMs can capture long- distance reordering: If president had as its mod- ifier a relative clause <ref type="figure" target="#fig_3">(Figure 3(c)</ref>) then a simple n-gram LM would be conditioned on days before (assuming n = 3), while an SLM would condition met on yesterday president.</p><p>Summarizing the ideas of words being con- ditioned on a structurally defined subset of the preceding sentence, <ref type="bibr" target="#b4">Chelba and Jelinek (2000)</ref> formalize the generation process of W as fol- lows: <ref type="bibr">2</ref> Each new word w i is conditioned on a <ref type="bibr">2</ref> The original model by <ref type="bibr" target="#b4">(Chelba and Jelinek, 2000</ref>) is de- fined in terms of a lexicalized constituency grammar, but as sequence of exposed heads Expos(W, D). Then a tag t i is predicted, and the parse D i−i of W i−1 is extended to D i incorporating w i and t i (where W i−1 is the prefix of W preceding w i ):</p><formula xml:id="formula_2">p(W, D) = |W | i=1 p(w i |Expos(W i−1 , D i−1 )) · p(t i |w i , Expos(W i−1 , D i−1 )) · p(D i |w i , t i , Expos(W i−1 , D i−1 )).<label>(1)</label></formula><p>They use a shift-reduce parser with reduce-left, reduce-right, and shift operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Bilingual structured language models</head><p>In this section, we combine the direct correspon- dence assumption (Section 2) and SLMs (Sec- tion 3), and define bilingual structured language models (BiSLMs) for PBSMT. Structured LMs have been successfully applied in SMT before. <ref type="bibr" target="#b36">Yamada and Knight (2001)</ref> use SLMs in a string- to-tree SMT system where a derivation of a target- side parse tree is part of the decoding algorithm, and target syntactic representations are obtained 'for free'. <ref type="bibr" target="#b37">Yu et al. (2014)</ref> use an on-the-fly shift- reduce parser to build an incremental target parse. The approaches sketched above rely on re- sources that a standard PBSMT system does not have access to by default. Phrase-based decoders do not provide us with a parse of the target sentence, and inferring the parse of a target string with an external parser is computationally expen- sive and potentially unreliable (see Section 1). Our main insight is that in a bilingual setting one does not need an additional probabilistic target parsing model. We assume that the source parse is given (precomputed) and that the DCA (Section 2) holds, and project the parse deterministically onto the target side via word alignments <ref type="bibr">3</ref> . We obtain the following equation:</p><formula xml:id="formula_3">p(T |S, D S ) = |T | i=1 p(t i | Expos(T i−1 , ProjP(D S , S, T i−1 ))),<label>(2)</label></formula><p>where T is a target sentence, T i−1 is the sequence in T preceding the i-th target word t i , S is a we discussed in Section 2, constituency parses can be trans- formed into dependency parses. In words, at each time step i we predict the next word t i conditioned on the exposed heads of the partial parse of T i−1 projected from the source side. We limit Expos to returning the four preceding exposed heads. <ref type="bibr">4</ref> Because the function ProjP is determinis- tic and because we do not have to predict tags for words, Equation 2 is simpler than Equation 1. We first illustrate Equation 2 with an example in <ref type="figure" target="#fig_4">Figure 4</ref>. Since word alignment is monotonic in <ref type="figure" target="#fig_4">Figure 4</ref>(a), it is straightforward to project the source dependencies onto the target side. We aim to imitate a monolingual parser in the way we build up our projected parse: Reduce operations should be invoked whenever both of the subtrees involved in the operation are complete, i.e., are not expected to have any more modifiers (Sec- tion 4.2). For example, when the target word likes is produced its exposed heads are said and he <ref type="figure" target="#fig_4">(Fig- ure 4(b)</ref>), since Putin is a modifier of said. Like- wise, the exposed heads for women are said likes all Russian <ref type="figure" target="#fig_4">(Figure 4(c)</ref>).</p><p>In what follows we discuss how to define ProjP. Compared to projection approaches like (Quirk <ref type="bibr">4</ref> As written above, we choose the dependency structures over the lexicalized constituency ones because the latter can be mapped to the former. It is thus more likely that a pro- jected dependency tree is still be a well-formed parse, than a projected constituency tree. We decided to work with struc- tural models that are more flexible, but one may also define BiSLM in terms of the more constraining constituency trees and see if the such model has better generalization power. and Menezes, 2006), we would like our model to project a source parse incrementally, allowing it to be used in a PBSMT decoder. We think of ProjP as a function that computes the output in two stages: first, it infers from the source parse the dependency relations between target words (Sec- tion 4.1), second, it decides how to parse the tar- get sequence, i.e. in which order to assign these dependencies <ref type="figure" target="#fig_2">(Section 4.2)</ref>. Additionally, in Sec- tion 4.3 we propose to use additional labelings of target words, and in Section 4.4 we describe some important implementation details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dependency graph projection</head><p>Adoption of DCA (Section 2) allows to build up a target dependency tree from a source tree by pro- jecting the latter through word alignments. The definition of DCA can be rephrased as requiring a one-to-one correspondence map between words of a sentence pair, allowing one to unambigu- ously map dependencies: Given a source parse, if t 1 is the head of t 2 , then map(t 1 ) is the head of map(t 2 ). The correspondence relation that we have in PBSMT is the word alignment align: in the most general case, it is a many-to-many correspondence, and the straightforward projec- tion described above can lead to incorrect depen- dency structures. To overcome these problems, we describe a simple ordered set of projection rules, based on the ones specified by <ref type="bibr" target="#b28">(Quirk and Menezes, 2006</ref>) (and we point out if otherwise).</p><p>The general idea behind this set of rules is to ex- tract a one-to-one function align 1−1 from source words to target words from align and use it to project source dependencies as described in the paragraph above (R1 below). We then use addi- tional rules (R2-R4 below) for the target words that are not in align 1−1 . Given a source sen- tence S with a parse D S , a target sentence T and word alignment align, align 1−1 is extracted as fol- lows: For all t i ∈ T with multiple aligned source words {s i 1 , s i 2 , ...} only align 1−1 (s i 1 ) = t i (only leftmost source word is kept, the links from the rest of the source words are removed 5 ). For all s i ∈ S with aligned target words {t i 1 , t i 2 , ...} keep the link only for the leftmost aligned target word: align 1−1 (s i ) = t i 1 . For example, in <ref type="figure" target="#fig_6">Figure 5</ref>(b) the link between f 0 and e 1 is not in align 1−1 , and in <ref type="figure" target="#fig_6">Figure 5</ref>(c) the link between f 1 and e 0 is re- moved (and the arc from f 2 to f 1 is not projected). (a) The following rules should be applied in order (as else-if conditions). Given a source sentence S with a parse D S , a target sentence T and word alignment align between them, t i ∈ T is a head of t j ∈ T (i.e. D T (t i , t j )): (R1) if there are s k , s l ∈ S s.t. D S (s k , s l ) and align 1−1 (s k ) = t i and align 1−1 (s l ) = t j ; see Fig- ures 5(a)-5(c); (R2) if ∃s ∈ S s.t. align 1−1 (s) = t i and (s, t j ) ∈ align. This rule deals with one-to-many align- ments; see <ref type="figure" target="#fig_6">Figure 5</ref>(d); (R3a) if ∃s k s.t. align 1−1 (s k ) = t i and ∃s l s.t. (s l , t j ) ∈ align and and D S (s l , s k ), and t i linearly precedes t j . In words: if two target words are in align 1−1 but do not get connected via R1, find a source word aligned to the second target word that may get them connected; see <ref type="figure" target="#fig_6">Figure 5</ref>(e); (R3b) same as R3a, but in case t j precedes t i (i.e., find an additional source word aligned to the first target word; see <ref type="figure" target="#fig_6">Figure 5</ref>(f)). 6 (R4) In case ¬∃s (s, t j ) ∈ align (t j is unaligned), we consider two strategies: We simplify the rule of <ref type="bibr" target="#b28">Quirk and Menezes (2006)</ref> (dealing with the same situation) by adjoining it to the immediately pre- ceding head. We also consider a strategy whereby the word remains unconnected to any word in the sentence; see <ref type="figure" target="#fig_6">Figure 5</ref>(g). <ref type="bibr">6</ref> R3a and R3b differ from the rules proposed in <ref type="bibr" target="#b28">Quirk and Menezes (2006)</ref> dealing with the same situation, since we had to adapt it to the left-to-right parsing scenario. </p><formula xml:id="formula_4">f 0 f 1 e 0 e 1 e 3 (b) f 0 f 1 f 2 e 0 e 1 (c) f 0 f 1 e 0 e 1 e 2 e 3 (d)<label>f</label></formula><formula xml:id="formula_5">f 0 f 1 f 2 e 0 e 1 e 2 (a) f 0 f 1 f 2 e 0 e 2 e 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">BiSLM parsing procedure</head><p>Given an inference procedure for dependency re- lations between target words (Section 4.1), one can specify in which order the corresponding de- pendency arcs are assigned to the target sentence. We define an incremental parsing procedure in terms of three operations: shift, left-reduce, and right-reduce. The operations are applied as soon as the sufficient conditions hold: We specify the conditions using the following structural proper- ties. A target subtree is source-complete if all the descendants of align −1 1−1 (root(sub)) (source corre- spondent of the root of the current subtree) (Sec- tion 4.1) have been translated and reduced. A tar- get subtree is complete if it is source-complete and all the target words that are its children through non-projected arcs (through R2 or R4 in Sec- tion 4.1) have been translated and reduced. The bilingual parsing operations and the sufficient con- ditions for them are defined as follows: Shift: after the word is produced it is shifted onto the stack as an elementary subtree. Left-reduce: if a disconnected subtree sub i and a disconnected subtree sub i−1 imme- diately preceding it are both complete and</p><formula xml:id="formula_6">D T (root(sub i ), root(sub i−1 )),</formula><p>adjoin sub i−1 to sub i so that root(sub i−1 ) is a modifier of root(sub i ). Right-reduce: analogous to left-reduce, but D T (root(sub i−1 ), root(sub i )).</p><p>In the case of non-cohesive translation the re- sulting target dependencies are non-projective. Our definition of left-and right-reduce only pro- duces projective parses. For a non-cohesive translation, certain subtrees will never be source- complete and will never be reduced; see <ref type="figure" target="#fig_7">Fig- ure 6(a)</ref>. Note that this is not a disadvantage of our model. <ref type="bibr" target="#b5">Cherry (2008)</ref> simply assumes that non-cohesive reordering should be penalized, and our model is able to learn this pattern. We also consider an alternative to incorporating non- cohesive alignments by relaxing the definition of completeness for subtrees: A projected subtree sub is weakly source-complete if all descendants of all source word(s) which are aligned to the root of sub have been translated and, only if the defini- tion of reduce applies, reduced; see <ref type="figure" target="#fig_7">Figure 6</ref>(b).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Syntactic labeling of tokens</head><p>One of the problems with SLMs in general is that at time steps i and j the sets of exposed heads for t i and t j can differ in size, which may imply dif- ferent predictive power. To this end, we add an ad- ditional detail to our model: Each time a reduction occurs, we label the root of the subtree to which another subtree has been adjoined, thus making the conditioning history more specific. We use the following labelings: Reduction labeling: if a subtree is adjoint to sub from the left, then label root(sub) with LR. If it is adjoint from the right, then label it with RR. Reduction POS-labeling: same as in simple re- duction labeling, but add the POS tag of the root of the reduced subtree to the label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Implementation and training</head><p>To use BiSLM during decoding, one needs access to phrase-internal alignments and target POS tags. We store phrase-internal alignments and target- side POS annotations of each phrase in the phrase table, based on the most frequent internal align- ment during training and the most likely target- side POS labelingˆtlabelingˆ labelingˆt given the phrase pair: ˆ t = arg max ¯ t p( ¯ t|¯ e, ¯ f ). We train BiSLMs on the par- allel training data (Section 5.1) and use the Stan- ford dependency parser ( <ref type="bibr" target="#b3">Chang et al., 2009</ref>) for Chinese and and the Stanford constituency parser <ref type="bibr" target="#b13">(Green and Manning, 2010</ref>) for Arabic <ref type="bibr">7</ref> . POS- tagging of the training data is produced with the Stanford POS-tagger ( <ref type="bibr" target="#b33">Toutanova et al., 2003</ref>). We learn a 5-gram model using SRILM <ref type="bibr" target="#b32">(Stolcke et al., 2011</ref>) with modified Kneser-Ney smoothing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>To evaluate the effectiveness of BiSLMs for PB- SMT, we performed rescoring experiments for <ref type="bibr">7</ref> We extract dependency parses from its output based on <ref type="bibr" target="#b6">Collins (1999)</ref> Arabic-English and Chinese-English. We com- pare the resulting 1-best translation lists with an output of the baseline system and the baseline aug- mented with soft cohesion constraints from <ref type="bibr" target="#b0">Bach et al. (2009</ref>  <ref type="table">Table 2</ref>: Arabic-English baseline and comparison model <ref type="bibr" target="#b5">(Cherry, 2008;</ref><ref type="bibr" target="#b0">Bach et al., 2009</ref>) results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental setup</head><p>This section provides information about our base- line system. Word-alignment is produced with GIZA++ ( <ref type="bibr" target="#b24">Och and Ney, 2003)</ref>. We use an in- house implementation of a PBSMT system similar to Moses ( <ref type="bibr" target="#b18">Koehn et al., 2007)</ref>. Our baseline has all standard PBSMT features including language model, lexical weighting, and lexicalized reorder- ing. The distortion limit is set to 5. A 5-gram LM is trained on the English Gigaword corpus (1.6B tokens) using SRILM with modified Kneser-Ney smoothing and linear interpolation. Information about the training data for the Arabic-English and Chinese-English systems is in  <ref type="bibr" target="#b23">Noreen, 1989;</ref><ref type="bibr" target="#b29">Riezler and Maxwell, 2005</ref>) is used to detect sta- tistically significant differences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Baseline and comparison systems</head><p>As a comparison model, we implemented six fea- tures from Cherry (2008) and <ref type="bibr" target="#b0">Bach et al. (2009)</ref>  <ref type="bibr">9</ref> and added them to the log-linear interpolation used</p><p>Training set N. of lines N. of tokens Source side of Ar-En set 4,376,320 148M Target side of Ar-En set 4,376,320 146M Source side of Ch-En set 2,104,652 20M Target side of Ch-En set 2,104,652 28M by the baseline system. Since these features are bi- nary or count-based, we cannot use them directly in rescoring. For that reason we integrated the fea- tures into the decoder and tuned the correspond- ing weights. The results for Chinese-English and Arabic-English translation experiments are pre- sented in <ref type="table">Table 1</ref> and 2, respectively. We see that adding the cohesion constraints does not improve performance. This finding is different from, for example, <ref type="bibr" target="#b8">Feng et al. (2010)</ref>, where they get im- provement for Chinese-English: however, we note that their training set is smaller than ours, and their baseline is weaker as it does not contain lexical- ized distortion models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Rescoring experiments</head><p>Rescoring with BiSLMs is performed as follows:</p><p>For the test runs of the baseline system we com- pute the n = 1000 best translation hypotheses for each source sentence and extract their deriva- tions (sequence of phrase pair applications). Each phrase pair in our implementation is associated with a unique phrase-internal alignment and tar- get POS-sequence. We fully reconstruct word- alignment for each pair of a source sentence and its translation hypothesis. We project a precom- puted source parse onto the target side and com- pute representations of the target sentence to be computed by a BiSLM. For each hypothesis, we take its BiSLM score and its score assigned by the baseline system and compute the final score as a weighted sum of the original baseline score and a length-normalized BiSLM score 10 , where the weight λ is empirically set to 0.3:</p><p>λ · score BiSLM length Hypothesis + (1 − λ) · score Baseline (3)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Chinese-English</head><p>Our main focus here is Chinese-English, since it has more instances of longer-distance reordering, at which syntax-based models are typically good.  words with a reduction label, or target words with a reduction label and a POS of the root of the re- duced subtree (Section 4.3). The column com- plete indicates whether we use a strong or weak definition of a complete subtree (Section 4.2). The column unalign-adjoin indicates whether we ad- join an unaligned target word to the preceding subtree (Section 4.1). Statistically significant im- provements over the baseline are marked at the p &lt; .01 level and at the p &lt; .05 level. marks significant decrease at the p &lt; .01 level.</p><p>SLMs by design are good at capturing longer- distance dependencies. We try out several varia- tions of BiSLM. First, we test whether to use a strong or weak definition of a complete subtree (Section 4.2). Second, we investigate whether to adjoin unaligned target words to a preceding head (Section 4.1; unalign-adjoin+/-). Third, we com- pare several target-side labeling methods (Sec- tion 4.3): plain (just target words), reduce (LR or RR) or reduce-POS (LR POS or RR POS, where POS is the tag of the root of the reduced subtree). The rescoring results are presented in <ref type="table" target="#tab_4">Table 4</ref>.</p><p>The results show statistically significant im- provement over the baseline of up to 0.7 BLEU (for all of the employed BiSLM variants except one). The rescoring experiments also demonstrate the tendency of the unalign-adjoin-feature value to produce higher scores than unalign-adjoin+. But the other two distinguishing features do not have an effect on BLEU scores. As future work, we are interested in examining if these features produce the same distribution of scores when a BiSLM is fully integrated into the decoder.   <ref type="table">Table 5</ref>: Rescoring experiments for Arabic MT08+09 n-best translation sets. Unrescored BLEU for is 47.18. For notation see <ref type="table" target="#tab_4">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Arabic-English</head><p>We also rescore the n-best lists for the output of the Arabic-English baseline system and results are shown in <ref type="table">Table 5</ref>. Arabic and English are typolog- ically very different, but the range of reordering is much smaller than for Chinese-English. We ex- pect reordering-related models to have lesser ef- fect on Arabic as compared to <ref type="bibr">Chinese (Carpuat et al., 2010)</ref>. Experimental results on Arabic- English could indicate what kind of translation aspect benefits from BiSLMs. We see that for Arabic-English, just as for the cohesion constraint, BiSLM have little effect on BLEU scores, or even decrease them. This is a weak indication that BiSLMs are better at capturing reordering as- pects. As for the varying features defining dif- ferent BiSLM versions, we again see little effect of the labeling type or subtree completeness def- inition. On the other hand, we see the oppo- site pattern for the unalign-adjoin feature, where unalign-adjoin+ is preferred.</p><p>To gain further insight into the different effect of BiSLM on the two language pairs, we evalu- ated our experimental output against a reordering- sensitive metric LRscore ( <ref type="bibr" target="#b1">Birch et al., 2010)</ref>. We use the version of LRscore which is an average of the inverse Kendall's Tau distance and the Ham- ming distance. In order to compute alignments for test sets which are needed to compute the score we concatenated the parallel text with an additional 250K lines of parallel text from the training data to ensure better generalization of the alignment algo- rithm (GIZA++). The LRscores of the baseline are compared to the best performing BiSLM system with respect to BLEU, for each of the language pair. The results are provided in <ref type="table" target="#tab_7">Tables 6 and 7</ref>.   <ref type="table">Table 7</ref>: LRscores for Arabic-English baseline and BiSLM with plain-labeling, weak completeness, unalign-adjoin+.</p><p>As expected, the scores for Chinese-English are much lower than for Arabic-English, which is con- sistent with the observation reordering is more dif- ficult for Chinese-English. BiSLM yields larger improvements for Chinese-English suggesting that the proposed model helps addressing difficult re- ordering problems. While there are also small im- provements for Arabic-English the they may be too small to be detectable by BLEU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper we proposed a novel way to adapt structured language models to phrase-based SMT. Our method requires minimal changes to the PB- SMT pipeline. We tried a number of variations of our model and evaluated them in rescoring ex- periments, resulting in statistically significant im- provement for Chinese-English. The model is based on the idea of syntactic transfer (DCA; Sec- tion 2) and the positive result indicates its ability to capture syntactic patterns across languages. For Arabic-English, we did not observe any improve- ments, suggesting that our models indeed mainly improve reordering aspects. Improvements in rescoring are a positive indication that our model may be a strong feature during decoding. As fu- ture work, we will fully integrate our model into a PBSMT decoder and evaluate it on other language pairs with different reordering distributions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Examples of cohesive and uncohesive translations. (a-b): cohesive (a) and uncohesive (b) translations of the same dependency parse. (b) is uncohesive because words a and c translate the source subtree {(1, 2)}, but the target word b does not translate this subtree. (c-d): cohesive (c) and uncohesive (d) translations. (d) is uncohesive because a and c translate the source subtree {(0, 1)}, but b does not translate it.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: A fully parsed sentence (a) and its partial parse (b) during sequential generation. The partial parse in (b) has two disconnected subtrees with roots yesterday and president. These roots are the exposed heads for met. (c) is an alternative sentence with a similar structure: president is still a root of a subtree, and thus and an exposed head.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Chinese-English sentence pair (a) and sets of exposed heads (underlined) at different generation (b and c) steps of a bilingual SLM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Examples for dependency projection rules. (a): no alignment links get removed (R1). (b): f 0 − e 1 link is removed from align 1−1 (R1). (c): f 1 − e 0 link gets removed (R1). (d): e 1 and e 2 get adjoined to e 0 (R2). (e): R3a. (f): R3b. (g) demonstrates two versions of R4: the dashed arrow gets 'realized' only if we adjoin unaligned words to the preceding head.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: (a): The dashed lines are the dependency arcs that would project through word alignment, resulting in a non-projective projective (impossible under strong source-completeness). (b): The dashed lines are the parse produced under weak source-completeness. Under strong completeness none of the words will get connected.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>) .</head><label>.</label><figDesc></figDesc><table>System 
MT06 MT08 MT06+MT08 
baseline 
32.60 
25.94 
29.56 
cohesion 32.52 
25.98 
29.54 

Table 1: Chinese-English baseline and compari-
son model (Cherry, 2008; Bach et al., 2009) re-
sults. 

System 
MT08 MT09 MT08+MT09 
baseline 
45.84 
48.61 
47.18 
cohesion constr. 45.61 
48.49 
47.02 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 3 .</head><label>3</label><figDesc></figDesc><table>8 Feature 
weights are tuned using pairwise ranking opti-
mization (Hopkins and May, 2011) on the MT04 
benchmark (for both language pairs). For testing, 
we use MT08 and MT09 for Arabic, and MT06 
and MT08 for Chinese. We use case-insensitive 
BLEU (Papineni et al., 2002) as evaluation met-
ric. Approximate randomization (</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 : Training data for Arabic-English and Chinese-English experiments.</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Rescoring experiments for Chinese 
MT06+08 1000-best translation sets. Unrescored 
BLEU is 29.56. The column labeling contains in-
formation about the kind of labeling used on the 
target side of a BiSLM: just target words, target 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>LRscores (average inverse Kendall's 
Tau distance and Hamming distance) for Chinese-
English baseline and BiSLM with reduce-labeling, 
weak completeness, unalign-adjoin-. 

system 
LRscore MT08+09 
baseline 
0.6671 
BiSLM 
0.6719 

</table></figure>

			<note place="foot" n="1"> A dependency parse (a dependency tree analysis of a sentence) is more primitive because every constituency parse can be formalized as a projective dependency parse with labeled relations, but not vice versa (Osborne, 2008).</note>

			<note place="foot" n="3"> Phrase-internal word alignments are stored in the phrase table and are available at decoding time, see Section 4.4.</note>

			<note place="foot" n="5"> This is an ad-hoc solution, other heuristics could be used.</note>

			<note place="foot" n="8"> The standard LDC corpora were used for training. 9 Exhaustive and non-exhaustive interruption check, exhaustive and non-exhaustive interruption count, verb-and noun-dominated subtree interruption count.</note>

			<note place="foot" n="10"> Normalization is needed to ensure comparability of scores for translation hypotheses of different lengths, since longer translation hypotheses will have lower scores.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the reviewers for their useful com-ments. This research was funded in part by the Netherlands Organization for Scientific Research (NWO) under project numbers 639.022.213 and 612.001.218.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Cohesive constraints in a beam search phrase-based decoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nguyen</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Metrics for mt evaluation: evaluating reordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miles</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Translation</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="15" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Improving Arabic-to-English statistical machine translation by reordering post-verbal subjects for alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Marton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2010 Conference Short Papers</title>
		<meeting>the ACL 2010 Conference Short Papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="178" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Discriminative reordering with chinese grammatical relations features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pi-Chuan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huihsin</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Syntax and Structure in Statistical Translation</title>
		<meeting>the Third Workshop on Syntax and Structure in Statistical Translation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="51" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Structured language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ciprian</forename><surname>Chelba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick</forename><surname>Jelinek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech and Language</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="283" to="332" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cohesive phrase-based decoding for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Association for Computational Linguistics</title>
		<meeting>Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="72" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Head-Driven Statistical Models for Natural Language Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
		<respStmt>
			<orgName>University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improving reordering with linguistically informed bilingual n-grams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Josep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Crego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yvon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="197" to="205" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A source-side decoding sequence model for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arne</forename><surname>Mauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference of the Association for Machine Translation in the Americas</title>
		<meeting><address><addrLine>Denver, Colorado, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Phrasal cohesion and statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heidi</forename><forename type="middle">J</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="304" to="311" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Garmash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dependency-based bilingual language models for reordering in statistical machine translation</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="1689" to="1700" />
		</imprint>
	</monogr>
	<note>October. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A direct syntax-driven reordering model for phrase-based machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Niyu Ge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="849" to="857" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Better arabic parsing: Baselines, evaluations, and analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spence</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="394" to="402" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Beyond projectivity: Multilingual evaluation of constraints and measures on nonprojective structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Havelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association of Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="608" to="615" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Tuning as ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011-05" />
			<biblScope unit="page" from="1352" to="1362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Evaluating translational correspondence using annotation projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Hwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Weinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Okan</forename><surname>Kolak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="392" to="399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Statistical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</title>
		<meeting>the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="48" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics on Interactive Poster and Demonstration Sessions</title>
		<meeting>the 45th Annual Meeting of the Association for Computational Linguistics on Interactive Poster and Demonstration Sessions</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Mildly non-projective dependency structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Kuhlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions</title>
		<meeting>the COLING/ACL 2006 Main Conference Poster Sessions<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006-07" />
			<biblScope unit="page" from="507" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Source-side classifier preordering for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uri</forename><surname>Lerner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Empirical Methods in Natural Language Processing</title>
		<meeting>the Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Selective sharing for multilingual dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tahira</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Globerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="629" to="637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Wider context by using bilingual language models in machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Niehues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teresa</forename><surname>Herrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Waibel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="198" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Computer Intensive Methods for Testing Hypotheses. An Introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">W</forename><surname>Noreen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<publisher>WileyInterscience</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A systematic comparison of various statistical alignment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="51" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Major constituents and two dependency grammar constraints on sharing in coordination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Osborne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linguistics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1109" to="1165" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Parsers as language models for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Conference of the Association for Machine Translation in the Americas</title>
		<meeting>the Eighth Conference of the Association for Machine Translation in the Americas</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="172" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Dependency treelet translation: The convergence of statistical and example-based machine translation? Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arul</forename><surname>Menezes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006-03" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="43" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On some pitfalls in automatic evaluation and significance testing for MT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">T</forename><surname>Maxwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</title>
		<meeting>the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Modelling and optimizing on syntactic n-grams for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="169" to="182" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A new string-to-dependency machine translation algorithm with a target dependency language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><forename type="middle">M</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="577" to="585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Srilm at sixteen: Update and outlook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Abrash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Automatic Speech Recognition and Understanding Workshop</title>
		<meeting>IEEE Automatic Speech Recognition and Understanding Workshop</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Feature-rich part-ofspeech tagging with a cyclic dependency network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</title>
		<meeting>the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="173" to="180" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Stochastic inversion transduction grammars and bilingual parsing of parallel corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="377" to="403" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Improving reordering for statistical machine translation with smoothed priors and syntactic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niyu</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><surname>Ittycheriah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation</title>
		<meeting>the Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="61" to="69" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A syntaxbased statistical translation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 39th Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="523" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A structured language model for incremental treeto-string translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitao</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1133" to="1143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Syntax augmented machine translation via chart parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Zollmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Venugopal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Statistical Machine Translation</title>
		<meeting>the Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="138" to="141" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
