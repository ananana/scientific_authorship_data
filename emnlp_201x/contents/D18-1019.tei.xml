<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:36+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural Segmental Hypergraphs for Overlapping Mention Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bailin</forename><surname>Wang</surname></persName>
							<email>bailinwang@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Massachusetts Amherst</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
							<email>luwei@sutd.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Massachusetts Amherst</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Neural Segmental Hypergraphs for Overlapping Mention Recognition</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="204" to="214"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>204</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this work, we propose a novel segmen-tal hypergraph representation to model overlapping entity mentions that are prevalent in many practical datasets. We show that our model built on top of such a new representation is able to capture features and interactions that cannot be captured by previous models while maintaining a low time complexity for inference. We also present a theoretical analysis to formally assess how our representation is better than alternative representations reported in the literature in terms of representational power. Coupled with neu-ral networks for feature learning, our model achieves the state-of-the-art performance in three benchmark datasets annotated with overlapping mentions. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>One of the most crucial steps towards building a natural language understanding system is the iden- tification of basic semantic chunks in text. Such a task is typically characterized by the named entity recognition task <ref type="bibr" target="#b12">(Grishman, 1997;</ref><ref type="bibr" target="#b41">Tjong Kim Sang and De Meulder, 2003)</ref>, or the more general mention recognition task, where mentions are defined as references to entities that could be named, nominal or pronominal ( <ref type="bibr" target="#b9">Florian et al., 2004</ref>). The extracted mentions can be used in var- ious downstream tasks for performing further se- mantic related tasks, including question answer- ing ( <ref type="bibr" target="#b0">Abney et al., 2000</ref>), relation extraction ( <ref type="bibr" target="#b28">Mintz et al., 2009;</ref><ref type="bibr" target="#b24">Liu et al., 2017)</ref>, event extraction ( <ref type="bibr" target="#b35">Riedel and McCallum, 2011;</ref><ref type="bibr" target="#b23">Li et al., 2013)</ref>, and coreference resolution ( <ref type="bibr">Soon et al., 2001;</ref><ref type="bibr" target="#b32">Ng and Cardie, 2002;</ref><ref type="bibr" target="#b4">Chang et al., 2013)</ref>.</p><p>One popular approach to the task of mention ex- traction is to regard it as a sequence labeling prob- lem, with the underlying primary assumption be- ing that the mentions are non-overlapping spans in the text. However, as highlighted in several prior research efforts ( <ref type="bibr" target="#b1">Alex et al., 2007;</ref><ref type="bibr" target="#b8">Finkel and Manning, 2009;</ref><ref type="bibr" target="#b25">Lu and Roth, 2015)</ref>, men- tions may overlap with one another in practice. Thus, models based on such a simplified assump- tion may result in sub-optimal performance for a down-stream task when they are deployed in prac- tice. For example, consider a phrase "At the Seat- tle zoo, . . . " shown in <ref type="figure" target="#fig_0">Figure 1</ref>, the relation LO- CATEDIN between the mentions "the Seattle zoo" (of type FACILITY) and "Seattle" (of type GPE: Geo-political entities) will not be extracted unless both of these two overlapping mentions could be extracted. Similarly, there are 4 mentions of the same type (PROTEIN) in the text span ". . . PEBP2 alpha A1, alpha B1 . . . " taken from the biomed- ical domain. A downstream question answering system may fail to return the correct answer as de- sired, if the mention extraction system it relies on is unable to extract all these valid mentions.</p><p>Various approaches to extracting overlapping mentions have been proposed in the past decade. The cascaded approach <ref type="bibr" target="#b1">(Alex et al., 2007</ref>) builds a pipeline of sequence labeling models using condi- tional random fields (CRF) ( <ref type="bibr" target="#b21">Lafferty et al., 2001)</ref>. However, the model is unable to handle overlap- ping mentions of the same type. <ref type="bibr" target="#b8">Finkel and Manning (2009)</ref> presented a parsing based approach to nested mention extraction. Due to the chart-based parsing algorithm involved, the model has a cubic time complexity in the number of words in the sen-tence. A recent approach by <ref type="bibr" target="#b25">Lu and Roth (2015)</ref> introduced a hypergraph representation for captur- ing overlapping mentions, which was shown fast and effective. The work was improved by <ref type="bibr" target="#b31">Muis and Lu (2017)</ref>, who proposed a sequence labeling approach that assigns tags to gaps between words. However, both approaches suffer from the struc- tural ambiguity issue during inference, as we will further discuss in this paper.</p><p>We summarize our contributions as: 1. We propose a novel segmental hypergraph representation that is capable of modeling arbitrary combinations of (potentially over- lapping) mentions in a given sentence. The model has a O(cmn) time complexity (m is the number of mention types, n is the number of words in a sentence, and c is the maximal number of words for each mention), and is able to capture features that cannot be cap- tured by existing approaches. 2. Theoretically, we show that our approach based on such a new representation does not have the limitations associated with some re- cently proposed state-of-the-art approaches for overlapping mention extraction. 3. We show through extensive experiments on standard data that by exploiting both word- level and span-level features learned from neural networks, our model is able to achieve the state-of-the-art performance for recogniz- ing overlapping mentions. Our model is also general and robust. Further experiments show that our model yields competi- tive results when evaluated on data that does not have overlapping mentions annotated when com- paring against other recently proposed state-of- the-art neural models that are capable of extracting non-overlapping mentions only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overlapping Mention Recognition</head><p>One of the earliest research efforts on handling overlapping mentions is a rule-based approach ( <ref type="bibr" target="#b45">Zhou, 2006</ref>) that is evaluated on the GENIA dataset ( ). The authors first detected the inner- most mentions and then relied on rule-based post- processing methods to identify overlapping men- tions. <ref type="bibr" target="#b27">McDonald et al. (2005)</ref> presented a multil- abel classification algorithm to model overlapping segments in a sentence systematically. <ref type="bibr" target="#b1">Alex et al. (2007)</ref> proposed several ways to combine multiple conditional random fields (CRF) ( <ref type="bibr" target="#b21">Lafferty et al., 2001</ref>) for such tasks. Their best results were obtained by cascading several CRF models in a specific order while each model is responsible for detecting mentions of a particu- lar type. Outputs of one model can also serve as features to the next model. However, such an ap- proach cannot model overlapping mentions of the same type, which frequently appear in practice. <ref type="bibr" target="#b8">Finkel and Manning (2009)</ref> approached this task from a parsing perspective by constructing a constituency tree, mapping each mention to a node in the tree. This approach assumes one mention is contained by the other when they overlap. While such an assumption largely holds in practice, it comes with a cost -the chart-based parser suf- fers from its cubic time complexity, making it not scalable to large datasets involving long sentences. Based on the same idea, <ref type="bibr" target="#b42">Wang et al. (2018)</ref> pro- posed a scalable transition-based approach to con- struct a constituency forest (a collection of con- stituency trees).</p><p>Instead of relying on structured models, <ref type="bibr" target="#b43">Xu et al. (2017)</ref> proposed a local classifier for each possible span. However, this local approach is unable to capture the interactions between spans. Similar to <ref type="bibr" target="#b1">(Alex et al., 2007)</ref>, <ref type="bibr" target="#b15">Ju et al. (2018)</ref> dynamically stacked multiple flat layers which recognize mentions sequentially from innermost mentions to outermost mentions.</p><p>Our work is inspired by the model of <ref type="bibr" target="#b25">Lu and Roth (2015)</ref>, who introduced a mention hyper- graph representation for capturing overlapping mentions. Their model was shown fast and ef- fective, and was improved by the mention sepa- rator model <ref type="bibr" target="#b31">(Muis and Lu, 2017)</ref>. However, we note that (as also highlighted in their papers) both models suffer from the structural ambiguity issue during inference, which we will discuss later. Our new representation does not have this limitation. <ref type="bibr">2</ref> Recently, <ref type="bibr" target="#b16">Katiyar and Cardie (2018)</ref> also proposed a hypergraph-based representation based on the BILOU tagging scheme. Their model is trained greedily using neural networks by viewing the hy- pergraph construction procedure as a multi-label assignment process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neural Models for Mention Recognition</head><p>Recently, neural network based approaches to en- tity or mention recognition have received signifi-</p><formula xml:id="formula_0">Ai Ai+1 Ai+2 Ai+3 Ei Ei+1 Ei+2 Ei+3 T 1 i T k i T m i X X X X X I k i,i I k i,i+1 I k i,i+2 I k i,i+3 i i + 1 i + 2 i + 3</formula><p>. . .</p><p>. . .</p><p>. . . . . . . . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ai+4</head><p>Figure </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Segmental Hypergraph</head><p>A segmental hypergraph is a representation that aims at representing all possible combinations of (potentially overlapping) mentions in a given sen- tence. It belongs to a class of directed hypergraphs ( <ref type="bibr" target="#b10">Gallo et al., 1993)</ref>, where each hyperedge e con- sists of a single designated parent node (head of e) and an ordered list of child nodes (tail of e). Specifically, our segmental hypergraph consists of the following 5 types of nodes:</p><p>• A i encodes all such mentions that start with the i-th or a later word • E i encodes all mentions that start exactly with the i-th word • T k i represents all mentions of type k starting with the i-th word • I k i,j represents all mentions of type k that con- tain the j-th word and start with the i-th word • X marks the end of a mention. Hyperedges connecting these nodes are de- signed to indicate how the semantics of a par- ent node can be re-expressed in terms of its child nodes. <ref type="figure" target="#fig_1">Figure 2</ref> gives a partial segmental hyper- graph representing all combinations of mentions within the span [i, i + 3] consisting of 4 words. There are 4 types of hyperedges:</p><p>1. A hyperedge {A i → (A i+1 , E i )} from A i to its children implies the fact that A i consists of those mentions that either "start exactly with the i-th word" (E i ), or "start with a word that appears strictly after the i-th word" (A i+1 ).</p><formula xml:id="formula_1">2. A hyperedge {E i → (T 1 i , . . . , T m i )</formula><p>} from E i to its children implies that we should consider all possible types for the mentions (possibly of length 0) that start with the i-th word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Two hyperedges {T</head><formula xml:id="formula_2">k i → I k i,i } and {T k i → X} from T k i</formula><p>indicate that either there exists at least one mention starting with the i-th word (the former hyperedge), or there does not ex- ist any such mention (the latter hyperedge).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Three hyperedges {I</head><formula xml:id="formula_3">k i,j → I k i,j+1 }, {I k i,j → X}, and {I k i,j → (I k i,j+1</formula><p>, X)} from I k i,j indi- cate the following three cases respectively: 1) both the j-th and (j + 1)-th words belong to at least one mention that starts with the i-th word, 2) there exists one mention that starts with the i-th word and ends with the j-th word, and 3) both cases are valid. Essentially, the complete hypergraph compactly encodes the whole search space of all possible mentions that can ever appear within a sentence, where such mentions may or may not overlap with one another. When we traverse the complete seg- mental hypergraph by following the directions as specified by the hyperedges, selecting only one outgoing hyperedge at a time at each node, we arrive at a hyperpath 3 -a rooted, directed sub- structure contained by the original hypergraph. <ref type="figure">Figure 3</ref> shows an example. Here, "Israeli UN Ambassador" of type PERSON is captured by the following sequence of nodes (along a hyperpath):</p><formula xml:id="formula_4">"A 1 , E 1 , T 2 1 , I 2 1,1 , I 2 1,2 , I 2 1,3 , X"</formula><p>, while "Israeli UN Ambassador Danny" of type PERSON corre- sponds to the following node sequence: "A 1 , E 1 , T 2 1 , I 2 1,1 , I 2 1,2 , I 2 1,3 , I 2 1,4 , X". Similarly, the follow- ing sequence "A 1 , A 2 , E 2 , T 1 2 , I 1 2,2 , X" represents the mention "UN" of type ORGANIZATION. As we can see, such node sequences together form a single hyperpath that encodes this specific combi- nation of mentions that overlap with one another.</p><formula xml:id="formula_5">A1 A2 A3 A4 E1 E2 E3 E4 T 1 1 T 2 1 T 1 2 T 2 2 T 1 3 T 2 3 T 1 4 T 2 4 X X X X X X X X X I 2 1,1 I 2 1,2 I 2 1,3 I 2 1,4 I 1 2,2 Israeli UN Ambassador Danny [ ] PERSON [ ] PERSON [ ] ORGANIZATION</formula><p>Figure 3: A specific hyperpath for encoding three mentions. For brevity, we only show two types.</p><p>More details on segmental hypergraph and hyper- paths are in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theoretical Analysis</head><p>Our proposed segmental hypergraph representa- tion has the following theoretical property:</p><p>Theorem 3.1. (Structural Ambiguity Free) For any sentence and its segmental hypergraph G = (V, E), let S be the set of all possible mention com- binations for the given sentence, and P be the set of all hyperpaths contained by G, there is a one-to- one correspondence between elements in P and S.</p><p>Due to space, we provide a proof sketch and in- clude more details in the supplementary material. Proof Sketch We note that each hyperpath is uniquely characterized by its collection of hy- peredges that involve X nodes. These hyper- edges uniquely determine the collection of men- tions. Conversely, a collection of mentions can be uniquely characterized by a collection of such hy- peredges, which yields a unique hyperpath.</p><p>Note that such a theorem states that our novel representation has no structural ambiguity, a nice property that both mention hypergraph model of ( <ref type="bibr" target="#b25">Lu and Roth, 2015</ref>) and mention separator model of (Muis and Lu, 2017) do not hold. As the au- thors have mentioned in their papers, for a given sub-structure in their model, there exist multiple ways of interpreting the combination of mentions. Specifically, in both representations, the decisions on where the beginning and the end of a men- tion are made locally. Such a design will lead to the structural ambiguity as there will be multiple interpretations to the mentions given a particular collection of positions marked as beginning and end of mentions. To illustrate, consider a phrase with 4 words "A B C D" where there are only two overlapping mentions "B C" and "A B C D". In both of the previous approaches, their models would make local predictions and assign both "A" and "B" as left boundaries, and both "C" and "D" as right boundaries. However, based on such lo- cal predictions one could also interpret "A B C" as a mention -this is where the ambiguity arises. In contrast, our model enjoys the structural ambi- guity free property as it uses our newly defined I nodes (together with X nodes) to jointly capture the complete boundary information of mentions. <ref type="table" target="#tab_1">Table 1</ref> shows a full comparison. <ref type="bibr">4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Learning</head><p>We adopt a log-linear approach to model the con- ditional probability of each hyperpath as follows:</p><formula xml:id="formula_6">p(y|x) = exp f (x, y) y exp f (x, y )<label>(1)</label></formula><p>where f (x, y) is the score function for any pair of input sentence x and output mention combina- tion y, which corresponds to a unique hyperpath G y . Our objective is to minimize the negative log- likelihood of all instances in the training set D:</p><formula xml:id="formula_7">− (x,y * )∈D log p(y * |x)<label>(2)</label></formula><p>We define features over each hyperedge within the hyperpath G y . The score function can be de- composed into the following form:</p><formula xml:id="formula_8">f (x, y) = e∈Gy ψ(e, x)<label>(3)</label></formula><p>where e ∈ G y denotes a hyperedge that appears within the hyperpath G y , and ψ(e, x) is a score defined over e when the input sentence is x. Apart from word-level features, the segmental hypergraph also allows span-level features to be defined. The node I k i,j corresponds to a particu- lar span [i, j] over which we can extract our local features. The hyperedge between I nodes can cap- ture the interactions between partial mentions and hyperedge between I k i,j and X precisely represents the mention <ref type="bibr">[i, j]</ref> with type k. We note that such features and interactions cannot be captured by the models of ( <ref type="bibr" target="#b25">Lu and Roth, 2015)</ref> and <ref type="bibr" target="#b31">(Muis and Lu, 2017)</ref>. Such a unique property makes our segmen- tal hypergraph model more expressive than theirs.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Softmax-Margin Training</head><p>Inspired by <ref type="figure" target="#fig_0">(Mohit et al., 2012)</ref>, we consider the softmax-margin ( <ref type="bibr" target="#b11">Gimpel and Smith, 2010</ref>) in our model. The function ψ(e, x) is defined as follows:</p><formula xml:id="formula_9">ψ(e, x) = φ(e, x) + ∆(e, G y * )<label>(4)</label></formula><p>where φ(e, x) is a feature function, and ∆(e, G y * ) is the cost function that defines the margin:</p><formula xml:id="formula_10">∆(e, G y * ) = β TX[e] ∧ e / ∈ G y * 1 TI[e] ∧ e / ∈ G y * 0 otherwise<label>(5)</label></formula><p>Here, y * is the gold mention combination, and TX[e] and TI[e] are indicator functions that re- turn true if e is between T and X and between T and I respectively, and false otherwise. We set β ≥ 1 such that the cost function will assign more penalty to false negatives than to false positives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Feature Representation</head><p>We use two bidirectional LSTMs to learn word- level and span-level feature representations that can be used in our approach, resulting in our neu- ral segmental hypergraph model. We first map the i-th word in a sentence to its pre-trained word em- bedding e i , and its POS tag to its embedding p i if it exists. The final representation for i-th word is the concatenation of them:</p><formula xml:id="formula_11">v i = [e i , p i ].</formula><p>Next, we use the a bidirectional LSTM to capture context- specific information for each word, resulting in the word-level features:</p><formula xml:id="formula_12">h w i = [biLSTM1(v0, ..., vn)]i<label>(6)</label></formula><p>Such representations are then used as inputs to a second LSTM to generate span-level features: In- spired by <ref type="bibr" target="#b19">(Kong et al., 2016)</ref>, we compute all pos- sible span embeddings efficiently with time com- plexity O(cn) using dynamic programming, with n being the number of words in the input x and c being the maximal length of a mention.</p><formula xml:id="formula_13">h s i:j = biLSTM2(h w i , ..., h w j )<label>(7)</label></formula><p>Recall that there are 4 types of hyperedges in our hypergraph, over which we can define the score functions. Since every valid mention hyper- path contains the first and second kind of hyper- edges, defining scores over such hyperedges are unnecessary as their scores would serve as a con- stant factor that can be eliminated in the overall loss function of the log-linear model. Thus we only need to define the score functions on the lat- ter two types of hyperedges. For hyperedges that only involve two nodes, we use a linear layer to compute their scores:</p><formula xml:id="formula_14">φ({T k i → X}, x) = W (k) TX · h w i<label>(8)</label></formula><formula xml:id="formula_15">φ({T k i → I k i,j }, x) = W (k) TI · h w i (9) φ({I k i,j → I k i,j+1 }, x) = W (k) II ·[h s i:j , h s i:j+1 ]<label>(10)</label></formula><formula xml:id="formula_16">φ({I k i,j → X}, x) = W (k) IX · h s i:j<label>(11)</label></formula><p>where matrices W TX , W TI ∈ R d 1 ×m , W II ∈ R 2d 2 ×m , W IX ∈ R d 2 ×m , with superscript (k) re- ferring to the k-th column of the matrix, d 1 is the dimension of h w , d 2 is the dimension of h s , and m is the number of mention types. For the hyperedges that involve more than two nodes, the score is computed as follows:</p><formula xml:id="formula_17">φ({I k i,j → (X, I k i,j+1 )}, x) = W (k) II · [h s i:j , h s i:j+1 ] + W (k) IX · h s i:j<label>(12)</label></formula><p>where</p><formula xml:id="formula_18">W II ∈ R 2d 2 ×m , W IX ∈ R d 2 ×m .</formula><p>Note that in this work, we set W II = W II and W IX = W IX to reduce the number of free parameters.</p><p>Learning uses stochastic gradient descent with the update rule of Adam ( <ref type="bibr" target="#b18">Kingma and Ba, 2014</ref>) and a gradient clipping of 3.0. Dropout ( <ref type="bibr" target="#b38">Srivastava et al., 2014</ref>) for input vectors v and 2 regulariza- tion are used to reduce overfitting; both are tuned during the development process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Character-level Representation</head><p>To make fair comparisons with recent models ( <ref type="bibr" target="#b15">Ju et al., 2018;</ref><ref type="bibr" target="#b42">Wang et al., 2018</ref>) that additionally incorporate character-level components in captur- ing orthographic and morphological features of words, we follow <ref type="bibr" target="#b22">Lample et al. (2016)</ref> to use a bidirectional LSTM that takes the character em- beddings as input. Specifically, the character-level representation ch i for each word is obtained by concatenating the last hidden vectors of the for- ward and backward LSTMs. When this compo- nent is activated, the representation of each word is changed to:</p><formula xml:id="formula_19">v i = [e i , p i , ch i ].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Inference</head><p>Inference can be done efficiently using a gener- alized inside-outside style message-passing algo- rithm <ref type="bibr" target="#b2">(Baker, 1979)</ref>. The partition function of <ref type="formula" target="#formula_6">(1)</ref> can be computed using the inside algorithm ap- plied to the complete hypergraph G, where we tra- verse from leaf nodes X to the root node A 1 , pass- ing messages to a parent node p from its child nodes:</p><formula xml:id="formula_20">µ[p]← log e:h(e)≡p exp ψ(e, x) + c∈T (e) µ[c]<label>(13)</label></formula><p>where h(e) is the head of the hyperedge e, and T (e) is the collection of nodes that form the tail of e -they are the child nodes of h(e) given e. The message passing step for the outside algorithm can be defined analogously. It can be verified that such a message passing algorithm, that is analo- gous to the sum-product belief propagation algo- rithm ( <ref type="bibr" target="#b20">Kschischang et al., 2001</ref>) used in standard graphical models, will converge after one forward and one backward pass. For decoding, we perform the standard MAP in- ference on top of the complete hypergraph to find the most probable hyperpath. The resulting proce- dure is similar to the max-product message pass- ing algorithm, where we consider only the feature function φ for constructing the messages:</p><formula xml:id="formula_21">µ[p] ← max e:h(e)≡p φ(e, x) + c∈T (e) µ[c]<label>(14)</label></formula><p>During inference, each node corresponds to a sum/max computation. Since one node is incident to 3 hyperedges maximally, the time complexity of inference algorithm can be implied by the number of nodes in the graph, which is O(cmn), where c is the maximal length for any mention. This com- plexity is the same as that of a zero-th order semi- Markov CRF model <ref type="bibr" target="#b36">(Sarawagi and Cohen, 2005)</ref>. Please refer to the supplementary material for a detailed explanation of the inference algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACE-2004 GENIA Train (%) Test (%) Train (%) Test (%) # sentences</head><p>6,799 (00) 879(00) 14,836 (00) 1,855 (00) with o.l.</p><p>2,683 <ref type="formula" target="#formula_8">(39)</ref> 272 <ref type="formula" target="#formula_7">(42)</ref> 3,199 <ref type="formula" target="#formula_7">(22)</ref> 448 (24) # mentions 22,207 (00) 3,031 <ref type="formula" target="#formula_8">(00) 46,473 (00) 5,600 (00)</ref> o.l. 10,170 <ref type="formula" target="#formula_9">(46)</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Datasets</head><p>We mainly evaluate our models on the standard <ref type="bibr">ACE-2004</ref><ref type="bibr">, ACE-2005</ref><ref type="bibr" target="#b7">(Doddington et al., 2004</ref>), and GENIA ( ) datasets with the same splits used by previous works ( <ref type="bibr" target="#b25">Lu and Roth, 2015;</ref><ref type="bibr" target="#b31">Muis and Lu, 2017)</ref>. Sample data statistics of these datasets are listed in <ref type="table" target="#tab_3">Table 2</ref>. <ref type="bibr">5</ref> We can see that overlapping mentions frequently appear in such datasets. For ACE2004, over 46% of the mentions overlap with one another. GENIA fo- cuses on biomedical entity recognition 6 and over- lapping mentions are also common in it. Most mentions (over 93%) are not longer than 6 tokens which we select as maximal length (c) for the re- stricted models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Baseline Approaches</head><p>We consider the following baseline models:</p><p>• CRF (LINEAR): a linear-chain CRF model. Since the linear-chain CRF cannot handle overlapping structures, we only use the outer- most mentions for learning. Specifically, ev- ery outer-most mention is labeled based on the BILOU tagging scheme, which was em- pirically shown to be better than the BIO scheme <ref type="bibr" target="#b34">(Ratinov and Roth, 2009</ref>).</p><p>• CRF (CASCADED): the cascaded CRF based approach following <ref type="bibr" target="#b1">(Alex et al., 2007)</ref>. Note that this approach cannot model the overlap- ping mentions of the same type.</p><p>• Semi-CRF: the semi-Markov CRF model <ref type="bibr" target="#b36">(Sarawagi and Cohen, 2005</ref>). The semi-CRF model is also only trained on the outer-most mentions. It can also capture span-level fea-</p><formula xml:id="formula_22">ACE-2004 ACE-2005 GENIA P R F 1 P R F 1 P R F 1</formula><p>Non-Neural CRF (LINEAR) 71.8 40.8 52.1 69.5 44.5 54.2 77.1 63.3 69.5 CRF (CASCADED) 78.4 46.4 58.3 74.8 49.1 59.3 75.9 66.1 70.6 Semi-CRF (c=6) 76.1 41.4 53.6 72.8 45.0 55.6 74.5 66.0 70.0 Semi-CRF (c=n) 66.7 42.0 51.5 67.5 46.1 54.8 74.2 65.8 69.7 <ref type="bibr" target="#b8">Finkel and Manning (2009)</ref> - - - - - - 75.4 65.9 70.3 <ref type="bibr" target="#b25">Lu and Roth (2015)</ref> 70.0 56.9 62.8 66.3 59.2 62.5 74.2 66.7 70.3 Muis and <ref type="bibr" target="#b31">Lu (2017)</ref> 72.7 58.0 64.5 69.1 58.1 63.1 75.4 66.8 70.8 SH <ref type="figure">(-NN, c=6)</ref> 69.4 57.0 62.0 70.3 55.8 62.2 77.0 66.1 71.1 SH <ref type="figure">(-NN, c=n)</ref> 71.1 60.6 65.4 69.5 60.7 64.8 76.2 67.5 71.  tures defined over a complete segment. Sim- ilar to our model, semi-CRF typically comes with a length restriction (c) which indicates the maximal length of a mention.</p><p>• Finkel and Manning <ref type="formula" target="#formula_7">(2009)</ref>: a parsing-based approach for recognizing nested mentions that reported results on the GENIA dataset.</p><p>• <ref type="bibr" target="#b25">Lu and Roth (2015)</ref>: the model that makes use of mention hypergraphs for recognizing overlapping mentions.</p><p>• Muis and <ref type="bibr" target="#b31">Lu (2017)</ref>: the model that makes use of mention separators to tag gaps between words for recognizing overlapping mentions.</p><p>• FOFE ( <ref type="bibr" target="#b43">Xu et al., 2017)</ref>: a local classifier based on neural networks that runs on every possible span to detect mentions. The maxi- mal mention length (c) can also be used here. • SH (-NN): a non-neural version of our seg- mental hypergraph model that excludes the LSTMs but employs handcrafted features. 8 As discussed earlier, we also evaluate the vari- <ref type="bibr">7</ref> Note that in ACE2005, <ref type="bibr" target="#b15">Ju et al. (2018)</ref> did their exper- iments with a different split than <ref type="bibr" target="#b25">Lu and Roth (2015)</ref> which we follow as our split.</p><p>8 To make a proper comparison, we use the same hand- crafted features used by ( <ref type="bibr" target="#b25">Lu and Roth, 2015)</ref>, which were proven effective in previous approaches.  ants of our model that takes character-level repre- sentations (+char).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Training</head><p>Pre-trained embeddings GloVe ( <ref type="bibr" target="#b33">Pennington et al., 2014</ref>) of dimension 100 are used to initialize the trainable word vectors for experiments in ACE and GENIA datasets. <ref type="bibr">9</ref> The embeddings for POS tags are initialized randomly with dimension 32. Early stopping is used based on the performance of development set. The value β used in softmax- margin is chosen from <ref type="bibr">[1,</ref><ref type="bibr">3]</ref> with step size 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Experimental Results</head><p>Main results can be found in <ref type="table" target="#tab_5">Table 3</ref>. Using the same set of handcrafted features, our unre- stricted non-neural model SH (-NN, c=n) achieves the best performance compared with other non- neural models, revealing the effectiveness of our newly proposed segmental hypergraph represen- tation. It achieves around 1-2% gain in terms of F 1 compared with mention hypergraph of <ref type="bibr" target="#b25">Lu and Roth (2015)</ref> and mention separator of <ref type="bibr" target="#b31">Muis and Lu (2017)</ref>, showing the necessity of eliminating struc- tural ambiguity. CRF (LINEAR) and Semi-CRF do not perform well due to incapability of handling overlapping mentions. In contrast, the pipeline ap- proach CRF (CASCADED) performs better. Our unrestricted neural segmental hypergraph model SH (c=n) already achieves the best results among all previous models in ACE datasets, show- ing the effectiveness of our neural segmental hy- pergraph. The improvement mainly comes from its ability to recall more mentions. In GENIA, even without using external features like Brown clustering features as all non-neural models do, our neural models still get significant improve- ments. Compared with the non-neural SH (-NN) which has around 4.2M parameters, our neural model SH only has 1.9M parameters yet it still per- forms better. We empirically see that the represen- tations learned by LSTM can better capture com- plex contextual dependencies in sentences. The character-level representations (+ char) make both restricted and unrestricted SH perform even bet- ter. Particularly, SH (c=n) + char achieves the best results in all datasets compared with other recent neural models <ref type="bibr" target="#b16">(Katiyar and Cardie, 2018;</ref><ref type="bibr" target="#b15">Ju et al., 2018;</ref><ref type="bibr" target="#b42">Wang et al., 2018)</ref>.</p><p>One hypothesis we may have is that, without length restriction, a model will enjoy the benefit of recalling more long mentions, but also will be exposed to more false positives. This poses a chal- lenge for a model -whether it is capable of balanc- ing these two factors. Empirically, we find that the length restriction (c=6) improves the precision of semi-CRF and SH at the expense of the recall, pro- viding some evidence to support the hypothesis. However, in terms of F 1 , the unrestricted semi- CRF performs worse while unrestricted SH per- forms better compared to their restricted counter- parts. The reason is that the span-level handcrafted features that the semi-CRF relies on can be very sparse when mentions are overly long. We empir- ically found this issue is alleviated in the model SH (-NN), possibly due to its ability in captur- ing interactions between neighboring spans. Even with length restriction, SH still yields competitive results, making it attractive in processing large- scale datasets considering its linear time complex- ity. Furthermore, we find that as c increases, SH performs better consistently in terms of F 1 . The choice of c then becomes a tradeoff between time complexity and performance. Please refer to the supplementary material for details.</p><p>Compared with the local approach FOFE, our global approach gives a much better performance, showing its effectiveness in capturing interactions <ref type="bibr" target="#b25">and Roth (2015)</ref> 68.1 52.6 59.4 64.1 65.1 64.6 503 Muis and Lu <ref type="formula" target="#formula_6">(2017)</ref>   between spans. Moreover, FOFE's performance suffers significantly in the absence of the length restriction. The reason is that it will generate much more negative training instances under this setting, which makes its learning more challenging.</p><formula xml:id="formula_23">Overlapping Non-Overlapping w/s P R F 1 P R F 1 Lu</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Additional Analyses</head><p>To understand our model better, we conduct some further experiments in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation study</head><p>We first conduct an ablation study by removing dropout, softmax-margin and pre-trained embed- dings from our model respectively. The results are shown in <ref type="table" target="#tab_7">Table 4</ref>. The dropout and pre-trained embeddings can improve the performance of our model significantly and this behavior is consistent with previous neural models for NER ( <ref type="bibr" target="#b5">Chiu and Nichols, 2016;</ref><ref type="bibr" target="#b22">Lample et al., 2016)</ref>. Meanwhile, our new cost function based on softmax margin training also contributes significantly to the good performance of our model across these datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>How well does it handle overlapping mentions?</head><p>To further understand how well our model can handle overlapping mentions, we split the test data into two portions: sentences with and without overlapping mentions. We compare our model with the two state-of-the-art models and report re- sults on ACE-05 in <ref type="table" target="#tab_9">Table 5</ref>. <ref type="bibr">10</ref> In both portions, SH achieves significant improvements, especially in the portion with overlapping mentions. This ob- servation indicates that our model can better cap- ture the structure of overlapping mentions than these two previous models. It also helps explain why the margin of improvement is larger in ACE than in GENIA since the former has more overlap- ping mentions than the latter, as shown in <ref type="table" target="#tab_3">Table 2</ref>. Compared with the model with length restriction c, the unrestricted model mainly benefits from its ability to recall more overlapping mentions.</p><formula xml:id="formula_24">Model F 1 SH (c=6)</formula><p>89.6 SH (c=6) + char 90.5 SH (c=n) 89.2 SH (c=n) + char 90.2 Collobert et al. <ref type="formula" target="#formula_6">(2011)</ref> 88.7 Chiu and Nichols (2016) 90.9 <ref type="bibr" target="#b22">Lample et al. (2016)</ref> 90.9 <ref type="bibr" target="#b26">Ma and Hovy (2016)</ref> 91.2 <ref type="bibr" target="#b43">Xu et al. (2017)</ref> 90.7 <ref type="bibr" target="#b39">Strubell et al. (2017)</ref> 90.5 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Running time</head><p>Since other compared models also feature linear time complexity (see <ref type="table" target="#tab_1">Table 1</ref>), we examine the de- coding speed in terms of the number of words pro- cessed per second. We re-implement the models of <ref type="bibr" target="#b25">Lu and Roth (2015)</ref> and Muis and Lu (2017) using the same platform as ours (PyTorch) and run them on the same machine (CPU: Intel i5 2.7 GHz). The model of ( <ref type="bibr" target="#b42">Wang et al., 2018</ref>) is also tested with the same environment. Results on ACE-05 are listed in <ref type="table" target="#tab_9">Table 5</ref>. The length bound (c=6) makes our model much faster, resulting in a speed compa- rable to the model of <ref type="bibr" target="#b31">Muis and Lu (2017)</ref>. The transition-based model by ( <ref type="bibr" target="#b42">Wang et al., 2018</ref>) has the best scalability partially because of its greedy strategy for decoding.</p><p>What if the data has no overlapping mentions?</p><p>To assess the robustness of our model and under- stand whether it could serve as a general men- tion extraction model, we additionally evaluate our model on CoNLL 2003 dataset which is annotated with non-overlapping mentions only. We com- pared our model with recent state-of-the-art neu- ral network based models. For a fair comparison, we used the Collobert et al. (2011) embeddings widely used by previous models, and ignored POS tag features even though they are available. Re- sults are in <ref type="table" target="#tab_4">Table 6</ref>. Only neural models without using external features are included. 11 By only relying on word (and character) embeddings, our model achieves competitive results compared with other state-of-the-art neural models that also do not exploit external features, yet these models are mostly designed to handle only non-overlapping mentions. The only exception is the FOFE ap- proach by ( <ref type="bibr" target="#b43">Xu et al., 2017</ref>) as we discussed earlier. <ref type="bibr">11</ref> See the supplementary material for complete results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notes on mention interactions</head><p>The dependencies between overlapping mentions can be very beneficial. SH can capture a specific kind of interaction between neighboring spans. Such interactions happen between mentions that share the same type and the same left boundary. As we can see from the sentence in <ref type="figure">Figure 3</ref>, one mention could also serve as a pre-modifier for an- other mention and both could share the same type. As shown in <ref type="table" target="#tab_3">Table 2</ref>, there are over 8% such men- tions in ACE and over 4% in GENIA. Specifi- cally, SH relies on the hyperedges between I nodes to capture such interactions explicitly. To verify the effectiveness of this connection, we zero the weights between I nodes. The ablated model only achieves around 70.0% in ACEs and 71.4% in GE- NIA, implying the impact of this dependency con- nection. On the other hand, it also reveals the potential direction of improving SH by explicitly modeling more dependencies between mentions, such as the dependencies between mentions with different types. LSTM that serves as feature rep- resentation may capture such interactions implic- itly, but building the connections could still be an important aspect for improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>In this work, we propose a novel neural segmental hypergraph model that is able to capture overlap- ping mentions. We show that our model has some theoretical advantages over previous state-of-the- art approaches for recognizing overlapping men- tions. Through extensive experiments, we show that our model is general and robust in handling both overlapping and non-overlapping mentions. The model achieves the state-of-the-art results in three standard datasets for recognizing overlap- ping mentions. We anticipate this model could be leveraged in other similar sequence modeling tasks that involve predicting overlapping struc- tures such as recognizing overlapping and discon- tinuous entities (Muis and Lu, 2016) which fre- quently exist in the biomedical domain.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Examples of overlapping mentions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>2 :</head><label>2</label><figDesc>Figure 2: An example of partial segmental hypergraph (hyperedges of different types in different colors).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Spurious</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>•</head><label></label><figDesc>Katiyar and Cardie (2018): a hypergraph- based model that uses LSTM for learning fea- ture representations. • Ju et al. (2018): a cascaded model that makes use of multiple LSTM-CRF layers to recog- nize mentions in an inside-out manner. • Wang et al. (2018): a neural transition-based model that construct nested mentions through a sequence of actions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Model comparison. |G| is the number of rules in grammar G. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Statistics (ACE04, GENIA). o.l.: overlapping 
mentions, st/slb: same type/left boundary. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>6</head><label>6</label><figDesc></figDesc><table>Neural 

FOFE (Xu et al., 2017) (c=6) 68.2 54.3 60.5 67.4 55.1 60.6 71.2 64.3 67.6 
FOFE (Xu et al., 2017) (c=n) 57.3 46.8 51.5 56.3 44.6 49.8 63.2 59.3 61.2 
Katiyar and Cardie (2018) 
73.6 71.8 72.7 70.6 70.4 70.5 79.8 68.2 73.6 
Ju et al. (2018) 7 
-
-
-
74.2 70.3 72.2 78.5 71.3 74.7 
Wang et al. (2018) 
74.9 71.8 73.3 74.5 71.5 73.0 78.0 70.2 73.9 
SH (c=6) 
79.1 67.3 72.7 75.7 69.6 72.5 76.6 71.0 73.7 
SH (c=6) + char 
80.1 67.5 73.3 75.9 70.0 72.8 76.8 71.8 74.2 
SH (c=n) 
77.7 72.1 74.5 76.6 71.9 74.2 76.1 72.9 74.5 
SH (c=n) + char 
78.0 72.4 75.1 76.8 72.3 74.5 77.0 73.3 75.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Main results. SH: segmental hypergraphs (our approach). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Results of various ablations. D: dropout, SM: 
softmax-margin, P: pre-trained embeddings. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Results on different types of sentences 
(ACE05), w/s: # of words decoded per second. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Additional results on CoNLL-2003. 

</table></figure>

			<note place="foot" n="1"> We make our system and code available at: http:// statnlp.org/research/ie</note>

			<note place="foot" n="2"> A model comparison can be found later in Table 1.</note>

			<note place="foot" n="3"> Each hyperpath is a hypertree (Brandstädt et al., 1998).</note>

			<note place="foot" n="4"> The mention hypergraph (Lu and Roth, 2015) also suffers from the spurious structures issue, while we do not. We refer the readers to (Muis and Lu, 2017) for details.</note>

			<note place="foot" n="5"> See supplementary material for complete data statistics. 6 Following previous works, we used version 3.02p which comes with annotated POS tags (Tateisi, 2004). Following (Finkel and Manning, 2009), we collapse DNA, RNA and protein subtypes into DNA, RNA and protein respectively, keep cell line and cell type and remove mentions of other types.</note>

			<note place="foot" n="9"> We also additionally tried using embeddings trained on PubMed for GENIA but the performance was comparable.</note>

			<note place="foot" n="10"> Full results are listed in the supplementary material.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank the anonymous reviewers for their valu-able comments. This work was done after the first author visited Singapore University of Technology and Design. This work is supported by Singapore Ministry of Education Academic Research Fund (AcRF) Tier 2 Project MOE2017-T2-1-156.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Answer extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Abney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Singhal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the sixth conference on applied natural language processing</title>
		<meeting>of the sixth conference on applied natural language processing</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Recognising nested named entities in biomedical text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Alex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Grover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of BioNLP</title>
		<meeting>of BioNLP</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Trainable grammars for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">S1</biblScope>
			<biblScope unit="page" from="132" to="132" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Dually chordal graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Brandstädt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feodor</forename><surname>Dragan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Chepoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaly</forename><surname>Voloshin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Discrete Mathematics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="437" to="455" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A constrained latent variable model for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajhans</forename><surname>Samdani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Named entity recognition with bidirectional lstm-cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Jason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nichols</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="357" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The automatic content extraction (ace) program-tasks, data, and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>George R Doddington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Przybocki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Lance A Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph M</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of LREC</title>
		<meeting>of LREC</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A statistical model for multilingual entity detection and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Florian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ittycheriah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kambhatla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nicolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roukos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of HLT-NAACL</title>
		<meeting>of HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Directed hypergraphs and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Gallo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giustino</forename><surname>Longo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Pallottino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sang</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete applied mathematics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="177" to="201" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Softmaxmargin crfs: Training log-linear models with cost functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of HLT-NAACL</title>
		<meeting>of HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Information extraction: Techniques and challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Summer School on Information Extraction</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="10" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Bidirectional lstm-crf models for sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.01991</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A neural layered model for nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meizhi</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL-HLT</title>
		<meeting>of NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Nested named entity recognition revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arzoo</forename><surname>Katiyar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACLHLT</title>
		<meeting>of NAACLHLT</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Genia corpus-a semantically annotated corpus for bio-textmining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J-D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuka</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="180" to="182" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>suppl</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
		<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Segmental recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
		<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Factor graphs and the sum-product algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><forename type="middle">J</forename><surname>Frank R Kschischang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H-A</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Loeliger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on information theory</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="498" to="519" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando Cn</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML</title>
		<meeting>of ICML</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL-HLT</title>
		<meeting>of NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Joint event extraction via structured prediction with global features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Heterogeneous supervision for relation extraction: A representation learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi</forename><surname>Zhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Joint mention extraction and classification with mention hypergraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">End-to-end sequence labeling via bi-directional lstm-cnns-crf</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Flexible text segmentation with structured multilabel classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of HLTEMNLP</title>
		<meeting>of HLTEMNLP</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL-IJCNLP</title>
		<meeting>of ACL-IJCNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>Rion Snow, and Dan Jurafsky</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Recalloriented learning of named entities in arabic wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behrang</forename><surname>Mohit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishav</forename><surname>Bhowmick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kemal</forename><surname>Oflazer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EACL</title>
		<meeting>of EACL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning to recognize discontiguous entities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aldrian</forename><surname>Obaja Muis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Labeling gaps between words: Recognizing overlapping mentions with mention separators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aldrian</forename><surname>Obaja Muis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Improving machine learning approaches to coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Design challenges and misconceptions in named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CoNLL</title>
		<meeting>of CoNLL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Fast and robust joint models for biomedical event extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Semimarkov conditional random fields for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>William W Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NIPS</title>
		<meeting>of NIPS</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A machine learning approach to coreference resolution of noun phrases</title>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<editor>Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong Lim</editor>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="521" to="544" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Fast and accurate entity recognition with iterated dilated convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emma</forename><surname>Strubell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Verga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Part-of-speech annotation of biology research abstracts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuka</forename><surname>Tateisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of LREC</title>
		<meeting>of LREC</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Introduction to the conll-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik F Tjong Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fien De</forename><surname>Meulder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CoNLL</title>
		<meeting>of CoNLL</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A neural transition-based model for nested mention recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bailin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxia</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A local detection approach for named entity recognition and mention detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingbin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sedtawut</forename><surname>Watcharawittayakul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Enhancing hmm-based biomedical named entity recognition by studying special phenomena</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chew-Lim</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="411" to="422" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Recognizing names in biomedical texts using mutual information independence model and svm plus sigmoid</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Medical Informatics</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="456" to="467" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Recognizing names in biomedical texts: a machine learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chewlim</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1178" to="1190" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
